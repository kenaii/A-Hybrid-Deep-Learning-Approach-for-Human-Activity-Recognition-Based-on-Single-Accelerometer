{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "sns.set(style='ticks', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_CLASSES = [('downstairs', 'upstairs'), ('downstairs', 'walking'), ('jogging', 'upstairs'), ('upstairs', 'walking')]\n",
    "N_CLASSES = 7\n",
    "N_TIME_STEPS = 200\n",
    "N_FEATURES = 3\n",
    "\n",
    "N_EPOCHS = 170\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_swish(x):\n",
    "    return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def ks_swish(x):\n",
    "    return x * K.sigmoid(x)\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, (2, 2), input_shape=(N_TIME_STEPS, N_FEATURES, 1)))\n",
    "    model.add(Activation(ks_swish))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(ks_swish))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(ks_swish))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    adam = optimizers.Adam(lr = LEARNING_RATE, decay=1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma\n",
    "\n",
    "def segment_signal(data, N_TIME_STEPS = 200, step = 20):\n",
    "    segments = [] \n",
    "    labels = []\n",
    "    for i in range(0, len(data) - N_TIME_STEPS, step):\n",
    "        xs = data['x-axis'].values[i: i + N_TIME_STEPS]\n",
    "        ys = data['y-axis'].values[i: i + N_TIME_STEPS]\n",
    "        zs = data['z-axis'].values[i: i + N_TIME_STEPS]\n",
    "        label = stats.mode(data['activity'][i: i + N_TIME_STEPS])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    return segments, labels\n",
    "\n",
    "def combinations(combination, features, labels):\n",
    "    combinations_x = [0] * len(combination)\n",
    "    combinations_y = [0] * len(combination)\n",
    "    for i in chosen:\n",
    "        temp_x = [] \n",
    "        temp_y = [] \n",
    "        for k in range(2):\n",
    "            for j in range(len(labels)):\n",
    "                if (combination[i][k] == labels[j]):\n",
    "                    temp_x.append(features[j])\n",
    "                    temp_y.append(labels[j])\n",
    "        combinations_x[i] = np.asarray(temp_x, dtype=np.float32).reshape(len(temp_x), N_TIME_STEPS, N_FEATURES, 1)\n",
    "        combinations_y[i] = np.asarray(pd.get_dummies(temp_y), dtype=np.float32)\n",
    "    return combinations_x, combinations_y\n",
    "\n",
    "def final_prediction(X_temp_test, predictions, threshold):\n",
    "    cnn_predictions = np.copy(predictions)\n",
    "    i = 0\n",
    "    while i < len(predictions):\n",
    "        sorted_index = np.argsort(cnn_predictions[i])[::-1]\n",
    "        test_cnn = X_temp_test[i].reshape(1, N_TIME_STEPS, N_FEATURES, 1)\n",
    "        k = 0\n",
    "        j = 1\n",
    "        while j < len(sorted_index):        \n",
    "            if sorted_index[k] > sorted_index[j]:\n",
    "                t = int(N_CLASSES * sorted_index[j] - sorted_index[j] * (sorted_index[j] + 1) / 2 + sorted_index[k] - sorted_index[j] - 1)     \n",
    "            else:\n",
    "                t = int(N_CLASSES * sorted_index[k] - sorted_index[k] * (sorted_index[k] + 1) / 2 + sorted_index[j] - sorted_index[k] - 1)\n",
    "            if cnn_models[t] != None:\n",
    "                if threshold > cnn_predictions[i][sorted_index[k]] / cnn_predictions[i][sorted_index[j]]:    \n",
    "                    p = cnn_models[t].predict(test_cnn)\n",
    "                    if np.argmax(p):\n",
    "                        if sorted_index[k] < sorted_index[j]:\n",
    "                            k = j\n",
    "                    else:\n",
    "                        if sorted_index[k] > sorted_index[j]:\n",
    "                            k = j\n",
    "                else:\n",
    "                    break;\n",
    "            j = j + 1     \n",
    "        cnn_predictions[i] = 0\n",
    "        cnn_predictions[i][sorted_index[k]] = 1\n",
    "        i = i + 1\n",
    "    return cnn_predictions\n",
    "\n",
    "def threshold_vs_accuraccy(history):\n",
    "    plt.rcdefaults()\n",
    "    plt.plot(history['threshold'], history['accuracy'], 'r-')\n",
    "    plt.plot(history['threshold'], history['f1score'], 'g-')\n",
    "    plt.show()\n",
    "    \n",
    "def confusion_report(predictions, y_test):\n",
    "    max_test = np.argmax(y_test, axis=1)\n",
    "    max_predictions = np.argmax(predictions, axis=1)\n",
    "    confusion_matrix = metrics.confusion_matrix(max_test, max_predictions)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(confusion_matrix, xticklabels=np.unique(df.activity), yticklabels=np.unique(df.activity), annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['x-axis', 'y-axis', 'z-axis','activity']\n",
    "df = pd.read_csv('data/SHOAIB_wrist.txt', header = None, names = columns)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x-axis      float64\n",
       "y-axis      float64\n",
       "z-axis      float64\n",
       "activity     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x-axis'] = feature_normalize(df['x-axis'])\n",
    "df['y-axis'] = feature_normalize(df['y-axis'])\n",
    "df['z-axis'] = feature_normalize(df['z-axis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kinai\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\stats\\stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "segments, labels = segment_signal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations:  21\n",
      "[('biking', 'downstairs'), ('biking', 'jogging'), ('biking', 'sitting'), ('biking', 'standing'), ('biking', 'upstairs'), ('biking', 'walking'), ('downstairs', 'jogging'), ('downstairs', 'sitting'), ('downstairs', 'standing'), ('downstairs', 'upstairs'), ('downstairs', 'walking'), ('jogging', 'sitting'), ('jogging', 'standing'), ('jogging', 'upstairs'), ('jogging', 'walking'), ('sitting', 'standing'), ('sitting', 'upstairs'), ('sitting', 'walking'), ('standing', 'upstairs'), ('standing', 'walking'), ('upstairs', 'walking')]\n"
     ]
    }
   ],
   "source": [
    "combination = list(itertools.combinations(np.unique(labels, axis=0), 2))\n",
    "n_combination = len(combination)\n",
    "print(\"Combinations: \", n_combination)\n",
    "print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = []\n",
    "for i in range(len(BI_CLASSES)):\n",
    "    chosen.append(combination.index(BI_CLASSES[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_segments, labels, test_size=0.3, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c_train, y_c_train = combinations(combination, X_train, y_train)\n",
    "X_c_validation, y_c_validation = combinations(combination, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(pd.get_dummies(y_train), dtype = np.float32)\n",
    "y_test = np.asarray(pd.get_dummies(y_test), dtype = np.float32)\n",
    "y_validation = np.asarray(pd.get_dummies(y_validation), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDEN_UNITS = 128\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(inputs):\n",
    "    W = {\n",
    "        'hidden': tf.Variable(tf.random_normal([N_FEATURES, N_HIDDEN_UNITS])),\n",
    "        'output': tf.Variable(tf.random_normal([N_HIDDEN_UNITS, N_CLASSES]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([N_HIDDEN_UNITS], mean=1.0)),\n",
    "        'output': tf.Variable(tf.random_normal([N_CLASSES]))\n",
    "    }\n",
    "\n",
    "    X = tf.transpose(inputs, [1, 0, 2])\n",
    "    X = tf.reshape(X, [-1, N_FEATURES])\n",
    "    hidden = tf_swish(tf.matmul(X, W['hidden']) + biases['hidden'])\n",
    "    hidden = tf.split(hidden, N_TIME_STEPS, 0)\n",
    "\n",
    "    # Stack 2 LSTM layers\n",
    "    lstm_layers = [tf.contrib.rnn.BasicLSTMCell(N_HIDDEN_UNITS, forget_bias=1.0) for _ in range(2)]\n",
    "    lstm_layers = tf.contrib.rnn.MultiRNNCell(lstm_layers)\n",
    "    outputs, _ = tf.contrib.rnn.static_rnn(lstm_layers, hidden, dtype=tf.float32)\n",
    "\n",
    "    # Get output for the last time step\n",
    "    lstm_last_output = outputs[-1]\n",
    "\n",
    "    return tf.matmul(lstm_last_output, W['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kinai\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-16-821460619a78>:14: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, N_TIME_STEPS, N_FEATURES], name=\"input\")\n",
    "Y = tf.placeholder(tf.float32, [None, N_CLASSES])\n",
    "\n",
    "pred_Y = create_LSTM_model(X)\n",
    "\n",
    "pred_softmax = tf.nn.softmax(pred_Y, name=\"y_\")\n",
    "\n",
    "L2_LOSS = 0.0015\n",
    "\n",
    "l2 = L2_LOSS * \\\n",
    "        sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred_Y, labels = Y)) + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred_softmax, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train accuracy: 0.3591217 loss train: 3.043539 test accuracy: 0.35693872 test loss: 3.0510464\n",
      "epoch: 10 train accuracy: 0.8150254 loss train: 2.1237364 test accuracy: 0.8145443 test loss: 2.1224868\n",
      "epoch: 20 train accuracy: 0.8861602 loss train: 1.9189947 test accuracy: 0.8867365 test loss: 1.9250238\n",
      "epoch: 30 train accuracy: 0.9470723 loss train: 1.7820052 test accuracy: 0.9472849 test loss: 1.7836318\n",
      "epoch: 40 train accuracy: 0.96255744 loss train: 1.7228943 test accuracy: 0.9577644 test loss: 1.7349298\n",
      "epoch: 50 train accuracy: 0.97060245 loss train: 1.6911968 test accuracy: 0.9666561 test loss: 1.7015302\n",
      "epoch: 60 train accuracy: 0.9688483 loss train: 1.6687979 test accuracy: 0.9633746 test loss: 1.6856239\n",
      "epoch: 70 train accuracy: 0.98040164 loss train: 1.6229731 test accuracy: 0.9769239 test loss: 1.6364135\n",
      "epoch: 80 train accuracy: 0.9838495 loss train: 1.5952486 test accuracy: 0.97755903 test loss: 1.6139634\n",
      "epoch: 90 train accuracy: 0.98717636 loss train: 1.5664254 test accuracy: 0.9812639 test loss: 1.5846554\n",
      "epoch: 100 train accuracy: 0.98941445 loss train: 1.5406476 test accuracy: 0.98316926 test loss: 1.5625904\n",
      "epoch: 110 train accuracy: 0.9892935 loss train: 1.5228056 test accuracy: 0.98263997 test loss: 1.547907\n",
      "epoch: 120 train accuracy: 0.9868134 loss train: 1.5132825 test accuracy: 0.9800995 test loss: 1.5358944\n",
      "epoch: 130 train accuracy: 0.98058313 loss train: 1.5128543 test accuracy: 0.9727956 test loss: 1.5424744\n",
      "epoch: 140 train accuracy: 0.97054195 loss train: 1.5245959 test accuracy: 0.96538585 test loss: 1.5499787\n",
      "epoch: 150 train accuracy: 0.99401164 loss train: 1.4406127 test accuracy: 0.9860273 test loss: 1.46622\n",
      "epoch: 160 train accuracy: 0.9854222 loss train: 1.4447184 test accuracy: 0.976818 test loss: 1.4778941\n",
      "epoch: 170 train accuracy: 0.9869949 loss train: 1.4217126 test accuracy: 0.98052293 test loss: 1.455439\n",
      "\n",
      "final results: accuracy: 0.98052293 loss: 1.455439 validation accuracy: 0.9787697 validation loss: 1.4592198\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], train_acc=[], test_loss=[], test_acc=[])\n",
    "\n",
    "sess = tf.InteractiveSession()  \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_count = len(X_train)\n",
    "\n",
    "for i in range(1, N_EPOCHS + 1):\n",
    "    for start, end in zip(range(0, train_count, BATCH_SIZE), range(BATCH_SIZE, train_count + 1, BATCH_SIZE)):\n",
    "        sess.run(optimizer, feed_dict={X: X_train[start:end], Y: y_train[start:end]})\n",
    "\n",
    "    train_predictions, acc_train, loss_train = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_train, Y: y_train})\n",
    "\n",
    "    _, acc_test, loss_test = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_test, Y: y_test})\n",
    "\n",
    "    history['train_loss'].append(loss_train)\n",
    "    history['train_acc'].append(acc_train)\n",
    "    history['test_loss'].append(loss_test)\n",
    "    history['test_acc'].append(acc_test)\n",
    "        \n",
    "    if i != 1 and i % 10 != 0:\n",
    "        continue\n",
    "\n",
    "    print('epoch:', i, 'train accuracy:', acc_train, 'loss train:', loss_train, 'test accuracy:', acc_test, 'test loss:', loss_test)\n",
    "    \n",
    "predictions, acc_final, loss_final = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_test, Y: y_test})\n",
    "validation_predictions, validation_acc, validation_loss = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_validation, Y: y_validation})\n",
    "print()\n",
    "print('final results: accuracy:', acc_final, 'loss:', loss_final, 'validation accuracy:', validation_acc, 'validation loss:', validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8YAAANJCAYAAADOdyXMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XeYFdXdwPEvnaiIgsQCogh6JEizAAqKYmwgLYqJBRWjvCoJSBIClogFC8HesIBiL6AoFuwvKMgrYgmicEDKAgbUYIkNFmHfP+buuqxLh529u9/P8+xzuHNnzvxm5t7L/d1TpkJeXh6SJEmSJJVXFdMOQJIkSZKkNJkYS5IkSZLKNRNjSZIkSVK5ZmIsSZIkSSrXTIwlSZIkSeWaibEkSZIkqVyrnHYAkpTNQgijgDM2YNX7Y4xnboH9TQD2jDHuuZHbjQLOiDFW2NwYsl0IIY8tdD2KqftM4D6gV4xx1JauX9mpuNdcCGGvGOO8lOL5NfB9jPH7zONR+PkgqZwzMZakzXMX8Gqhx4cCvYG7gTcLLZ+7hfZ3FbDtJmxXNM7yrCdb7npIG2KN11wIoRdwB/Crkg4khHAc8AjQEvg+s9jPB0nlnomxJG2GGOMUYEr+4xBCZZLEeEqM8aGtsL9XNnG7NeIsz7bGdSlkeab8cSvuQ1mmmNdce6B6GrEArYEdCi/w80GSHGMsSdKWlN8qOCfVKCRJ0kaxxViSSlAIYQHwCskPk6cC/yHp0vgf4H+As4DGQBVgAcl41X/GGPMy20+g0BjjzOPlwE3AEGA/4HPgXuCKGOPqzHqjKDSGMPO4DUkXz+uAg4BvgceBgTHGghbPEEIA/knSyvUTSTfMD0m6izeIMS5Yx/GeC5wPNCJpRX0DuCTG+FGhdaoDl2TOR11gMfAQMCTGmFtovROAQcC+wGpgKnBZjHFyoXXaA1cCzUj+j/sXcG2M8dlC6xQ33rMrMJDkWqwoFOf0IttdCOQCfYB6wOzMeR6dWW02kJcpCSFUAP6RObY9gG+Al4GLYoyL1nHeLsuckyYk3VxbkVzXEcA1McZVhdYbBJwMDCfpZn9BjHFkCKF25lx0BXbi59fTsPztM3XsBgwFjgWqAuOAMcDTwBExxgmFxk6fSPJ62ZnkdXlZSV+/dZyzPwJ/ztT/beY8X5z/+gwhzARWxhibFdnucOB/Sd4fD2SWnQn0I3kvfgs8D1wYY1ySeX5PYD7QP3NODgLejDH+di2xFbzmMu/Z9kWXZx4fDFxB8t6EpBX3khjj1EJ1LWATP0OKzIkwP4QwMcZ4eHFjjEMIe5B8phwL1AAicFuM8Z5C64xiAz5HNvV9IEklyRZjSSp5JwMtSL543xNj/IIkGRgOfAz8BbiIJOG9Fjh9PfU1BZ4AJgB9gXnAYODc9Wz3a5Ivp7MysUwmSSwuz18hhFAfmAQcQvLF9zqgeyaudQohnJo5pvcz9V8PtAUmhBBqZtapBDwH/JUkIesLvA5cDDyZ+UKdnzA9DiwB/paJsSHwaghhr8w6gSSBqUBy/gaSJIrPhBDarSPOPiRJYJXMdjeQdDd9K4RwUJHVzyNJhu4BBmTqfzyEsB9AjPGbGGPFGON3mfUvIrkWL5Ik0/cA3YCXM8e+LhVIxn3+CPwdeJfkdXJHkfWqkCTMN5Jcn0khhB2Bt4A/kiS5/YGZwDUkP2zkH3sNkh8BfkfyQ8dlwP4kP6wU5z7g4cwxvVoarl9m22GZc/AfkusyguQHgamZJJZM3E1DCPsW2fz3JOd4bKauwZnj/CRz3u4mec1PCSHsVGTbIcCnwAWZ+jfEVfw8/0BPkh8+CCEcBUwEapIkkUOA+sAbIYRDi9SxqZ8hd+UfZ+bYriouwBBCA+AdknOY/1r/Erg7hPDPIquv93OEzXsfSFKJsMVYkkrer4CTYoxzAUIIVUi+SD5WpBVzBEkr4QnA/euobzegS36rWgjhAeDfJK0zRZOownYE+sYYb808vieE8HFmu79nlg0mGY/YLMY4M1P/gyRfgtfnVOCjGGPBrN0hhA+AYSQt25NJEoMjgWNjjC8VWm8qyZf4LsAzJMnLD0DXQq3nr5AkffuT/BjQlSSR6h5j/E9mncdIEsSWJAn+GjKtqv8kab08NL+FM3MOPwJuI0mS89UGGsUYl2bWexv4P5JE5eK1nIPxMcZ+hfa5iCTB3pN1TwJWEZgG/C5zzLeFEB4Czgkh3JR/PTLr3RpjHFpoH9cC+2TOxdOZxXeEEG4Hzg8hjIoxjidJ6BoCR8UYX81sOwKYAdQqJqanYoyXFNrPmaR4/TLrNCZJzMcCJxSq/2mSFtehmf0/QpI89siU+T/MnACMizF+m0nSLyVppb6w0D4eBd4jucb9C+1+CXBajHFlcbEVJ8b4SuZHo0Pzxx6HECoCd5K8DtsX6hFwG/ABcEvmHOTbpM+QGOOUEMJ0kkT/6XX09riG5LV+UIzxvUxdt5Ncy7+FEO4v1OtjQz5HNud9IEklwhZjSSp5n+R/oQXIfKnemWTSrsJ2Av4LbLee+n4gaWnLr285SbfHXTYglieKPP5XJpb87o/dSL7Q5idhxBg/Jekquz6LgX1DCIPzW+1ijC/EGJsU6j57AvAF8G4IYaf8P+AFYBVwfKG6agC3ZBIhYowfxhhDjHFMoXUgSSAPyKyzLLNO/pf2oo4EtgGuL9ztN5MwPAi0CiHsWmj9N/OT4owPMuXazvVi4IgQQr8Qws6Zuu+KMbYo/BpYh2vzE72MG0haVI8vst5LRR53AWYWSorzXZkpu2XK7sCH+UlxJr5vWfsPKkX3k/b1A+hMck7WOFcxxrdJWjKPDyFUztwaaQpwUqFtjwTq8HNrb3eS70bjihzPUpKeD0XP++sbkxSvQ0tgL5KeCzsW2u+vgGeBFiGEeoXW39KfIQUyPxZ0Al7KT4oz+1hN0sJcgeT1VdhaP0cyNvd9IElbnS3GklTyPi9mWS7QKTPWNQB7k7TEwPp/xFyWP5a4kBXAhnRR/GId29XK/BU3kdSGtBhfARxM0j33skwr0jhgRKEvww1JEpOiceSrnylvA44B/gT8KYQwn6QL78gY478y64wmSWx+D/w+hLCEJEG7P8b4JsVrkCljMc/l/xiwB0nLIEXjjDGuSHoAr/Vc/40ksbkJuDGE8C7JObinSIK9Nh8XeZx/LfYssrzoa6oBSbfVNcQYl4YQviY5JkheZy8Xs9+1Xd+i+0n7+sH6r+ExJAniUpJW41tDCPvGGGdl9vUlP5+rhpnyrbXsK7fI4+Ley5sif7/DMn/F2Z2ffzzY0p8hhe1Ekkiv7z1R2Lo+R2Dz3weStNXZYixJJW9V4QeZltmHSLqVNiD5Uv43ki+2GzIxTdGkeIMVk1AXViVTrijmueXFLCta92KgOfBb4NZMfYOAjzNjTiH58jwHOGotfxdl6vpvjLE9SaI9lGSCnz8D74UQTsmsszLG2INk4qbLgIVAL5IxmoPWEmaFtSyHn/+PLJwMbdS5jsnkXXuTdBMeSdKyfAUws5ixrsUp2hqZn2ysKrK86OP1HVf+MVVh465v0f2kff1g467h4yQTyJ2U6X7cHRhdqNU3//x2WcvxdCpSf9Hzsany9/uPtez3KNb8sWJLf4YUtrHvifV9jmyJ94EkbXW2GEtS+g4lGaN6ZYzx0vyFIbkncm2S8Zdp+Bz4jmSsalF7r2/jEEJTgBjja8BrmWVtSWYA7ksy0dAC4ECSLqmrC21bhWRCqEWZx/sANWOM/0cypndQCOE3JBNH/RV4JDNRWP0Y4ySSWbMvz3Q/fZ1k8qDiJgxbkCn3Jen+ucYhZMrFbIJMl9TmwH9jjONIWsgIIZxEkqCdk4l9XfZizVbj/PO+vttBLSA5pqIx7QJsz8/J0jw28foW2k+a1y8/BjLH+3bRQwa+B74CiDF+kRnb3I1k/PaOrDlpVn5di2KMHxRaTgihI8lsyltD/n6/K9ytPbPfg0h6bqzr3thb8jPkC5JzVlzCmv+e2OBkewu9DyRpq7PFWJLSVztTFu02ew7J+NdUfsTMJDrjgOMys9QCEJIZj0/egCpGAw8WmXX2fZLWpvwWr3EkX/rPK7LtucBjJK3NkEw+NC6EUHis5Czg60J1XQS8FkKoW+gYFpMktmtr2XuFpHX0LyGEqoWOsR5wGjA1xrip3WUrkfwIcFOR5fnJ24a0Nv65yOO/krR4jlvPds+SjO/uVmR5fsvrc5lyLLB/CCH/9kCEEKqRzGa9IdK+fpAcK8DATMtp/nHsT9LS+nyRcdoPk4zp7UPSKl14Uq/8ui4sUleLzLFesI44Nkb+5Fr538OmkXTX71v4HIUQticZv3sfyXVfm435DMk/l8V+B8xM/DUeODpzDvNjqUAyU3geheY02ABb4n0gSVudLcaSlL63SCbIuTHTavY1cATJ+MflJJMWpeVSku6j/xdCuIWk2+25/Dx2MW9tG5KMlRxBkuyMJumi2ROozs+TO40gua/qrZkv4VNJbj/1PySzAN+XWe8Gki/rb4YQ7ic5L91Ixmbm3xbmdpLb0rwRQriLpJWwA8m5LGhFKyzGuCyEkH+LpskhhIdJzvf5JIlD3/Wcn7WKMeZmztklIYSxJONYtyGZIOkH1n5LpMLODMmtrSaR3E+2M8l9k3PWs901JBNjPR5CGE5yX+UjSVpxn8rMSA3J7Z16Aq+EEG4maS08nZ9bBtd1fSHl6wcQY/woc577Zo7jaWBXkh8VvuLnHwPyPU3SItqRX07YNaNQXbUzddXK1PUtSVfnLSF/TO7lIYT/jTG+HkL4M0kS/F5mNunlJIntHsCpMcZ1JcYb8xmSv+8BIYTxmVbcogaRnPsJIYRbSZL27pllN8QYiybga7WF3geStNXZYixJKYsxfkbyJX0uyRfvq0m+DP+BJIFskj+TawqxzQXaA9NJWvQGkbSc3ZZZpbjxqfnbjiRJmrYjOaZrSbqDHhdjnJBZZwVJwnZ9pryFZObf4cDRMcYfMuu9TDLu83uSJOkGkoTl5Bjjg5l1PiRpofyEZHzlrUATkqRmyDrivJEkgcgjSSgvIEk0WmdmNt4cg0nuKdsoc4yDSbq1HpaZ/Gl9upOMGb0hU0fvGOPg9W0UY/ySZDzvAySvoxuAxiRdkk8qtN5XwGEkLed9ScZ9TufnBHCt1zezferXL+MCkhbgnTOx/JGkNfyAGOP8IjF/T3LbISh0T+cidZ1PMqnYdZl63wTabeA12xDDSe4T/PfMHzHGJ4GjSVrI/0Eyg/h/SW7F9ui6KtvIz5DHSO6P3YtkvHdx9c0luU3ZCyQ/hP2T5LZtf4wxbkq35819H0jSVlchL299PwZLksqrEMKvgS+KdEUl04p0HvCrLXS7GhUSQriMJHloENd+r9ktsZ+dgK8y3WcLL/8rSVLYMHObI0mSyjRbjCVJ6zIa+KjQWEhCCNuQdOn9wKQ4610PfBFC+FX+gsyY8B4kXW4XpBSXJEklyjHGkqR1eRC4B3g+hPAMyfjgnkA9knGkym4PkVzP/w0hPETSnfwEkm6056zvNjySJJUVthhLktYqxjiCZHbm2iTjDC8jmdDoyBjjSymGpi0gxvgKydjU5STji68l+fHjhMy1lySpXHCMsSRJkiSpXCtXXakz92Y8iOS2A943T5IkSZLKlkokt+17J3P3hA1SrhJjkqT4zbSDkCRJkiRtVYcCkzZ05fKWGC8BePjhh9lll13SjkWSJEmStAUtXbqUU089FTK534Yqb4nxKoBddtmFevXqpR2LJEmSJGnr2Kihs85KLUmSJEkq10yMJUmSJEnlmomxJEmSJKlcMzGWJEmSJJVrJsaSJEmSpHLNxFiSJEmSVK6ZGEuSJEmSyjUTY0mSJElSuWZiLEmSJEkq10yMJUmSJEnlmomxJEmSJKlcq5x2AJIkSZJUmgwaNIixY8eu9fm6devy+uuvb3LdS5cuZdSoUZu0fc+ePalfvz5XXXXVJm2v4pkYS5IkSVIhF198MX/9618BWLJkCT169OCOO+6gWbNmAFSqVGmz6l69evUWiVNbjomxJEmSJBVSo0YNatSoAcCKFSsAqFmzJnXq1Nkidav0cYyxJEmSJG2CDh06MHToUI455hjatGnDRx99xOLFi+nbty+tW7emSZMmdOjQgREjRhRsM2jQIM4880wA3n77bZo2bcqrr77KscceS4sWLTjppJOYNm3aBscwbdo0TjvtNFq2bMkhhxzCkCFD+PHHHwuev/vuuznyyCPZb7/9OOaYY3j44YcLnps3bx5nnXUW+++/PwcccADnn38+ixcv3vwTk4VMjCVJkiSVjD33LP7v9tt/Xqdnz+LX+cMffl7nnnvWXldubrLOrFk/L9uKHn30Ua688kruuusuGjduzHnnnUdubi4PPPAAL7zwAl27dmXYsGHMnDmz2O1XrlzJbbfdxpAhQ3jkkUcAuOiii8jLy1vvvv/1r39x5pln0rRpU8aMGcM111zDa6+9Rv/+/QF4/fXXGTlyJEOGDOGll17i7LPP5sorr+Sdd94B4G9/+xu77bYbY8eO5eGHH+arr77ioosu2kJnJrvYlVqSJEmSNlGHDh1o1aoVAMuXL6d79+506tSJnXfeGYA//elP3HnnncQYady48S+2z8vLo3///hx44IEA9O7dmz59+vDVV19Rq1atde773nvvZb/99mPgwIEANGzYkMsuu4zevXszZ84cFi5cSJUqVdhtt92oW7cuPXr0oF69euy1114A5OTk0LZtW+rWrUvlypUZNmwY//nPf7bYuckmJsaSJEmSSsaCBetf58EH17/OOeckf+uy774btr/NtPvuuxf8u3r16px22mm88MILTJ8+nZycHGbOnMnq1avXOeFWgwYNCv6dPwZ55cqV6933nDlzaN++/RrL8hPsOXPm0LlzZ8aMGcPRRx/NPvvsQ7t27ejSpQu1a9cGoF+/fgwdOpRHHnmENm3acPjhh9O5c+cNP/gyxK7UkiRJkrSJqlWrVvDvH374gZNOOomRI0dSq1YtTjrpJJ566ikqVlx32lW1atVfLNuQrtSF9110u8qVK1O7dm3GjRvHQw89RIcOHZgyZQonnHACzz77LACnn346EydOZNCgQVStWpVrrrmGk08+mdz87ujliC3GkiRJkrQFTJ06lZkzZ/L222+zww47AMkEV6tXr96gRHdjNWrUiPfff3+NZe+++y6QdKt+4YUX+Oqrrzj11FM56KCD6N+/P+eccw7jxo2jXbt23HbbbZxzzjn06NGDHj16MH36dHr06MGsWbMKbk1VXthiLEmSJElbQP6Y4GeffZZPP/2UKVOmcMEFFwBslVbYc845hw8//JChQ4cyb9483nzzTS6//HLat29Pw4YNyc3NZejQoYwbN64gno8//pjmzZtTs2ZN3njjDS699FJmzZpFTk4OTz31FNtvv/0aXbvLC1uMJUmSJGkLaNasGX//+9+55557GDZsGLvtthsnnngib7zxBh9++CEnn3zyFt3fPvvsw5133slNN93Egw8+yA477ECnTp0KkvFu3bqxbNkybr31VpYsWULt2rX53e9+x7nnnkvFihW56667uPbaa+nZsye5ubk0bdqUkSNHlst7LVfYGk36pVUIYU9g/muvvUa9evXSDkeSJEmStAUtXryYI488EqBBjHHBhm5nV2pJkiRJUrlmYixJkiRJKtdMjCVJkiRJ5ZqJsSRJkiSpXDMxliRJkiSVaybGpcmyZdC8OTzzTNqRSJIkSVK5YWJcmixbBtOnw9NPpx2JJEmSJJUbJsalyS67QMWK8P77aUciSZIkSeWGiXFp8s03sHo1zJqVdiSSJEmSVG5UTjsAFVK3btJivGIF/Pe/sP32aUckSZIklTuDBg1i7Nixa32+bt26vP7665tc99KlSxk1atQmRqetwcS4NKlYEXbcMRlrPGcOHHBA2hFJkiRJ5c7FF1/MX//6VwCWLFlCjx49uOOOO2jWrBkAlSpV2qy6V69evUXi1JZjYlza1K2bJMbvvGNiLEmSJKWgRo0a1KhRA4AVK1YAULNmTerUqbNF6lbp4xjj0iaEpHznnXTjkCRJkrROHTp0YOjQoRxzzDG0adOGjz76iMWLF9O3b19at25NkyZN6NChAyNGjCjYZtCgQZx55pkAvP322zRt2pRXX32VY489lhYtWnDSSScxbdq0te7z66+/5sILL6Rdu3Y0adKEdu3aMXTo0DVaoSdOnEiPHj1o3rz5L/b/3Xffcfnll3PIIYfQsmVL/vjHPzJv3jwAbr31Vo466qg19ld42eLFiwkhcOedd3LwwQdz3HHHkZuby9tvv81pp51Gy5Yt2W+//ejatStvvPFGQR0rV67kxhtvpH379rRo0YI//OEPfPDBB6xcuZI2bdqsER/ATTfdRLdu3TbyamyeEk+MQwj1QgijQwhfhhC+DiE8FkLYbR3rHx1C+CCE8GMIYXoI4biSjLfE7b9/Us6cmW4ckiRJktbr0Ucf5corr+Suu+6icePGnHfeeeTm5vLAAw/wwgsv0LVrV4YNG8bMtXy/X7lyJbfddhtDhgzhkUceAeCiiy4iLy+v2PUHDhzI3LlzGT58OC+++CLnnXce9913X8GY5/fff59zzz2Xtm3b8vTTT3PhhRdy++2388QTTwBwwQUXMGXKFK6//nqefPJJttlmG84++2xWrly5wcf8/PPP89BDD3HdddexbNkyzjnnHA444ADGjRvHmDFj2HXXXRk4cCC5ubkADBkyhCeffJJ//OMfPPPMMzRu3Jizzz6bb7/9luOPP55x48YV1J2Xl8ezzz5b4olxiXalDiFUAJ4HvgCOyCy+BXgW+EW/4RDCb4BxwJXAk8CpwNMhhP1jjB+VSNAlrVcvuOQSWMsbQZIkScpWe960Z7HLBxwygD6t+gDQc2xP3sx58xfrtKnXhsdOfAyAe969h6vevKrYumb/eTZVK1Vl1n9mcexDxwKw4IIFmx/8WnTo0IFWrVoBsHz5crp3706nTp3YeeedAfjTn/7EnXfeSYyRxo0b/2L7vLw8+vfvz4EHHghA79696dOnD1999RW1atX6xfqHHnoorVu3Zu+99wbg1FNPZcSIEcQY+e1vf8uDDz7IgQceyAUXXABAgwYNGDx4MJUqVWLevHm8+eabPPDAA7Ru3RqAK664grvuuouvv/56g4/51FNPpWHDhgAsXLiQfv36cdZZZ1GhQgUAzjzzTM444wyWLVtGjRo1ePLJJ7niiiv47W9/CyTjrKtXr87XX3/N7373Ox588EFijIQQePfdd1m6dCldunTZ4Hi2hJIeY7wzMBMYFGNcABBCuIEk2d0xxvhVkfX7Af8XY8x/1f8jhNAus7x3CcVcsnbeGRo0gLlz045EkiRJ0nrsvvvuBf+uXr06p512Gi+88ALTp08nJyeHmTNnsnr16nVOuNWgQYOCf+ePQV5bC+7JJ5/Ma6+9xujRo1mwYAExRpYuXVpQ/+zZsznssMPW2Ca/9fXFF18EKJhEDGDHHXdk0KBBG3PIaxxz/fr16datG/fffz8xxoJjBli1ahXz589n5cqVa+yzcuXKDBw4sODxvvvuy7hx4xgwYADjxo3jsMMOK/ZHga2pRBPjGONS4A/5j0MI9YD/Ad4pJikGOBR4osiyCYXrKJMaNoSXXkrua1yzZtrRSJIkSVvEhrTcPtj9wfWuc84B53DOAeesc519d9p3q7YU56tWrVrBv3/44QdOOeUUVq1axTHHHEPr1q1p3rw5RxxxxDpqgKpVq/5iWXFdqfPy8ujduzfz58+nc+fOdO3alWbNmnHGGWcUrFO58tpTvHU9tzY//fTTL5YVPuY5c+Zwyimn0Lx5cw4++GA6duzITz/9xLnnngtAlSpV1ruP7t27M2rUKPr168f48eO5+uqrNzrOzZXarNQhhKeBrsBXwOFrWa0e8GmRZf8Gdi9m3bLjgw+SctYsyHRxkCRJklS6TZ06lZkzZ/L222+zww47ADBv3jxWr1691jHDG+OTTz5h0qRJPPXUUzRp0gRIJtP64osvCupv2LAhM2bMWGO7G2+8kTlz5jBgwAAAZsyYwUEHHVSw/VFHHcWtt95KlSpV+P7779fYNicnZ50xPfXUU+y6665rTKD12GNJl/e8vDzq169P5cqVmTFjBo0aNQJg9erVHHfccfTt25dOnTrRpUsXrrvuOu69914qVqxI+/btN/UUbbI0Z6W+FGgNTAJeDSHULWadbYDlRZatAKqvr/IQwmUhhLzCf8D8zQ26ROR3TZgyJd04JEmSJG2w/O6/zz77LJ9++ilTpkwpGOubPxHV5th+++2pXLky48ePZ/Hixbz//vucf/755ObmFtR/1lln8c4773DHHXeQk5PDSy+9xAMPPECHDh1o0KABRx55JJdffjnTpk1j7ty5XHjhhdSoUYNmzZrRokULli1bxqhRo1i8eDGPPPLIGrNLr+2YP/30UyZPnsynn37KM888w4033lhwzNtssw2nnHIKN954IxMnTmTBggVcccUVfPPNNwXjnGvVqsWhhx7K8OHD6dy5c7Et6FtbaolxjHF6jHEqSbfoSsAZxaz2I1CtyLJqwPfFrFu0/stijBUK/wEN1rddqbDvvkn53nvpxiFJkiRpgzVr1oy///3v3HPPPRx33HFcfvnldOnShdatW/Phhx9udv0777wzV199NS+++CLHHXccAwYMoHnz5nTp0qWg/iZNmnDrrbfy4osv0qlTJ4YNG0b//v058cQTAbj22mtp2rQp559/PieddBIrV65kxIgRVK1alTZt2vDnP/+Ze+65h06dOjFlyhT69u27zphOP/10jjrqKPr370+XLl14+OGHufzyy9lmm20KYhowYADHHXccF110Ed26dWPu3LmMHDmSnXbaqaCebt26sXz58hKfjTpfhS3RpL+hQgg7A0fEGB8rsnwqyTjjPkWWfww8GmO8stCywcDvY4y/2YT97wnMf+2116hXr96mHELJuPlmuOACOOggmDo17WgkSZIkaat66KGHePzxx3n22Wc3q57Fixdz5JFHAjTIn/B5Q5R0i/EewKMhhAPzF4QQagIB+LiY9ScBRTt7uso8AAAgAElEQVSYHwGsuz0/2x18cFIuXJhuHJIkSZK0Fc2YMYNnnnmGO++8k549e6YWR0lPvjUNeBMYEULoDawEriW5r/H9IYRfATWBL2KMq4BbgXdDCJcDjwKnkIxLPq+E4y5Z+fc3+/LLdOOQJEmSpK3ovffe4/rrr+fYY48t6O6dhhJtMY4xrgZ+B3wAPAdMBP4LtI8xfgf8HlhCZtbpGOOHQHfgxMw2XYDOMcaZJRl3iatRA5o3h5Ur4avi7mIlSZIkSdnv9NNP51//+hdDhw6lYsX05oYu8ds1xRj/A5y5ludGAaOKLHseeH5rx1XqHH44/OtfMGcOtGqVdjSSJEmSVGalebsmrcveeydljOnGIUmSJEllnIlxabVgQVK+8EKqYUiSJElSWWdiXFrZYixJkiRJJcLEuLQ65JCkXLw43TgkSZIkqYwzMS6t8luMnZVakiRJkrYqE+PSqlo1+NWv4KefYNmytKORJEmSpDKrxG/XpI3w619DTk5y26YOHdKORpIkSSoXBg0axNixY9f6fN26dXn99dc3ez+zZ89myZIltG/fvtjnTz75ZPbee2+uuOKKzd6X1s0W49IsPxn+5JN045AkSZLKkYsvvphJkyYxadIkRo8eDcAdd9xRsGzMmDFbZD/nnnsuH3300RapS5vHFuPS7JRT4L774NNP045EkiRJKjdq1KhBjRo1AFixYgUANWvWpE6dOmmGpa3IFuPSLH8Crjlz0o1DkiRJ0i+sWLGCq6++mrZt27L//vvTs2dPpk+fXvD8559/Tp8+fWjVqhUtW7akV69ezJo1C0i6SX/66afcfPPNHHXUURu0v3feeYdTTjmFli1b0rZtW6666iqWL19e8Pxdd91Fhw4d2G+//TjmmGN49NFHC56bO3cuvXr1Yv/99+eAAw6gT58+/Pvf/95CZyL72WJcmm23HVSoAFtg/IIkSZKUqgEDINMtucT16AHDhm3xav/2t7/x2Wefccstt7Djjjvy7LPP0rNnT5599lnq16/P4MGDqVChQkGCet1119GvXz9eeuklhg8fTteuXencuTNnnXXWevf13nvvceaZZ3LmmWcyZMgQFi5cyODBg/n3v//N7bffziuvvMK9997LzTffzO67786kSZO49NJL2XfffWnZsiX9+/enRYsWXH755fzwww8MHjyYSy65hHvvvXeLn5dsZGJcmu2wQ1L+5z+Ql5ckyZIkSZJSN3fuXF5++WXGjx/PXnvtBUC/fv2YNm0a9913H4MHD2bhwoU0a9aMevXqUa1aNa688krmzp1LXl4eO+ywA5UqVWKbbbahVq1a693fvffeS4sWLRgwYAAAe+21F4MHD+a8885j3rx55OTkULVqVerWrUvdunX5/e9/T/369dljjz0AWLRoER06dGC33XajcuXKXHfddXz55Zdb7wRlGRPj0qxSJdh2W/juuyQ5dkyDJEmSstWwYVul1TYtM2fOBOCEE05YY3lubi4VMg1affr0YdCgQYwfP56DDjqI9u3b07Vr14LnN8acOXM4+uij11h20EEHFTzXtWtXnnrqKX77298SQqBdu3Z06dKlIOnu27cvw4YN46GHHqJNmzYcfvjhdO7ceaPjKKtMjEu7XXZJZqWeOhU6dUo7GkmSJElAlSpVABg9enTBv/NVq1YNgI4dO9K2bVsmTpzI5MmTufXWWxk1ahRPPPHEBrUSF1a1atVfLFu1ahUAlStXpk6dOjz33HNMmzaNSZMmMWHCBO6//36GDRtGx44d6dWrF8cffzwTJkxg8uTJXHXVVTz66KM8+uijxdZd3jj5VmnXoEFSTpmSbhySJEmSCjRq1AiAZcuWscceexT8jRw5ktdff53c3FyuueYalixZQpcuXRg6dCjjxo1j0aJFTJs2baP3t/fee/Puu++usSz/ccOGDXn22Wd5/PHHadWqFX/5y18YN24crVu3Zty4cXz55ZdceeWV5OXl0aNHD2666SZGjhzJjBkzmONEv4CJcenXuHFSfvxxunFIkiRJKtCwYUOOOeYYLrnkEt58800WLlzIddddx5gxY2jUqBFVq1ZlxowZXHbZZUyfPp1FixbxxBNPUKVKFRpnvuNvu+22zJ8/n88++2y9++vduzcffPABw4YNY968eUycOJEhQ4bQoUMH9txzT1asWMG1117Lc889x6effsrkyZOZOXMmzZs3p2bNmvzv//4vl156KTFGcnJyePrpp9lhhx0KxiCXd3alLu0OPhhuuQV+/DHtSCRJkiQVcvXVV3PdddcxcOBAvvvuOxo1asRtt91Gq1atALjhhhu4+uqr6d27N99//z0hBIYPH87uu+8OwFlnncXVV1/N5MmTmTx58jrHHu+7774MHz6cm2++mfvvv58dd9yR448/nn79+gFw4okn8tVXX3HTTTexdOlSateuzUknnUTv3r2pVKkS99xzD9dccw2nnXYaubm5NGvWjBEjRrDddttt/ROVBSrk5eWlHUOJCSHsCcx/7bXXqFevXtrhbJjvv09u23TUUfDyy2lHI0mSJEml1uLFiznyyCMBGsQYF2zodnalLu223RZ22glyctKORJIkSZLKJBPjbPCrX8G8ecm9jCVJkiRJW5SJcTb4/nv46SdYsiTtSCRJkiSpzDExzgZ16iRlkenZJUmSJEmbz8Q4G+RPFPb+++nGIUmSJEllkIlxNth776ScOTPdOCRJkiSpDDIxzgb77ZeU8+enG4ckSZIklUEmxtngwAOT8uuv041DkiRJksogE+Ns0KoVbLcdVKuWdiSSJEmSVOZUTjsAbYAKFWDPPSEnJ+1IJEmSpDJv0KBBjB07dq3P161bl9dff32z9zN79myWLFlC+/btN7subR5bjLNFzZrwzTfw5ZdpRyJJkiSVaRdffDGTJk1i0qRJjB49GoA77rijYNmYMWO2yH7OPfdcPvrooy1SlzaPLcbZYunSpHz3XTjqqHRjkSRJksqwGjVqUKNGDQBWrFgBQM2aNalTp06aYWkrssU4W9Stm5TvvZduHJIkSZKAJGm++uqradu2Lfvvvz89e/Zk+vTpBc9//vnn9OnTh1atWtGyZUt69erFrFmzADj55JP59NNPufnmmzlqLQ1fX375JRdeeCFt27alSZMmHHrooQwbNoy8vLyCdSZMmMAJJ5xA8+bN6dChA/fdd1/Bc9999x2DBw/m4IMPZv/99+fss89mwYIFANx4440ce+yxa+yv8LKcnBxCCNx55520adOG448/npUrVzJlyhROOeUUWrZsSdOmTenWrRuTJk0qqCM3N5cbbriBww47jBYtWnDyySczffp0cnNzad26NaNGjVpjn9dffz0nnHDCxp/8LczEOFs0apSUH3+cbhySJEmSAPjb3/7GBx98wC233MKYMWM48MAD6dmzJwsXLgRg8ODB5OXl8eijjzJmzBiqV69Ov379ABg+fDi77LIL55xzDo8//nix9Q8YMID58+dz11138eKLL/I///M/jBgxggkTJgAwbdo0zjvvPA4//HCefvppBg4cyM0338yTTz4JQN++fXnnnXe48cYbGT16NFWrVuXss89m1apVG3yM48eP5+GHH+af//wnn3/+Ob179+bggw9m3LhxjB49mp133plBgwbx008/AXDFFVcwduxYLrvsMp555hn23ntvzj77bH744Qc6duzIuHHjCurOy8vjueeeo3v37ht97rc0u1Jni9/8JinnzUs3DkmSJGkTDHh5AKM/Hp3Kvnv8pgfDjh62ReucO3cuL7/8MuPHj2evvfYCoF+/fkybNo377ruPwYMHs3DhQpo1a0a9evWoVq0aV155JXPnziUvL48ddtiBSpUqsc0221CrVq1i93H44YdzyCGH0LBhQwBOO+007r77bmbPns0RRxzBAw88QOvWrfnzn/8MQIMGDfj++++pXr06c+bMYfLkyTz88MMcmLn965AhQ7j77rv5eiNuA3vaaacV7D8nJ4e//OUv9OrVq+D5008/nbPOOosvv/yS6tWrM3bsWK6++mo6dOgAwD/+8Q+22WYbvv76a7p3784jjzzC3LlzadiwIVOnTuWLL76gU6dOG3n2tzwT42xxwAFJ+emn6cYhSZIkiZkzZwL8ohtwbm4uFSpUAKBPnz4MGjSI8ePHc9BBB9G+fXu6du1a8Pz6nHLKKbzyyis89thj5OTkEGPks88+K2jxnT17NkcfffQa2/zud78D4Pnnn6dChQo0a9as4LlatWoxaNCgjTrO3XffveDfe+yxB507d+a+++5j9uzZ5OTkFJyH1atXM2/ePH766ac19lmlSpU19rn33nszbtw4+vfvzzPPPMMRRxzBjjvuuFExbQ0mxtli//2TctmydOOQJEmSNsGwo4dt8VbbNFWpUgWA0aNHF/w7X7Vq1QDo2LEjbdu2ZeLEiUyePJlbb72VUaNG8cQTT6y1lTjf6tWr+eMf/8iiRYs4/vjj6datG02bNuW00077RQzFqVx541O94rpYV69eveDfMUZOOeUUDjjgANq0aUOnTp1Yvnw5ffr02eB9duvWjUceeYTzzz+fl156iWHDSsdrwjHG2WL77ZN7GRd6YUqSJElKR6PMHEDLli1jjz32KPgbOXIkr7/+Orm5uVxzzTUsWbKELl26MHToUMaNG8eiRYuYNm3aeuufPXs2U6ZM4fbbb6d///507NiRmjVrsmzZsoLJt/baay9mzJixxnbXXXcdffv2pWHDhuTl5a3x/DfffEObNm14//33qVKlCt99990a2+bk5KwzpieffJL69etz9913c9ZZZ9GuXTs+++wzIBkvvOeee1KpUqU19rlq1SqOOuooxo8fD0DXrl1ZunQp9913H9WqVeOwww5b77koCSbG2aRhQ/j8c/jxx7QjkSRJksq1hg0bcswxx3DJJZfw5ptvsnDhQq677jrGjBlDo0aNqFq1KjNmzOCyyy5j+vTpLFq0iCeeeIIqVarQuHFjALbddlvmz59fkFwWVrNmTSpVqsT48eNZvHgx7777Lueffz4rV64kNzcXgD/+8Y9MmTKFu+66i5ycHMaPH89DDz1Ehw4daNSoEYcffjiDBw9m2rRpzJ07lwsvvJAddtiBJk2a0LJlS7744gsefPBBFi9ezMMPP7zG7NLFqVWrFosWLWLKlCksXryYp59+mptuuglIupBvt912/OEPf+D666/njTfeYMGCBVx++eV8//33tG7dGoA6derQrl07hg8fTufOnTepZXtrMDHOJrvtlpSzZ6cbhyRJkqSCWzUNHDiQ448/nrfeeovbbruNVq1aAXDDDTew884707t3bzp27MjEiRMZPnx4wbjds846iwkTJtC9e/c1bsEEsOuuu3LVVVfx3HPP0bFjRwYOHMgBBxzA8ccfX9Ai26xZM26++Waee+45OnXqxA033MCAAQPo1q0bAP/85z9p0qQJ5513HieddBJ5eXncc889VK1alUMOOYQ+ffowfPhwjj/+eN5+++2CSbzW5owzzqBDhw707duXrl278uijjzJkyBCqV6/Ohx9+CMDAgQM5+uijGTRoEN27d2fBggWMHDlyja7j3bp1Y/ny5aViNup8FYpegLIshLAnMP+1116jXr16aYez8dq2hbfegptvhr59045GkiRJkjbaqFGjeOaZZxg7duwWr3vx4sUceeSRAA1ijAs2dDtbjLNJZhp4iowjkCRJkqTSbvr06Tz99NPcfffda0wiVhqUjg7d2jD59zL+5JN045AkSZKkjfTuu+9y00030bFjx1LVjRpMjLNLy5ZJ6b2MJUmSJGWZXr160atXr7TDKJZdqbPJQQcl5RdfpBuHJEmSJJUhJsbZpHZtqFABvv027UgkSZIkqcwwMc42v/kNrF4NK1emHYkkSZIklQkmxtmmRYskMXacsSRJkiRtESbG2WaPPZJy/vx045AkSZKkMsLEONssWZKUTz2VbhySJEmSVEaYGGeb3XdPytmz041DkiRJksoIE+Nsk38v48WL041DkiRJksoIE+Ns06pVUn7+ebpxSJIkSVIZYWKcbXbdNbmX8X//m3YkkiRJklQmmBhnmwoVoHp1yM2FVavSjkaSJEmSsp6JcTZq3Dgp82eoliRJkiRtMhPjbHTEEUn573+nG4ckSZIklQEmxtmofv2kXLgw3TgkSZIkqQwwMc5GK1Yk5dix6cYhSZIkSWWAiXE2qlMnKWNMNw5JkiRJKgNMjLPRAQck5dKl6cYhSZIkSWWAiXE2yp+V+uuv041DkiRJksoAE+NsVLly8vfjj2lHIkmSJElZz8Q4W223HaxeDd98k3YkkiRJkpTVTIyzVYMGSTl7drpxSJIkSVKWMzHOVt26JaXjjCVJkiRps5gYZ6v69ZNy4cJ045AkSZKkLGdinK2qV0/KV19NNw5JkiRJynImxtlq++2T8v33041DkiRJkrKciXG2OvDApPzPf9KNQ5IkSZKynIlxtvr1r6FCBfj227QjkSRJkqSsZmKczapXh9zc5H7GkiRJkqRNYmKczWrWTMq5c9ONQ5IkSZKymIlxNtt556T88MN045AkSZKkLGZinM3OOCMp8/LSjUOSJEmSspiJcTbbY4+kXLgw3TgkSZIkKYuZGGezOnWScurUdOOQJEmSpCxmYpzNttkmKSdPTjcOSZIkScpiJsbZrGnTpPzqq3TjkCRJkqQsZmKczapWhcqV4Ycf0o5EkiRJkrKWiXG223ZbWL0avvsu7UgkSZIkKSuZGGe7WrWS8v33041DkiRJkrKUiXG223XXpHzvvXTjkCRJkqQsZWKc7U48MSm33TbdOCRJkiQpS5kYZ7v8makXL043DkmSJEnKUibG2W733ZNy1qx045AkSZKkLGVinO222y4pX3st3TgkSZIkKUuZGGe73XZLym+/TTcOSZIkScpSJsbZrkIFqF4dVqyAvLy0o5EkSZKkrGNiXBZsv31SLliQahiSJEmSlI1MjMuCOnWSctq0dOOQJEmSpCxkYlwW1KuXlNOnpxuHJEmSJGUhE+Oy4Oijk7JKlXTjkCRJkqQsZGJcFrRrl5Rff51uHJIkSZKUhUyMy4L69ZNy4cJ045AkSZKkLGRiXBbUrp3ctunVV9OORJIkSZKyjolxWVClClSsCN99l3YkkiRJkpR1TIzLiu22g1WrYNmytCORJEmSpKxiYlxW7LprUk6cmG4ckiRJkpRlTIzLir33Tsq33ko3DkmSJEnKMibGZUWLFkk5fXq6cUiSJElSljExLiuOOiopV69ONw5JkiRJyjImxmXFIYdA1arwzTdpRyJJkiRJWcXEuKyoVAkaNYI5cyAvL+1oJEmSJClrmBiXJZUrJy3GMaYdiSRJkiRlDRPjsqR69aR8/fV045AkSZKkLGJiXJY0bpyU77yTbhySJEmSlEVMjMuSVq2S8uOP041DkiRJkrKIiXFZcvjhSblwYaphSJIkSVI2MTEuSxo3hgoV4Msv045EkiRJkrJG5ZLeYQhhZ+CfwNHAr4C3gb/GGGesZf13gAOLLB4ZYzx7qwaajSpUgNq1k8T4p5+SWaolSZIkSetUoi3GIYSKwFhgH6ArcAjwDfBaCKF2MetXABoDpwK7Fvr7S0nFnHWOPhpWr4bFi9OORJIkSZKyQkk3KTYHDgZ+E2OcCRBC6Al8CXQCHiiy/l7AtsCUGOPSkgw0a+2zT1LOng177plqKJIkSZKUDUp6jPFC4HggFlq2GqgA7FjM+vsBPwI5Wz+0MqJ2puH9iSfSjUOSJEmSskSJthjHGJcBzxdZ3BeoDrxczCb7AV8DD4cQ2gPLgPuAm2KMq7dmrFlrt92ScvLkdOOQJEmSpCyR6uxMIYQuwDXADfldq4toAmwHvARcDbQFhgE1gcHrqfuy9a1TJrVvn5RLlqQbhyRJkiRlidQS4xDCmcA9wGPA39ey2unAdjHGrzOPPwwh1AQuDiFcFmPMW1v9McbLgMuK7HNPYP5mBV7a1a4NlSrBt99CXl4yU7UkSZIkaa1SuY9xCOFiki7RdwKnr61bdIzxp0JJcb4PgRokrcYqzg47JDNTL1qUdiSSJEmSVOqVeGIcQvg7MAS4NMb453W1+oYQ/i+EcFORxQcC/y4mYVa+evWScsKEVMOQJEmSpGxQol2pQwjNSMYK3wvcE0LYpdDT35LMUF0T+CLGuAp4CrgihPAeMBk4HBgI9CvJuLPOvvvCv/4Fc+akHYkkSZIklXol3WL8B6AScBawpMhff+D3mX/vnll/GHARcAnwEUlS3D/GOKJkw84yJ5+clDVqpBuHJEmSJGWBkr5d00Ukie66jCq0fh5wQ+ZPG2qffZJy9ux045AkSZKkLJDK5FvayvbaCypWhIkT045EkiRJkko9E+OyqFo1qFoVPvkEli9POxpJkiRJKtVMjMuqOnWS8v33041DkiRJkko5E+Oyas89k/KNN1INQ5IkSZJKOxPjsmq//ZJy2rR045AkSZKkUs7EuKw6+OCkjDHdOCRJkiSplDMxLqvatUvKpUvTjUOSJEmSSjkT47Jqjz3gV7+CunXTjkSSJEmSSjUT47KqYkXYd1+YNQtWrUo7GkmSJEkqtUyMy7IQkvsYv/VW2pFIkiRJUqllYlyWVa6clCNGpBuHJEmSJJViJsZl2SGHJOWHH6YbhyRJkiSVYibGZdkRRyRlTk66cUiSJElSKWZiXJY1agQVKsBXXzkBlyRJkiSthYlxWVa5MtSsCXl5MG9e2tFIkiRJUqlkYlzW1a+flBMnphuHJEmSJJVSJsZl3THHJGWdOunGIUmSJEmllIlxWdemTVLOmZNuHJIkSZJUSpkYl3W/+U1STp2abhySJEmSVEqZGJd1DRsmM1OPGePM1JIkSZJUDBPjsq5KFdh+e2emliRJkqS1MDEuD/Jnpn7jjXTjkCRJkqRSyMS4PNhvv6ScNCndOCRJkiSpFDIxLg8OOSQpp09PNw5JkiRJKoVMjMuD9u2TcsGCVMOQJEmSpNLIxLg8CAEqVoTddks7EkmSJEkqdUyMy4OqVWGffWDx4mR2akmSJElSARPj8qJJE/j6a1i0KO1IJEmSJKlUMTEuL2rUSMrBg9ONQ5IkSZJKGRPj8qJly6R0ZmpJkiRJWoOJcXlx2GFJmZOTbhySJEmSVMqYGJcX++6blF9+CatWpRuLJEmSJJUiJsblRfXqyTjjvDz45JO0o5EkSZKkUsPEuDypXz8p33or3TgkSZIkqRQxMS5PWrdOyopedkmSJEnKZ4ZUnnTokJTffZduHJIkSZJUipgYlydNmyblu+8mY40lSZIkSSbG5UqTJrDNNvDggzB1atrRSJIkSVKpYGJcnlSqBI0bw08/wdNPpx2NJEmSJJUKJsblTefOSfn88+nGIUmSJEmlhIlxedOlS1LOnAkrV6YbiyRJkiSVAibG5U2zZlC1atKd+r330o5GkiRJklJnYlzeVKr08+zUjjOWJEmSJBPjcqlr16SsWjXdOCRJkiSpFDAxLo/yJ+BatCjdOCRJkiSpFDAxLo+aNYMdd4QJEyAvL+1oJEmSJClVJsblUcWK0Lw5zJ8PF12UdjSSJEmSlCoT4/KqQ4ek9H7GkiRJksq5jU6MQwiVQwi1Qwgm1dksf5yx9zOWJEmSVM5V3pCVQgjHAacARwC7ZhavDiH8G3gJGBNjfHnrhKitolkzqFYNVqyAd9+FNm3SjkiSJEmSUrHOxDiEcARwI7Af8BbwBLAA+B7YEagHtAV6hRCmA4NijK9szYC1hVSsmNzPeNo0GDvWxFiSJElSubXWxDiEcBvQmSQxfizGuHQd6+4MnA3cF0IYF2M8f4tHqi2vS5ckMX7hBRg6NO1oJEmSJCkV6xon/BkQYow3rSspBogxfhZjvAoIme2UDfLHGe+0U7pxSJIkSVKK1tpiHGO8cmMrizF+D1y+WRGp5OTfzzgnJ+1IJEmSJCk1GzT5FkAIYTugRoxxSQihCvAnYHfgyRjj5K0VoLaiihXhsMPgmWdgxgzYb7+0I5IkSZKkErdBt1wKIbQGFgJ9M4tuAa4HzgQmhBA6b5XotPUdcURStmoF33+fbiySJEmSlIINvRfxEGAWcHcIYRvgdOCOGGMt4F7gkq0Un7a2k0+GSpXgxx/h0UfTjkaSJEmSStyGJsatgStjjPOBo4HqwIOZ5x4juZ2TstGvfw0nnJD825mpJUmSJJVDG5oYrwaWZ/59DPA1MDXzeHvg/9m78zgb6/eP468x9rFkKbKVaD7WKEtZEm34RoW0L9q/SYv2VZFKSouSFolKm0hRvlmiEomorB+FRGQP2cbM3L8/rjm/M5jhYM6cWd7Px+N+3Ofc933Ouc4Z3x7f674+n+uzI4vjkuz0SFrB//ffYc6c2MYiIiIiIiKSzSJNjGcDNzrnTgMuBsZ57wPn3DHAA2nnJbeqXx8aNLDHTz4Z21hERERERESyWaSJ8X3A2cB0IBmbcwwwH6gJPJT1oUm26tPH9uPGwe7dsY1FREREREQkG0WUGHvv5wA1gGbACd7739JO3QTU8d7PjVJ8kl06dIBq1ezx5s2xjUVERERERCQbRVoxxnu/zXs/EyjnnDvNOZcATPDer49eeJJtChSABx6ApCR49dVYRyMiIiIiIpJtIk6MnXMdnXOLgeXANMABI5xzbznn4qMVoGSjq6+GMmXgpZdgtqaNi4iIiIhI/hBRYuyc6wiMARYCN6R73STgSuDBqEQn2SshAdq2ha1b4Y47Yh2NiIiIiIhItoi0YtwbGOa97wy8EzrovR8E9AGujkJsEgv9+9t+xgz488/YxiIiIiIiIpINIk2MawMfZXJuGlA1a8KRmKtaFU49FYLA9v/+G+uIREREREREoirSxHgDkJjJucS085JXfPYZlCgBf/8NZ50FqamxjkhERERERCRqIk2MPwSecM5dCBROOxY4504CHk0K71IAACAASURBVAVGRiM4iZEKFWDKFIiPhx9/hFdeiXVEIiIiIiIiURNpYvwo8AMwGtiSdmwyMBdYkXZe8pLGjeHtt+3x88/DunWxjUdERERERCRKCkZykfd+F9DeOXcOcBZQFkuQvwG+8N4H0QtRYuaqq+CPP6BXL7joIkuUa9SIdVQiIiIiIiJZKqLEOMR7PxGYGKVYJCd65BGYNw9GjoT69WHjRihWLNZRiYiIiIiIZJmIEmPn3BsHu8Z7f9ORhyM5TlwcDBsGU6fC+vW2nNNjj8U6KhERERERkSwTacX4XGDf4dIlgHLARmBWVgYlOUzx4tCvH1x/Pbzwgg2tjouLdVQiIiIiIiJZItI5xsdndNw554AxwDtZGJPkRN26Qc+esGULjBgBV14Z64hERERERESyRKRdqTPkvffA44DG1uZ1BQrA7bfb40fVhFxERERERPKOI0qM0/wDHJ8F7yM53cMPQ6FC1qn6t99iHY2IiIiIiEiWiLT5VqUMDscDVYEngEVZGZTkUEWLQvfu8NJLMG6cDa0WERERERHJ5SKtGK8CVu6z/QFMA+oAD0QjOMmBHn3UmnG98ALs2RPraERERERERI5YpF2pr2P/rtQBsBX42nu/NUujkpyrXDlrxPXqq3DLLTBkSKwjEhEREREROSKRdqUeFuU4JDfp0cMS42HDbFh1QkKsIxIRERERETlsmSbGzrmHDuF9Au/901kQj+QGtWtDnTqwcCE89JAlxyIiIiIiIrnUgSrGfQ/hfQJAiXF+MmAAtG8Pb7wBzz1n3apFRERERERyoUwTY+99VizlJHlVu3ZQtSqsXGnLOPXvH+uIREREREREDkuWJL/OuZpZ8T6SywwaZPuBA2H37tjGIiIiIiIicpgiXcf4KGxo9RlAYSAu7VQBIAE4BlvXWPKTjh3BOfAepk6Ftm1jHZGIiIiIiMghi7Ri/AJwE7AMS4q3A3OBYsDRaeckPxoxwvZ9+kCw74peIiIiIiIiOV+kiXF74DHv/QXA68BK7/0lgAN+BepGKT7J6Ro1ggsugOnT4eWXYx2NiIiIiIjIIYs0MS4LTE97vABoDOC9/xcYAHTI+tAk13j0Udvfcw/s2BHbWERERERERA5RpInxBqBU2uPfgQrOubJpz1cClbM6MMlFGjWCWrVgzx64/fZYRyMiIiIiInJIIk2MJwMPOeeqAkuBTcA1aefOwxJnyc/eesv2w4fDtm2xjUVEREREROQQRJoY9wKqAO957wPgaWCAc24tcA8wNErxSW7RvDnUqwfJydC9e6yjERERERERiVhEibH3fjmQCNyZ9vx54ErgE+A6733vqEUoucfQtPsj778PmzfHNhYREREREZEIRZQYO+euAQp47+eGjnnv3/fe3+q9Hx616CR3adIEGjeG1FR49dXMrxs8GBo2hI0bsy82ERERERGRTEQ6lHoosNY5975zrr1zLtLXSX4zahQUKwaDBmXcoXr+fOjRA375Bfr2zf74RERERERE9hFpgnsc0BsbTv0FsNo595JzrnHUIpPcqVo16NkT1qyBZ5/d+9yePdCxo1WUAd580+Yki4iIiIiIxFCkc4xXee+f9d43BhzwKnAWMNM5t9g593A0g5Rc5r77oGhR6N0bli7d+/gff0ChQnDKKbB9O4wZE7MwRUREREREIPKK8f/z3v/mve8DtAMGATWAPlkdmORipUvD2WdDEMCVV9qx2bPhpZfs8auvwnvv2eOXX45NjCIiIiIiImkKHsrFzrkKwMXApcBp2PrFg4F3sz40ydWGD4ejj4YffoBZs+DGGy1RbtsWbrjBrjnnHJg4EWbMgGbNYhuviIiIiIjkWxElxs65G7FkuBWwBxgLXAD8z3uvSaKyv7Jl4dJLbemmNm1s2PQNN8Abb4SvOeEE2991lyXHIiIiIiIiMRDpUOrXgHjgv0BF7/0l3vtxSorlgF5/HQoUsKS4ShUYMADi4sLne/e25zNnwtq1sYtTRERERETytUgT4+re+9be+7e891ujGpHkHSVKwB132OOrroJSpfY+X6ECNG9uQ6x79sz++ERERERERIi8K/Wf0Q5E8qgBA2DJEnjqqYzPDxxo+1GjbDknERERERGRbHbIXalFDklcHJx4YubnTznF5honJUG/ftkXl4iIiIiISBolxhJ7ffva/qOPYhuHiIiIiIjkS0qMJfYuuwxat4YFC2DZslhHIyIiIiIi+UxEibFz7hnnXK1oByP5WLduth8xIqZhiIiIiIhI/hNpxfgKYIFzbqZz7r/OuaMO9wOdcxWcc8Odc2ucc/84575yztU7wPXnOud+ds7tdM796pxrf7ifLTlYp05QsCD07w+pqbGORkRERERE8pFIE+OqQHvgN+A5YLVz7kPnXDvnXNyBXxrmnCsAfAokAhcAzYEtwGTnXLkMrq8DfA6MBE4GPgPGOOfqRvqZkkuUKgUVK8K//8KHH8Y6GhERERERyUciXa4p8N5P8N5fCVQEbgVKAaOBlc65p5xzNSN4qwZAM+A67/2P3vuFwFVACeC8DK6/A/jBe/+k936x9/5RYHracclrrr7a9gMGxDYOERERERHJVw65+Zb3/l/gC2As8DNQCUuUvXNutHOu4gFe/ifQAfDpjqUCcUCZDK4/HZi6z7Gpacclr3ngAVve6eefYffuWEcjIiIiIiL5RMSJsXOuqHPuMufcF8AqoD+wBGjjvS8NtAEaA59k9h7e+43e+y+89+knkd4OFAUmZPCSKsBf+xxbjQ3tlrymZEmoXdvmGD//fKyjERERERGRfCLSrtRvA2uBEcBRQHfgWO99N+/9NwDe+2+Bt4GTIv1w59z5wNPA8977RRlcUhzYtc+x3VgifbD3ftw5F6TfgOWRxiYx0qOH7YcMiW0cIiIiIiKSbxSM8Lq2wGvAUO+9P8B1U4B5kbyhc64b8CbwIXBfJpftBIrsc6wIsP1g7++9fxx4fJ/PPB4lxznbTTfB/ffD6tWwfTskJMQ6IhERERERyeMi7krtvb8f2BM64Jwr75xrkf4i7/1U732mQ6nTvfZhrLr8GnD1PkOr01sJHLvPsUrsP7xa8or4eLjzTti1Cz77LNbRiIiIiIhIPhBpYlzGOfcD8FW6Y02B75xzk5xzpSP9QOfcfUBfoJf3/jbvfXCAy6cBZ+xzrA3wbaSfJ7nQFVfYfvjw2MYhIiIiIiL5QqRDqQcAFYAb0h0bjyWtw4CnsM7UB+ScOynt2qHAm/t0sN6GdaguDaz33qcALwM/Oed6Ax8AlwOnArdEGLfkRs5BhQowYQIsXAh16sQ6IhERERERycMirRi3A+713k8OHUhb2/g74GHgwgjf51IgHrgOWLPP1hO4JO1x1bTPmAd0Ai7CloY6H+iYSaMuyUuaNbP9Y4/FNg4REREREcnzIq0YF2X/7tAh27BO1QflvX8IeOgglw3b5zVfYOsmS37SuzeMGQOjR8PUqdC6dawjEhERERGRPCrSivFM4A7n3F6JtHMuHugB/JjVgUk+d9JJcN55tqbx2WfDpEmxjkhERERERPKoSCvGvYCpwFLn3JfAOuBobIj1scCZUYlO8rexY6FVK5g2Ddq2terxBRfEOioREREREcljIqoYe+9/AJoBs7D5xA8CXYFfgBbe+xlRi1Dyr7g4mDwZGjaEggWhc2cYOjTWUYmIiIiISB4TacUY7/1crAmWSPYpXBh++glmzbKh1ddfD4sXQ58+ULRorKMTEREREZE8IOLE2DlXFKgLFAbi0g4XABKA0733j2R9eCJAgQJw6qnw9dfQsiU8+yx88QUMGwZNmsQ6OhERERERyeUiSoydc2cAHwPlM7lkG6DEWKIrCCA52R4vXGhLOt1/P/TqBUWKxDY2ERERERHJtSLtSt0X2IQNpR4DjAI6AK8CAdA+KtGJpNegAcybB23a2PPUVHjqKWjcGLyPbWwiIiIiIpJrRZoYnwz09t5/CowFqnnvx3vvbwPeQtViyS41alhDriFDoGRJOzZ/PjRvDtOnxzY2ERERERHJlSJNjAsAf6U9/g2baxwyCjglK4MSOaC4uHATrs6d4cYbYcsWOOss+PTTWEcnIiIiIiK5TKSJ8VLCybAHEpxzLu15PFAyqwMTOahjj4VRo+CNN2zN4/h46NIFBg2KdWQiIiIiIpKLRJoYvw/0d851995vAGYDA51z7YFHgQXRClAkIu3b29zjIIAePawpVxBkfv3OnXD22XDffdkXo4iIiIiI5EiRJsbPAEOAlmnPu2PDp78A6gD3Zn1oIoeof3+oVi38+IUXMr/2vvtsrvLAgbBjR/bEJyIiIiIiOVKkiXE17/1d3vvLAbz3s4ETgFPTzn0brQBFIla7NsyZA6edZs/vvTfjhlxffgmvvGKPd++GCROyL0YREREREclxIk2Mpzrnrkx/wHu/zXs/y3u/NQpxiRyecuVg0iSoXt2Wc+rQAdatC59ftw6uvRYKF4ZTT7VjQ4bEJlYREREREckRIk2MiwIbohmISJZJSICJE22/eTNcfjmkpNic46uusuS4d2946CG7fvJkSE6ObcwiIiIiIhIzBSO8rhfwsnOuDzAfWLvvBd771VkZmMgRqVEDVq2Cq6+2jtWPPQYVKoSHTSckQLt2VjnetQu++86ad4mIiIiISL4TaWL8ElAYGHaAa+KPOBqRrHTUUTB8ODRqBE8+acs5gXWjvvVWKFAAWre2ZHnwYCXGIiIiIiL5VKSJ8X+jGoVItJQpY4nwm2/acOpKleCTTywpBrj9dkuMv/rKhlrHxcU2XhERERERyXYRJcbe++HRDkQkagYMsIZca9fC119D6dLhc23bQpMmMGsWzJsHJ52092tXrIDHH7c5yaGloEREREREJE+JKDF2zl1+sGu89+8feTgiUVCyJCxaZOsVlymz97mCBeHuu+HSS2HMmL0T49RU6NjREubVq62qLCIiIiIieU6kQ6nfy+R4AKQAyYASY8m5ihSxLSPt20OhQvDBB9CrV/j4k09aUgw23Pr336FmzejHKiIiIiIi2SrS5ZqqZ7DVB24FVgPNoxKdSHYoWdIS48WLYelSO+a9DaEGOP542w8YEIvoREREREQkyiKdY7wik1MLnHOFgZeB07MsKpHsFBcHTZvC1Knw3HPwyis29zg11Tpaz5gBtWrB22/bsk8VK8Y6YhERERERyUKRVowP5FegURa8j0js3Hmn7T/7DAYOtKZbxYrB//5n1eT77oPdu8PXiYiIiIhInnFEibFzrhBwPbA2a8IRiZGOHaFwYVizBh56CI4+2uYXly9v56++2hp1ffSRDbkWEREREZE8I9Ku1L9hjbbSiweOAYoD92RxXCLZq0ABG049bRrs2gXvvQc1aoTPFysG558Po0fDVVfZ8k4iIiIiIpInRNqV+nv2T4wDYCswzns/KUujEomFu+6yxPjEE6FLl/3PDxliSzrNnm1b48bZH6OIiIiIiGS5SJtvddv3mHOuCBB475OyOiiRmOjUySrCrVtnfL5MGbj4YvjwQ7jySmvWpUZcIiIiIiK5XkRzjJ1zcc65fs65b9MdbgFscM71yux1IrlOp06WAGfm5Zdt2LX30LMnzJljTbkuucTmIe/enX2xioiIiIhIloi0+dZjwB3AxHTH5gPPAvc753pmdWAiOVL58uHO1B9+aMs5lSgBn38O774LN98Mwb6zDkREREREJCeLNDG+BrjXe/9E6ID3fl3a84eB/0YjOJEc6bnn4Mcf4fXX4ZZboEkTqyIDDB9u50VEREREJNeItPnWMUBma9TMA6plTTgiuUBcnCXDTZqEj23dCq1awS+/2JrHderAeefFLkax5bYKFYJatWIdiYiIiIjkcJFWjD3QKZNzHYGlWROOSC5VqhR8/TXUrGnPO3WCFStiG1N+FgRw9tm2PrWIiIiIyEFEWjF+ARjunCsLjAHWAUdjSfFlwA3RCU8kFylb1pZ7OuUUWL0a3n4bHn881lHlT6tXw7p1tm3fDgkJsY5IRERERHKwSJdretc5Vwp4FLgEW8M4DtgI3Om9Hxa1CEVykwoVYOZMG1bduzesXWvDqm+9NTwPeV+7dkHRotkbZ173ww/hxz/9ZH8PEREREZFMRDqUGu/9IOBYoDZwOlAfqOi9fyVKsYnkTlWqwOTJULUqvPYa3H47lCxpyfGWLbB+PYwaBfffDy1bWjWzVi34/fdYR553LFsWfjx5cuziEBEREZFcIeLE2Dn3H6C/N9OBBOB/zrk2UYtOJLeqXh0WLYJnn4WKFWHHDnj1VVsj+Zhj4KKLoH9/mDEDCha0dZETE6FbN7tWjsyvv4Yfz5wZuzhEREREJFeIKDF2zl0MjAXqpDu8Pe31E5xz7aIQm0julpAA99wDa9ZY1bJ+fWsKFR8PZ5wBkyZZBXnzZutgHQS23NPRR8PLL9vcWDk8M2faDQewmw4iIiIiIgcQacX4YWCQ9/7/15/x3i/w3p8FvAb0iUZwInnGmWdaFXPDBqsIT50KZ50FJUpA8eIwbhx8951Vk3fssOHXFSvCNdfAxImQkhLrb5B77Nljw9KTk61b+NatsY5IRERERHK4SBPjmsCnmZz7lL0rySKSmXLloHDhjM+1bAkrV1pS3LIllC8P77wD555rCd6NNypBjsSSJVZ9L1HCmm5t2mTzukVEREREMhFpYrwWaJTJuZOATVkTjkg+V7gwvPSSVY+XLbPlnypUsCrykCHQrBns3h3rKHO2GTNsX7Uq1Ktnj+fPj108IiIiIpLjRbqO8QjgMefcNvZfx7g38Gp0whPJx+LioEULqyKPHg1XXgmzZkHDhjB7ttbmzcy339q+fn3YuNEef/kltFGfQBERERHJWKQV4z7A/4DBwGogGVgDvAlMBHpFJToRgUKF4JJLYPp0qygvXmxrI2/eHOvIcqZffrF98+ZWbQe7oSAiIiIikomIKsbe+z1AV+dcXaAlUA7YAkzz3v8SxfhEJKRJE5gzB5o2hT//tM7WY8bY0lBxcbGOLudYvtz2p51mQ9D79rV5xyIiIiIimYh0KDVgnaiBBaHnzrm4tPWN/+u9Pz+rgxORfdSta0neU0/Zusg1alhX69q1wTnbmje35l1Fi8Y62uy3dSts2wanngoNGsCuXXZ83TpryKUbCCIiIiKSgUNKjEOcc8cC1wM3ANWApKwMSkQOoHJleOUVS/xeew3mzoWffrItpHhxaN0a2rWz7cQTYxZutgo12WrRwm4MhLZdu6zKftxxsY1PRERERHKkSOcYA+Cca+ucGw2swOYdrwNuBypHITYRyUxcHNx0EwwbBrfeaks7hcTHW3X0yy9t6afERLj88vyxZNGcObavWzd8rEoV28+cmf3xiIiIiEiucNDE2DlXwTn3oHNuGfAl0AyIB7p675t671/x3m+MdqAikoGTTrLq8erVMH48XH+9da1u3NgqpG++CTVrwgcfQK1a8P77ljTnVVOm2P7rr8PHzj7b9vPmZX88IiIiIpIrZDqU2jl3NnAzcAHWhfoz4L/AbGADkA/KTyK5RKFC4WHT6d1wA0yaBL//bl2sr7jCkuPnnrOljH7+2bo4//wzHH00DB0a7uScG4WS3+bNw8fuuceGnIeacomIiIiI7ONAc4wnAPOwZHiU934LgHOudHYEJiJZZMQIS3pfecWWe/riC9vSi4uzSvIZZ8DkyTaPObcJAquSg1XNQ6pXtznXqhiLiIiISCYONJR6LlAf6Ak8mLZUk4jkNvHxMHAgvPACJCVZcty0Kdx1l81RLlcuPLzae0uOV6yIaciHZdUq2L3bHteuvfe5hARYsAD27Mn+uEREREQkx8s0MfbeNwIaAJOAa4FfnXOzsQpyHp6kKJIHxcXBnXfC6NGWKHfoAAMGwDXX2LJPEybYur8AS5dCq1Y2/Do3CVWES5SAMmXCxwsUsPWMU1Jy33cSERERkWxxwOZb3vt53vueWNfpi4C/gCeAOKCPc+5q51zJ6IcpIlmiUyf49tu9E8eLL4ZzzoHPP7dGXWBDklu1gq++skrr6tWwc2fObtw1e7btTzhh/3NVq9p+xozsi0dEREREco2Ilmvy3id77z/13l8AVAHuA8oBw4C1zrlR0QtRRLJU48bQo8f+x48+2jpbn346PPIIrFljzbzq1bM5x8WL25rApUrBUUdB2bI2DPvYY+GCC2DQIFiyJHbJ86JFtr///v3P1a9v+2+/zb54RERERCTXOFDzrQx579cBzwHPOeeaYsOsL8nqwEQkBmrWhG++saHXzZrZ0OtNm2wo8vbtsG0bJCfb8GSA1FTYssWqzZ9/bseqVYP27W195VBCmh0WLLC5xJdeuv+5Fi1g5Ejrvi0iIiIiso9DTozT897/CPzonLszi+IRkViLi7N9lSrwv//BX3/tf83HH0PXrva4enUoX94S4pQUWxbp9ddtO+88eOABaNky/NrkZJg7F6ZPhxo17JrQZx6upCRYvBhOPjmctKcXWr7pjz+O7HNEREREJE86osQ4xHu/OyveR0RykE2b4KabbG7xrl227dxpVeLjjgtfd+65MG4czJkTPlaiBFSqFF4aqnlzOPts+OEHS4j//Td8bdeu1gCsfPnDj9V76zg9b55VtUvu0/qgTh2LaetWq3wnJBz+Z4mIiIhInpMlibGI5EGtW9t2MK+/bvOKly+H776DadNs2PKzz9o85GeescR5+nS7vnZta+x12mkwZIhd++239rhDB7smCCzR/uQTmDULunWDK6/MPIZQR+r4+P2TYrBEuFs3W8t50SKbZw2wfj18/z20bQvFikX2u4iIiIhInqPEWESOXFycdYM+4QRbAqp/f2vQFRdn85Z79LDh1JUrW7X4zz/ht99sPvPzz1uzr44d4dprrXL8ySeWaIdMnmzDugcNgtKl9//8ULW6Ro3MY6xXz/bffQe//goffWTvm5ICV10F77yTdb+HiIiIiOQqESXGzrnmwCzv/Z4oxyMieUH65aAGD4ZRo2xLr3hx6NsX7r3Xul9fcw28/badK1kSLr8cLroIEhPh+uthxAir7r7/vjUGS0mx9ZfffBPGjrXXnXJK5jEVLmz7u+4KH2va1IZXv/uuLVsVqliLiIiISL4SacV4JPAA8G4UYxGRvKhXL1tHeOZMqxhXq2bPq1ULX/PWW3DGGdC9OxxzjA21njfPhlsXKmRV3j594MknbTmpyy6DqVNh1Sp7fbVqVoVu1CjzOELLSB1zjFWv4+PhpJPgwgstob7pJutsnT6pFxEREZF8IdLEOBnYFs1ARCSPio+HG26wLSM7dsCXX9rQ6urVbV3krl2t0/SsWTYfeOtW+OUXqz737QvvvWdV5ZtvtvcdNQr69bMmW5kJJc3r1tkyVAArVtgw7sces33PnjBsWJZ+fRERERHJ+SJNjPsCrzvn6gPzgbX7XuC9n56VgYlIPlG8uCW9vXvDc89Z5bdhQ6vqlipl14waZcOlx46FLl3g4YftdeXKWeK8ezcULWoV4MzUq2dDsvfssUp0s2Z2LAis03ZCAgwfbkn5eedlz3cXERERkRwhLggNLzwA51zqPofSvygOCLz38VkZWDQ4544Hlk+ePJkqVarEOhwR2dfGjVCkiC2ttK+pU+Gee+Cnn8LHWreGKVOO/HO7dbOkuEABqFjRhlQfdVTm12/dCh98YEl1166WoIuIiIhIzK1atYqzzjoLoLr3/o9IXxdpxbjN4QQlInJIDpRgtm4NP/4IH35oQ6/r17d5yVlh4EDrkL1iBaxeDXfcAW+8YUl6egsXWmfsd94Jr8V8++3WtOuaa6B9+3CTLxERERHJNSKqGOcVqhiLSKa++86afhUubPOb4+KgUqXwMlR//hmuTlepArfcYonz8OHhdZTLl7ch4DVq2Fazpm3HH2/vJyIiIiJRFe2KMc65WkBvoDVQGtgAfAf08d4vOpRgRURynNNPhwcfhKefhlq1bEj1smW2RNR339k1Z55pS0stW2YV4sqVbfmnceNsTeQPP4QxY/Z/7+OOs3WaO3a0Kve+lehIBAFMm2ZdtZ07su8qIiIiInuJdI5xfeB7YAfwOdZ861igI5AANPPez4tinFlCFWMROaCkJGvKdfnllvDGxcHzz9uw6T174LPPwtXhAQPsmr//tgpynTo2V7lePdi1CzZtsqHZCxbYestbttjrSpSwYeFHH20Nv0JbpUo2JLtChb1jCgL44gtb9mruXDvWqpV15O7c2ZqOHYqUFPj6a0vik5Ph/PMt2U9IOJJfTkRERCRHiHbF+BlgMdDGe789dNA5lwBMxrpWXxBxtCIiOVHhwvDpp9blOjT0uX9/WJvWiL9QIeuKfe210LatHfv3X7jgAuuYfffd4feKi7O1mx97zJLqJ5+0dZenTrUKc0bi4mwodpculvQuXgyPPmrvExcHF19sDcomT4Zvv4WyZeHqqy25Pe00KFYs4/cNAkuqR4ywpmFr1oTPvfOOJdft2kGnTvbZSpJFREQkn4m0YrwNuMp7v98YQedcZ+At732ZKMSXpVQxFpFDEgTw668wZ45Vk7t0sXnEGdmwAT75BJYsscRzzRpLRCtXtseVKtl1VarAqafCySdbdfnoo20t53nzbFmq6dPtc9Pr3NmWs6pXz57//jsMGQJvv23rMoMl9aeeatXoBg3gjz9g0SLbFi6Ef/6x68qUsQT7yistkf70U9sWLrTzp5xiyXvJkpH9RklJFvPu3eGbBSIiIiIxcrgV40gT47XATd77zzI4dyHwjve+VOThxoYSYxGJiU2b4N13rcr77beWRIeMGmWJL1hzrxIlYNYsG7ZdsqTNe27YEOLTVsT7+murFNeqZctLTZhgr5s6FX7+2dZkTi8+3hqAnXwyXHpp5p2zvYc+feD99+Hcc60CnlmH7aVL4X//g6++ss8OdegePdqqziIiIiIxEu3EeAxQARtKvSvdgnYxqwAAIABJREFU8WLA18AW7327Qw06uykxFpGYCwIbIh1Kkp9/3uYV//tvuEqbkAC1a9vjxYstWe3Y0Z5XqQJ//WVJcY0aVkXu0AEuusiS4mnTrEpcvbq9x4kn7p/g7tplXbX37LE51c2b2/JXYIntuHFw1VXWcTt9N+2NG215qvffDx9LTLSmZMOGWdzz5sGxx0blpxMRERE5mGjPMX4Q+BFY7pz7HPgbqIg13yoFnH5I0YqI5FdxcZaw1q5tDbRCkpPh8cfDQ59//dWuTUwMV4GDAB54wBp6hbb0Q6Gfe86S5A4d7P3WrIGffrK5zXPnQteuVjkuWtSS8mXLbLg3WFLbtCnceiusX28V7kqVoF8/O//55xbv339D48Zwww02dDo+Hq67zpLvjRvh+uutWZiWpxIREZFcJKLE2Hu/yDnXHOiFNdkqC2wGvsGWa5ofvRBFRPKBo46yRl0hKSm2Dw2hBks2e/QIPw8CWL7cktvQcOwgsLnGP/2U8bDqk0+2x99+C9u2wYwZtk2fbsOiO3e2inGLFvDMM1C6tFWt33nHkt9+/azJWMGCMHIk3HRTeP7yySfD+PEweDB07561v4+IiIhIFEU0lDqv0FBqEcnzVq60OcJHH23DrqtUgapVbZ7x6afbHObMrF0bXi5q+XIbYv333/a8cWMbLl23LmzdakOqhw+H4sXhhResM3dKig3J3rnTKtRabzl7/POPNVtr2DDWkYiIiMRctIdSi4hIblC1qg3HPhyhpDglxYZlP/aYdb/u1Anuv9+qxGCNt4YPh0aNrFqdPgF+8UVbQurKK60KXajQkX0fObCffrK/z6pV9nufdlqsIxIREcmVlBiLiMje5s+3hDg+3pLgqlXhkUds/WbnbK5ySootX5W+sdeWLZZMlykDs2dbF+wmTaBUKRuSXbq0DbeuXDl23y0vGTHC5nrvSuuJ2a8fjNlvVUURERGJgBJjERHZW4MGtoxUp042LDspyeYuB4HNO46Lg8su2/91pUvDOefAG2/YnOnRo23bV/Pmllx36WJJtxya5GSr4D//vN10aNUKvvnGlvhauBDq1Il1hCIiIrmOEmMREdlfhw7w4YdwxRU2PPeWWyyZPZgBA2DyZFvreMAAW1Jq1y6rJm/cCBMnWhI3fTr07GmNwlq3tspy48ZQrdqRd7ROTrZlo6ZPt0SxSxdbUiov2LLF/g4TJ1r1vnJlW8u6YkWbD96/v80FFxERkUNy2M23nHNHA8cC8733qQe7PidQ8y0RkUOUnByeWxypGTOgZctwV+x166wZWHIy9OoF7dpZwjpyJEydunf37PLlbbh11aqW7IW2+HhYsgS8D287d4bPV6gAxxxjS1D98IOtC51ejx421Dgh4Yh+jpi76SZ48037DXfssO7iZ51llfnTToPffrObEtWqxTpSERGRmDjc5lsRJcbOuZLAi8Ac7/0g51xX4D2s4rwYaOu9X3U4gWcnJcYiItlk9Gj45BPYsAG+/NKS688/t+7VYB2yb77ZkrqFC2HWLJuXPHu2dVg+kPh4q0SXKGGdtNeutaQ7pHZtW26qRQtLmu++2z6jZk1rGta8edS+dlTNmWNV9cREG0I9a5b9nh9+aGtTv/WWzTm+4w5rgiYiIpIPRbsrdT+gKzAp7fkzwC9A37StP3B5pB8qIiJ5XOfO4bWVQ9q3tyrx66/DpEnw3XdQrhycdx689hoUK2bXbdtmw4LTb7t3W0LoHJxwwt7drlNTYfNmS5ArVoSyZeGvv+Dddy0p79vXhlUPGGAJ+d13w1132bW5RRDYEllBYMnvgw/CVVfB0KF202HzZnj4YShSxCrKjzxi1XcRERGJSKSJ8QXA3d77D5xzjYDjgXu995875woBr0UrQBERySMKFYKLLrLt998tgRs+3IYDFy1q18yZA++8Yw3Aate25l+lS+/9Pt9/b3Npt2yx5C+0HXMM3HabXbNqlSWPYJXrl16yz+nWDZ591pajOuMMuOQSS+CPOebQvsvu3dbsauRIS+TBklawSvYjj9iQ8Kzy4Yf2vS+8EO65B9q0sfcvUMDOlyljv9fUqfb8lVfg8cez7vNFRETyuEgT43LYkGmA/wDJwIS055uAYlkcl4iI5GU1a1qH66efhjVrwg23Pv/cktj0jj3WKsVTptjznTvtuoycc44liI0bwwcf2NzmK66wauudd1riPXw4fPSRJZFTp8Ktt0KzZhbTcceFt0qVLOEsU8YqsQA//2xV2hEjYNOmzL/fF1/YcOabbz7yZmLbt8O991oM/frZsUaN9r+ue3f7PkWLwssvWwJdosSRfbaIiEg+EWli/AdQH/gO6ATM8N6n3SLnP8DyrA9NRETyvAIF9l7X+IEH4OyzbU7wokXh7eefrUJcurQ19lq92pLezZth/Xqby7xhgy0TBTYP+dJL7fEPP8B//mOJavXqliTfdptVlUeOtCT5++9ty0zRopZkbthgzytUsGS1Wzcb2g3hBHjyZLj6auvk/c03NnS8VCk7FwTw669Wbd69G84/3zpyhyq/GenXz4aG16lj3+ObbyCjPhkXXmg3ETZtsm3IELsZICIiIgcVafOtO7B5xcuAWsBl3vuPnHOjgAuBHt77wVGNNAuo+ZaISD71zz/w5JM237hIEUusCxWy5BosSV25ElassO2PP2zO8j//WPL9zz+21akD111n86XTz3MO2bTJOmLHxVliPn06nHgiPPWUdev+9FNYvs+95MqVw3OyW7TY+32XL7cKeOnS1t27USNrupVZFfrxx6F3b/uOCQm2HnXr1lnwA0quk5oKL7xgN5oaNIh1NCIi2SaqXakBnHOXAa2AKd77j9OOjQAme++HHnLEMaDEWEREAGu+9cILcNJJtsZx69ZwyilWiT2Uoc9ffWVDs3//3bbNm+34rbfaPObHHrP50CElS1qzsU6drAo9erQNCw+9rnBhS74bNLDYJkywz2jY0KrmX31l864z89dfNgy8YUP45RdLjvr2hfvvP3BVWvKeKVPs33aTJvDjj7GORkQk20Q9Mc4LlBiLiAgAw4bBe+/Z8Oldu8LHmzWzKi9YZXbWLOv6XLCgJZYLFsDGjTbPGGwo9sUXW0Jbo4bNU/7tN3s+bZolwhMmWBfu1q1tearQfOWQPXtsbvCYMZbAzJ+/d0z168O8edYsbMqUgyfu8+ZBvXpWob74YkuW//Mfa2pWrtwR/nCSa9x6K7z6qj2eOROaNo1tPCIi2SQ7KsZXARu89+OdcycB7wJVgZHAbd77pEOOOpspMRYRkb3s2mUJ5PffW4X1uOOs0gtW7e3TZ//XFC1qQ6aLFYMdO2yOc5UqNq8ZYOtWG05dqZI9T0kJnwtJTc28gpuSYtXnX36BJUtg7FhLmL///tDWYN6zx4Z/X3mlJefVqtl85WbN7HseaVMwyblSU22I/oYNtsb3VVfZjRERkXwgqusYO+fuxtYq7gWMBwYDxwDDgG7AZuCBQwlYREQk5ooWtaWP2rTZ/1zXrjasOTk5vB1/PJx2WnjN5eLFLclMr1SpcLOtWbOsQdfgwVa5nTbN1m9u1cqWVAKYO9eS1AYNbB8fb124nbOk+913oUOHQ0uKk5NtyHbDhpZY9+tn848vv9zOly1rnbsbN7a1nVu2jF0H6yCApKT9K+ly+KZPt/W/r7vObqh89JHd8DnUZclERPKRSLtS3wD0994/mVZ1bQbc6r0f7JxbDDyMEmMREclL6tWz7UjMmGEdts84I3ysWDFLrkN697Yu1VWqWCJbrpxtDRpYd+sFC8JzkCO1bp01EZs40YZmv/++dcCeOBFmz7ZtwgTbwBp+nXqqDfU+80wbdhtaWzpadu60Za8GDrQK+cCBcP31qmRnhU8+sX3XrvZv6vbbrUv5Qw/FNi4RkRws0sS4OlYpBjgPCICxac8XY9VjERERSe/2221I66efWoJy+ulw8sk2BznkmmtsLvL48TBuXPh4hw6WGBcsGO6eHalKlWxe6WWX2fuedpo1+br33vA1mzZZRXvKFPj6a6syTptmiXrhwpYct2xpMdeqZRXIP/+07t0rV1qlt3ZtqFvXtvLlI4tt5Uqb+/rGGxZDfLzdLLjxRqtuDhpklXg5PKmp1o38qKPsJkfz5pYQDx4M991n/55ERGQ/kf7XcT3h5Pc/wGLv/aq05ycBf2d1YCIiInlCly62ZaZTJ9uCALZts3mhGzce+dDio46yRPuBB2wYbdOmlqCHho2XLQtt29oGVpX+5htLlKdNCyfK/fpF9nnHHGPvGQSWnIX2SUk2lzu0JSfb9eXKWcJ2yy12rGtXa4r2009W8UxMPLLvn1/9+KOt0X3NNXaDo3BhezxokN0c6dw51hGKiORIkSbGY4FnnHNnA+2xodM45+7C5h2/FZ3wRERE8om4uPD85BNOyJr3jI+HZ5+1ztY33bT3kOy777bh26efbtXsMmXgwgttA2si9sMPNid6+XKrQlerBlWr2j4lxYaJL1xow70XLrSEvkAB+y5xcfa4SBH7TkWL2laqlCXBl10WnqsNloTfdZdVkxs3tviSk62qvHGj7WvXhu7dbf61ZGzUKNtfdJGtx12pknWoHjTI5rUrMRYRyVBEXamdc0WBl0hbxxi4w3u/xzm3CJgF3Oy93xnVSLOAulKLiEi+tXy5DXcuWdKS3jJlrKIL1nireXNLkrt0sQQ0Vt5/35L47dszv+bcc+G222wZKq3PHBYEdlNl40ab337yydCunc1hP+ccmDzZ5pzXrRvrSEVEoiaqXam997uAmzM41SA3LNMkIiKS71WvHn5cqhQsW2bV4NAWasZVpUo4MX79dXveoIENid6xwxLWypXt+OH6918YPtyGe19xRfizLrzQOme3bGlDqsuWta1cOYv5f/+Dl18Ox1q9ulWvt261bds22L0bTjoJWrSwrXlze4/8YM4cqxJffrmt071nj3Ulf+896NHDEuNXXrH5xmCJ9O+/2293yilqfCYi+dqhrGNcFLgWaA2UBjYA3wHv5IZqMahiLCIikqn16204c7NmULGiJcKlS9u84H09+WS4w/G119ow6sRES5ZDieyJJ1oFGuDXX23bts3WZn77bdiyxRLwBQtsbnObNrb01bhxB+8G/ssvluCNGGHdrUuUCA9Dj4sD78PVcICaNS2BrlTJkvpKlWyI999/w5o1tv/7b4u/c2drfBZacitkzRpLzGfNsu966qlWkY129+5D8eCDNid85Ehr/LZjh/0tX3wRzj4batSwOewPP2zD5GfMsOdgzc8GDbIO5fvassUad5UoYX/7nPSdRUT2cbgV40iHUpfFhlDXB34H1gLHAicAi4CW3vtDXEsi+ykxFhERidCePTB1qlWTlyyx+cDFi0NCgg3PPfNMu+788y1h3LNn79d36GDVSrBE7KmnwueOOcbmvf73v/Y4CCzhevRRS0g//jjcFCxk925L2tIPnU5Otuf7DqfeutW6ck+bZp2uf/klnABmpmDBcGOwwoUtkezY0Za9Gj/e3mNfhQpZctykic17rlnTbggcd1zGCWY0BYEl7GvWWDX+oovsNx44MPz79OtnyXPIccdZRX3RIvj5ZxtuPXKk3RAJ+eknuPhiG2EANh995Ej7rpK5bdugZ08b/dCtW6yjEclXop0YvwF0BM733s9Kd7wpMAYY473vfqhBZzclxiIiIlGQnGxLOf39t81v3bjRKpXt2tn5WbMs8SpZ0uY2t26dcdftDz6wCnRysq1p/OCDcPzx9rxYMTj2WEumr78eKlQ4tBh377akcfVq+Osvq4hXrGjvWbGixbVokTWvGjVq70S4cGFbi7p9exue/fvvVnGdORPmzt3/pkB8vFWmy5a19w0NCa9WzarhdevaXOD4ePtuc+fCt9/aNm+eNR+74AKbQ12mTGTf79dfbcj7xRdDnz6WEN94oyWyAGvX2jXz5llC3KyZVc7BhrZffrndyKhbF774wmIdNMiaoCUl2d9i40ZbZqtkSRg61JLvWBs2DB5/HL76Kuc0Zdu50/52U6fa8+eftyRZRLJFtBPjtcBD3vv9uk87524A+njvK0UebmwoMRYREcnhpk+3pHDDBmsadf75drxzZ5tXvH27VWO7drUkuXlzSzCz2tKllmxVq2bDvBMSMr5u1y4bDv7777b99pvtV660LuDbtmX8uqJFrbq8fLklpiGlS9vQZbAqdqtWlmQlJlpCe9xxe1d0Q3r1gieegI8+suQ4vaQkq/Bu327D3jO6qZCSYknwSy/Z+SZNbFh7+fI2RzlUwX/vPbj5Zhum3aMH9O2bcTzZYfFimxu9c6f9e/j449jEkV5Ski2/9uWXdiPl55/thsyzz8I998Q6OrNhg/27a9Ik1pGIREW0E+OtwEXe+wkZnGuLVYyL7f/KnEWJsYiISC6waZMlPXXr7p10bd0K77xjSzotWmTHli616uvmzZY0liwJjRrZ/OZWrSxxyu5hzent2WOxbdxow5Hnz7dtwQL7jscdZ9XoVq0s5ipV7Pxnn9k2e/b+71m6tM3jTkmxinNoWav4eBv2XrXq/q95+WWbd9y5s83N/vdfq9qXLLn/dXfeaXO0W7WyLuGVK+99zcKFloguXGjPK1aEWrWsYnvCCXYzIDRve+1aG+Z9//3W8TyrGnwlJdlNkZ9+ss//+29LQhs0yJr3PxzJyVZ5HznSRkuMGWMjKdq0sVEKTz2191D2WGnf3qY/jBsH550X62hEsly0E+PvgSXe+2szODccqOe9bxR5uLGhxFhERCQPCAJr2DV8ODz3nCWJGzbYHNmNG61aG1K8uA3RDlWev/jC5jWHKrOhrXZtqFMnNt/nQP76y+Z5r1gR3v780xLhQoWsqhzaLr3Ukt4yZWx+dfq516mpNoT9u+/Cx/r3h3vvtcdz51o37/h4mDLFbjzcdJO97+7d1sCrfHkbxg5Wfe7XD3780Zqd/fmn/V32VaRIOIE/+2xLvGvVOvLf5ZFHbF76NdfY927f3kYajBlz5O99MHPnWlKZmGi/2Ykn2m99/fU2tLtVK5uXXry4Xb90qc3J//NPG+b+6KPRjzEzS5aEh5yXL283E/a98SGSy0V1uSbgSWBcWhOuD4G/gYrAZcB5aXsRERGR6IuLsySvdevwsfLlLWEBWLUqvAzVt9+GG0WlplrVcvfu/d+zb99wYvzss5bonHOOVXyXLLGtWTNbQxksoSha1JKjaK6lXLmyJX6RmDHDkq5LL90/pgIF7EZC9+6WwJYoYV2qweYet2hhFesPPrAKZ5s2di4IbCj311/b84UL7fdJSLCh2yE7d9ow8j/+sJsOFSpYJbd0aRtaftttNjT9pJPgrrsssS1RIvPvsnGjzU2vU8eGs6c3fTo8/bTNPx840KreLVpYhX3WrMMfIrxggQ0Pv/XWzOdPz5wJZ5219zrbRYrY32nZMvvssWPDSTHY7xzqvN6rlw1jfvHF/TufZ4fXXrN9u3ZWNb7ySpg0KTrTEURymUNZrula4Ckg/cSUtcDD3vuhUYgty6liLCIiko8lJVnzqKVLbbjvUUdZ4la6tA3LbdzYEsGKFWHduv1f36OHVTzBEuSJE60626SJNbmqX9/eIysqoofjhhvgrbdsLvY550T+un/+sQTpiy9sKPSnn1oCG/LJJ5ZETZ9uleQrrrDmW4ULR/4ZQWDV3DvvtMppiRLhRmShbfPmcBOy+fPtdfHxNjz5vvvs+m3b7LdevtySzdCSYFOmWFW2XTur1mb0+ZD5UO7Nm+3vuHSpXfPmm+HqeMiiRfZ5mzfDCy9YJXzePLuxsGCBDdsfOzbzdbP//NOq2j//bMn+0KGWZGeXHTssgS9SxGK59FL7Wz/+ODz2WPbFITlTENhSeueee2Tr1OcAUR1KHeKciwMcUBbYDCz23kf+BjGmxFhEREQOavVqSy6/+caqkYmJttWrF+7k/PbbVkWdMcOSqZAuXSyRBBtq/Nln4WWujjnGEs/ExHBFcuVKG/Ycmne8fLnNEa5b16qq+84Bzsy//1qH7bJl7T0OtYqdmmoJ0hNPWLxnnGGNttIneZs22TJcM2bYUlaffXboc4Z37IBnnrF5uL/9Fl4iK71ixcI3KsaNs98FbD5soUKWYD/wgFWN0zvzTEuQv//eXh8ya5YNuS5e3F677/8HTEmx7zN+vN0gGD/eKtYvvgh33GHXrFxp77lqld18uO66/X+/9L/5woXWBK15c6vShs4lJdkQ8CeftM+95RYb0n6g6nlWeestu3nyyCP2d9682W4yrFpl/5bPOCP6MeR0u3bZ33zWLJg8OfKu8HnBxImWFF97rd20ycUONzEmCIIj2hITEzskJiaOPtL3yY4tMTHx+MTExGDlypWBiIiISJbYtCkIvvkmCF5+OQjGjg0fv/XWIChUKAisFhPeatQIX/Pqq3ufK17c9gULBkFSkl2zdGkQNG0aBPfeGwTjxgXBP//sH8PQofa6xx47su8yenQQlChh7zVo0P7nt28Pgg4dguD99+15UlIQbN26/3WpqbYdyO7dQTB/fhB8/HEQPP54EDzzTBDMmGHHQ1JSguDzz4OgefPwb3TyyeFrtm8PgvvvD4InngiCadPs/Jln2rnk5CB46in7LUOvrVIlCH79de84HnnEzrVta6+ZPz8IKla0Y088EQTr1wdBrVr2/JlnDv4b/vBDEJQta9ffdlvG18yeHQR169o1J5xg3zuaUlPtdytQIAj+/DN8/PvvgyA+PggqVbLvmZ/99Zf97yz0b2Xw4FhHlL26d7fvXbNmrCM5YitXrgwSExODxMTE44NDyBWzItm8IzExMeVI3yc7NiXGIiIiku2SkoJg8+YgWLjQEtvRo8PnvA+CgQODYPLkIPj7b0tg1q8Pgh9/DF/z2Wd7J3cFClgyVbt2EKxZY9cMGRIEcXFB8McfRx7vsmVBMHVq5ufTJ7yzZllMFSoEQcuWQXDZZUHQokUQlCkTBKtW2TWbNgXB6acHwfjxRxbXd98Fwe23242ClJQg2LnTkvJKlYKgSJEg+O23IGjXzuIZPjwIzjjDHleqFASTJllSC0FQqpT93kEQBJ9+Gk5ON24Mf9ZvvwXBcceFvxsEwT33HDzGiRODICHB/kavvRb+rVJS9n7/IAiCXbssqY+Ls79v//52XTT88IN9h06dwsdWr7b9U0/ZubPOCoJt26Lz+TndjBlBcOyx9jt06WJ/k+bNYx1V9klNtZtGof/GhP67kkvlysQ4MTHx9cTExCEHuWZk2hdLv006zM9TYiwiIiK5z7//WtL18MOWgFasGATly1syHQSWhF59dfbHNXt2EJx7bhBUr27JYChxT0wMgrlz7ZqRI8PnOna0pPNI9e4dBI0aBcHKlUHw4Yf23u3bB8HMmeH/cx9KBDdsCL/u/feDoHBhq+Q/+WQQlCxpVfpfftn/M1auDALn7H26dTt4BfyTT+y9ixSxhDu9++8PguOPD4LFi/d/3eTJ4Qp1+/ZBsG7dwb//1q12M2TixIPHFQRBcNVV9v4TJtjzXr3sBsGCBZaMd+hg5xs02LuinB8MHWp/twIFguCFF+z3PPts+z2y4t9qbvDTT/Z9QyNcPv441hEdkcNNjKPYRjFzzrk451wf4KYILq8HPAAcm27rGsXwRERERHKWhARb7qhvX+u2vWYNrF9v3Z/BmioNH579cTVqZN2mly2zztTLl9s8Yu9t/irYfOo5c2wZo7Fjbf50jx42j3tfQWBzXseNs7m348fvvwzU2LHWLGrDBusMfvHF9tuMH2/LW112mc0nfuMNGDXKlvMKuewy+9yEBHj4YWvm9dZb1mwsJcWajG3bZtdWqWLzlT/5xJpxheZT//qrzRHu08fmZa9da8dXrLCGZOPHw4UX7v2dEhKsY3eLFjB16t7f58wz4ZdfoG1be22DBrbPaP71v//aHO3q1W2+8Dnn2O86ZUrmf6MNG+Cjj2xu+3vvwY03WvOvrVttGbPNm2H0aLj5ZoujaVNbhis/GDbM5osnJNi/4zvvtL/zVVfZ+ffei2l42eazz2zfvbvtp02LXSyxdChZdEbboVaMExMTT0hMTJySmJi4PjExccWBKsaJiYmFExMT9yQmJrY50jgDVYxFREREYic1NQg++igIqla1qtQVV4TPDR8eBG3ahOfmhrb0w1lTU63iWqpUEBQrFgRz5oTPLV5s1a5q1WwO9s6d4XPbtlml/ZlnwtXV+fODoHFjm0McMm+eDYM+8UR7nJG33rKKcPoYf/45fD40fDwjQ4bYfN4CBWwu+J49e59PSbEY4+PtfUuUCIJzzgmCPn2C4Ouvbah1+fJ2rnRpmxvdsWM4jjZtbJ71vkJDyB96yD67YUP7HR5+OPy6pCQ79uKLdk3Rova3yss2bbLfs0SJIFiyZO9z27bZSIITToisIp/bNWxoVfP16+3f98knxzqiI5KbKsbNgGVAfWD5Qa6tja21vCjaQYmIiIhIFMXFWXV3yRLrgnznneFzH39sVc8yZayzd58+VuV89tnwNd2723JJW7fCkCFw8snhc87BPffYMkQTJ1olGawKWK+eVXgHDLDqKFjVetYs69AcUq8edOtm3bJPPRVGjAifS021z7/+eqtGDx9uXYunTAmvBw1Wuc/M9dfbUlRVq0Lv3rZUU1JS+HyBArYs1YwZVtWtUsW+S69eVlW+7z5bV/vxx636/MQT8PnntrZyu3YWS8uWtm73f/9rle7162HwYOv0/ddf9j0eeMD+Fn36WGV7yhTrxBwXZ/uxY6379yWXwPPPR/jHzYVCow569YITTwwfX7HC/t107mwjIaZPj12M2WHFCltC7MwzbT34Jk1s5MDWrbGOLNsVzOyEc+43IJKlmI46lA/03o8ARqR9xsEurwckAb2dc+2BncBIoK/3ftehfK6IiIiI5ABFi0KbNnsfGzHCErNSpTJ+TWrBQVxDAAAgAElEQVSqDcdev94S4Msv3/+aRx6xZZeaNbPllnr2hHfftbWQb7rJEvGM1hgeOhQ6dbKk/JVXLGG95hpbumnGDEsOQ2s2n3SSrf17wgmH992bN4e5cy3xrVw547WgmzSxDez7TptmQ7rLlbPlnY7a5/96N21qQ6+//95inTQJXn/dtpDLL4cPPrAkvksXO1aggP0+LVta8nzuuZYo/+c/lgy2bw93323remf0e+dm8+bBq6/a8PLQklxgw+JbtbIbLM8/b0Op333XhsDnVWPH2v78821/+un2b27GDBven49kmhgD3xNZYhxNdYE4wAOvYFXm54GqwDUHeqFz7nFAq5WLiIiI5HSlSx/4fIEC8MMPVt067riMryle3JLipCSb+7xiBZxyis0hDs13Bli0yKqFb71lW8+eNqd59Gg736mTVZS7dIFBg6BgQVvT+MUXrWKbkHBk37VMGVvHOSXFnqemwr332vqx9ertfe3RR1s8nTod/H1btLAtORlmz7YEedIkm/ddtKj9LvfdZ98npEQJm1/65pu2RnVIvXqWbLdoYXFVqWIJY14QBJYMp6TY3zT9zYmnn7akGKyKeuyxNnLhxRfDoxDymtD84vSJ8dNPWy+DfJYYxwX7NjTIRs65qcDv3vsbMjlfADjKe78p3bFLgA+B8t77jYf4eccDyydPnkyVfRd3FxEREZG84aWXLBHs2XPvRBBsSPTgwVY9XbrUkp/vv7eGVult3w4PPWRbqMlZNEyYYAlIqOlT795w/PFZ9/47d9p3LFYsnCQfyKZN4cr65Mk2TLtECasi166ddXHFyiefQNeuNrrg88/3PpeUBO+8Y4nhmjXW4Ozll+01oUp7XvLPP3bzpWFDm1oQOla2rN0I2bdRXC6xatUqzjrrLIDq3vs/In1dpnOMnXOHNWbAOXf64bwuI9771PRJcZp5afuqWfU5IiIiIpKH3HGHVWH3TYoBBg60ucRLl1oCMHHi/kkxWGX4pZeimxSDdZb+4guoX9+SssREGzI9c+b+HbkB1q2zxC0x0b5LyKOPwtVX2/zr9evDx4sVs2r7228fPCl+6SWbb7tggT0/6yx7v3/+sSHWoQ7cudWO/2PvvsOjKtM+jn9nMpNeCSWh94OAooAaARVQEAREUbFh1/XVVVfWhrrqKu6uurqr69pd1q6Luliw0cUFCx2lHEpIpAUS0vu0948nGQihDJhJQH8fr7lm5pwzM/dMIpn73M9zP+VmeHhkZN3505mZ5joy0iTD115rTijUDu1/443Gj7UxfPGFGWFQWy0GM1T/uOPM719VVdPF1gQO1HzrOcuy3rUsq/cBjgmyLOtEy7I+AJ5tmNDAsqyplmVN22tzf6AK2NBQryMiIiIivxIulxlC/dZbpgraq1fTxuNwmKRz2TITU7t28MILZo5zLY/HxDphgtl/771mWasWLXYf88UXJoG7/nozL3jwYJM4b9kCPXqYyu/BNGtmKsYjRsDmzWbblVfubvg1erQZdv2HP5jq9mmnmSZojz22u7HZkeyxx8xQ6dtvN03KwHzmllV3aaarrzYnVy6/3Cyf9emnplHXL03tMOqxY+tuP/VUqKw08/p/RQ40x7g/8EdgcU0jrg+A7zGdpMswTbfaAgOBswELeAY47Nn5lmVFAs2AfNu2q4H3gXcty/o98BFwAvAE8IRt26WH+zoiIiIi8ivmdB55DaVqY7rwQjO8urJy99rJ99xjumqDGc58002mOrxns7K5c00S/OmnZr70V1+Z4bEdO5o5wqG4/HLIyTFzkc86yzRhatbMdG7OyjLr/i5evPt4h8N0sJ40yXTJvuYak1Du2an7SFG7NnabNubEApjPp3Yd4379dh+bnm7mFYP5TO64w8w1/u1vGyaWigpTyW9K1dVmHnmHDma0wgcfmIZby5aZz+Sf/zTzjE85pWnjbET7rRjbtu2xbfs+oAvwJXA9MB34EZMcL6u5fxkwG+hm2/bdtm3/nJr7AGB7zTW2bU8FrgKurnndJ4GngQd+xmuIiIiIiByZ3G4YNarunFafDy65xCxztWoV3Hxz/Q7e8fGmMnz77WbO9Nat8MQTpgFXWVnor3/HHWZu9po1pnt4drZJgF96yVSkX33VJOGZmWao7Y4dZlmtlBQzH7dbN9PR+r77TBV26VIzhLmgwCRi998PZ565e8juo4/ubngVDmVlcMMNZk6x32/ml8fHmyr8tdeaBPE//9n3/OlAwFTFnU6TKNr2z4vF44ELLjDD85cv/3nP9XPNnw9FRaZaXFZmTgA8+aT5HYuKMsd8/XXTxtjIDqn5lmVZPYDOQBKQB2Tbtr0uTLE1ODXfEhERERE5CL8fbr3VdOW+6SZzfTAej2lS9eSTsGTJwY/v2tUkxLVrOZ96qlk7OSbGVK1zckzSXVpqlpQaNcpUNmur6KH4/nsz/Hz9evPYt94y12Cqx3ffbYaev/TSvh8/YoSpoo4bZ04IuFxmjegHHzRr/h4Kv99U+WvXx+7Vy1Tfm6rb9S23mGR/1iwzJ/2SS6B/fxPT3XebtcULC80QcueBZt8eeQ63+VaTdqVubEqMRURERERC9J//mMZMhzrsd8cOU3FevXr3JSICMjLMWs4nn2yGaBcUmCG8b71lhn4fLC9p187Mxz79dJOYJiWZynNSkmkitW3b7suqVWautt9vquiPPLK7Erppk0lMExJMnPta3xpMdfuRR8xa18nJZoj5hg3m9e67zySXoSS2gYA5wfDCC2Zo8jHHmOecOLFuE7ADKS83ay+fe+7u+dGHY+1aM9T+ySfNZ7NzpzkhMW2aGVo+aJCZc3388aYZ3A8/1F9G7AinxDgESoxFRERERA7Dq6/unn8aGWmSzMhIk1webB3qUGzeDJ99Zp43Lc0MN05LMwn1zJlm3xdfmOZgoWrXziR3gwfX3V5YaOZFn3bageeaZ2VB584mmV2wwFS3n38eHn7YxJGcbKrJl1xihp1HROz7eSZNMo2/+vQxSyC53WaN7XXrTMXWJHH7l5trhoJ/953poL5kiRm6HqrsbNNw7oMPzEkKMDH85S+mYt6ypUm2f/zRzC2fMcNU1O+6y7zf//u/0F/rCKDEOARKjEVEREREDpHPByeeaBLjvY0dCx9+aG57PCbhChev1ySHS5aY+bFFRSbJLSw0SWmbNubSurW59O9vGmv9HLWJ4qpV0LOn2VZQYOZVv/66mcsNJpEfP97Mm27VavflrbdMdbl7dzNnt2VLc/z335vqeXq6qcomJ+/79TMzzZDu9evNHPK1a03V/JNPQhvivHq1OQGwa5c56TBihJm/PmaMec233jLDzR96yDRZe+opU8mePNlUzC+9dPfw76PE4SbGB+pKLSIiIiIiv3YREabS+cwzZuhtdbVpvFVdbebN1jr/fFPdPP98GD780OcEH4zLBQMHmsvhKCw0VeeLLgo9ruuvN4nxK6/sHvackgJ//rMZZv2//8E778B775nPZ1/atzeV4dqkGOCkk0wi+uCDptv1vpLPpUt3rx99zz2mUj1qlKmeP/KIefyBZGaadbJ37TIV4BtvNI3H9vTTTyZhHj/e3B81yrynjAwzXL22AZfPZ+Zb//e/Zt7xSy813fzoMFHFWEREREREfp5AwKxz/MUXZu4qmETwjDPgqqtMogwmydy82TTVSkw0Q4Nrl5Ryhblmd9NNZmjw66+bLsyhqK42Q7L79TMJ6f54PGa4dXa2SWRrL2DWgd7XvGCv1yT5338Pf/+7GWrt95skdOtW0wCtrMysR33zzeYxu3aZYdi1Q8/3tz711q2modmmTWY+8e9/v//YS0vrJ8wA551nRgNccQV8+eXu99OmjZmbnZCw/+dsQo0+lNqyrBOAdsA827aLD+tJGpkSYxERERGRMNq50yRRM2eaKun27WbY8R13mP2nnALfflv/cSNGmOWcwFx//71JmDt3No2gDjcJ8/tNMv7cc2b4cc+eZkh4ZGTozzFrlql+t2pl7nu9DZfEr19v3l95ef19UVHw9ttmHvOeFi82CXVcnKkqd+xYd39urmlQtmaNqUj/8Y+HF1vtsGqAFi1M469x42Do0EP7/BpZWIdSW5aVDrwJzLVt+xHLsm7GrCfsAHItyxpi2/bqQw9bRERERER+MVq2NNXYyy83VeS9uz7fc48Z0hwfb+bqZmWZquYJJ+w+Zvp0k8jWcjhMF+lBg8x2h8NUcp3OAyeoX35philv3Gjun3iiGRJ9qEndmWfuvj1jBtx2m+nYXbv006FautRUdMeMMes+z50LH39shqzveRk50lSR99a/v1lC6/rrTaL6u9+ZYc0xMSaZvuce87lPnGgS4/2ZPNkk1RMm1B1anp1tqut9+5rh4/36mUR8f83FfiFCqhhblvUGcAZwNTAT2AqsBO4EngGKbdseE8Y4G4QqxiIiIiIiR7gtW0xil5VlOjcvWmSqpD17mkoymAT3hhtMIp6ebpp+7dplku2dO00St3ixGU58ySUm0evf/+fHNnmymdsbHW2WgTrnHPO8B2qEVVxs5h/fdZcZJt25s+lq/eWXprJ7uK691iz7tC/XXWfmAe9vLnVBgamA9+5tEvU9lZWZkxm11fWjTLibbw0HJtq2/aVlWYOAVsDTtm2vtCzrceDoalUmIiIiIiJHprZtzWVPXq9p+lSrWTNTQd62DWzbzPFt3tx0oy4tNUtI9e8POTkNs5xUrfvvN52nr7oK/vQnc2ne3CTLt9xijlmzxsQbE2OWQLrlFpPsN2tmGmC9+qqZj33OOaap2Z7V8kPx4otmeHNeHlRUQGWlubRqZeI7UIOxDz80n1lt0609xcWZTta1Q+HT0w8vvqNMqIlxArC55vbZQBUwp+Z+FWZItYiIiIiISMNzucy6xrXGjas79zYQ2Hci2JBJca2xY81w45kzzXzozz+H2Njd+6+4wlSra7ndZkjzNdeY+8OHwxtvmEr2iBGmade+mnPV+u47M8e3c+e6210uMxz7UOXkmOQc9p0YgxnGPWuWaaZ29dWH/hpHoRAWvwJgHXCaZVlu4HxMw63Kmn0TavaLiIiIiIg0voZcFioUiYlmWapXXjHV4D2Xrbr4YjO3+Zpr4De/McOR//hHM/+31kUXwT//aYZ9Dx9uKrN7W7XKdIbOyDDzhmu3XXqpqRAfjiefNBXg+fPNOsp7J9u1Ro4017UN0X4FQq0YPwa8jplTHA/cDGBZ1ndAP+CSsEQnIiIiIiJyJHM4TFW41u23h/a4m24yifGrr5rh32CWknruOdMgbMEC01X7lFPMsWCWdXrnHTN8+qOPzHDtA5k+HaZOhddeM3H27w9nnWU6S1911f4f16MHdOhgquJer2kWNnu2SfInTtx/Qn0UCykxtm37HcuyfgIGAV/Ztl3bY30ucJ9t27PCFaCIiIiIiMgv0oMPmq7SKSnmfk6OaYbl8Zi5zI88YuYj11bEn3vOJNOffGLmF3/0kWkEtrfCQtM9+7XXTNI+caKZy3z66aE1/HI4zNrHlZVQVWUS5OuvN/syMn6RifHPWcc4Aog7WtYwBnWlFhERERGRo0BVlaka72uIeFUVXHCBqQYPH26S6wEDzD6/33S7vv56U+Xt29ckx717/7x4srLM855wglmm6mCV6iYU7nWMXcA9wEbbtt+2LGsw8D6QYlnWLOAi27YLDzlqERERERERqWvP+cj72vf++6b52GefmS7UtYnxxInwj3+YKvHkyXD33XWHeR+ujh3N8li/YKE233oIeABIrrn/DJAPTAR6AH9p+NBERERERESknqgomDYN3nvPrFlcq1UrM/R60SL4wx8aJin+lQi1+dYlwD22bT9nWdYxQC/gKtu2X7csaxfwBHBjuIIUERERERGRPURGmiHVe7r33qaJ5Rcg1Ipxa+C7mtujAD/wWc39LUAYFggTERERERERCb9QE+NtQMea2+cAy2zbzqu5PwCTHIuIiIiIiIgcdUJNjN8G/m5Z1heYJZumAFiW9RTwR+CNsEQnIiIiIiIiEmahzjG+HygDTgMm2bb9fM32vsBjwCNhiE1EREREREQk7EJKjG3bDmA6T/9lr+2nhSMoERERERERkcYSasUYy7KcwEXAMCAduBXIAJbYtr06POGJiIiIiIiIhFdIc4wty0oCFgBvAoOB4UACcBnwrWVZJ4QrQBEREREREZFwCrX51l+B9sAJQHfAUbP9QmAVmmMsIiIiIiIiR6lQE+PzgHtt214JBGo32rZdAjwKnByG2ERERERERETCLtTEOBbYuZ99lUB0w4QjIiIiIiIi0rhCTYwXAzfuZ9/FwNKGCUdERERERESkcR3KOsYzLctaAnyKGU493rKsPwBjgBFhik9EREREREQkrEKqGNu2PR+zTFMlcC+m+dadmIZcY2zbnh22CEVERERERETCKKSKsWVZA4BvbNseaFlWDJACFNu2XRrW6ERERERERETCLNSh1O8Bk4A3bNuuACrCF5KIiIiIiIhI4wm1+ZYXKAlnICIiIiIiIiJNIdSK8SPAi5ZlHQv8COzY+wDbthc2ZGAiIiIiIiIijSHUxPjFmuuHaq4De+xz1NyPaKigRERERERERBpLqInxkLBGISIiIiIiItJEQkqMbdv+KtyBiIiIiIiIiDSFUJdreuAAu/1AKbABmGHbdnVDBCYiIiIiIiLSGEIdSn050BaIwnSozgNSATdmfrGj5rg1lmUNtm07t6EDFREREREREQmHUJdregCzdvFFQLRt262BaGAssLNme29M0vxoGOIUERERERERCYtQE+OHgHtt237Ptm0/gG3bAdu2PwH+ADxi2/Zq4M/A2eEJVURERERERKThhZoYtwGy97NvO9C+5vY2IOnnBiUiIiIiIiLSWEJNjJcDt1mWVWdOsmVZEcCtwA81m3oDmxsuPBEREREREZHwCrX51iTgSyDTsqzpQC7QEhgJtADOtizrFOCvwOPhCFREREREREQkHEKqGNu2/TXQH5gHjAHuBoYDc4Hja9Y5jgEm11xEREREREREjgqhVoypaa51xQH2zwHmNERQIiIiIiIiIo0l5MTYsqwWwB3AYEyDrTzga+Ap27Z3hCU6ERERERERkTALaSi1ZVkdMA24bgWKgEVAJXAbsNyyrHZhi1BEREREREQkjEKtGD8OlAEZtm0Hu07XJMQzgUeByxo+PBEREREREZHwCnW5pmHAA3smxQA19x/CNOISEREREREROeqEmhgDlOxnezEQ2wCxiIiIiIiIiDS6UBPjxcD/7WffjcDShglHREREREREpHGFOsf4AeBry7KWA/8BcoA04CKgF3BWeMITERERERERCa+QKsa2bX8LjAQ8wCPAv2quq4Gza9YwFhERERERETnqhFQxtizrQmCebdsnWpYVCyQDRbZtl4U1OhEREREREZEwC3Uo9XOYOcYf2LZdDpSHLyQRERERERGRxhNq861dQFw4AxERERERERFpCqFWjJ8HnrMs63TgR2DH3gfYtv12QwYmIiIiIiIi0hhCTYz/XnN99X72BwAlxiIiIiIiInLUCTUx7hTWKERERERERESaSEiJsW3b2eEORERERERERKQpHDAxtizrN8BtQAdgI/CsbdsvNkZgIiIiIiIiIo1hv12pLcu6AXgBcACfAF5MA65HGik2ERERERERkbA70HJN/we8C/S0bfti27b7Yppw3WxZlqNRohMREREREREJswMlxt2AKbZtB/bY9iyQiJpxiYiIiIiIyC/EgRLjGKBkr21baq4TwxOOiIiIiIiISOM6UGLswKxPvCd/CI8TEREREREROWoowRUREREREZFftYOtY3ylZVln7nHfiakiX2NZ1og9tgds2/5Lg0cnIiIiIiIiEmYHS4xv3M/2m/a6HwCUGIuIiIiIiMhRZ7+JsW3bGmYtIiIiIiIiv3hKfkVERERERORXTYmxiIiIiIiI/KopMRYREREREZFfNSXGIiIiIiIi8qumxFhERERERER+1ZQYi4iIiIiIyK/awdYxBsCyLD9mreJ9CQClwAbgadu232ig2ERERERERETCLtSK8e1ANbAaeAi4EfgjsKxm/5tAJjDFsqyLGzhGERERERERkbAJqWIMZABfAONs296zcjzZsqy3gWTbtsdblvUXTBL9bgPHKSIiIiIiIhIWoVaMRwEv7JUU13oVGFtzewZwTAPEJSIiIiIiItIoQk2Mi4Ee+9l3DFBRcztqj9siIiIiIiIiR7xQh1K/A/zJsqwq4L9ALtASUymeDPzbsqxE4BZgUTgCFREREREREQmHUBPjSUBz4NmaSy0/8DpwN3AeZi7ysIYMUERERERERCScQkqMbdv2AFdalvUwMASTJG8FFti2nQlgWdYXQBvbtivDFayIiIiIiIhIQwu1YgyAbdsbgY372VfQIBGJiIiIiIiINKKQEmPLsqKBe4DRQBz1m3YFbNu2Gjg2ERERERERkbALtWL8NHAdMA/4ETO3WEREREREROSoF2pifAFwr23bj4UzGBEREREREZHGFuo6xpHA9+EMRERERERERKQphJoYzwBGhjMQERERERERkaYQ6lDqN4GXLctqDiwEyvc+wLbttxsyMBEREREREZHGEGpi/EHN9VU1l70FACXGIiIiIiIictQJNTHuFNYoRERERERERJpISImxbdvZ4Q5EREREREREpCnsNzG2LOsl4M+2bWfV3D6QgG3bNzRsaCIiIiIiIiLhd6CK8TDg2ZrbwzHziPfnQPtEREREREREjlj7TYxt2+60x+2OjRKNiIiIiIiISCMLdR1jERERERERkV+kkJpvWZYVDdwDjAbiqJ9QB2zbtho4NhEREREREZGwC3W5pqeB64B5wI+AP1wBiYiIiIiIiDSmUBPjC4B7bdt+LJzBiIiIiIiIiDS2UOcYRwLfhzMQERERERERkaYQamI8AxgZzkBEREREREREmkKoQ6nfBF62LKs5sBAo3/sA27bfbsjARERERERERBpDqInxBzXXV9Vc9hYAlBiLiIiIiIjIUSfUxLhTWKMQERERERERaSIhJca2bWeHOxARERERERGRprDfxNiyrJeAP9u2nVVz+0ACtm3fcKgvblnWi0CEbdvXHeCY/ph1lE8AtgKTbdt+/VBfS0RERERERGRfDlQxHgY8W3N7OGYe8f4caF89lmU5gIeA3wD/OsBxLYAvMfOXr62J6V+WZeXYtj3jUF5TREREREREZF/2mxjbtt1pj9sdG+oFLcvqjEmGewM/HeTw64Ai4He2bfuBtZZl9QXuwCwhJSIiIiIiIvKzhLqO8QFZltX1EA4/BcgEjgU2HeTYU4H5NUlxrXnAQMuyGiR2ERERERER+XULqfmWZVnJwCPA6UAk4KjZ5QTigJZARCjPZdv2W8BbNc97sMPbAsv22rYNiAWaAXmhvKaIiIiIiMgvjT/gJxDYPavV4XDgdKh+eDhCXa7p78BlwOfAMUAZsA4YBLTAzBUOh1igcq9tVTXX0Qd6oGVZfwQeDENMIiIiIiKyH4WVheSU5pBblsvOsp3klucSCATolNKJEV1HAODxeaj0VuIP+PEFfOba76PcU06nFDOjs6iyiDmb5lBaXUppdSllnjJKq0sp95Rz1fFX0bNFTwDunHEnVb4q0uLT6ly6p3YnPjK+yT6HUAQCAb7Z8g2REZH0b90fgDmb5pBdmE331O6c3PZkXE5XvcfM2TSHZxc9yyfrPsHr9wb3TR4ymT+c9gcA1u9aT7ukdkS7Dpg2SY1QE+ORwIO2bf/FsqzbgdNt277Isqx4YD7QK0zxVQBRe22rvV92oAfatv1H4I97brMsqyMHH74tIiIieyiuKsbtdBPtisbhcBz8AT9TIBAgQGC/VY9AIMD20u1sKtiEO8JNcnQyKdEpJEcn445wB49buWMl2YXZFFQW4PV7g5d2ie0YY40BIKc0h8LKQlrEtqDaV822km1sK9lGSXUJlx57KQCl1aVkFWbRKbkTcZFxAFT7qimqLCIlJgWX04U/4GfxtsX4A/56ly4pXWiX1A6A77Z8x66KXcF9ydHJtIxrSVp8GsnRycHY/QE/ZdVlFFcVU1JdQnFVMZXeSk7rcBoAuWW5zNg4g1h3bPByfNrxJEQlNPwP5CiTV57HpoJN9G7Zmxh3TL39u8p3MX3ddGZtmkX3Zt258cQbaR7bvAkiDY0/4GfVzlUkRSfRPql9U4fDpFmTKKkqweP34PGb5Da3LJeLel3E9f2uB+Cy/17GZ+s/q/fYk9ucHEyMX1n6Cjd9dtM+X6PqD1VERkSyuXgz46aO2+cxg9oPCibGb//4NttKttU75so+V/Lqua8CsCZ3DSkxKaTFpx3ye96Tx+dhbtZcPlr7EZmFmVzU6yKuOv4qAEa/PZrZm2YT644lzh1HXGQcSVFJDOs8jMlDJ9d5nl3lu3hj5Ru8tOQl1uSt4d5B9wYT42e+f4YP134IQHJ0MsM6D2NE1xGc1eUs2iS2weP3cOl/L2Vn2U56tehFq/hWweftmNwxeHvc1HFkF2YztsdYRnYdSddmXemS0oVmMc1C+rd8a/FWnlj4BOkJ6fRo3oPTOpxW59+pX5pQE+NmwMKa26uA2wFs2y61LOtJTGX29w0fHpuB9L22tQZKMU25REREDovP76O4qpiUmBQA8ivy+WHHD/gCPrx+Lw4cuCPcuJ1u+qT1CVYdKr2VIZ99X5O7hmlrp7Embw1tEtowpvsYBrYfCMDmos3kV+RTUl1CSVUJJdUlVPuqaZPQhiGdhgCwImcFbRPbkhqb+rPf7+aizWQXZVNUWcSpHU4lMSoRj8/DA3MfoKiqyFwqzXVBRQG/P+X3XHPCNQCc/dbZLNi8AAcOol3RxLpjcTldnNbhNKZeOBWAJxc+ySNfP0JkRCRREVFERkQGL0t+s4QIZwQb8zdy25e3cVzL4zi57Xio9FwAACAASURBVMmc1Oakel9SF25eyIXvXUhOaQ4tYluQFp9Gq/hWtIprxWNnPkZ6QjplnjLa/K3NPt/no2c8yt2D7gbg/6b/H99s+abeMSO7jgwmxi8veZkH5j1Q75hYdywX9bqICGcE3235jjPfOBOAlOgUKr2VVHgrAFjz2zX0aN6Dal81J79y8j5j+tvwvzHxlIkA3DnzTr7+6et6xwztNJTZV8wG4I/z/sjDXz1MYK9FP2LdsZTda+oCa/LWMGHahDr72yS0YfYVs7GaH3SqWoMp95RTUlVClCsq+LOPcNafXRcIBFiVu4p5WfOYmzWXDfkb8Af8vD3ubY5tdSwAJ718Eu4INwmRCSREJZAQmUC5p5yLel3EececB8DYd8fSPKY5tw+4PZgU7enFxS9y+4zbKfOU4XK66NOqDxltM8hom8Flx16Gw+Hgrpl3MWX5lOBj/vy/P3NlnyuZmDEx+NllFWYxc+NMZmbOZN2udQzpOIRxx4xjQLsB+3x/P0elt5Kswiw2FWxiU+Emc7twE5OHTKZH8x4EAgH6vdQPj99Dn1Z9GGuN5dwe53J82vF1kptAIECFt4LCykKKKosorCyksLKQCGcEwzoPO6STWl6/ly83fMmszFl8lf0Vz4x8hoHtB1JUWcQLi1+gqKr+1/AOSR1Iik5i2fZl5JTk0CWlC1ERUUS5ooh2RRPtiqZNQhve+eEdOiZ3xIGDwR0HU+4pp6y6jHJPOeWecqJcUdzy2S20TWxLQlQCV/W5CofDgdfvxeP3UOWtosJTwXOLnuPxBY8HT3w1j21OYlQi0a5o3E5zgiw1JpWiyiKSopO49YtbmZU5i0t6X8LTI56mRVyLQ/o5fbb+M95b/R4frf2IgsqC4PYeqT3YXLSZbSXbSIhMoHV8ayp9lZR7yimoKGCdd12dvxkzNs7g+cXP8/n6z6nyVeF2ujm9w+mUVZfx5MInAUiLS2N8z/GUVJewKncV761+j/dWv8fZ3c7m00s/JTIikieGP0FWgfldKagsMCfRqkp4ZP4jPLHwCcYdM45T251KaXUpb658kzdXvhmM4YHTHuChIQ8d8P2WVZcx5p0xLMvZPav122u/5eS2+/537pcg1MQ4D0isub0BaGVZVjPbtvMxyeu+/zr9fP8DrrYsy2Hbdu1fhyHAgr0acomIyBEkEAhQWl0anOvkwIHD4SAqIgqHw0FpdSmfr/+c3PLcOkPtcstzuf+0+xnaaSgAE/47gZ+KfiLGHUNafBrp8emkx6dzQvoJwcrZ2ry1bCnegtPhJC0+jc4pneslrjvLdjIrcxYzNs7gmy3fkFuWS0FlAc1jmzPz8pnsLNvJDzt+4I6Zd+zz/bxz/jt0bdaVVnGt6Px0Z2LcMbSKb0VafBrtEtvRMbkjY7qP4ZR2p+D1e7l/zv1MWzsNe5dd53lSolOCifG4qeNYvG1xvdca1W0UfdP7UuGt4N/L/81Haz/i8wmf06N5j0P6GXh8HhZuXsin6z/ls/WfsSp3VXDfUyOeom1CW8o8ZTy64NF6j411xzJ11VSWbV9GQWUB+RX5pMenEwgE8GMqnV6/l8yCTJ5Y+AQup4tlOcuIc8fh9Xup8FRQWl2K1+/FF/DxybpPcDldZOZnMn3ddKavmx58rfZJ7WkV14q5V84lLjKOGFcMxVXFpMenU+2rxt5ls2LHCgAy2mSQGJ3Imtw1dEjqYH7HcBDhjMDhcBAIBJi9aTYrdqwgrzyPrSVbSY5KpspXVef9zc+eT4u/tqBZTDOcDiftE9vXSUKrfdWUe8pxT3bTLKYZbRLb0K1ZN3wBH5XeSpKjk4lxxxDjiuGDNR+QGJlISXUJGW0yglU0v9+P0+HE6XQyJ2sOa/PWBr/Y92zRE4/Pg9fvJTIiErfTTbw7nv+u+S/p8ekUVhbStVlXHDjwY4aX1iY1A/81kEqfmWXWP70/CVEJxEXGUe2tZkbmDM54/Qzsm+1gZXt/AoEAXr+XKl8VO0p3MD97Pl9lf8VX2V/x+WW7f9/e/fFdRnYdSVJ0EgAlVSWs2LGCQe0HAfDfNf/l8mmX13nu2ir4rMtn0S6pHUu3L2XEmyPILc/d/TvmiiXCGcG6XetIiErA5XBh59mUVJfUOyFgpVqM7TGWokqTjE1ZPoUpy6cwqtso7hxwJ4PaDwomq7Xvu11iOzx+D8tzlrNk+xJmbJzByK4j+XbLt/gCPrqmdCW3PJcWsS0oqS7hxSUvUlhZyLsXvIvX76XPC30orioGwOVwsWLHCp767qk6w1RnbDQLpNSeAOrarCst41oe9HPfWLCRrs1M39pvt3zLgH8NqPeeAQa2G0isO5aEyATuGHAHy3OWB3+/H57/MG0T2zLtomnBKmPLJ1qSV16//c7QjkM5vcPpRLn2HoRZX1ZhFq8sfYUpy6awvXS7ef9OFw9/9TBbS7YG/x2JccWQEpNCakwqURFRrMtfF/y5HMybP7x50GNeWvrSQY8BcDqcwREjAQLkluVSUl0S3L9ixwqe+f4ZhnUZRovYFhzX6jje+fEdZmycwdMjnubSYy8N6YSB1+/lntn3sHLHShIiE7BSLQIEyK/I56nvnuKp75464OP/99P/uPC9C7n5xJuZsmwKH679kK4pXenZsicrd6wM/r+3L9GuaE7vcDot41pyZqczmbpqKlNXTeXT9Z9S6a2sd2xiVCLFVcU8OO9BHDgY1nkY155wLTGuGLYUbyGzMJPj044HzO/jvKx5wZOxtfwBP1d+eCXLcpbRp1Ufuqd2p7S6lAWbF7AhfwPdUrtxUpuTDvq5HW0ce07W3h/Lst4AugLjgS3ATuDPtm3/3bKsx4CLbdvucKgvblnWPGCDbdvX1dyPxFSn823brrYsqxVgA/8BngLOBJ4ERti2PecwXq8jsGn27Nm0bdv2UB8uItIoPD4P1b7qg36xDadAIMCCzQv42P6YTsmdGNxxMD2a9wjpC8SSbUsY/954Mgsz6+2bd+U8SqtLWbFjBffNuW+fj28V14oWcS2IdkWzeudqyr3l9Y45pvkxjO4+mmhXNF9u+JLvt31fZ3+HpA70a92PD8Z/AMDdM+/m8YWPA+ZLrMvpwuv3Uu2rPuj72Zvb6SbKFYU/4KfCUxH8QvvIkEe4c+CdeP1eej7bky3FW3BHuOt9cemY3JFjmh/D9tLt5Ffk4/F5qPKZCkiVrwp/oP5538SoRD6++GNO73h6yHEu2rqIk14xX1wcOPb5xbupOB1OWse3JsoVRV55HiVVJVzf73qWbl/Kom2LQn6epKgkHA4HRZVF+3x/ce44msc2Jyk6qd6w7EpvJbvKd5FfkY8v4KuzLzk6mVZxrWge25ydZTvZVLipzhy+puRyuoh2RVPlrcLj99TZlxiVyD2D7mHSoEn1HpdblssbK9/gphNvwu10s7l4M52e7lTvuKiIKDokdyAxKpGzupzFn77+EzGuGC7sdSFev5dpa6YR4Yzghxt/YM6mOazcsZJvNn9DgACBQABfwIzEKKgsYM4Vc2gZ15KcshyGvT6MlJgUSqtLySnN2e/7c+AIVotj3DF4fB6Kq4oprCwM/ozT49OJcEawpXhL8HGLr1/Mmyvf5MUlLwar+Xs/796/I+2T2vNTkVk5tFNyJ3574m+5LeM2iqqKuGH6DazLW8e6/HVUeitpGduS1omteXjww8HRBimPpVBYWVjnZzPWGssdA+4go21GcLvP72N+9nze/fFdpq2dRm55LlsmbqFNYhtKqkoY9sYwoiKiKPOUsbV4Kzll+/58WsS2oEfzHsS6Y8mvyGdN3hpuP+V20uPT2VS4iTdWvkFZdRkV3op6/7ad3OZkpl4wlayirOBJxb1V+6pJfzKd/Ip8YlwxpMamklOaE/zdj3HFMKDdAJwOJ3nleeSV55FbnkuVtwqruUXf9L70TetL3/S+dEvtRoSjbmW9oLIgWBnPKswiqyiLxMhEuqV2o3tqd7qndqdTcifKPeXklOawvXQ7OaU55FfkkxiVSEp0CikxKcFEOCUmhYTIhHp/l2qHdm8r2cbMzJl8sOYDlucsByDCEUFG2wyWbl9KhbeCs7udzb/O+dd+h1dnF2bjdDgZ/c5oVu5YWWdf7f8rrRNakx6fTuuE1qTFpxEfGR+slEdFRLGzbCcvLnkxeIKvR2oPujbryuxNs6nwVhDtiubS3pcyuvvoOnOJfQEf3235jk/WfVLnxGatHs17mNEUPc6jXVI7EiITglNJiiqLmLpqKv9e/u86o2Zqf66pMamkxqaSGJnIh/aHPDHsCW4fcHvwuPdWvcf498eTEJlQ50TDnnbdtYtmMc32ua+pbdmyhTPOOAOgk23bWaE+LtTEuDPwFZBp2/bplmX9HngCyAWaAw/btn3gevy+n3cedRPjwcBcYIht2/NqtmUA/wCOA7Ixc53fPdTXqnmujigxFpEDWJ27mo/WfmSG0tb8sXXgoEVcC37Tz/QZrPJWEeGMqPMHLBAI4A+YCtHef6Q9Pg87y3ayo2wHO0p30K91v2BV4e6Zd7OtdBt55XlsK9nG9pLt5JbncsuJt/CXM/9CXGQc3235juTo5OAQP6/fS3ZhNu4Id3C+2cf2x6zIWYHH7yEQCJAUnURydDLp8emM6j4qGOPBEtvcslxeW/Earyx9pU61M9oVTeHdhUS5oiitLqW4qpjWCa3rPd4f8DPxi4n84/t/HNLnDhAdEU2MO4YoVxTVvmozXHWPxPNQxbhiGNF1BJsKN/Hjzh/rJDYOHLRLame+jDXrTlp8GhXeimCDl9pqZ4w7hugIMwQwMiKS7KJslucsZ1Ph/ttVOB3OYHLbPLY5Z3c7mxPSTmBj/kZW561mde7qOolBVEQUqbGpNItpRmJUIjGuGGLdscS4Y/ip6Ce+3fItYKpW/z7330w4bsI+XxfMzw/ghcUv8OKSF9lashUwyfzQTkPp3bI3ce44YtzmNaJd0fW+vDodTpKik2gW0yz45TPWHUuFp8IMefSUUVZdRqW3Mjjs3Ov3BiugB7sUVBawYPMCvt/6fb1kM8IRweCOgzmvx3kc1+o4dpTtCM753V66nXh3PD1b9AxeWsa1xOFw4A/4KakqobCykJLqEpKjk0mNSd3n/NK9BQIBiquK2VWxi8iISFrEtqhXWav9f25D/gayi7KDn6nL6cLldOGOcBMfGU98ZDwJkQnER8YTGRFZp6GQL+DD7XQHK82x7lgiIyLJK88juyib7MJssouy2V6ynWYxzWid0Np84U5Ip2Vcy+DPq/bfHX/Az/aS7cHHLtq2iL9/+3dSY1L5csKXHNvqWNbvWk9qbCpPLHyC5xY9R4W3InhSKCoiCl/Ah8vpIhAI1Kmqu51uApiKcozL/D9ZmwC2iG1BQlQCWYVZ+zyJczDxkfEMaDeAns17BivWVb4qqrxVlHnKgsP5iyqLKK4qJsYdE/xdrP0SPjNzJuUec8IsJTqFKl8VHp+p1LdLbMekQZO4oOcFbMjfwI87f+SHHT/wY+6PREZEckrbU8hom8HJbU4mJSaFpduX8uj/HuX91e8TIEDrhNbsKN0RPFnSo3kPjmt1HJ+v/zyYIGS0zWCsNZYVOStwOpxEOMyIhSXbl7AqdxUvjHqBG/rfwLaSbTz2v8eYunpq8P/55jHN6dGiB71b9GZT4SaWbl9ap5KeGJVo5s4270m5p5ziajM8tqiqiJ+KfiKzoP4Jxz1FRkTSIakDnVI60SnZXJbvWM67P75LfGQ8pdWlTDhuAg8Nfoh5WfOYtnYaZ3U5i5tPuplVO1fx289+y+JtiynzmCH7/dL7MbzLcM7sfCYD2g3Y5zQSr99brznUkWZj/kY+WPMBU5ZNwd5l0zKuJa3iWpFXnsea364hKTqJkqoSMx3AFYXH5+HuWXfz7KJnSY5OZmfZTs7tcS6D2g2iR/MeHNPiGDokdQh5WH0gEGDh5oX8c9E/eX/1+3j9Xjold+KmE2/i6uOvPuh0mcwCM9rmq+yv6NWiF+N7jadXi14hnaxem7eW15a/xpLtS9hVYU4G7irfFfx9rk1+/zHiH9xy8i0AeH1e+r7Ulx92/sAVfa7guhOuq9PvIDUmlfN7nh/Se28KYU2MASzLigF62La9rOb+pcBA4Hvbtl875IibgBJjkSNXta+aal/1frtHev1elm5fSpw7jl4tTb+/rcVbiY+MDw7x+7mqvFX0fr43G/I31NuXEp3CLSfdQtdmXbHzbP78vz8T647F4zfJQO0XxIcGP0RKdAol1SU8/NXDOB3OetWLCcdOoHNKZ6p8VTy76FlKq0sBkxQ4HU68fi8BAkS7ohlrjWV5znLsXTZdm3XF5XSxMX8jHr+H0d1G0691P6p91UxfN50fdv5QL+6OyR1ZdP0iUmNSeX/1+/zui9/RLbUb3Zp1Izk6OZjovDzmZSIjInl9xetc+eGV9aor7RPb8+DgBxnfazzvr36faz66hkHtBzG+13jOP+Z8tpdux+PzMHn+ZD5d/ykt41oyaeAkqnxVwXluhZWFJEUl0TG5Ix2TO9IppRPtk9qTHJ1MtCt6n42Waod7VngrqPRWHvBS7iknqzCL1bmrWZO3hjW5ayjzlBHtiub4tOPpl96Pfun96Jvel+6p3UNKmvansLKQFTkrWLljJTvKdpjKY6X5slHhreDU9qcypvsYMtpm7POLU35FPqXVpaTGpBLrjt3vlxuf38eD8x7kT1//KbjtocEPcf9p99d7zNLtSxn99mjKPeUUVRWREp3CqO6jGGuNZXiX4SRGJe799E2qtLqUBT8tYF7WPLaUbGFY52GM7j76iK1AHA2mLJvCdR9fR3xkPP3S+7Fo26Lg8G+3043H76FNQhu6p3YPnuDYMwGqTRr7te5HfkU+zy96nheWvEBeeV7wBEptwpjRNoPxPcfTOqF18Mty7Vz5Sm8l1b7qYMIb4YzgpNYncWqHUzmu1XE/O4kqrS7lw7Uf8ubKN5mZORN/wE+n5E7ce+q9XNHnCiIjIg/5Oe08m8cXPM67q96ld8venNfjPM7tcW5wSHm5p5wP137I6yteD77m3pwOJz2b92R099GM7TGWjkkdafO3NsRGxtI2sW2wU/OeOiZ3pG96X05tfyqndTiNPq36HDDZKqsuY03eGlbtXMWavDXEuGJ2J8EpnWid0Lrev6WBQIAXFr/A7774Xb1RBgA9m/fEHeEOVjRbxrXk6uOv5toTrqVbardD/iyPZNW+av664K9Mnj+ZKl8VQzsNZco5U+iQ3CE4N/cc6xyyCrP4+qevgyc6nxj2BL8/5fcN0nxwe8l2sgqzOKnNSQ0+X/1QbMzfyNDXh/JT0U/BkyZ/Hvpn7jn1HiZ+MZGnvnuKMzqdweeXfV6nqeHRINwV4/8Az9dWcY9WSoxFQucP+KnyVh1y8uD1e8mvyGdD/gbW71rP+nxzGdl1ZLBr49q8tSRGJZJTmsPszNnM3jSbr3/6mgdOeyDYNGfSrElkFmTSMbkjK3as4H/Z/6PcW85xLY8jPSGdE9JOYOGWhczPnk+XlC6M7zWePw390wH/aK3btY688rxgt8hYdywFlQV8nf01afFp3DHzDjILMnE73UQ4I6j2VR9WReRwOXCQnpBOu8R2tElsw487f2TdrnWAqQLUVqSdDme94bkHE+Myc2Jzy3KDX4T3dPXxV5NTmsOcTXOClaOB7QYyuvto5mXNY8bGGQQIEB8ZT0abDLKKsoInEBw1/7kiXFT7qhnWeRhvjnvzoHPtws0f8LOjdAct4loc8dWMg5m2ZhqXT7ucMk8ZJ7Y+kbfPf5suKV2YsXEGHZM7smTbEq766Krgl94Jx07gn2f/s8FOGsnR4z8//ocJ0ybgdDjx+X0kRiVSWl2Kx+/hyj5X8o+R/zikkyQVngre/uFtnl/8PADje41nfK/xdTrfNqWc0hzW5q1lYLuBjfblfVvJNhZtXVTnpF9BZQGLty0OzmEGgp997d+R5Ohkzuh0BhltM+ib3pfj045v1BNB3235jgvfu5DNxZuDw/FrT4BGRkQytNNQrjvhOsZYYw7r5MLRZP2u9dz46Y3M3jSbaFe0mafuiGBZzjJ2lu0ECDZgfO3c17i498VNHHF4ZBVmMfS1oWwq3ESsK5Zybzmntj+Vr3/6mp4terLgmgVHZRfqcCfGRcC5tm3PPewIjwBKjEUOLhAI8NYPb3HbF7dRXFXM86OeJzk6mS3FW7hvzn3BLr1upxt3hBunw8ldA+8iITKBvPI8bvvytn0+71ldzuL8Y86ne2p3Jn45sU6XQzDD6xw4aBXfip4terJ42+I6Sy/UVjv2pfaM7twr5jK40+B9HuPz+7jo/Yv4cO2H9eYT1nI5Xdxy0i08cPoDwT8EXr+XSm8leeV5bMzfyPr89Sbpz1+Pz++rN7fI5XTVqWLWdpys7cq5Z4fOPW8nRCaQFp9W54tdIBBgyfYlvLnyTd758Z3gH+v4yHgy2mYwsN1AMtpmkBCZEFwH0uf3UeWrIqc0p84Q1E0Fm7B32QdNqHs078GEYydw6bGXBteRBDPP6t/L/82/l/87OCdv75+N0+Fk8pDJTBo0ab/L7MjhW5u3lnPeOYf1+esB0221uKq4zv8Xce44Xh7zMpcce0lThSlHgOnrpnPB1AuCJ7lSolN4acxLXNDzgiaO7JevsLKQ2Zmz+XLjl8zNmkvLuJac1eUshncZTv/W/Zv8JF1eeR5XfXgVszfN5sTWJzKk4xAGdxxMRtuMnzWK5mgUCAR4c+WbPLrgUVbnrg5ur/1OkRSVxIcXf8jgjoObLshGsLloM0NeG8LGgo0kRydTVFlEy7iWfHvdt0fMCbBDFe7E+APMEkm/sW276mDHH6mUGMuvXUlVCR+t/YhlOcs4vePpDOk4pM6al4u3LuaKD69gTd6asMficrrw+X11h+smtaesuoxdFbvqHZ8QmcAYawwX9ryQge0GsjxnOV//9DVf//Q1CzcvpNpXXWe5k71tyN9Ar+d67bfZ0tndzuZvw//WqMucHAqv38uCnxaQEJVw2EMRfX5fcKjx6tzVZmmgxDa0SWgTvK5duuhAz7EsZ1lwGF/tc0VGRPLC6Bf229RFGkZJVQmvLn+VhVsW8u2Wb8kqzAru65dumo11SD7kXpjyCzR301zGTR3HyW1O5l/n/Is2ieFaQESORqH0nPg12VW+i4WbF7Jg8wIWbF6Az+/jpTEv0btl76YOrVFsLd7K0NeHsm7XOmJcMXx11Vec2ObEpg7rsIU7MX4VuBSoBjYCO/Y6JGDb9lmhvmhTUWIsv2S1S6cEAgESohJIjk4m1h0LwEdrP+LZRc8yZ9OcOtXS7qndefD0B+mb1pc7Zt7Bp+s/De67oOcFXHbsZcFuoAUVBRRWFuIL+ILL79QO602OTq7T5TApKgmX04XD4Qgu01NUWcT6/PWs27UueB3njmNAuwEMaDeAU9qeQnqCWbY8tyw3mHBlF2VzSttTOKvrWftdO3bBTwsY9O9BOHCQc0dOvSG8gUCAG6bfwMtLX+bSYy+lWXQzU9H1VeIP+Ln8uMsZ0XVEQ/9IRMJuZ9lOvtvyHVW+Ks7rcV6TzleTI4/P79PvhIiEJKc0h7tn3c1lx17G8C7DmzqcnyXcifFBh1Dbtj3kYMc0NSXG8kvyzeZv2JC/gbdWvsW6/HVsLt5cp8PrwHYDuezYy9heup2nvn0q2H3Q7XTTrVk31uev3+fQ5EHtBvHimBfp2aJno72XhtD9me6sz1/PN9d+U2eZDIDHFzzOpFmTaJfUjsxbM/VFUUREROQX6nAT45DG4h0NSa/Ir8XH9sf87Zu/7Xch+Fq1w4GgpqlGx6Fc3+96xnQfQ1xkHF6/l2XblzE/ez7zf5pPpaeS+0+/n0HtBzXG22hwj575KOdPPZ8py6bUSYwDgQB/XfhXAgS4+cSblRSLiIiISD37TYwty5oD3GTb9tpGjEdE9uDz+4Lr4i7auogJ0yYEuxQP6TiEi3tfTGFlIS6nC3/Aj8fnwR3hNmugumKIcceQEJnAoPaD6nWndTldnNjmRE5sc2KdRd2PVmOtsXRJ6cLrK17ndyf/Lrik06frPiWvPI9oVzS3nnxrE0cpIiIiIkeiA1WMBwNH1qKHIkeR/Ip8tpdsp7S6lJ1lO9lZvpOiiiJGdR+1zwZP+RX5PDzvYWZtmmU6NDsc7CrfxcaCjURFRAXXwo2KiOKugXfx0OCH1DhjDxHOCK7vez2TZk9i3NRx2DfbAEyaPQmAa46/hihXVFOGKCIiIiJHqKN7YUeRI0wgEGDh5oX86es/8cWGL+p0XK519+y7GdJxCKO7jyY9Pp2T257MXTPv4oPVH+ANmDnCLqcLB47gHOAKbwURjgiu6HMFz496Xgneftxy8i38Ye4fWLdrHevy1uFwOFiVu4oIRwR/OeMvTR2eiIiIiByhDpYYH7wzl8ivTFl1GbMyZxHhjCDGFWOGLbtj+H7r9zy36DlW7FgBmIXhU2NSiYuMI85tLu4IN2WeMmZmzmRm5sx6z90usR33nXofV/S5IrieoD/gx+v34nK6tDbsQcS6YxnRZQTT10/nti9vwx/wAzCy60gSozUARkRERET27WCJ8TOWZRWH8DxHxXJNIgezs3QnzeOa7zcBLa0uZdCUQcHkd29Oh5MLel7ATf1v4pjmx5CWkLbP47YUb+GdH97hxSUvsrl4MyekncBfh/2VUzucus/njIyIPPw39Svz9Minmb5+OjM2ziAtPg23080/z/5nU4clIiIiIkewgyXG7pqLyC/etDXTGDd1HGnxaSy/YTmt4lvV2e/xebjwvQtZsWMF/dL7Ye+yKa0urXPM+cecz9QLpx70tdomtuXOgXdy58A7G/Q9CHRO6UzPFj1ZnbuarSVbufWkW+mQ3KGpwxIRERGRI9jBEuMbbdv+vlEiEWlC/oCfaz++FjALnJ/yr1OYfcVsOqV0Aszc3qNwTwAAIABJREFU4VFvj2Jm5kxGdh3JRxd/hDvCTUlVCZkFmWzI30BydDJDOw1tyrchNR4941HOefccnA7nL6LjtoiIiIiEl5pviQD3zL6HgsoCmsU0Y2TXkbz1w1tk/CuDTy/9lP6t+zNh2gRmZs4kPjKe/1zwH9wRZiBFQlQCfdL60CetTxO/A9nTGGsMp7U/jeaxzWmf1L6pwxERERGRI5wSY/nF8wf8bCrYRIW3gt4te9fbX1BRwN+++RsAr5/7OqO6j+KUtqdw6xe3kvFKBsO7DOfzDZ8H9ydEJTRq/HJ4vrr6q6YOQURERESOEgdqcfsakNtYgYiEw5biLfR8tic9nu3B8S8cz+srXq93zLUfX4vX76VvWl9GdR8FwG9P+i3XnnAtvoAvmBQ/fdbTnHfMeY0av4iIiIiIhN9+E2Pbtq+2bXtTYwYj0pBeWfoKnZ/ujL3LxoGDhKgErvzwSoa+NpRAwKxEllmQyWfrPyM1JpX/XvTfOo9/cfSL/Kbvb3Dg4M4Bd3Jrxq1N8TZERERERCTMtCiq/KIEAgFW7VzFkFeHcP0n1+Pxe+jdojfZt2Uz/6r5REZEMjdrLie9fBJ+v587ZtxBla+Kf579z3qdix0OBy+OeZHKP1Ty+LDHm+gdiYiIiIhIuGmOsRzVPl//OffNuY/OKZ0p85SRXZjNmrw1gFn/98HTH+T+0+7H4XCQnpDOwmsWMmDKABZvX0ybv7chpzSHk1qfxEW9Ltrva2gNYRERERGRXzYlxnJUsvNsrv7oar7Z8g0Ay3KWAZASnUJafBptE9ryxrg36NG8R53H9WvdjyW/WUL/l/qTU5oDwBV9rsDhcDTuGxARERERkSOGEmM5quwo3cF9c+5jyrIpBAjgwMF1fa/j5pNuplNyp5A6Rvdu2ZuVN65k4JSBdE7pzG9P+m0jRC4iIiIiIkcqJcZyRAsEAuSV59EirgWBQIDrPr6O6eunA9A5uTPTLprGcWnHHfLzdk/tTu6darouIiIiIiJKjOUIFQgEuHf2vUxZPoXEyEQGdxzM5xs+Z2vJVpwOJ/cMuocHTn9A839FRERERORnU2IsR6SXl7zMowseBWBn2U42FGwgNSaVS4+9lIkZE+nfun8TRygiIv/f3r3HS1XX+x9/7b25CKh4ARWCNEU/lHij8Jh3f6dDgp6stN/PMM3K6phaWWm/U9rRMuukXUxDTT1efuL1aLdj4inzbkQKEqJ9+4k3QBFRbnKHPeePNdvGEdiwgVkzs17Px2M/Zs93fWfPZ/PlO7Pfs9b6LkmSmoXBWHXnhfkvcMbdZwAwZNshfHyvjzN699GMGDiCtta2nKuTJEmS1GwMxqor7aV2jr3tWFa0r2D7Xtvz58/9mW222CbvsiRJkiQ1sda8C5AqTZszjSdmPwHAL//PLw3FkiRJkjY7g7HqRqlU4oKHLmB1aTVnHXgWB+98cN4lSZIkSSoAD6VWXWgvtXPZxMu4bdptHDT4IC78xwvzLkmSJElSQRiMlbsVq1dw5vgzGfvYWPp078O4j46jW6v/NSVJkiTVhulDm9VrS17jmdefYWi/ofTdou9btq1YvYLvP/R9Lv7jxSxasQiAH478ITtvs3MepUqSJEkqKIOxNqlX3niFn0z4CfdMv4fp86azcPnCN7cN3nowXz/o6+y23W78Kv2Kaydfy/LVywHo1a0XZx90Np9/3+fzKl2SJElSQRmMtcncMOUGPvPrz7CqfdVb2ltbWmkvtTNj4QxOv/v0t2wbtNUgvnnoN/n0fp+mR1uPWpYrSZIkSYDBWJtAe6mdMXeM4dZpt7LtFtvyib0/wa7b7sr+A/dnj357sH2v7Zm7ZC7T501n+uvTmT5vOvOXzeeYOIbDdjks7/IlSZIkFZzBWBtl5eqV7H/1/jwx+wn6dO/DAyc/wF477vW2fv379Kd/n/4cMOiAHKqUJEmSpLUzGKvLlq5cyl6X78X0edPp2daT+z95/xpDsSRJkiTVM4OxumR1+2r2uGwPZi6cSe/uvZn8ucns0W+PvMuSJEmSpA1mMFaXfPpXn2bmwpls3XNrpp06jUF9B+VdkiRJkiR1SWveBajxzFw4k9ueuo0WWvj9Sb83FEuSJElqaO4x1gYplUp89jefZdmqZfz0yJ8yYuCIvEuSJEmSpI3iHmNtkO89/D3GPzOekbuN5PT9T+/8AZIkSZJU5wzGWm/T5kzjnD+cQ1tLG1cedSUtLS15lyRJkiRJG81grPXSXmpn1LhRlChx1O5Hscu2u+RdkiRJkiRtEp5jrHWav2w+E2dN5MrHr2TGwhn06d6HW467Je+yJEmSJGmTMRjrLRYtX8SlEy/lsZceY/LsyTw///m3bL/uw9fRq3uvfIqTJEmSpM3AYCxKpRKPzHiEayZfw01/uYkV7SsA6Ne7H4fvcjjPzXuOd2z9Dk4YdgLHvee4nKuVJEmSpE3LYFxwT855ko/d/jH+Ovevb7Zt2WNLbj3uVkYNGeUCW5IkSZKanotvFdiq9lWc9IuT+Ovcv7Jz350BGLr9UJ489UlG7z7aUCxJkiSpENxjXGCXTLiEybMns9OWO/HCghc4aPBB/Prjv2a7XtvlXZokSZIk1YzBuKCem/cc37r/W2zXazuG9hvKAYMO4KaP3uTCWpIkSZIKx2BcQKVSiVPvOpUlK5fw86N/zpi9xtBeaqettS3v0iRJkiSp5gzGBXTzkzdzz/R72H/g/ozZawwtLS20tRiKJUmSJBWTi28VzGtLXuPL479Mt9ZuTHxpIrc/dXveJUmSJElSrgzGBXPW787i1SWv0l5qZ+e+OzN699F5lyRJkiRJuTIYF8iklydx7RPX0rtbb9pL7Vx+1OVs2WPLvMuSJEmSpFwZjAvkyseuBGDJqiWM2WsMo3YflXNFkiRJkpQ/F98qiDdWvMG4qeNooYVtttiGH3/wx3mXJEmSJEl1wWBcELc8eQuLVy7m0Hceymff+1l26LND3iVJkiRJUl0wGBfEVZOuorWllRs/eiOD+w7OuxxJkiRJqhueY1wAU2ZPYeKsiRw55EhDsSRJkiRVMRgXwFWTrgJg0kuTeGPFGzlXI0mSJEn1xWDc5JasXMINU24AYM8d9vTyTJIkSZJUxWDc5G6fdjuLViwC4Iz9z8i5GkmSJEmqPwbjJnfF41cAMHCrgRy9x9E5VyNJkiRJ9cdg3MSmzZnGhJkTADhtxGm0tbblXJEkSZIk1R+DcRO7etLVAHRr7cYpw0/JuRpJkiRJqk8G4ya1cPlCrp9yPTv22ZGHPvUQO/TZIe+SJEmSJKkuGYyb1MWPXsy8ZfM4Y/8zOGDQAXmXI0mSJEl1y2DchGa/MZuLHr2I3t17ewi1JEmSJHXCYNyEzrv/PJatWsaSlUt46tWn8i5HkiRJkuqawbjJ/O21v3HVpKsAOHHvEzniXUfkXJEkSZIk1TeDcZM5c/yZtJfa2arHVvz4gz/OuxxJkiRJqnsG4ybyp5l/4rfP/BaAsaPHsn3v7XOuSJIkSZLqn8G4SZRKJb5w1xcAGDFwBCfsfULOFUmSJElSYzAYN4nxz4xn0uxJvH/Q+7ntY7fR0tKSd0mSJEmS1BAMxk3i2w9+mxZauOLoK9hlm13yLkeSJEmSGobBuAlMfWUqE2ZOYPiA4ey94955lyNJkiRJDcVg3AS+8+B3ABi89eCcK5EkSZKkxmMwbgLjnxkPwLmHnptzJZIkSZLUeAzGDe6RFx9h0YpF9O3Zl+EDh+ddjiRJkiQ1HINxg7vwoQsBGDVkVM6VSJIkSVJjMhg3sJWrV3Lvc/cCcNZBZ+VcjSRJkiQ1JoNxA1uwbAElSmy7xbbst9N+eZcjSZIkSQ3JYNzAHn/5cVasXsHJ+55MS0tL3uVIkiRJUkMyGDeo5auW84u//gKAY+KYnKuRJEmSpMZlMG5Ql028jKsnXU3fnn056J0H5V2OJEmSJDUsg3EDKpVKXP7Y5awurebIIUfSrbVb3iVJkiRJUsMyGDegybMnM33edACOH3Z8ztVIkiRJUmMzGDeg65+4HoAebT0YudvInKuRJEmSpMZmMG4w7aV2bpl2CwAjdxtJ7+69c65IkiRJkhqbwbjBPDrjUeYsngPAR4d+NOdqJEmSJKnxGYwbzIiBI9h1213p1tqNo/c4Ou9yJEmSJKnhGYwbzNNzn+bZec9y1O5H0b9P/7zLkSRJkqSGZzBuILMWzuJnE38GwMn7npxvMZIkSZLUJAzGDeSiRy7i6slX07dnX0bvPjrvciRJkiSpKRiMG0SpVGLck+MAOGmfk+jR1iPniiRJkiSpORiMG8TEWROZu2QuAJ/Z7zM5VyNJkiRJzcNg3CCun3I9AO/a5l3ss9M+OVcjSZIkSc3DYNwASqUStzx5CwBfGPGFnKuRJEmSpOZiMG4AaW5i3rJ5tLa0uhq1JEmSJG1iBuMGsHTVUgA+sOsH6Ne7X87VSJIkSVJzMRg3gOueuA6A00aclm8hkiRJktSEDMZ17qlXn+LaJ65lh947MGrIqLzLkSRJkqSmYzCucz989IcsWrGI9w58L93buuddjiRJkiQ1HYNxnXt67tMAHDnkyJwrkSRJkqTmZDCucy+/8TIA++64b86VSJIkSVJzMhjXuXlL5wGwz0775FyJJEmSJDWnbrV+wohoAy4ATga2AsYDp6WUXllL/9uB46qa700pfWBz1lkvFq9cTAst9N2ib96lSJIkSVJTymOP8XnAJ4GTgEOBQcAd6+g/DPi/wICKr49t3hLrw8rVK1nVvope3XvlXYokSZIkNa2a7jGOiB7Al4AvppR+V247HnguIg5MKT26hv5DgIkppdm1rLUeLFm5BIARA0fkXIkkSZIkNa9a7zHel+zw6fs7GlJKzwPPA4esof+7ycL705u/tPoza9EsAGL7yLkSSZIkSWpetT7HeFD5dlZV+0vA4DX0HwasAM6PiFHAUuB24IKU0rLNVmWdePrV7POAQVsP6qSnJEmSJKmrah2MewPtKaWVVe3LgS3W0H9PoAVIwGXAXsCPyEL0J9f1RBFxHvBvG1lvrm5+8mYAXlv6Ws6VSJIkSVLzqnUwXgq0RkS3lNKqivaewOI19D8HuDil9Hr5/tSIWA3cEhFfSSmtNTGmlM4jW+jrTRGxC/Bc18uvrRcXvAjA0H5Dc65EkiRJkppXrYPxjPLtgIrvAQby9sOrSSm1A69XNU8t3w4GmnpX6iuLsytY7bvjvjlXIkmSJEnNq9aLb00BFgGHdTSU9+LuAjxY3TkibouIX1Q1v4/s0OtnNluVdWLe0nkA7LXjXjlXIkmSJEnNq6Z7jFNKyyNiLHBxRMwF5gBjgQdSShPKl2faDng9pbQC+E/Kh00DvwL2Ay4mO7z6jVrWnoclK5fQ2tJKnx598i5FkiRJkppWrfcYQ3be8DjgRuA+4AXguPK2A4GXy7eklG4DTgY+BTwJ/BC4BPhWTSvOwbKVy1hdWk3v7r3zLkWSJEmSmlqtzzGmvOjWV8tf1dvuJ1uFurLtBuCGmhRXRxYsXwDAnv33zLkSSZIkSWpueewx1nroWHhr+IDhOVciSZIkSc3NYFynZizIFu0evPXgnCuRJEmSpOZmMK5T1z1xHQDLVi3LtxBJkiRJanIG4zr17LxnAXhn33fmXIkkSZIkNTeDcZ2as2QOAPsN2C/nSiRJkiSpuRmM69T8ZfMBeE+/9+RciSRJkiQ1N4NxnVqycgltLW1s0X2LvEuRJEmSpKZmMK5Di1cspr3UTu/uvfMuRZIkSZKansG4Ds1+YzYAu267a86VSJIkSVLzMxjXoQXLFwBw6M6H5lyJJEmSJDU/g3EdmrlwJgCDtx6ccyWSJEmS1PwMxnXozqfvBKBba7ecK5EkSZKk5mcwrkNTZk8BoF/vfjlXIkmSJEnNz2Bch+YsmQPAvjvtm3MlkiRJktT8DMZ1aP6y+QAM7Tc050okSZIkqfkZjOvQslXL6Nbaje5t3fMuRZIkSZKansG4zixcvpD2Ujt9uvfJuxRJkiRJKgSDcZ15dt6zAOy05U45VyJJkiRJxWAwrjMrV68EYPTuo3OuRJIkSZKKwWBcZ2YsnAHA4K0H51yJJEmSJBWDwbjO3PvsvQBs3XPrnCuRJEmSpGIwGNeZh158CIA+PVx8S5IkSZJqwWBcZ15d/CoAwwcMz7kSSZIkSSoGg3GdWbB8AQC7bbtbzpVIkiRJUjEYjOvMslXL6N7anbbWtrxLkSRJkqRCMBjXkXlL51GixJY9tsy7FEmSJEkqDINxHZk6ZyoA2/XaLudKJEmSJKk4DMZ1ZIc+OwBw7LuPzbkSSZIkSSqObnkXoL+L7YO7xtzFgYMPzLsUSZIkSSoMg3EdaWlpYfTuo/MuQ5IkSZIKxUOpJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBWawViSJEmSVGgGY0mSJElSoRmMJUmSJEmFZjCWJEmSJBVat1o/YUS0ARcAJwNbAeOB01JKr6yl//uAS4D9gFnAd1JKN9SmWkmSJElSs8tjj/F5wCeBk4BDgUHAHWvqGBH9gXuAScBw4KfANRExsiaVSpIkSZKaXk2DcUT0AL4EfCOl9LuU0iTgeOCgiDhwDQ85BVgAfCml9NeU0qXAjcDXala0JEmSJKmp1XqP8b5kh0/f39GQUnoeeB44ZA39DwEeTCm1V7TdTxakPT9akiRJkrTRan2O8aDy7ayq9peAwWvpP3kNfXsD2wFzN/D52wBmz569gQ+TJEmSJNW7iqzXtiGPq3Uw7g20p5RWVrUvB7ZYS/9la+jLWvq/KSLOA/5tTdtOOOGETguVJEmSJDWsAcD09e1c62C8FGiNiG4ppVUV7T2BxWvp37OqreP+mvq/KaV0HtlCX2+KiJ7ACOBlYPV6V117zwHvyrsIbTaOb3NzfJub49vcHN/m5vg2N8e3uW3I+LaRheI/b8gT1DoYzyjfDqj4HmAgbz+8uqP/gKq2gcAbZItybZCU0nLg4Q19XK1FRMe512pCjm9zc3ybm+Pb3Bzf5ub4NjfHt7l1YXzXe09xh1ovYDUFWAQc1tEQEbsAuwAPrqH/w8ChEdFS0XYE8EjVglySJEmSJHVJTfcYp5SWR8RY4OKImAvMAcYCD6SUJpQv57Qd8HpKaQVwDXA2cEVE/AT4ADAGOLKWdUuSJEmSmlcelzw6BxhHdj3i+4AXgOPK2w4kO//3QICU0itkIXg/stWpTwdOSin9ocY1S5IkSZKaVK3PMaa86NZXy1/V2+4HWqraJgD716S4+nF+3gVos3J8m5vj29wc3+bm+DY3x7e5Ob7NbbOPb0upVNrczyFJkiRJUt3K41BqSZIkSZLqhsFYkiRJklRoBmNJkiRJUqEZjCVJkiRJhWYwliRJkiQVWs0v16Q1i4g24ALgZGArYDxwWvlazmowEbEj8ANgJNAL+BPw1ZTSk+Xtc4D+VQ87N6V0QU0LVZdExJ7Ak2vYdEhK6eGIGEk2/gH8f+DrKaW7a1mjuiYiDgfuW8vm+1JK/ysi/gy8r2rbNSmlUzZrcdpoEXEl0FY5Vp3N14jYAbiM7PV8BXAt8M3y5SdVR9YyvqcDpwODgReAH6WUrq7YfhHwtaofNT2lNKQGJWsDrGV81/l67PxtHNXjGxHPAzuvpfvOKaUXI+I0svGttDql1KWMazCuH+cBnwROAl4DxgJ3AAfnWJO6ICJagV+QXZP7GOANsvG9NyLeQzbv+gOHkv0R1mFRbSvVRhgGzAX2qmp/rTzGvwa+QzaHTwB+GRHDU0rTalumuuBRYEBV2z8B1wH/HhEtwLvJxvUPFX2W1KQ6dUl53M4HPgdcU9G+PvP1DqAEHAa8g+z/wirgm7WqX+u2jvE9Ffg+8C/AH4EjgLERsTyl9P/K3YYBPyPbOdHB0FRH1jG+6/N67Pytc2sbX2AE0FZxvw/ZB9cPppReLLcNI3sN/3xFvy5fi9hgXAciogfwJeCLKaXflduOB56LiANTSo/mWqA21D7A+4H3pJSeBoiIE4HXgaOAWWQvyn9KKa3IrUptjGHAUyml2dUbIuJLwISU0nfLTedGxMFkc/xzNaxRXVCek2+Oa0T0JdubeFFK6Z6I2I3szfmPaxp/1Z+I2JXsj61hwItVm9c5XyPi/WQfUO+aUnoOmBIRZwGXRsS3U0rLa/NbaG06Gd9/AX6WUrqxfH96eUw/BVQG49ucz/Wpk/HdlXW8Hjt/69+6xjel9GpV38vJ/n6u/FtqGPCHTTV/Pce4PuxLdvj0/R0NKaXngeeBQ3KpSBvjReBoIFW0tZPtQd6WbBJPNxQ3tGHA02vZdggVc7nsfpzLjepcYDnw7fL9YcBSskMy1RjeDzxLdoTHc1XbOpuvhwAvlP+orty+Fdl7t/K3rvH9InBFVVs72Xtxxwdfg1j767nyt67x7ez12Plb/9Y1vm+KiH3IAvHpKaXKIwL2ZBPOX/cY14dB5dtZVe0vkZ0TowaSUnoNuKuq+YvAFsB/A18BVkXEf5GdFzML+EnFYV2qf8OALSJiArAL2fnG30gpTSSbz87lJlA+N+104NSKN+JhwHxgXEQcRnbqy7Vkc7g9n0q1LimlccA4gIio3tzZfF3bdsp9/rTJClWXrGt8U0oPVN6PiHcCHwcuLTcNK99+KiJuKn9/N9nr+YLNVbPWXyfzt7PXY+dvnetkfCudBzycUvptR0NEvIPsQ65REXEe2dEDDwBnp5ReWtMP6Yx7jOtDb6A9pbSyqn05WZhSA4uIDwHfI1vw42myT7e2Jzt05IPA7cC1EfGp/KrU+oqIXmSHb/UFzgI+RPZG+0BEvJtsPi+rephzuTGdCswBbqxo2xPYEriHbP7+jOzcqH+reXXaFDqbr2/bXn6vLuGcbigR0Z/sQ+vZZOcdQzafIQtUxwBfJluk6Zfl8x5V3zp7PXb+NoGIeBfZ31oXVm3qmL8rgePJTpEIsjV9enXludxjXB+WAq0R0a1qlbyewOKcatImEBEnA1cBtwBnl5uPAHqklDoW25oSETuT7Um+tuZFaoOklJZGxLbA8o7zk8rj/F7gC2TzuWfVw5zLjekTwLVVH1qeBGyZUppfvj+1fDjmNyPivJRSlxf9UC46m69v2x4R3clOjXFON4jyeYx3kwWlwyr2Bl8F3JlSmlu+PzUiXgEmAMOBx2terDbEOl+Pcf42ixOAGWRHXb4ppfTfEdG/Yv4SEdOAmcBosoXXNojBuD7MKN8OqPgeYCBvPwREDSIivkm2yuVlZAurlQDKYap6wYepZId3qQGklBZW3W8vvxgPJpvD1asaO5cbTPmSXEPIPtR6U/nDy/lV3aeSnbPWdw3bVN86m68zyP7Aqt4OzumGEBH7kYXiecCBKaU3/84qvy/PrXrI1PLtYAzGdW09Xo+dv83hGODWNX3wXBmKy/dfjojX6OLpax5KXR+mkF2q57COhojYhezcxQfzKUkbIyLOJgvF30opndExmSOiW0TMiIgzqx7yPsBL+TSAiHhvRCyMiOEVbW1kC3lMAx6mYi6XHYFzudEcAszuWFm+Q0RMiIifVPV9H/BSxV4LNY7O5uvDwK4RMbhq+yLgic1fnjZGRAwFfk+2ONPBlaG4vP3iiKgOvx3XxH2qBiVqI6zH67Hzt8FFRB9gP956Oa6ObV+MiJfKRwF0tO1MdknULv1N7R7jOpBSWh4RY4GLI2Iu2TltY4EHUkoT8q1OGyoi9iY7D+I/gKsiYqeKzYuA3wDnRMR0sjfeDwMnkl3KSfVvCtmK8T8vX1j+DeDrQD/gEmBH4PGIOB+4GRgD/APZ+apqHPvx9z1Hle4Evh0Rk4BHgMPJxv9LtStNm9ClrHu+/pHssNpbI+J0svn972RrRnhlgfp3A9k5picC3Svej1eV9zTdCXw5In4A/Jxs/YixwLiU0t/yKFgbpLPXY+dv49ub7FrGa3o/vgv4LnBNRFxItn7PJWT/F37flSdzj3H9OIdsVbYbyS5e/QJwXK4VqauOJ5vEnwZervo6s/x1BfBTsk+0TgT+d0rpv9f401RXyodujSK7HNdvgInATsChKaU5KaWpwEfI5u8TZAtG/HP1nkfVvQFkC/JUuwj4Btlr9jSyP8LOTCldXcPatIl0Nl/LR/t8BHgFeIhsHYhr+Pvlu1SnImIPYATZobOJt74XTwAA5I5iAAAFvElEQVRIKT1KNuaHk33oeQPwa+CU2lesLljn67Hztyl0nOrytvfjlNJ04J/IDpueSDZ3/0L2Gt6l9T5aSiXXCZEkSZIkFZd7jCVJkiRJhWYwliRJkiQVmsFYkiRJklRoBmNJkiRJUqEZjCVJkiRJhWYwliRJkiQVWre8C5AkKW8RcR3wyU66PZBSOnwjn+d54PcppfW+TmpXHtNVEdHZNRz/NaX0/c1dR6WIuB9YlVL6QC2fV5JULAZjSZLgO8AVFffHAquAL1a0LdwEz/MRYEENHrMxrgSuW8u2F2tYhyRJNWMwliQVXkppOjC9435ELCTbSzlhEz/P5Fo8ZiPN3NS/tyRJ9c5gLEnSBigf2vsCsBXwAeCelNLHImJX4PxyWz/gdeBu4MyU0rzyY5+nfFh0ROwCPAccC3wCGAmsAP4T+HJKaclGPKYH8D1gDLA1cBfwR+BHKaWWTfBvcDhwX/n5zwf2K9f1nZTSzRX9titvPxoYAEwDvptSurOiTw/g3PLvsyPwTLnPrRVP2RIR/wqcCvQHJgNnpJQe39jfRZIkcPEtSZK6YgywmOww58sjojfwALAHWXgbCfwUOAH4bic/62rgWeAY4CLgFOBfN/IxV5XruAg4DuhJFpTXR2tEdFvT1xr63go8TPbv8ARwU0QcA1D+N3m4/PzfLfd5GrgjIk6q+BnjgK+QHcr+z8CDwM0RcXRFn8OBDwGnAycC7wB+HRFt6/k7SZK0Tu4xliRpw60EPpdSWgoQEcOB54ETU0rPl/vcFxH/ABzWyc/6TUrpa+Xv742IfyLbw3puVx4TEbuRhcczUko/K9d3D/AXYM/1+N3OL3+9TUT0Siktq2i6NaV0dvn78RGxB3AO8CvgU8C7gf1TSn8u97m7vBf5BxExrrz9OOC0lNLYit9nN+AI4L/KbUuBUSml+eU6+pJ9OBDAU+vxO0mStE4GY0mSNtz0jlAMkFKaBBwSEa0RsTswhCyEvns9ftYjVfdnAoM24jFHAC3AHRX1tUfE7axfML4c+I+1bFtedf+mqvt3AN8t7y0+FHimIhR3GAeMAoYCB5fbflHZIaU0quoxUztCcdlz5dtt1lKnJEkbxGAsSdKGe6W6ISK+AnwD2L68/TGyw6237ORnLam6307npzqt6zH9y7evVvWZ3cnP7PBSSumx9e1bdX8OWSjvC2y3lufs+LfrS/Zv1fG4dVlcdb+9fOspYZKkTcI3FEmSNlJEjAF+CHwf6J9S2imldDTwtxzKmVW+3aGqvfr+prB91f0dgdVkC4/NA3Zaw2MGlG/n8vfLUPWv7BARw8qHoUuSVBMGY0mSNt7BwNyU0sUppbkAEbFlub3W77WPkIXTY6raq+9vCkdX3T8WeCSltJxsMbIhETGiqs/HyfYkP0O2OBdki25VugS4cBPXKknSWnkotSRJG28icGpE/IDs0kiDgK+R7TGtPqR5s0opTY+IG4CLI2ILspWgTya7pFJpPX7EoIg4YC3bFqSUnq64f1ZELAUmAZ8G9gH+sbztOuAMstWjzyU7D3oM2fnFp6SU2oEnIuJO4EflDxL+AnyYbBXqD67fbyxJ0sYzGEuStPGuB95FFg7PIDuc+S5gLPDziNgjpVTLw6pPIzsv9xygF9kq0VeQrVbdmc+Xv9bkXrLrNHc4E/gs8C1gKnBkSukBgJTS4og4jOzw8u8Dfcp9jq28jjFZWP428FWy85KfAj6UUvr9etQqSdIm0VIqrc+Hx5IkqRGUL4d0JPDbypWcI+I2YEhKafgmeI7DgfuAQ1JKD3fSXZKkuuceY0mSmstS4DJgQkRcCiwDRpKd//uZPAuTJKleufiWJElNpHx95ZFk7/E3kh3SPRI4KaV0XY6lSZJUtzyUWpIkSZJUaO4xliRJkiQVmsFYkiRJklRoBmNJkiRJUqEZjCVJkiRJhWYwliRJkiQVmsFYkiRJklRo/wP8L4L8YPkAwAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2500f5dd390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 14))\n",
    "\n",
    "plt.plot(np.array(history['train_loss']), \"r--\", label=\"Train loss\")\n",
    "plt.plot(np.array(history['train_acc']), \"g--\", label=\"Train accuracy\")\n",
    "\n",
    "plt.plot(np.array(history['test_loss']), \"r-\", label=\"Test loss\")\n",
    "plt.plot(np.array(history['test_acc']), \"g-\", label=\"Test accuracy\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2500f5a9dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 39s 10ms/step - loss: 0.3036 - acc: 0.8807 - val_loss: 0.2612 - val_acc: 0.9019\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 30s 8ms/step - loss: 0.2120 - acc: 0.9176 - val_loss: 0.2214 - val_acc: 0.9167\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.1805 - acc: 0.9336 - val_loss: 0.2141 - val_acc: 0.9251\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.1626 - acc: 0.9414 - val_loss: 0.1940 - val_acc: 0.9329\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 33s 9ms/step - loss: 0.1377 - acc: 0.9545 - val_loss: 0.1964 - val_acc: 0.9264\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 32s 8ms/step - loss: 0.1175 - acc: 0.9612 - val_loss: 0.2304 - val_acc: 0.9206\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 32s 9ms/step - loss: 0.0961 - acc: 0.9663 - val_loss: 0.1430 - val_acc: 0.9529\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.0751 - acc: 0.9743 - val_loss: 0.1377 - val_acc: 0.9574\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 30s 8ms/step - loss: 0.0543 - acc: 0.9810 - val_loss: 0.1307 - val_acc: 0.9613\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.0465 - acc: 0.9842 - val_loss: 0.1399 - val_acc: 0.9542\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 29s 8ms/step - loss: 0.0387 - acc: 0.9845 - val_loss: 0.1147 - val_acc: 0.9716\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 29s 8ms/step - loss: 0.0258 - acc: 0.9920 - val_loss: 0.1152 - val_acc: 0.9690\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.1423 - val_acc: 0.9684\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 30s 8ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.1323 - val_acc: 0.9684\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 32s 9ms/step - loss: 0.0093 - acc: 0.9981 - val_loss: 0.1232 - val_acc: 0.9729\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.0106 - acc: 0.9971 - val_loss: 0.1551 - val_acc: 0.9677\n",
      "935/935 [==============================] - 1s 1ms/step\n",
      "3737/3737 [==============================] - 4s 1ms/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 34s 9ms/step - loss: 0.2979 - acc: 0.8772 - val_loss: 0.2592 - val_acc: 0.9032\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.2010 - acc: 0.9229 - val_loss: 0.3169 - val_acc: 0.8754\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 35s 9ms/step - loss: 0.1745 - acc: 0.9315 - val_loss: 0.2305 - val_acc: 0.9161\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.1541 - acc: 0.9409 - val_loss: 0.2052 - val_acc: 0.9316\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 32s 9ms/step - loss: 0.1313 - acc: 0.9516 - val_loss: 0.2295 - val_acc: 0.9103\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 32s 8ms/step - loss: 0.1107 - acc: 0.9601 - val_loss: 0.1697 - val_acc: 0.9471\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 30s 8ms/step - loss: 0.0892 - acc: 0.9700 - val_loss: 0.1419 - val_acc: 0.9567\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 34s 9ms/step - loss: 0.0674 - acc: 0.9762 - val_loss: 0.1633 - val_acc: 0.9464\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 36s 10ms/step - loss: 0.0559 - acc: 0.9794 - val_loss: 0.1414 - val_acc: 0.9522\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 35s 9ms/step - loss: 0.0414 - acc: 0.9853 - val_loss: 0.1021 - val_acc: 0.9677\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 32s 8ms/step - loss: 0.0314 - acc: 0.9885 - val_loss: 0.1025 - val_acc: 0.9722\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 31s 8ms/step - loss: 0.0212 - acc: 0.9936 - val_loss: 0.1056 - val_acc: 0.9664\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 33s 9ms/step - loss: 0.0205 - acc: 0.9930 - val_loss: 0.1306 - val_acc: 0.9626\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 33s 9ms/step - loss: 0.0173 - acc: 0.9930 - val_loss: 0.1182 - val_acc: 0.9703\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 35s 9ms/step - loss: 0.0130 - acc: 0.9973 - val_loss: 0.1256 - val_acc: 0.9684\n",
      "935/935 [==============================] - 1s 1ms/step\n",
      "3737/3737 [==============================] - 4s 1ms/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 36s 10ms/step - loss: 0.2986 - acc: 0.8812 - val_loss: 0.3149 - val_acc: 0.8825\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 34s 9ms/step - loss: 0.2013 - acc: 0.9216 - val_loss: 0.2344 - val_acc: 0.9174\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 35s 9ms/step - loss: 0.1667 - acc: 0.9401 - val_loss: 0.2753 - val_acc: 0.9032\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 35s 9ms/step - loss: 0.1543 - acc: 0.9430 - val_loss: 0.2140 - val_acc: 0.9322\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 37s 10ms/step - loss: 0.1373 - acc: 0.9478 - val_loss: 0.2183 - val_acc: 0.9270\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 33s 9ms/step - loss: 0.1227 - acc: 0.9561 - val_loss: 0.1982 - val_acc: 0.9406\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 33s 9ms/step - loss: 0.1014 - acc: 0.9636 - val_loss: 0.1763 - val_acc: 0.9451\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 35s 9ms/step - loss: 0.0841 - acc: 0.9706 - val_loss: 0.1680 - val_acc: 0.9496\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0644 - acc: 0.9797 - val_loss: 0.1677 - val_acc: 0.9522\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0488 - acc: 0.9826 - val_loss: 0.2177 - val_acc: 0.9309\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0370 - acc: 0.9866 - val_loss: 0.1350 - val_acc: 0.9651\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0261 - acc: 0.9914 - val_loss: 0.1295 - val_acc: 0.9645\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0323 - acc: 0.9896 - val_loss: 0.1138 - val_acc: 0.9703\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0141 - acc: 0.9963 - val_loss: 0.1485 - val_acc: 0.9664\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0179 - acc: 0.9941 - val_loss: 0.1360 - val_acc: 0.9664\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0062 - acc: 0.9995 - val_loss: 0.1529 - val_acc: 0.9722\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 37s 10ms/step - loss: 0.0116 - acc: 0.9968 - val_loss: 0.1575 - val_acc: 0.9690\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 35s 9ms/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.1501 - val_acc: 0.9722\n",
      "934/934 [==============================] - 1s 1ms/step\n",
      "3738/3738 [==============================] - 4s 1ms/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 36s 10ms/step - loss: 0.2887 - acc: 0.8791 - val_loss: 0.2508 - val_acc: 0.9135\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.2035 - acc: 0.9262 - val_loss: 0.2414 - val_acc: 0.9193\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 33s 9ms/step - loss: 0.1809 - acc: 0.9310 - val_loss: 0.2499 - val_acc: 0.9148\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 36s 10ms/step - loss: 0.1547 - acc: 0.9438 - val_loss: 0.2597 - val_acc: 0.9077\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.1407 - acc: 0.9460 - val_loss: 0.2054 - val_acc: 0.9354\n",
      "Epoch 6/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.1201 - acc: 0.9559 - val_loss: 0.3013 - val_acc: 0.8890\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0990 - acc: 0.9642 - val_loss: 0.1684 - val_acc: 0.9509\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0785 - acc: 0.9727 - val_loss: 0.1736 - val_acc: 0.9522\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0666 - acc: 0.9759 - val_loss: 0.2300 - val_acc: 0.9303\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0501 - acc: 0.9831 - val_loss: 0.1568 - val_acc: 0.9619\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0427 - acc: 0.9856 - val_loss: 0.1561 - val_acc: 0.9613\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 36s 10ms/step - loss: 0.0345 - acc: 0.9877 - val_loss: 0.1438 - val_acc: 0.9638\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0237 - acc: 0.9917 - val_loss: 0.1600 - val_acc: 0.9619\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.1390 - val_acc: 0.9703\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0195 - acc: 0.9928 - val_loss: 0.1894 - val_acc: 0.9587\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0125 - acc: 0.9949 - val_loss: 0.1376 - val_acc: 0.9735\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.2277 - val_acc: 0.9574\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.1779 - val_acc: 0.9664\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0101 - acc: 0.9955 - val_loss: 0.1346 - val_acc: 0.9742\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0059 - acc: 0.9976 - val_loss: 0.1428 - val_acc: 0.9722\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 34s 9ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.1449 - val_acc: 0.9761\n",
      "Epoch 22/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.1477 - val_acc: 0.9729\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0060 - acc: 0.9979 - val_loss: 0.1319 - val_acc: 0.9774\n",
      "Epoch 24/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9781\n",
      "Epoch 25/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.1308 - val_acc: 0.9819\n",
      "Epoch 26/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.1304 - val_acc: 0.9806\n",
      "Epoch 27/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.1393 - val_acc: 0.9768\n",
      "Epoch 28/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 0.0032 - acc: 0.9995 - val_loss: 0.1277 - val_acc: 0.9800\n",
      "Epoch 29/170\n",
      "3738/3738 [==============================] - 32s 8ms/step - loss: 2.2796e-04 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9800\n",
      "Epoch 30/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 1.4596e-04 - acc: 1.0000 - val_loss: 0.1313 - val_acc: 0.9813\n",
      "Epoch 31/170\n",
      "3738/3738 [==============================] - 31s 8ms/step - loss: 0.0068 - acc: 0.9973 - val_loss: 0.1522 - val_acc: 0.9774\n",
      "Epoch 32/170\n",
      "3738/3738 [==============================] - 32s 9ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.1290 - val_acc: 0.9806\n",
      "Epoch 33/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.1263 - val_acc: 0.9774\n",
      "Epoch 34/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 2.2414e-04 - acc: 1.0000 - val_loss: 0.1256 - val_acc: 0.9806\n",
      "Epoch 35/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 2.0822e-04 - acc: 1.0000 - val_loss: 0.1306 - val_acc: 0.9793\n",
      "Epoch 36/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 8.5681e-05 - acc: 1.0000 - val_loss: 0.1360 - val_acc: 0.9793\n",
      "Epoch 37/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 6.0653e-05 - acc: 1.0000 - val_loss: 0.1348 - val_acc: 0.9800\n",
      "Epoch 38/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.0105 - acc: 0.9976 - val_loss: 0.1339 - val_acc: 0.9768\n",
      "Epoch 39/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.1327 - val_acc: 0.9800\n",
      "934/934 [==============================] - 1s 1ms/step\n",
      "3738/3738 [==============================] - 4s 995us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 33s 9ms/step - loss: 0.2845 - acc: 0.8922 - val_loss: 0.3380 - val_acc: 0.8644\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.1972 - acc: 0.9256 - val_loss: 0.2258 - val_acc: 0.9167\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.1771 - acc: 0.9355 - val_loss: 0.2089 - val_acc: 0.9322\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.1545 - acc: 0.9436 - val_loss: 0.2104 - val_acc: 0.9193\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.1417 - acc: 0.9449 - val_loss: 0.1882 - val_acc: 0.9342\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.1228 - acc: 0.9540 - val_loss: 0.2033 - val_acc: 0.9180\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.1002 - acc: 0.9633 - val_loss: 0.1708 - val_acc: 0.9419\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0858 - acc: 0.9668 - val_loss: 0.1504 - val_acc: 0.9432\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0603 - acc: 0.9775 - val_loss: 0.1184 - val_acc: 0.9613\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.0459 - acc: 0.9842 - val_loss: 0.1096 - val_acc: 0.9632\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0390 - acc: 0.9848 - val_loss: 0.1014 - val_acc: 0.9658\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.0268 - acc: 0.9917 - val_loss: 0.1177 - val_acc: 0.9619\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0224 - acc: 0.9917 - val_loss: 0.1115 - val_acc: 0.9664\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 30s 8ms/step - loss: 0.0152 - acc: 0.9952 - val_loss: 0.1091 - val_acc: 0.9703\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.1081 - val_acc: 0.9684\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 29s 8ms/step - loss: 0.0150 - acc: 0.9949 - val_loss: 0.1217 - val_acc: 0.9729\n",
      "934/934 [==============================] - 1s 998us/step\n",
      "3738/3738 [==============================] - 4s 998us/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 19s 5ms/step - loss: 0.3256 - acc: 0.8681 - val_loss: 0.2768 - val_acc: 0.8954\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.2259 - acc: 0.9187 - val_loss: 0.2638 - val_acc: 0.9006\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1958 - acc: 0.9280 - val_loss: 0.2522 - val_acc: 0.9032\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1801 - acc: 0.9323 - val_loss: 0.2158 - val_acc: 0.9219\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1634 - acc: 0.9379 - val_loss: 0.2295 - val_acc: 0.9128\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1508 - acc: 0.9422 - val_loss: 0.2523 - val_acc: 0.9141\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 17s 5ms/step - loss: 0.1297 - acc: 0.9545 - val_loss: 0.1803 - val_acc: 0.9413\n",
      "Epoch 8/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1182 - acc: 0.9569 - val_loss: 0.1684 - val_acc: 0.9432\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1019 - acc: 0.9652 - val_loss: 0.1564 - val_acc: 0.9490\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0810 - acc: 0.9724 - val_loss: 0.1522 - val_acc: 0.9484\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 17s 5ms/step - loss: 0.0742 - acc: 0.9727 - val_loss: 0.1513 - val_acc: 0.9548\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0581 - acc: 0.9799 - val_loss: 0.1332 - val_acc: 0.9574\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.0512 - acc: 0.9807 - val_loss: 0.1500 - val_acc: 0.9567\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.0386 - acc: 0.9874 - val_loss: 0.1282 - val_acc: 0.9651\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 17s 5ms/step - loss: 0.0325 - acc: 0.9893 - val_loss: 0.1599 - val_acc: 0.9542\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.0291 - acc: 0.9898 - val_loss: 0.1224 - val_acc: 0.9671\n",
      "Epoch 17/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0201 - acc: 0.9933 - val_loss: 0.1361 - val_acc: 0.9645\n",
      "Epoch 18/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0165 - acc: 0.9952 - val_loss: 0.1291 - val_acc: 0.9703\n",
      "Epoch 19/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.1417 - val_acc: 0.9684\n",
      "Epoch 20/170\n",
      "3737/3737 [==============================] - 17s 5ms/step - loss: 0.0165 - acc: 0.9928 - val_loss: 0.1349 - val_acc: 0.9684\n",
      "Epoch 21/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0091 - acc: 0.9979 - val_loss: 0.1440 - val_acc: 0.9703\n",
      "935/935 [==============================] - 1s 583us/step\n",
      "3737/3737 [==============================] - 2s 614us/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 21s 6ms/step - loss: 0.3151 - acc: 0.8756 - val_loss: 0.2560 - val_acc: 0.9090\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.2112 - acc: 0.9232 - val_loss: 0.2414 - val_acc: 0.9154\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.1827 - acc: 0.9318 - val_loss: 0.2276 - val_acc: 0.9167\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.1668 - acc: 0.9363 - val_loss: 0.2392 - val_acc: 0.9064\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1550 - acc: 0.9401 - val_loss: 0.2475 - val_acc: 0.9116\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.1366 - acc: 0.9457 - val_loss: 0.2013 - val_acc: 0.9309\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.1239 - acc: 0.9564 - val_loss: 0.1977 - val_acc: 0.9258\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 17s 5ms/step - loss: 0.1106 - acc: 0.9615 - val_loss: 0.2031 - val_acc: 0.9335\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.1027 - acc: 0.9644 - val_loss: 0.1803 - val_acc: 0.9445\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 18s 5ms/step - loss: 0.0901 - acc: 0.9690 - val_loss: 0.1616 - val_acc: 0.9535\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 17s 5ms/step - loss: 0.0794 - acc: 0.9732 - val_loss: 0.1779 - val_acc: 0.9445\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0673 - acc: 0.9778 - val_loss: 0.1487 - val_acc: 0.9587\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0535 - acc: 0.9826 - val_loss: 0.1462 - val_acc: 0.9580\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0413 - acc: 0.9866 - val_loss: 0.1322 - val_acc: 0.9638\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0379 - acc: 0.9882 - val_loss: 0.1529 - val_acc: 0.9451\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0342 - acc: 0.9877 - val_loss: 0.1217 - val_acc: 0.9613\n",
      "Epoch 17/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0274 - acc: 0.9917 - val_loss: 0.1369 - val_acc: 0.9626\n",
      "Epoch 18/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0190 - acc: 0.9941 - val_loss: 0.1211 - val_acc: 0.9690\n",
      "Epoch 19/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0163 - acc: 0.9952 - val_loss: 0.1249 - val_acc: 0.9697\n",
      "Epoch 20/170\n",
      "3737/3737 [==============================] - 17s 4ms/step - loss: 0.0163 - acc: 0.9941 - val_loss: 0.1244 - val_acc: 0.9697\n",
      "Epoch 21/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.1250 - val_acc: 0.9729\n",
      "Epoch 22/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0089 - acc: 0.9976 - val_loss: 0.1257 - val_acc: 0.9722\n",
      "Epoch 23/170\n",
      "3737/3737 [==============================] - 16s 4ms/step - loss: 0.0096 - acc: 0.9960 - val_loss: 0.1307 - val_acc: 0.9697\n",
      "935/935 [==============================] - 1s 554us/step\n",
      "3737/3737 [==============================] - 2s 547us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 19s 5ms/step - loss: 0.3054 - acc: 0.8801 - val_loss: 0.2524 - val_acc: 0.90906\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2099 - acc: 0.9189 - val_loss: 0.2595 - val_acc: 0.9109\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1843 - acc: 0.9312 - val_loss: 0.2350 - val_acc: 0.9232\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1652 - acc: 0.9390 - val_loss: 0.2259 - val_acc: 0.9258\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1529 - acc: 0.9444 - val_loss: 0.2198 - val_acc: 0.9219\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1404 - acc: 0.9460 - val_loss: 0.2083 - val_acc: 0.9322\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1225 - acc: 0.9556 - val_loss: 0.2042 - val_acc: 0.9342\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1015 - acc: 0.9655 - val_loss: 0.1890 - val_acc: 0.9445\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0843 - acc: 0.9724 - val_loss: 0.1571 - val_acc: 0.9561\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0672 - acc: 0.9799 - val_loss: 0.1612 - val_acc: 0.9484\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0554 - acc: 0.9829 - val_loss: 0.2613 - val_acc: 0.9167\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0541 - acc: 0.9815 - val_loss: 0.1301 - val_acc: 0.9619\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0360 - acc: 0.9872 - val_loss: 0.1235 - val_acc: 0.9658\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0296 - acc: 0.9898 - val_loss: 0.1409 - val_acc: 0.9606\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0254 - acc: 0.9922 - val_loss: 0.1362 - val_acc: 0.9626\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0215 - acc: 0.9946 - val_loss: 0.1237 - val_acc: 0.9684\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.1341 - val_acc: 0.9690\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0150 - acc: 0.9952 - val_loss: 0.1283 - val_acc: 0.9684\n",
      "934/934 [==============================] - 0s 535us/step\n",
      "3738/3738 [==============================] - 2s 528us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 19s 5ms/step - loss: 0.3056 - acc: 0.8678 - val_loss: 0.3043 - val_acc: 0.8890\n",
      "Epoch 2/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 17s 4ms/step - loss: 0.2076 - acc: 0.9248 - val_loss: 0.2832 - val_acc: 0.9019\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1838 - acc: 0.9312 - val_loss: 0.2600 - val_acc: 0.9116\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1689 - acc: 0.9363 - val_loss: 0.2407 - val_acc: 0.9238\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1533 - acc: 0.9409 - val_loss: 0.2310 - val_acc: 0.9316\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1433 - acc: 0.9470 - val_loss: 0.2202 - val_acc: 0.9264\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1247 - acc: 0.9529 - val_loss: 0.2018 - val_acc: 0.9380\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1139 - acc: 0.9599 - val_loss: 0.2007 - val_acc: 0.9380\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0949 - acc: 0.9644 - val_loss: 0.1833 - val_acc: 0.9458\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0781 - acc: 0.9698 - val_loss: 0.1679 - val_acc: 0.9529\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0688 - acc: 0.9759 - val_loss: 0.2017 - val_acc: 0.9380\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0553 - acc: 0.9802 - val_loss: 0.1451 - val_acc: 0.9606\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0416 - acc: 0.9850 - val_loss: 0.1431 - val_acc: 0.9632\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0338 - acc: 0.9874 - val_loss: 0.1265 - val_acc: 0.9684\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0338 - acc: 0.9888 - val_loss: 0.1297 - val_acc: 0.9664\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0263 - acc: 0.9922 - val_loss: 0.1394 - val_acc: 0.9651\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.1366 - val_acc: 0.9671\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0170 - acc: 0.9946 - val_loss: 0.1545 - val_acc: 0.9651\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0156 - acc: 0.9941 - val_loss: 0.1374 - val_acc: 0.9729\n",
      "934/934 [==============================] - 1s 566us/step\n",
      "3738/3738 [==============================] - 2s 568us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 19s 5ms/step - loss: 0.3041 - acc: 0.8831 - val_loss: 0.2750 - val_acc: 0.9045\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.2084 - acc: 0.9235 - val_loss: 0.2643 - val_acc: 0.9025\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1858 - acc: 0.9307 - val_loss: 0.2598 - val_acc: 0.9025\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1700 - acc: 0.9363 - val_loss: 0.2531 - val_acc: 0.9006\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 17s 4ms/step - loss: 0.1562 - acc: 0.9406 - val_loss: 0.2091 - val_acc: 0.9329\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 17s 5ms/step - loss: 0.1503 - acc: 0.9438 - val_loss: 0.2050 - val_acc: 0.9296ss: 0.1546 - acc: 0.94 - ETA: 3s - loss: 0.\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1336 - acc: 0.9524 - val_loss: 0.1999 - val_acc: 0.9354\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1222 - acc: 0.9548 - val_loss: 0.2304 - val_acc: 0.9064\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.1100 - acc: 0.9628 - val_loss: 0.1765 - val_acc: 0.9425\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 17s 4ms/step - loss: 0.0996 - acc: 0.9628 - val_loss: 0.1606 - val_acc: 0.9490\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 17s 4ms/step - loss: 0.0771 - acc: 0.9738 - val_loss: 0.1596 - val_acc: 0.9522\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0676 - acc: 0.9762 - val_loss: 0.1423 - val_acc: 0.9561\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 17s 4ms/step - loss: 0.0548 - acc: 0.9813 - val_loss: 0.1470 - val_acc: 0.9542\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0481 - acc: 0.9815 - val_loss: 0.1245 - val_acc: 0.9626\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0376 - acc: 0.9864 - val_loss: 0.1292 - val_acc: 0.9638\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 17s 4ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 0.1333 - val_acc: 0.9658\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.1326 - val_acc: 0.9664\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0201 - acc: 0.9930 - val_loss: 0.1319 - val_acc: 0.9677\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 16s 4ms/step - loss: 0.0161 - acc: 0.9955 - val_loss: 0.1377 - val_acc: 0.9684\n",
      "934/934 [==============================] - 1s 547us/step\n",
      "3738/3738 [==============================] - 2s 533us/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 15s 4ms/step - loss: 0.3741 - acc: 0.8320 - val_loss: 0.2599 - val_acc: 0.9109\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.2286 - acc: 0.9154 - val_loss: 0.2412 - val_acc: 0.9161\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1990 - acc: 0.9277 - val_loss: 0.2335 - val_acc: 0.9206\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 12s 3ms/step - loss: 0.1852 - acc: 0.9363 - val_loss: 0.2251 - val_acc: 0.9245\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1650 - acc: 0.9422 - val_loss: 0.2149 - val_acc: 0.9258\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1551 - acc: 0.9449 - val_loss: 0.2108 - val_acc: 0.9283\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1457 - acc: 0.9467 - val_loss: 0.2173 - val_acc: 0.9238\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1398 - acc: 0.9481 - val_loss: 0.2106 - val_acc: 0.9296\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1302 - acc: 0.9526 - val_loss: 0.2587 - val_acc: 0.9141\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1245 - acc: 0.9510 - val_loss: 0.2007 - val_acc: 0.9329\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1102 - acc: 0.9636 - val_loss: 0.1854 - val_acc: 0.9509\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1014 - acc: 0.9636 - val_loss: 0.1835 - val_acc: 0.9458\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 13s 3ms/step - loss: 0.0887 - acc: 0.9716 - val_loss: 0.1725 - val_acc: 0.9509\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.0772 - acc: 0.9740 - val_loss: 0.1612 - val_acc: 0.9567\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 12s 3ms/step - loss: 0.0650 - acc: 0.9786 - val_loss: 0.1787 - val_acc: 0.9464\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.0592 - acc: 0.9786 - val_loss: 0.1621 - val_acc: 0.9561\n",
      "Epoch 17/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0542 - acc: 0.9810 - val_loss: 0.1790 - val_acc: 0.9503\n",
      "Epoch 18/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0484 - acc: 0.9837 - val_loss: 0.1655 - val_acc: 0.9567\n",
      "Epoch 19/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0340 - acc: 0.9896 - val_loss: 0.1431 - val_acc: 0.9619\n",
      "Epoch 20/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0352 - acc: 0.9869 - val_loss: 0.1460 - val_acc: 0.9606\n",
      "Epoch 21/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0287 - acc: 0.9888 - val_loss: 0.1429 - val_acc: 0.9619\n",
      "Epoch 22/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0231 - acc: 0.9925 - val_loss: 0.1385 - val_acc: 0.9632\n",
      "Epoch 23/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0211 - acc: 0.9930 - val_loss: 0.1562 - val_acc: 0.9626\n",
      "Epoch 24/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0237 - acc: 0.9896 - val_loss: 0.1387 - val_acc: 0.9638\n",
      "Epoch 25/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.1518 - val_acc: 0.9703\n",
      "Epoch 26/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0131 - acc: 0.9957 - val_loss: 0.1402 - val_acc: 0.9664\n",
      "Epoch 27/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.1393 - val_acc: 0.9709\n",
      "935/935 [==============================] - 0s 461us/step\n",
      "3737/3737 [==============================] - 2s 459us/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 14s 4ms/step - loss: 0.3584 - acc: 0.8563 - val_loss: 0.3024 - val_acc: 0.8780\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.2228 - acc: 0.9213 - val_loss: 0.2478 - val_acc: 0.9141\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1960 - acc: 0.9269 - val_loss: 0.2330 - val_acc: 0.9167\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1780 - acc: 0.9299 - val_loss: 0.2308 - val_acc: 0.9154\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1649 - acc: 0.9398 - val_loss: 0.2241 - val_acc: 0.9206\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1496 - acc: 0.9433 - val_loss: 0.2177 - val_acc: 0.9264\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1465 - acc: 0.9451 - val_loss: 0.2199 - val_acc: 0.9232\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1399 - acc: 0.9438 - val_loss: 0.2180 - val_acc: 0.9270\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 12s 3ms/step - loss: 0.1230 - acc: 0.9577 - val_loss: 0.2123 - val_acc: 0.9277\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.1197 - acc: 0.9553 - val_loss: 0.2064 - val_acc: 0.9309\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1091 - acc: 0.9612 - val_loss: 0.2081 - val_acc: 0.9322\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.1054 - acc: 0.9633 - val_loss: 0.2019 - val_acc: 0.9354\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0991 - acc: 0.9641 - val_loss: 0.1887 - val_acc: 0.9425\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 12s 3ms/step - loss: 0.0861 - acc: 0.9700 - val_loss: 0.2251 - val_acc: 0.9258\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0833 - acc: 0.9703 - val_loss: 0.1857 - val_acc: 0.9425\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0739 - acc: 0.9759 - val_loss: 0.1734 - val_acc: 0.9471\n",
      "Epoch 17/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0694 - acc: 0.9791 - val_loss: 0.1617 - val_acc: 0.9490\n",
      "Epoch 18/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0611 - acc: 0.9794 - val_loss: 0.1922 - val_acc: 0.9419\n",
      "Epoch 19/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0549 - acc: 0.9799 - val_loss: 0.1577 - val_acc: 0.9503\n",
      "Epoch 20/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.0516 - acc: 0.9839 - val_loss: 0.1932 - val_acc: 0.9374\n",
      "Epoch 21/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0399 - acc: 0.9874 - val_loss: 0.1654 - val_acc: 0.9490\n",
      "Epoch 22/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0362 - acc: 0.9877 - val_loss: 0.1425 - val_acc: 0.9606\n",
      "Epoch 23/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0325 - acc: 0.9906 - val_loss: 0.1391 - val_acc: 0.9632\n",
      "Epoch 24/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0270 - acc: 0.9917 - val_loss: 0.1384 - val_acc: 0.9606\n",
      "Epoch 25/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0193 - acc: 0.9955 - val_loss: 0.1518 - val_acc: 0.9548\n",
      "Epoch 26/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0240 - acc: 0.9930 - val_loss: 0.1442 - val_acc: 0.9580\n",
      "Epoch 27/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0184 - acc: 0.9960 - val_loss: 0.1512 - val_acc: 0.9593\n",
      "Epoch 28/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0198 - acc: 0.9933 - val_loss: 0.1514 - val_acc: 0.9619\n",
      "Epoch 29/170\n",
      "3737/3737 [==============================] - 10s 3ms/step - loss: 0.0129 - acc: 0.9960 - val_loss: 0.1528 - val_acc: 0.9606\n",
      "935/935 [==============================] - 0s 459us/step\n",
      "3737/3737 [==============================] - 2s 462us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 14s 4ms/step - loss: 0.3636 - acc: 0.8649 - val_loss: 0.2782 - val_acc: 0.8967\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.2162 - acc: 0.9171 - val_loss: 0.2536 - val_acc: 0.9187\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1904 - acc: 0.9326 - val_loss: 0.2346 - val_acc: 0.9219\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1759 - acc: 0.9374 - val_loss: 0.2314 - val_acc: 0.9219\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1589 - acc: 0.9401 - val_loss: 0.2286 - val_acc: 0.9245\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1504 - acc: 0.9441 - val_loss: 0.2476 - val_acc: 0.9148\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1423 - acc: 0.9454 - val_loss: 0.2608 - val_acc: 0.9057\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1341 - acc: 0.9513 - val_loss: 0.2221 - val_acc: 0.9296\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 11s 3ms/step - loss: 0.1246 - acc: 0.9535 - val_loss: 0.2267 - val_acc: 0.9225\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1154 - acc: 0.9551 - val_loss: 0.2283 - val_acc: 0.9270\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1031 - acc: 0.9650 - val_loss: 0.2052 - val_acc: 0.9425\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0968 - acc: 0.9666 - val_loss: 0.1963 - val_acc: 0.9419\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0837 - acc: 0.9714 - val_loss: 0.1900 - val_acc: 0.9516\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0749 - acc: 0.9757 - val_loss: 0.1712 - val_acc: 0.9516\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0690 - acc: 0.9775 - val_loss: 0.1663 - val_acc: 0.9535\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0560 - acc: 0.9834 - val_loss: 0.1594 - val_acc: 0.9555\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0477 - acc: 0.9839 - val_loss: 0.1511 - val_acc: 0.9580\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0409 - acc: 0.9877 - val_loss: 0.1465 - val_acc: 0.9606\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0373 - acc: 0.9882 - val_loss: 0.1602 - val_acc: 0.9561\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0323 - acc: 0.9898 - val_loss: 0.1375 - val_acc: 0.9651\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0253 - acc: 0.9914 - val_loss: 0.1751 - val_acc: 0.9529\n",
      "Epoch 22/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0311 - acc: 0.9896 - val_loss: 0.1262 - val_acc: 0.9651\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.1466 - val_acc: 0.9632\n",
      "Epoch 24/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0158 - acc: 0.9946 - val_loss: 0.1626 - val_acc: 0.9567\n",
      "Epoch 25/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0139 - acc: 0.9963 - val_loss: 0.1486 - val_acc: 0.9671\n",
      "Epoch 26/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0125 - acc: 0.9965 - val_loss: 0.1522 - val_acc: 0.9677\n",
      "Epoch 27/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0174 - acc: 0.9938 - val_loss: 0.1400 - val_acc: 0.9697\n",
      "934/934 [==============================] - 0s 446us/step\n",
      "3738/3738 [==============================] - 2s 452us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 14s 4ms/step - loss: 0.3466 - acc: 0.8625 - val_loss: 0.3069 - val_acc: 0.8890\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.2108 - acc: 0.9251 - val_loss: 0.2674 - val_acc: 0.9077\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1896 - acc: 0.9278 - val_loss: 0.2492 - val_acc: 0.9167\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1751 - acc: 0.9334 - val_loss: 0.2426 - val_acc: 0.9225\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1659 - acc: 0.9387 - val_loss: 0.2312 - val_acc: 0.9238\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1537 - acc: 0.9438 - val_loss: 0.2367 - val_acc: 0.9219\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1374 - acc: 0.9502 - val_loss: 0.2145 - val_acc: 0.9342\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1256 - acc: 0.9518 - val_loss: 0.2147 - val_acc: 0.9309\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1142 - acc: 0.9569 - val_loss: 0.2343 - val_acc: 0.9199\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1029 - acc: 0.9620 - val_loss: 0.1888 - val_acc: 0.9464\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0948 - acc: 0.9671 - val_loss: 0.2057 - val_acc: 0.9380\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 11s 3ms/step - loss: 0.0774 - acc: 0.9738 - val_loss: 0.1785 - val_acc: 0.9509\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0719 - acc: 0.9703 - val_loss: 0.1705 - val_acc: 0.9484\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0627 - acc: 0.9775 - val_loss: 0.1662 - val_acc: 0.9522\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0501 - acc: 0.9831 - val_loss: 0.1696 - val_acc: 0.9542\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0443 - acc: 0.9842 - val_loss: 0.1570 - val_acc: 0.9587\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0381 - acc: 0.9885 - val_loss: 0.1551 - val_acc: 0.9567\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0349 - acc: 0.9885 - val_loss: 0.1595 - val_acc: 0.9561\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0287 - acc: 0.9909 - val_loss: 0.1551 - val_acc: 0.9587\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0259 - acc: 0.9901 - val_loss: 0.1387 - val_acc: 0.9658\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0199 - acc: 0.9928 - val_loss: 0.1428 - val_acc: 0.9671\n",
      "Epoch 22/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0172 - acc: 0.9944 - val_loss: 0.1441 - val_acc: 0.9658\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0157 - acc: 0.9952 - val_loss: 0.1516 - val_acc: 0.9651\n",
      "Epoch 24/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0181 - acc: 0.9928 - val_loss: 0.1395 - val_acc: 0.9690\n",
      "Epoch 25/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0124 - acc: 0.9965 - val_loss: 0.1453 - val_acc: 0.9709\n",
      "934/934 [==============================] - 0s 453us/step\n",
      "3738/3738 [==============================] - 2s 448us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 14s 4ms/step - loss: 0.3509 - acc: 0.8604 - val_loss: 0.2947 - val_acc: 0.8993\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.2143 - acc: 0.9248 - val_loss: 0.2787 - val_acc: 0.9038\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1923 - acc: 0.9342 - val_loss: 0.2482 - val_acc: 0.9180\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1735 - acc: 0.9358 - val_loss: 0.2495 - val_acc: 0.9128\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1644 - acc: 0.9358 - val_loss: 0.2313 - val_acc: 0.9187\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1517 - acc: 0.9436 - val_loss: 0.2133 - val_acc: 0.9277\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1482 - acc: 0.9454 - val_loss: 0.2038 - val_acc: 0.9296\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1299 - acc: 0.9513 - val_loss: 0.2817 - val_acc: 0.8928\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1195 - acc: 0.9537 - val_loss: 0.2087 - val_acc: 0.9219\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.1087 - acc: 0.9583 - val_loss: 0.2561 - val_acc: 0.9064\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0938 - acc: 0.9679 - val_loss: 0.1692 - val_acc: 0.9464\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0828 - acc: 0.9714 - val_loss: 0.1615 - val_acc: 0.9503\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0743 - acc: 0.9741 - val_loss: 0.1497 - val_acc: 0.9516\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0633 - acc: 0.9775 - val_loss: 0.1726 - val_acc: 0.9464\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0536 - acc: 0.9802 - val_loss: 0.1527 - val_acc: 0.9561\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 11s 3ms/step - loss: 0.0467 - acc: 0.9853 - val_loss: 0.1322 - val_acc: 0.9613\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 11s 3ms/step - loss: 0.0408 - acc: 0.9861 - val_loss: 0.1280 - val_acc: 0.9632\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0391 - acc: 0.9853 - val_loss: 0.1201 - val_acc: 0.9619\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0307 - acc: 0.9909 - val_loss: 0.1231 - val_acc: 0.9638\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0296 - acc: 0.9901 - val_loss: 0.1480 - val_acc: 0.9561\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0221 - acc: 0.9933 - val_loss: 0.1520 - val_acc: 0.9600\n",
      "Epoch 22/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0184 - acc: 0.9941 - val_loss: 0.1240 - val_acc: 0.9703\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 10s 3ms/step - loss: 0.0140 - acc: 0.9957 - val_loss: 0.1331 - val_acc: 0.9697\n",
      "934/934 [==============================] - 0s 462us/step\n",
      "3738/3738 [==============================] - 2s 452us/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.4108 - acc: 0.8245 - val_loss: 0.3115 - val_acc: 0.8657\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.2426 - acc: 0.9101 - val_loss: 0.2608 - val_acc: 0.9109\n",
      "Epoch 3/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.2126 - acc: 0.9240 - val_loss: 0.2534 - val_acc: 0.9103\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1912 - acc: 0.9331 - val_loss: 0.2410 - val_acc: 0.9180\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1815 - acc: 0.9368 - val_loss: 0.2274 - val_acc: 0.9206\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1641 - acc: 0.9449 - val_loss: 0.2134 - val_acc: 0.9296\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1549 - acc: 0.9454 - val_loss: 0.2168 - val_acc: 0.9270\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1385 - acc: 0.9518 - val_loss: 0.2028 - val_acc: 0.9354\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1300 - acc: 0.9516 - val_loss: 0.2029 - val_acc: 0.9374\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1230 - acc: 0.9532 - val_loss: 0.1892 - val_acc: 0.9400\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1044 - acc: 0.9644 - val_loss: 0.1760 - val_acc: 0.9471\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0966 - acc: 0.9663 - val_loss: 0.1754 - val_acc: 0.9484\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0805 - acc: 0.9738 - val_loss: 0.1653 - val_acc: 0.9542\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0748 - acc: 0.9759 - val_loss: 0.1581 - val_acc: 0.9542\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0667 - acc: 0.9773 - val_loss: 0.1455 - val_acc: 0.9613\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0565 - acc: 0.9807 - val_loss: 0.1398 - val_acc: 0.9619\n",
      "Epoch 17/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0549 - acc: 0.9813 - val_loss: 0.1458 - val_acc: 0.9574\n",
      "Epoch 18/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0432 - acc: 0.9866 - val_loss: 0.1358 - val_acc: 0.9600\n",
      "Epoch 19/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0448 - acc: 0.9845 - val_loss: 0.1331 - val_acc: 0.9671\n",
      "Epoch 20/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.1347 - val_acc: 0.9697\n",
      "Epoch 21/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0290 - acc: 0.9914 - val_loss: 0.1399 - val_acc: 0.9677\n",
      "Epoch 22/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0279 - acc: 0.9898 - val_loss: 0.1317 - val_acc: 0.9709\n",
      "Epoch 23/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0221 - acc: 0.9941 - val_loss: 0.1343 - val_acc: 0.9690\n",
      "Epoch 24/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0232 - acc: 0.9920 - val_loss: 0.1319 - val_acc: 0.9690\n",
      "Epoch 25/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.1306 - val_acc: 0.9709\n",
      "Epoch 26/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.1384 - val_acc: 0.9709\n",
      "Epoch 27/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0165 - acc: 0.9955 - val_loss: 0.1531 - val_acc: 0.9580\n",
      "Epoch 28/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0123 - acc: 0.9973 - val_loss: 0.1382 - val_acc: 0.9716\n",
      "Epoch 29/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0112 - acc: 0.9979 - val_loss: 0.1455 - val_acc: 0.9722\n",
      "Epoch 30/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.1382 - val_acc: 0.9735\n",
      "935/935 [==============================] - 0s 397us/step\n",
      "3737/3737 [==============================] - 1s 391us/step\n",
      "Train on 3737 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3737/3737 [==============================] - 11s 3ms/step - loss: 0.4266 - acc: 0.8220 - val_loss: 0.2655 - val_acc: 0.9096\n",
      "Epoch 2/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.2269 - acc: 0.9181 - val_loss: 0.2505 - val_acc: 0.9180\n",
      "Epoch 3/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.2152 - acc: 0.9221 - val_loss: 0.2583 - val_acc: 0.9154\n",
      "Epoch 4/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1898 - acc: 0.9331 - val_loss: 0.2377 - val_acc: 0.9206\n",
      "Epoch 5/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1795 - acc: 0.9360 - val_loss: 0.2397 - val_acc: 0.9135\n",
      "Epoch 6/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1638 - acc: 0.9435 - val_loss: 0.2237 - val_acc: 0.9225\n",
      "Epoch 7/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1572 - acc: 0.9438 - val_loss: 0.2158 - val_acc: 0.9258\n",
      "Epoch 8/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1464 - acc: 0.9492 - val_loss: 0.2106 - val_acc: 0.9277\n",
      "Epoch 9/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1373 - acc: 0.9505 - val_loss: 0.2086 - val_acc: 0.9361\n",
      "Epoch 10/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1299 - acc: 0.9542 - val_loss: 0.2041 - val_acc: 0.9322\n",
      "Epoch 11/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1306 - acc: 0.9521 - val_loss: 0.2420 - val_acc: 0.9174\n",
      "Epoch 12/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1169 - acc: 0.9580 - val_loss: 0.2008 - val_acc: 0.9348\n",
      "Epoch 13/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1123 - acc: 0.9609 - val_loss: 0.1974 - val_acc: 0.9425\n",
      "Epoch 14/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1028 - acc: 0.9620 - val_loss: 0.1996 - val_acc: 0.9361\n",
      "Epoch 15/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.1074 - acc: 0.9623 - val_loss: 0.1964 - val_acc: 0.9413\n",
      "Epoch 16/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0957 - acc: 0.9663 - val_loss: 0.1909 - val_acc: 0.9432\n",
      "Epoch 17/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0869 - acc: 0.9738 - val_loss: 0.1827 - val_acc: 0.9458\n",
      "Epoch 18/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0844 - acc: 0.9708 - val_loss: 0.1691 - val_acc: 0.9509\n",
      "Epoch 19/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0769 - acc: 0.9738 - val_loss: 0.1662 - val_acc: 0.9516\n",
      "Epoch 20/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0678 - acc: 0.9775 - val_loss: 0.1655 - val_acc: 0.9535\n",
      "Epoch 21/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0658 - acc: 0.9781 - val_loss: 0.1694 - val_acc: 0.9458\n",
      "Epoch 22/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0705 - acc: 0.9756 - val_loss: 0.1509 - val_acc: 0.9516\n",
      "Epoch 23/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0509 - acc: 0.9839 - val_loss: 0.1545 - val_acc: 0.9535\n",
      "Epoch 24/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0484 - acc: 0.9837 - val_loss: 0.1477 - val_acc: 0.9574\n",
      "Epoch 25/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0464 - acc: 0.9861 - val_loss: 0.1459 - val_acc: 0.9587\n",
      "Epoch 26/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0467 - acc: 0.9839 - val_loss: 0.1419 - val_acc: 0.9542\n",
      "Epoch 27/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0353 - acc: 0.9882 - val_loss: 0.1443 - val_acc: 0.9606\n",
      "Epoch 28/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0376 - acc: 0.9880 - val_loss: 0.1329 - val_acc: 0.9600\n",
      "Epoch 29/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0289 - acc: 0.9920 - val_loss: 0.1481 - val_acc: 0.9516\n",
      "Epoch 30/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0296 - acc: 0.9896 - val_loss: 0.1494 - val_acc: 0.9522\n",
      "Epoch 31/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0231 - acc: 0.9957 - val_loss: 0.1592 - val_acc: 0.9516\n",
      "Epoch 32/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0229 - acc: 0.9922 - val_loss: 0.1382 - val_acc: 0.9645\n",
      "Epoch 33/170\n",
      "3737/3737 [==============================] - 7s 2ms/step - loss: 0.0196 - acc: 0.9946 - val_loss: 0.1343 - val_acc: 0.9671\n",
      "935/935 [==============================] - 0s 378us/step\n",
      "3737/3737 [==============================] - 1s 383us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 11s 3ms/step - loss: 0.4203 - acc: 0.8189 - val_loss: 0.2755 - val_acc: 0.9064\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.2301 - acc: 0.9171 - val_loss: 0.2661 - val_acc: 0.9083\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.2083 - acc: 0.9230 - val_loss: 0.2539 - val_acc: 0.9135\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1947 - acc: 0.9294 - val_loss: 0.3074 - val_acc: 0.8941\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1868 - acc: 0.9307 - val_loss: 0.2492 - val_acc: 0.9180\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1684 - acc: 0.9374 - val_loss: 0.2497 - val_acc: 0.9193\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1596 - acc: 0.9398 - val_loss: 0.2396 - val_acc: 0.9225\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1502 - acc: 0.9476 - val_loss: 0.2418 - val_acc: 0.9206\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1385 - acc: 0.9481 - val_loss: 0.2290 - val_acc: 0.9309\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1351 - acc: 0.9489 - val_loss: 0.2279 - val_acc: 0.9303\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1245 - acc: 0.9521 - val_loss: 0.2159 - val_acc: 0.9354\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1165 - acc: 0.9591 - val_loss: 0.2122 - val_acc: 0.9380\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1105 - acc: 0.9591 - val_loss: 0.2011 - val_acc: 0.9387\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0972 - acc: 0.9655 - val_loss: 0.2610 - val_acc: 0.9090\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0902 - acc: 0.9684 - val_loss: 0.1915 - val_acc: 0.9413\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0882 - acc: 0.9671 - val_loss: 0.2015 - val_acc: 0.9406\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0714 - acc: 0.9751 - val_loss: 0.1887 - val_acc: 0.9464\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0720 - acc: 0.9727 - val_loss: 0.2521 - val_acc: 0.9193\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0623 - acc: 0.9802 - val_loss: 0.1831 - val_acc: 0.9458\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0547 - acc: 0.9797 - val_loss: 0.1692 - val_acc: 0.9535\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0466 - acc: 0.9858 - val_loss: 0.1664 - val_acc: 0.9574\n",
      "Epoch 22/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0417 - acc: 0.9858 - val_loss: 0.1550 - val_acc: 0.9561\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0342 - acc: 0.9896 - val_loss: 0.1536 - val_acc: 0.9606\n",
      "Epoch 24/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0361 - acc: 0.9904 - val_loss: 0.1594 - val_acc: 0.9600\n",
      "Epoch 25/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0315 - acc: 0.9906 - val_loss: 0.1465 - val_acc: 0.9613\n",
      "Epoch 26/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 0.1477 - val_acc: 0.9638\n",
      "Epoch 27/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0297 - acc: 0.9901 - val_loss: 0.1486 - val_acc: 0.9645\n",
      "Epoch 28/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0258 - acc: 0.9925 - val_loss: 0.1455 - val_acc: 0.9664\n",
      "Epoch 29/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0197 - acc: 0.9944 - val_loss: 0.1495 - val_acc: 0.9638\n",
      "Epoch 30/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0166 - acc: 0.9963 - val_loss: 0.1468 - val_acc: 0.9638\n",
      "Epoch 31/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.1715 - val_acc: 0.9567\n",
      "Epoch 32/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0138 - acc: 0.9979 - val_loss: 0.1630 - val_acc: 0.9671\n",
      "Epoch 33/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0149 - acc: 0.9960 - val_loss: 0.1529 - val_acc: 0.9658\n",
      "934/934 [==============================] - 0s 407us/step\n",
      "3738/3738 [==============================] - 2s 407us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 12s 3ms/step - loss: 0.4334 - acc: 0.8138 - val_loss: 0.2979 - val_acc: 0.8986\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.2278 - acc: 0.9197 - val_loss: 0.3116 - val_acc: 0.8948\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.2063 - acc: 0.9264 - val_loss: 0.2738 - val_acc: 0.9167\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1899 - acc: 0.9323 - val_loss: 0.2528 - val_acc: 0.9206\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1793 - acc: 0.9355 - val_loss: 0.2703 - val_acc: 0.9135\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1664 - acc: 0.9395 - val_loss: 0.2448 - val_acc: 0.9193\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1598 - acc: 0.9441 - val_loss: 0.2389 - val_acc: 0.9264\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1544 - acc: 0.9452 - val_loss: 0.2637 - val_acc: 0.9174\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1453 - acc: 0.9465 - val_loss: 0.2399 - val_acc: 0.9296\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1411 - acc: 0.9473 - val_loss: 0.2402 - val_acc: 0.9277\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1288 - acc: 0.9537 - val_loss: 0.2264 - val_acc: 0.9348\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1261 - acc: 0.9540 - val_loss: 0.2230 - val_acc: 0.9361\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1170 - acc: 0.9583 - val_loss: 0.2390 - val_acc: 0.9245\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1056 - acc: 0.9607 - val_loss: 0.2411 - val_acc: 0.9245\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0994 - acc: 0.9628 - val_loss: 0.2389 - val_acc: 0.9219\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0968 - acc: 0.9652 - val_loss: 0.1968 - val_acc: 0.9413\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0814 - acc: 0.9724 - val_loss: 0.2014 - val_acc: 0.9438\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0720 - acc: 0.9722 - val_loss: 0.1845 - val_acc: 0.9509\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0675 - acc: 0.9746 - val_loss: 0.1788 - val_acc: 0.9561\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0591 - acc: 0.9810 - val_loss: 0.1801 - val_acc: 0.9529\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0565 - acc: 0.9815 - val_loss: 0.1717 - val_acc: 0.9574\n",
      "Epoch 22/170\n",
      "3738/3738 [==============================] - 8s 2ms/step - loss: 0.0492 - acc: 0.9818 - val_loss: 0.1660 - val_acc: 0.9574\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0474 - acc: 0.9834 - val_loss: 0.2156 - val_acc: 0.9432\n",
      "Epoch 24/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0442 - acc: 0.9845 - val_loss: 0.1647 - val_acc: 0.9509\n",
      "Epoch 25/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0387 - acc: 0.9856 - val_loss: 0.1716 - val_acc: 0.9567\n",
      "Epoch 26/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0365 - acc: 0.9869 - val_loss: 0.2053 - val_acc: 0.9490\n",
      "Epoch 27/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0295 - acc: 0.9906 - val_loss: 0.1612 - val_acc: 0.9645\n",
      "Epoch 28/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0271 - acc: 0.9933 - val_loss: 0.1573 - val_acc: 0.9645\n",
      "Epoch 29/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0208 - acc: 0.9944 - val_loss: 0.1716 - val_acc: 0.9613\n",
      "Epoch 30/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0191 - acc: 0.9941 - val_loss: 0.1959 - val_acc: 0.9548\n",
      "Epoch 31/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0217 - acc: 0.9933 - val_loss: 0.1615 - val_acc: 0.9638\n",
      "Epoch 32/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0212 - acc: 0.9938 - val_loss: 0.1608 - val_acc: 0.9632\n",
      "Epoch 33/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0151 - acc: 0.9960 - val_loss: 0.1592 - val_acc: 0.9671\n",
      "934/934 [==============================] - 0s 397us/step\n",
      "3738/3738 [==============================] - 1s 395us/step\n",
      "Train on 3738 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "3738/3738 [==============================] - 11s 3ms/step - loss: 0.4078 - acc: 0.8189 - val_loss: 0.2858 - val_acc: 0.9045\n",
      "Epoch 2/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.2208 - acc: 0.9270 - val_loss: 0.2528 - val_acc: 0.9174\n",
      "Epoch 3/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.2012 - acc: 0.9318 - val_loss: 0.2741 - val_acc: 0.9070\n",
      "Epoch 4/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1891 - acc: 0.9358 - val_loss: 0.2472 - val_acc: 0.9128\n",
      "Epoch 5/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1792 - acc: 0.9339 - val_loss: 0.2380 - val_acc: 0.9212\n",
      "Epoch 6/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1642 - acc: 0.9414 - val_loss: 0.2331 - val_acc: 0.9225\n",
      "Epoch 7/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1655 - acc: 0.9387 - val_loss: 0.2371 - val_acc: 0.9187\n",
      "Epoch 8/170\n",
      "3738/3738 [==============================] - 8s 2ms/step - loss: 0.1517 - acc: 0.9428 - val_loss: 0.2142 - val_acc: 0.9296\n",
      "Epoch 9/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1434 - acc: 0.9484 - val_loss: 0.2399 - val_acc: 0.9135\n",
      "Epoch 10/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1394 - acc: 0.9494 - val_loss: 0.2405 - val_acc: 0.9135\n",
      "Epoch 11/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1288 - acc: 0.9521 - val_loss: 0.2086 - val_acc: 0.9342\n",
      "Epoch 12/170\n",
      "3738/3738 [==============================] - 8s 2ms/step - loss: 0.1283 - acc: 0.9486 - val_loss: 0.2008 - val_acc: 0.9342\n",
      "Epoch 13/170\n",
      "3738/3738 [==============================] - 8s 2ms/step - loss: 0.1262 - acc: 0.9535 - val_loss: 0.3096 - val_acc: 0.8832\n",
      "Epoch 14/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1207 - acc: 0.9553 - val_loss: 0.1987 - val_acc: 0.9348\n",
      "Epoch 15/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 0.1958 - val_acc: 0.9393\n",
      "Epoch 16/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.1022 - acc: 0.9625 - val_loss: 0.2066 - val_acc: 0.9290\n",
      "Epoch 17/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0969 - acc: 0.9636 - val_loss: 0.1817 - val_acc: 0.9438\n",
      "Epoch 18/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0902 - acc: 0.9668 - val_loss: 0.1816 - val_acc: 0.9393\n",
      "Epoch 19/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0819 - acc: 0.9727 - val_loss: 0.2071 - val_acc: 0.9296\n",
      "Epoch 20/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0745 - acc: 0.9727 - val_loss: 0.1646 - val_acc: 0.9503\n",
      "Epoch 21/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0696 - acc: 0.9770 - val_loss: 0.2825 - val_acc: 0.9064\n",
      "Epoch 22/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0645 - acc: 0.9770 - val_loss: 0.1832 - val_acc: 0.9438\n",
      "Epoch 23/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0623 - acc: 0.9754 - val_loss: 0.1767 - val_acc: 0.9458\n",
      "Epoch 24/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0494 - acc: 0.9834 - val_loss: 0.1469 - val_acc: 0.9561\n",
      "Epoch 25/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0440 - acc: 0.9856 - val_loss: 0.1555 - val_acc: 0.9555\n",
      "Epoch 26/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0414 - acc: 0.9837 - val_loss: 0.1443 - val_acc: 0.9542\n",
      "Epoch 27/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0406 - acc: 0.9848 - val_loss: 0.1879 - val_acc: 0.9445\n",
      "Epoch 28/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0309 - acc: 0.9896 - val_loss: 0.1328 - val_acc: 0.9638\n",
      "Epoch 29/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0257 - acc: 0.9936 - val_loss: 0.1307 - val_acc: 0.9664\n",
      "Epoch 30/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0256 - acc: 0.9912 - val_loss: 0.1365 - val_acc: 0.9651\n",
      "Epoch 31/170\n",
      "3738/3738 [==============================] - 8s 2ms/step - loss: 0.0216 - acc: 0.9928 - val_loss: 0.1393 - val_acc: 0.9632\n",
      "Epoch 32/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0261 - acc: 0.9914 - val_loss: 0.1409 - val_acc: 0.9619\n",
      "Epoch 33/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0215 - acc: 0.9930 - val_loss: 0.1239 - val_acc: 0.9677\n",
      "Epoch 34/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0165 - acc: 0.9955 - val_loss: 0.1253 - val_acc: 0.9651\n",
      "Epoch 35/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0174 - acc: 0.9949 - val_loss: 0.1276 - val_acc: 0.9664\n",
      "Epoch 36/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0129 - acc: 0.9960 - val_loss: 0.1365 - val_acc: 0.9658\n",
      "Epoch 37/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0087 - acc: 0.9992 - val_loss: 0.1767 - val_acc: 0.9561\n",
      "Epoch 38/170\n",
      "3738/3738 [==============================] - 7s 2ms/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.1624 - val_acc: 0.9619\n",
      "934/934 [==============================] - 0s 408us/step\n",
      "3738/3738 [==============================] - 2s 418us/step\n",
      "Train on 4672 samples, validate on 1549 samples\n",
      "Epoch 1/170\n",
      "4672/4672 [==============================] - 25s 5ms/step - loss: 0.2980 - acc: 0.8872 - val_loss: 0.2390 - val_acc: 0.9141\n",
      "Epoch 2/170\n",
      "4672/4672 [==============================] - 21s 4ms/step - loss: 0.2085 - acc: 0.9259 - val_loss: 0.2285 - val_acc: 0.9193A: 6s - -\n",
      "Epoch 3/170\n",
      "4672/4672 [==============================] - 21s 4ms/step - loss: 0.1751 - acc: 0.9330 - val_loss: 0.2507 - val_acc: 0.9045\n",
      "Epoch 4/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.1651 - acc: 0.9362 - val_loss: 0.2227 - val_acc: 0.9238\n",
      "Epoch 5/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.1503 - acc: 0.9437 - val_loss: 0.2016 - val_acc: 0.9303\n",
      "Epoch 6/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.1372 - acc: 0.9480 - val_loss: 0.1911 - val_acc: 0.9393\n",
      "Epoch 7/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.1252 - acc: 0.9561 - val_loss: 0.1872 - val_acc: 0.9406\n",
      "Epoch 8/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.1079 - acc: 0.9610 - val_loss: 0.1665 - val_acc: 0.9484\n",
      "Epoch 9/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0892 - acc: 0.9664 - val_loss: 0.1780 - val_acc: 0.9400\n",
      "Epoch 10/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0727 - acc: 0.9754 - val_loss: 0.1426 - val_acc: 0.9587\n",
      "Epoch 11/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0602 - acc: 0.9780 - val_loss: 0.1221 - val_acc: 0.9645\n",
      "Epoch 12/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0527 - acc: 0.9822 - val_loss: 0.1260 - val_acc: 0.9606\n",
      "Epoch 13/170\n",
      "4672/4672 [==============================] - 21s 4ms/step - loss: 0.0411 - acc: 0.9857 - val_loss: 0.1284 - val_acc: 0.9638\n",
      "Epoch 14/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0385 - acc: 0.9874 - val_loss: 0.1128 - val_acc: 0.9626\n",
      "Epoch 15/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0274 - acc: 0.9917 - val_loss: 0.1011 - val_acc: 0.9722\n",
      "Epoch 16/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0268 - acc: 0.9897 - val_loss: 0.1086 - val_acc: 0.9716\n",
      "Epoch 17/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0171 - acc: 0.9953 - val_loss: 0.1149 - val_acc: 0.9697\n",
      "Epoch 18/170\n",
      "4672/4672 [==============================] - 21s 4ms/step - loss: 0.0185 - acc: 0.9936 - val_loss: 0.1164 - val_acc: 0.9716 0.01\n",
      "Epoch 19/170\n",
      "4672/4672 [==============================] - 20s 4ms/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.1154 - val_acc: 0.9755s: 0.0089 - acc: 0 - ETA: 0s - loss: 0.0123 \n",
      "Epoch 20/170\n",
      "4672/4672 [==============================] - 21s 4ms/step - loss: 0.0116 - acc: 0.9966 - val_loss: 0.1295 - val_acc: 0.9690\n",
      "Best: 0.971104 using {'batch_size': 8}\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 36s 9ms/step - loss: 0.2424 - acc: 0.9029 - val_loss: 0.1840 - val_acc: 0.9273\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1704 - acc: 0.9349 - val_loss: 0.1597 - val_acc: 0.9358\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.1338 - acc: 0.9509 - val_loss: 0.1391 - val_acc: 0.9463\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1033 - acc: 0.9641 - val_loss: 0.1723 - val_acc: 0.9339\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0838 - acc: 0.9698 - val_loss: 0.0877 - val_acc: 0.9751\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0511 - acc: 0.9837 - val_loss: 0.0656 - val_acc: 0.9810\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0400 - acc: 0.9871 - val_loss: 0.0758 - val_acc: 0.9751\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0277 - acc: 0.9911 - val_loss: 0.1179 - val_acc: 0.9653\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0208 - acc: 0.9932 - val_loss: 0.0582 - val_acc: 0.9843\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0094 - acc: 0.9982 - val_loss: 0.0572 - val_acc: 0.9876\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0147 - acc: 0.9945 - val_loss: 0.1228 - val_acc: 0.9699\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0667 - val_acc: 0.9790\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0050 - acc: 0.9992 - val_loss: 0.0610 - val_acc: 0.9856\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0049 - acc: 0.9987 - val_loss: 0.0648 - val_acc: 0.9862\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0672 - val_acc: 0.9797\n",
      "953/953 [==============================] - 1s 1ms/step\n",
      "3811/3811 [==============================] - 4s 1ms/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 36s 9ms/step - loss: 0.2579 - acc: 0.8969 - val_loss: 0.1843 - val_acc: 0.9293\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.1731 - acc: 0.9344 - val_loss: 0.1804 - val_acc: 0.9273\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1497 - acc: 0.9438 - val_loss: 0.1703 - val_acc: 0.9286\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.1242 - acc: 0.9543 - val_loss: 0.1388 - val_acc: 0.9450\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0935 - acc: 0.9693 - val_loss: 0.2266 - val_acc: 0.9240\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0737 - acc: 0.9774 - val_loss: 0.0981 - val_acc: 0.9666\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0473 - acc: 0.9856 - val_loss: 0.0809 - val_acc: 0.9758\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0330 - acc: 0.9890 - val_loss: 0.0599 - val_acc: 0.9810\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0224 - acc: 0.9937 - val_loss: 0.0450 - val_acc: 0.9849\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0178 - acc: 0.9948 - val_loss: 0.0665 - val_acc: 0.9804\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0142 - acc: 0.9950 - val_loss: 0.0616 - val_acc: 0.9823\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0728 - val_acc: 0.9823\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0033 - acc: 0.9997 - val_loss: 0.0655 - val_acc: 0.9830\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0766 - val_acc: 0.9797\n",
      "953/953 [==============================] - 1s 1ms/step\n",
      "3811/3811 [==============================] - 4s 1ms/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 0.2498 - acc: 0.8914 - val_loss: 0.2120 - val_acc: 0.9064\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1732 - acc: 0.9302 - val_loss: 0.1814 - val_acc: 0.9306\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1518 - acc: 0.9391 - val_loss: 0.1580 - val_acc: 0.9417\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1195 - acc: 0.9520 - val_loss: 0.1328 - val_acc: 0.9555\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0988 - acc: 0.9656 - val_loss: 0.1136 - val_acc: 0.9594\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0677 - acc: 0.9764 - val_loss: 0.1066 - val_acc: 0.9673\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0439 - acc: 0.9856 - val_loss: 0.0873 - val_acc: 0.9784\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0318 - acc: 0.9913 - val_loss: 0.0719 - val_acc: 0.9784\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0216 - acc: 0.9940 - val_loss: 0.0696 - val_acc: 0.9830\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0627 - val_acc: 0.9843\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0075 - acc: 0.9984 - val_loss: 0.1167 - val_acc: 0.9771\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0110 - acc: 0.9961 - val_loss: 0.0669 - val_acc: 0.9830\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.0714 - val_acc: 0.9849\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0082 - acc: 0.9984 - val_loss: 0.0737 - val_acc: 0.9843\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9830\n",
      "953/953 [==============================] - 1s 1ms/step\n",
      "3811/3811 [==============================] - 4s 1ms/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 36s 9ms/step - loss: 0.2571 - acc: 0.8880 - val_loss: 0.1877 - val_acc: 0.9194\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.1753 - acc: 0.9278 - val_loss: 0.1883 - val_acc: 0.9247\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.1464 - acc: 0.9386 - val_loss: 0.1557 - val_acc: 0.9371\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1150 - acc: 0.9538 - val_loss: 0.1300 - val_acc: 0.9463\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0766 - acc: 0.9706 - val_loss: 0.0977 - val_acc: 0.9673\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0433 - acc: 0.9871 - val_loss: 0.0622 - val_acc: 0.9790\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0296 - acc: 0.9913 - val_loss: 0.0759 - val_acc: 0.9784\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0218 - acc: 0.9921 - val_loss: 0.0563 - val_acc: 0.9810\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0124 - acc: 0.9963 - val_loss: 0.0771 - val_acc: 0.9797\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0155 - acc: 0.9942 - val_loss: 0.1028 - val_acc: 0.9699\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0502 - val_acc: 0.9862\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0107 - acc: 0.9982 - val_loss: 0.0574 - val_acc: 0.9869\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0550 - val_acc: 0.9843\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0566 - val_acc: 0.9882\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 0.9869\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0847 - val_acc: 0.9849\n",
      "953/953 [==============================] - 1s 1ms/step\n",
      "3811/3811 [==============================] - 5s 1ms/step\n",
      "Train on 3812 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3812/3812 [==============================] - 36s 10ms/step - loss: 0.2440 - acc: 0.8901 - val_loss: 0.2031 - val_acc: 0.9194\n",
      "Epoch 2/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.1730 - acc: 0.9265 - val_loss: 0.1824 - val_acc: 0.9181\n",
      "Epoch 3/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.1505 - acc: 0.9376 - val_loss: 0.1506 - val_acc: 0.9352\n",
      "Epoch 4/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.1142 - acc: 0.9565 - val_loss: 0.1709 - val_acc: 0.9371\n",
      "Epoch 5/170\n",
      "3812/3812 [==============================] - 31s 8ms/step - loss: 0.0802 - acc: 0.9727 - val_loss: 0.0992 - val_acc: 0.9601\n",
      "Epoch 6/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0535 - acc: 0.9832 - val_loss: 0.0735 - val_acc: 0.9771\n",
      "Epoch 7/170\n",
      "3812/3812 [==============================] - 31s 8ms/step - loss: 0.0337 - acc: 0.9887 - val_loss: 0.0571 - val_acc: 0.9804\n",
      "Epoch 8/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0209 - acc: 0.9945 - val_loss: 0.0554 - val_acc: 0.9830\n",
      "Epoch 9/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0161 - acc: 0.9934 - val_loss: 0.0490 - val_acc: 0.9876\n",
      "Epoch 10/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0155 - acc: 0.9948 - val_loss: 0.0646 - val_acc: 0.9856\n",
      "Epoch 11/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0547 - val_acc: 0.9862\n",
      "Epoch 12/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0069 - acc: 0.9992 - val_loss: 0.0630 - val_acc: 0.9876\n",
      "Epoch 13/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0564 - val_acc: 0.9862\n",
      "Epoch 14/170\n",
      "3812/3812 [==============================] - 32s 8ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0997 - val_acc: 0.9764\n",
      "952/952 [==============================] - 1s 1ms/step\n",
      "3812/3812 [==============================] - 4s 1ms/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 21s 6ms/step - loss: 0.2717 - acc: 0.8874 - val_loss: 0.1880 - val_acc: 0.9267\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1775 - acc: 0.9336 - val_loss: 0.1964 - val_acc: 0.9234\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1624 - acc: 0.9412 - val_loss: 0.1907 - val_acc: 0.9267\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1380 - acc: 0.9533 - val_loss: 0.2085 - val_acc: 0.9162\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1214 - acc: 0.9557 - val_loss: 0.1537 - val_acc: 0.94170. - ETA: 1s - loss\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1013 - acc: 0.9651 - val_loss: 0.1471 - val_acc: 0.9437\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0865 - acc: 0.9706 - val_loss: 0.1103 - val_acc: 0.9653\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0655 - acc: 0.9777 - val_loss: 0.1012 - val_acc: 0.9692\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0476 - acc: 0.9866 - val_loss: 0.0702 - val_acc: 0.9790\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0332 - acc: 0.9908 - val_loss: 0.0689 - val_acc: 0.9810\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0250 - acc: 0.9919 - val_loss: 0.0989 - val_acc: 0.9699\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0699 - val_acc: 0.9797\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0176 - acc: 0.9948 - val_loss: 0.0614 - val_acc: 0.9849\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0153 - acc: 0.9945 - val_loss: 0.0639 - val_acc: 0.9856\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0107 - acc: 0.9971 - val_loss: 0.0777 - val_acc: 0.9804\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0611 - val_acc: 0.9843A: 1s - loss\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.0695 - val_acc: 0.9869\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0074 - acc: 0.9976 - val_loss: 0.0692 - val_acc: 0.9836\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0632 - val_acc: 0.9862\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9862TA: 1s - loss: 0.0 - ETA: 0s - loss: 0.0018 - a\n",
      "Epoch 21/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0109 - acc: 0.9958 - val_loss: 0.0689 - val_acc: 0.9882\n",
      "953/953 [==============================] - 1s 627us/step\n",
      "3811/3811 [==============================] - 2s 631us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.2694 - acc: 0.8880 - val_loss: 0.1889 - val_acc: 0.9208\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.1724 - acc: 0.9375 - val_loss: 0.2004 - val_acc: 0.9227\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1563 - acc: 0.9441 - val_loss: 0.1983 - val_acc: 0.9214\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1405 - acc: 0.9494 - val_loss: 0.1910 - val_acc: 0.9194\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1276 - acc: 0.9536 - val_loss: 0.1574 - val_acc: 0.9384\n",
      "Epoch 6/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1066 - acc: 0.9654 - val_loss: 0.1578 - val_acc: 0.9411\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0889 - acc: 0.9672 - val_loss: 0.1522 - val_acc: 0.9417\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0725 - acc: 0.9756 - val_loss: 0.1412 - val_acc: 0.9502\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0657 - acc: 0.9785 - val_loss: 0.1237 - val_acc: 0.9574\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0456 - acc: 0.9850 - val_loss: 0.0902 - val_acc: 0.9725\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0323 - acc: 0.9900 - val_loss: 0.1190 - val_acc: 0.9620\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0249 - acc: 0.9919 - val_loss: 0.0709 - val_acc: 0.9790\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0209 - acc: 0.9932 - val_loss: 0.0694 - val_acc: 0.9777\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0144 - acc: 0.9953 - val_loss: 0.0855 - val_acc: 0.9738\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0738 - val_acc: 0.9758- loss -\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0754 - val_acc: 0.9810A: 1s - loss: 0.00\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0737 - val_acc: 0.9817\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0088 - acc: 0.9984 - val_loss: 0.1134 - val_acc: 0.9666\n",
      "953/953 [==============================] - 1s 618us/step\n",
      "3811/3811 [==============================] - 2s 620us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 21s 6ms/step - loss: 0.2750 - acc: 0.8924 - val_loss: 0.1891 - val_acc: 0.9286\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1746 - acc: 0.9276 - val_loss: 0.1818 - val_acc: 0.9319\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1543 - acc: 0.9394 - val_loss: 0.1721 - val_acc: 0.9345\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1430 - acc: 0.9438 - val_loss: 0.1575 - val_acc: 0.9398\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1165 - acc: 0.9562 - val_loss: 0.1716 - val_acc: 0.9404\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.1006 - acc: 0.9659 - val_loss: 0.1476 - val_acc: 0.9542\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0890 - acc: 0.9703 - val_loss: 0.1185 - val_acc: 0.9620\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0656 - acc: 0.9780 - val_loss: 0.1174 - val_acc: 0.9646\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0485 - acc: 0.9856 - val_loss: 0.0887 - val_acc: 0.9758\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0349 - acc: 0.9895 - val_loss: 0.0802 - val_acc: 0.9784\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0271 - acc: 0.9927 - val_loss: 0.0727 - val_acc: 0.9817\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0857 - val_acc: 0.9784\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0117 - acc: 0.9971 - val_loss: 0.0652 - val_acc: 0.9849\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0148 - acc: 0.9942 - val_loss: 0.0606 - val_acc: 0.9849\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0075 - acc: 0.9979 - val_loss: 0.0681 - val_acc: 0.9849\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0096 - acc: 0.9966 - val_loss: 0.0659 - val_acc: 0.9843\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0048 - acc: 0.9992 - val_loss: 0.0727 - val_acc: 0.9849\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0804 - val_acc: 0.9843\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0056 - acc: 0.9982 - val_loss: 0.0763 - val_acc: 0.9862\n",
      "953/953 [==============================] - 1s 609us/step\n",
      "3811/3811 [==============================] - 2s 612us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.2767 - acc: 0.8772 - val_loss: 0.2018 - val_acc: 0.9194\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.1784 - acc: 0.9242 - val_loss: 0.1803 - val_acc: 0.9253\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1611 - acc: 0.9313 - val_loss: 0.2093 - val_acc: 0.9090\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.1434 - acc: 0.9420 - val_loss: 0.1681 - val_acc: 0.9345\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.1195 - acc: 0.9570 - val_loss: 0.1390 - val_acc: 0.9463\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.1026 - acc: 0.9593 - val_loss: 0.1238 - val_acc: 0.9483\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0759 - acc: 0.9724 - val_loss: 0.1048 - val_acc: 0.9653\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0538 - acc: 0.9837 - val_loss: 0.0876 - val_acc: 0.9745\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.0379 - acc: 0.9869 - val_loss: 0.0697 - val_acc: 0.9810\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0311 - acc: 0.9898 - val_loss: 0.0673 - val_acc: 0.9817\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0205 - acc: 0.9937 - val_loss: 0.0591 - val_acc: 0.9862\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0129 - acc: 0.9969 - val_loss: 0.0624 - val_acc: 0.9843\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.0491 - val_acc: 0.9862\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0502 - val_acc: 0.9869\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0053 - acc: 0.9992 - val_loss: 0.0676 - val_acc: 0.9843\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0043 - acc: 0.9995 - val_loss: 0.0667 - val_acc: 0.9823\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0134 - acc: 0.9953 - val_loss: 0.0610 - val_acc: 0.9849\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0572 - val_acc: 0.9856\n",
      "953/953 [==============================] - 1s 670us/step\n",
      "3811/3811 [==============================] - 3s 669us/step\n",
      "Train on 3812 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3812/3812 [==============================] - 22s 6ms/step - loss: 0.2721 - acc: 0.8825 - val_loss: 0.1975 - val_acc: 0.9136\n",
      "Epoch 2/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.1740 - acc: 0.9286 - val_loss: 0.1748 - val_acc: 0.9325\n",
      "Epoch 3/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.1603 - acc: 0.9336 - val_loss: 0.1737 - val_acc: 0.9280\n",
      "Epoch 4/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.1480 - acc: 0.9407 - val_loss: 0.1612 - val_acc: 0.9352\n",
      "Epoch 5/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.1301 - acc: 0.9502 - val_loss: 0.1880 - val_acc: 0.9050\n",
      "Epoch 6/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.1052 - acc: 0.9570 - val_loss: 0.1246 - val_acc: 0.9509\n",
      "Epoch 7/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0884 - acc: 0.9698 - val_loss: 0.1071 - val_acc: 0.9601\n",
      "Epoch 8/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0635 - acc: 0.9774 - val_loss: 0.0893 - val_acc: 0.9725\n",
      "Epoch 9/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0467 - acc: 0.9829 - val_loss: 0.0703 - val_acc: 0.9777\n",
      "Epoch 10/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0344 - acc: 0.9887 - val_loss: 0.0609 - val_acc: 0.9810\n",
      "Epoch 11/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0207 - acc: 0.9937 - val_loss: 0.0708 - val_acc: 0.9777\n",
      "Epoch 12/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.0529 - val_acc: 0.9856\n",
      "Epoch 13/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0147 - acc: 0.9958 - val_loss: 0.0507 - val_acc: 0.9882\n",
      "Epoch 14/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0073 - acc: 0.9982 - val_loss: 0.0642 - val_acc: 0.9876\n",
      "Epoch 15/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0062 - acc: 0.9987 - val_loss: 0.0661 - val_acc: 0.9876\n",
      "Epoch 16/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0135 - acc: 0.9945 - val_loss: 0.0673 - val_acc: 0.9849\n",
      "Epoch 17/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0050 - acc: 0.9990 - val_loss: 0.0599 - val_acc: 0.9856\n",
      "Epoch 18/170\n",
      "3812/3812 [==============================] - 17s 4ms/step - loss: 0.0032 - acc: 0.9995 - val_loss: 0.0655 - val_acc: 0.9856\n",
      "952/952 [==============================] - 1s 610us/step\n",
      "3812/3812 [==============================] - 2s 627us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.2949 - acc: 0.8706 - val_loss: 0.2042 - val_acc: 0.9168\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1733 - acc: 0.9339 - val_loss: 0.1777 - val_acc: 0.9247\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1596 - acc: 0.9417 - val_loss: 0.2040 - val_acc: 0.9214\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1473 - acc: 0.9459 - val_loss: 0.1645 - val_acc: 0.9378\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1371 - acc: 0.9520 - val_loss: 0.1912 - val_acc: 0.9280\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1195 - acc: 0.9580 - val_loss: 0.1652 - val_acc: 0.9384\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1045 - acc: 0.9669 - val_loss: 0.1386 - val_acc: 0.9496\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0899 - acc: 0.9711 - val_loss: 0.1182 - val_acc: 0.9587\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0745 - acc: 0.9753 - val_loss: 0.1160 - val_acc: 0.9627\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0581 - acc: 0.9840 - val_loss: 0.1109 - val_acc: 0.9601\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0467 - acc: 0.9853 - val_loss: 0.0925 - val_acc: 0.9758\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0371 - acc: 0.9885 - val_loss: 0.0876 - val_acc: 0.9745\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0308 - acc: 0.9895 - val_loss: 0.0686 - val_acc: 0.9790\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.0883 - val_acc: 0.9718\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0172 - acc: 0.9955 - val_loss: 0.0527 - val_acc: 0.9843\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0126 - acc: 0.9976 - val_loss: 0.0942 - val_acc: 0.9731\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0111 - acc: 0.9974 - val_loss: 0.0647 - val_acc: 0.9823\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0076 - acc: 0.9984 - val_loss: 0.0600 - val_acc: 0.9862\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.0588 - val_acc: 0.9849\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0665 - val_acc: 0.9810\n",
      "953/953 [==============================] - 0s 504us/step\n",
      "3811/3811 [==============================] - 2s 497us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.3134 - acc: 0.8625 - val_loss: 0.2188 - val_acc: 0.9149\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1755 - acc: 0.9344 - val_loss: 0.1922 - val_acc: 0.9221\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1643 - acc: 0.9381 - val_loss: 0.2045 - val_acc: 0.9234\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1583 - acc: 0.9428 - val_loss: 0.1928 - val_acc: 0.9267\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1433 - acc: 0.9494 - val_loss: 0.2087 - val_acc: 0.9214\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1291 - acc: 0.9557 - val_loss: 0.1591 - val_acc: 0.9339\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.1178 - acc: 0.9557 - val_loss: 0.1721 - val_acc: 0.9339\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0948 - acc: 0.9672 - val_loss: 0.1622 - val_acc: 0.9378\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0791 - acc: 0.9722 - val_loss: 0.1231 - val_acc: 0.9601\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0629 - acc: 0.9801 - val_loss: 0.1076 - val_acc: 0.9633\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0493 - acc: 0.9845 - val_loss: 0.0957 - val_acc: 0.9679\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0410 - acc: 0.9871 - val_loss: 0.0782 - val_acc: 0.9751\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0290 - acc: 0.9913 - val_loss: 0.0905 - val_acc: 0.9751\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0228 - acc: 0.9934 - val_loss: 0.0858 - val_acc: 0.9745\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0211 - acc: 0.9927 - val_loss: 0.0855 - val_acc: 0.9751\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.0802 - val_acc: 0.9777\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0089 - acc: 0.9979 - val_loss: 0.0788 - val_acc: 0.9804\n",
      "953/953 [==============================] - 0s 486us/step\n",
      "3811/3811 [==============================] - 2s 481us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.3129 - acc: 0.8764 - val_loss: 0.1885 - val_acc: 0.9273\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1709 - acc: 0.9339 - val_loss: 0.1996 - val_acc: 0.9162\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1633 - acc: 0.9365 - val_loss: 0.1747 - val_acc: 0.9312\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1508 - acc: 0.9389 - val_loss: 0.1757 - val_acc: 0.9352\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1347 - acc: 0.9507 - val_loss: 0.1591 - val_acc: 0.9391\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1173 - acc: 0.9559 - val_loss: 0.1426 - val_acc: 0.9502\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0998 - acc: 0.9643 - val_loss: 0.1267 - val_acc: 0.9568\n",
      "Epoch 8/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0784 - acc: 0.9759 - val_loss: 0.1254 - val_acc: 0.9581\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0633 - acc: 0.9803 - val_loss: 0.1010 - val_acc: 0.9699\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0496 - acc: 0.9869 - val_loss: 0.0913 - val_acc: 0.9725\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0368 - acc: 0.9900 - val_loss: 0.0788 - val_acc: 0.9764\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0286 - acc: 0.9927 - val_loss: 0.0826 - val_acc: 0.9784\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0224 - acc: 0.9934 - val_loss: 0.0729 - val_acc: 0.9790\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.0620 - val_acc: 0.9836\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.0778 - val_acc: 0.9771\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0112 - acc: 0.9976 - val_loss: 0.0785 - val_acc: 0.9777\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0085 - acc: 0.9982 - val_loss: 0.0631 - val_acc: 0.9849\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0069 - acc: 0.9990 - val_loss: 0.0902 - val_acc: 0.9777\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0064 - acc: 0.9990 - val_loss: 0.0673 - val_acc: 0.9849\n",
      "953/953 [==============================] - 0s 502us/step\n",
      "3811/3811 [==============================] - 2s 498us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.2927 - acc: 0.8843 - val_loss: 0.1947 - val_acc: 0.9227\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1760 - acc: 0.9265 - val_loss: 0.1803 - val_acc: 0.9234\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1618 - acc: 0.9328 - val_loss: 0.1788 - val_acc: 0.9306\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1437 - acc: 0.9438 - val_loss: 0.1697 - val_acc: 0.9332\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1343 - acc: 0.9486 - val_loss: 0.1577 - val_acc: 0.9378\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.1183 - acc: 0.9499 - val_loss: 0.1695 - val_acc: 0.9306\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0979 - acc: 0.9622 - val_loss: 0.1504 - val_acc: 0.9358\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0814 - acc: 0.9701 - val_loss: 0.1195 - val_acc: 0.9574\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0661 - acc: 0.9753 - val_loss: 0.1125 - val_acc: 0.9633\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0514 - acc: 0.9848 - val_loss: 0.0964 - val_acc: 0.9692\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0415 - acc: 0.9871 - val_loss: 0.1015 - val_acc: 0.9692\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0306 - acc: 0.9908 - val_loss: 0.0773 - val_acc: 0.9784\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0223 - acc: 0.9955 - val_loss: 0.0731 - val_acc: 0.9804\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0204 - acc: 0.9948 - val_loss: 0.0692 - val_acc: 0.9810\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0198 - acc: 0.9937 - val_loss: 0.0664 - val_acc: 0.9836\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0671 - val_acc: 0.9836\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0105 - acc: 0.9982 - val_loss: 0.0763 - val_acc: 0.9823\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0071 - acc: 0.9984 - val_loss: 0.0920 - val_acc: 0.9738\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0059 - acc: 0.9995 - val_loss: 0.0737 - val_acc: 0.9836\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0671 - val_acc: 0.9869\n",
      "953/953 [==============================] - 0s 495us/step\n",
      "3811/3811 [==============================] - 2s 503us/step\n",
      "Train on 3812 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3812/3812 [==============================] - 16s 4ms/step - loss: 0.3294 - acc: 0.8560 - val_loss: 0.1961 - val_acc: 0.9247\n",
      "Epoch 2/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.1770 - acc: 0.9263 - val_loss: 0.1991 - val_acc: 0.9240\n",
      "Epoch 3/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.1679 - acc: 0.9265 - val_loss: 0.1851 - val_acc: 0.9234\n",
      "Epoch 4/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.1523 - acc: 0.9407 - val_loss: 0.1889 - val_acc: 0.9181\n",
      "Epoch 5/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.1412 - acc: 0.9436 - val_loss: 0.1778 - val_acc: 0.9273\n",
      "Epoch 6/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.1362 - acc: 0.9494 - val_loss: 0.1526 - val_acc: 0.9391\n",
      "Epoch 7/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.1146 - acc: 0.9570 - val_loss: 0.1386 - val_acc: 0.9456\n",
      "Epoch 8/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0965 - acc: 0.9656 - val_loss: 0.1204 - val_acc: 0.9581\n",
      "Epoch 9/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0756 - acc: 0.9730 - val_loss: 0.1289 - val_acc: 0.9561\n",
      "Epoch 10/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0545 - acc: 0.9835 - val_loss: 0.0937 - val_acc: 0.9699\n",
      "Epoch 11/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0381 - acc: 0.9900 - val_loss: 0.0787 - val_acc: 0.9784\n",
      "Epoch 12/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0317 - acc: 0.9916 - val_loss: 0.0714 - val_acc: 0.9810\n",
      "Epoch 13/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0214 - acc: 0.9945 - val_loss: 0.0698 - val_acc: 0.9817\n",
      "Epoch 14/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0178 - acc: 0.9955 - val_loss: 0.0635 - val_acc: 0.9836\n",
      "Epoch 15/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0130 - acc: 0.9974 - val_loss: 0.0695 - val_acc: 0.9869\n",
      "Epoch 16/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0091 - acc: 0.9987 - val_loss: 0.0808 - val_acc: 0.9790\n",
      "Epoch 17/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0922 - val_acc: 0.9777\n",
      "Epoch 18/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0158 - acc: 0.9948 - val_loss: 0.0618 - val_acc: 0.9882\n",
      "Epoch 19/170\n",
      "3812/3812 [==============================] - 10s 3ms/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.0640 - val_acc: 0.9876\n",
      "Epoch 20/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0709 - val_acc: 0.9876\n",
      "Epoch 21/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0761 - val_acc: 0.9862\n",
      "Epoch 22/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0872 - val_acc: 0.9810\n",
      "Epoch 23/170\n",
      "3812/3812 [==============================] - 11s 3ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0882 - val_acc: 0.9823\n",
      "952/952 [==============================] - 0s 509us/step\n",
      "3812/3812 [==============================] - 2s 495us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.3686 - acc: 0.8339 - val_loss: 0.2799 - val_acc: 0.8762\n",
      "Epoch 2/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1789 - acc: 0.9362 - val_loss: 0.1772 - val_acc: 0.9325\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1617 - acc: 0.9433 - val_loss: 0.1868 - val_acc: 0.9293\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1558 - acc: 0.9415 - val_loss: 0.1726 - val_acc: 0.9267\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1641 - acc: 0.9389 - val_loss: 0.1685 - val_acc: 0.9339\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1379 - acc: 0.9528 - val_loss: 0.1808 - val_acc: 0.9306\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1274 - acc: 0.9559 - val_loss: 0.1583 - val_acc: 0.9371\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1244 - acc: 0.9606 - val_loss: 0.1802 - val_acc: 0.9352\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1110 - acc: 0.9609 - val_loss: 0.1423 - val_acc: 0.9515\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1064 - acc: 0.9648 - val_loss: 0.1353 - val_acc: 0.9574\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0925 - acc: 0.9719 - val_loss: 0.1315 - val_acc: 0.9528\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0858 - acc: 0.9722 - val_loss: 0.1414 - val_acc: 0.9515\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0750 - acc: 0.9738 - val_loss: 0.1266 - val_acc: 0.9574\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0660 - acc: 0.9793 - val_loss: 0.0978 - val_acc: 0.9686\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0576 - acc: 0.9819 - val_loss: 0.0961 - val_acc: 0.9705\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0453 - acc: 0.9879 - val_loss: 0.0838 - val_acc: 0.9764\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0367 - acc: 0.9903 - val_loss: 0.0742 - val_acc: 0.9804\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0314 - acc: 0.9927 - val_loss: 0.0940 - val_acc: 0.9731\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0266 - acc: 0.9916 - val_loss: 0.0687 - val_acc: 0.9804\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0219 - acc: 0.9940 - val_loss: 0.0682 - val_acc: 0.9810\n",
      "Epoch 21/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0162 - acc: 0.9966 - val_loss: 0.0824 - val_acc: 0.9758\n",
      "Epoch 22/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0153 - acc: 0.9958 - val_loss: 0.0754 - val_acc: 0.9804\n",
      "Epoch 23/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0117 - acc: 0.9982 - val_loss: 0.0662 - val_acc: 0.9830\n",
      "Epoch 24/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0843 - val_acc: 0.9758\n",
      "Epoch 25/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0793 - val_acc: 0.9797\n",
      "Epoch 26/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0724 - val_acc: 0.9804\n",
      "Epoch 27/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0053 - acc: 0.9995 - val_loss: 0.0676 - val_acc: 0.9843\n",
      "Epoch 28/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0603 - val_acc: 0.9849\n",
      "Epoch 29/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0607 - val_acc: 0.9843\n",
      "Epoch 30/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0662 - val_acc: 0.9836\n",
      "Epoch 31/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0656 - val_acc: 0.9843\n",
      "Epoch 32/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9804\n",
      "Epoch 33/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0035 - acc: 0.9995 - val_loss: 0.0622 - val_acc: 0.9856\n",
      "953/953 [==============================] - 0s 410us/step\n",
      "3811/3811 [==============================] - 2s 413us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.3623 - acc: 0.8371 - val_loss: 0.2494 - val_acc: 0.8900\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1843 - acc: 0.9313 - val_loss: 0.1911 - val_acc: 0.9267\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1676 - acc: 0.9396 - val_loss: 0.2071 - val_acc: 0.9260\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1548 - acc: 0.9486 - val_loss: 0.2075 - val_acc: 0.9234\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1477 - acc: 0.9475 - val_loss: 0.1797 - val_acc: 0.9306\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1529 - acc: 0.9449 - val_loss: 0.2069 - val_acc: 0.9247\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1409 - acc: 0.9507 - val_loss: 0.1851 - val_acc: 0.9280\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1284 - acc: 0.9543 - val_loss: 0.2273 - val_acc: 0.9168\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1233 - acc: 0.9557 - val_loss: 0.1578 - val_acc: 0.9365\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1130 - acc: 0.9593 - val_loss: 0.1612 - val_acc: 0.9365\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1006 - acc: 0.9654 - val_loss: 0.1582 - val_acc: 0.9371\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0955 - acc: 0.9669 - val_loss: 0.1361 - val_acc: 0.9470\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0835 - acc: 0.9730 - val_loss: 0.1554 - val_acc: 0.9430\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0698 - acc: 0.9774 - val_loss: 0.1299 - val_acc: 0.9528\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0656 - acc: 0.9769 - val_loss: 0.1333 - val_acc: 0.9463\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0522 - acc: 0.9853 - val_loss: 0.1334 - val_acc: 0.9483\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0430 - acc: 0.9871 - val_loss: 0.0920 - val_acc: 0.9699\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0374 - acc: 0.9908 - val_loss: 0.0876 - val_acc: 0.9686\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0269 - acc: 0.9937 - val_loss: 0.1071 - val_acc: 0.9666\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0255 - acc: 0.9924 - val_loss: 0.1041 - val_acc: 0.9646\n",
      "Epoch 21/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0205 - acc: 0.9945 - val_loss: 0.0714 - val_acc: 0.9797\n",
      "Epoch 22/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0159 - acc: 0.9961 - val_loss: 0.0808 - val_acc: 0.9771\n",
      "Epoch 23/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0126 - acc: 0.9979 - val_loss: 0.0881 - val_acc: 0.9745\n",
      "Epoch 24/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0128 - acc: 0.9963 - val_loss: 0.0698 - val_acc: 0.9823\n",
      "Epoch 25/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0790 - val_acc: 0.9777\n",
      "Epoch 26/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0075 - acc: 0.9990 - val_loss: 0.0676 - val_acc: 0.9823\n",
      "Epoch 27/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0075 - acc: 0.9987 - val_loss: 0.0724 - val_acc: 0.9836\n",
      "Epoch 28/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0768 - val_acc: 0.9817\n",
      "Epoch 29/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0054 - acc: 0.9990 - val_loss: 0.0780 - val_acc: 0.9804\n",
      "Epoch 30/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0963 - val_acc: 0.9771\n",
      "Epoch 31/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1133 - val_acc: 0.9731\n",
      "953/953 [==============================] - 0s 436us/step\n",
      "3811/3811 [==============================] - 2s 419us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.3727 - acc: 0.8586 - val_loss: 0.1977 - val_acc: 0.9221\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1739 - acc: 0.9307 - val_loss: 0.1906 - val_acc: 0.9293\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1670 - acc: 0.9328 - val_loss: 0.1891 - val_acc: 0.9188\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1532 - acc: 0.9394 - val_loss: 0.1732 - val_acc: 0.9378\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1428 - acc: 0.9475 - val_loss: 0.1792 - val_acc: 0.9306\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1349 - acc: 0.9501 - val_loss: 0.2804 - val_acc: 0.9050\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1414 - acc: 0.9483 - val_loss: 0.1643 - val_acc: 0.9411\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1191 - acc: 0.9572 - val_loss: 0.1526 - val_acc: 0.9496\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1085 - acc: 0.9625 - val_loss: 0.1444 - val_acc: 0.9522\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1008 - acc: 0.9641 - val_loss: 0.1552 - val_acc: 0.9496\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0899 - acc: 0.9698 - val_loss: 0.1370 - val_acc: 0.9607\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0846 - acc: 0.9709 - val_loss: 0.1314 - val_acc: 0.9587\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0716 - acc: 0.9769 - val_loss: 0.1197 - val_acc: 0.9607\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0628 - acc: 0.9795 - val_loss: 0.1189 - val_acc: 0.9620\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0554 - acc: 0.9803 - val_loss: 0.1016 - val_acc: 0.9679\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0427 - acc: 0.9898 - val_loss: 0.1081 - val_acc: 0.9679\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0458 - acc: 0.9832 - val_loss: 0.0944 - val_acc: 0.9751\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0318 - acc: 0.9919 - val_loss: 0.1059 - val_acc: 0.9699\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0266 - acc: 0.9932 - val_loss: 0.0814 - val_acc: 0.9771\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0210 - acc: 0.9948 - val_loss: 0.0826 - val_acc: 0.9790\n",
      "Epoch 21/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0189 - acc: 0.9950 - val_loss: 0.0866 - val_acc: 0.9764\n",
      "Epoch 22/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0182 - acc: 0.9953 - val_loss: 0.0762 - val_acc: 0.9804\n",
      "Epoch 23/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.1032 - val_acc: 0.9712\n",
      "Epoch 24/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0109 - acc: 0.9982 - val_loss: 0.0837 - val_acc: 0.9797\n",
      "Epoch 25/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0093 - acc: 0.9987 - val_loss: 0.0772 - val_acc: 0.9797\n",
      "Epoch 26/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0779 - val_acc: 0.9823\n",
      "Epoch 27/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0072 - acc: 0.9987 - val_loss: 0.0766 - val_acc: 0.9836\n",
      "953/953 [==============================] - 0s 431us/step\n",
      "3811/3811 [==============================] - 2s 430us/step\n",
      "Train on 3811 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.3918 - acc: 0.8339 - val_loss: 0.2075 - val_acc: 0.9273\n",
      "Epoch 2/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1840 - acc: 0.9263 - val_loss: 0.1865 - val_acc: 0.9234\n",
      "Epoch 3/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1689 - acc: 0.9297 - val_loss: 0.2065 - val_acc: 0.9090\n",
      "Epoch 4/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1641 - acc: 0.9331 - val_loss: 0.1843 - val_acc: 0.9247\n",
      "Epoch 5/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1632 - acc: 0.9323 - val_loss: 0.1840 - val_acc: 0.9240\n",
      "Epoch 6/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1581 - acc: 0.9334 - val_loss: 0.1761 - val_acc: 0.9267\n",
      "Epoch 7/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1442 - acc: 0.9415 - val_loss: 0.1835 - val_acc: 0.9273\n",
      "Epoch 8/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1365 - acc: 0.9444 - val_loss: 0.1654 - val_acc: 0.9299\n",
      "Epoch 9/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1186 - acc: 0.9543 - val_loss: 0.1677 - val_acc: 0.9286\n",
      "Epoch 10/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1101 - acc: 0.9575 - val_loss: 0.1511 - val_acc: 0.9411\n",
      "Epoch 11/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0985 - acc: 0.9635 - val_loss: 0.1381 - val_acc: 0.9496\n",
      "Epoch 12/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0829 - acc: 0.9693 - val_loss: 0.1300 - val_acc: 0.9548\n",
      "Epoch 13/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0725 - acc: 0.9745 - val_loss: 0.1175 - val_acc: 0.9614\n",
      "Epoch 14/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0586 - acc: 0.9829 - val_loss: 0.1077 - val_acc: 0.9686\n",
      "Epoch 15/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0470 - acc: 0.9866 - val_loss: 0.1128 - val_acc: 0.9653\n",
      "Epoch 16/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0427 - acc: 0.9890 - val_loss: 0.0988 - val_acc: 0.9686\n",
      "Epoch 17/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0330 - acc: 0.9890 - val_loss: 0.0832 - val_acc: 0.9784\n",
      "Epoch 18/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0261 - acc: 0.9945 - val_loss: 0.0882 - val_acc: 0.9745\n",
      "Epoch 19/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0246 - acc: 0.9942 - val_loss: 0.0767 - val_acc: 0.9790\n",
      "Epoch 20/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0186 - acc: 0.9958 - val_loss: 0.0720 - val_acc: 0.9849\n",
      "Epoch 21/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0134 - acc: 0.9974 - val_loss: 0.0748 - val_acc: 0.9817\n",
      "Epoch 22/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0114 - acc: 0.9982 - val_loss: 0.0703 - val_acc: 0.9836\n",
      "Epoch 23/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0110 - acc: 0.9974 - val_loss: 0.0712 - val_acc: 0.9830\n",
      "Epoch 24/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0101 - acc: 0.9976 - val_loss: 0.0822 - val_acc: 0.9843\n",
      "Epoch 25/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0080 - acc: 0.9990 - val_loss: 0.0693 - val_acc: 0.9869\n",
      "Epoch 26/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0066 - acc: 0.9992 - val_loss: 0.0718 - val_acc: 0.9830\n",
      "Epoch 27/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.0708 - val_acc: 0.9869\n",
      "Epoch 28/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0197 - acc: 0.9942 - val_loss: 0.0930 - val_acc: 0.9758\n",
      "Epoch 29/170\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0049 - acc: 0.9992 - val_loss: 0.0694 - val_acc: 0.9869\n",
      "Epoch 30/170\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0038 - acc: 0.9995 - val_loss: 0.0697 - val_acc: 0.9862\n",
      "953/953 [==============================] - 0s 426us/step\n",
      "3811/3811 [==============================] - 2s 426us/step\n",
      "Train on 3812 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "3812/3812 [==============================] - 13s 3ms/step - loss: 0.3835 - acc: 0.8360 - val_loss: 0.2324 - val_acc: 0.8847\n",
      "Epoch 2/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1834 - acc: 0.9229 - val_loss: 0.1835 - val_acc: 0.9273\n",
      "Epoch 3/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1645 - acc: 0.9318 - val_loss: 0.1886 - val_acc: 0.9260\n",
      "Epoch 4/170\n",
      "3812/3812 [==============================] - 8s 2ms/step - loss: 0.1634 - acc: 0.9273 - val_loss: 0.1778 - val_acc: 0.9293\n",
      "Epoch 5/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1532 - acc: 0.9391 - val_loss: 0.2416 - val_acc: 0.8946\n",
      "Epoch 6/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1521 - acc: 0.9339 - val_loss: 0.1781 - val_acc: 0.9280\n",
      "Epoch 7/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1350 - acc: 0.9473 - val_loss: 0.1625 - val_acc: 0.9371\n",
      "Epoch 8/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1258 - acc: 0.9494 - val_loss: 0.1768 - val_acc: 0.9345\n",
      "Epoch 9/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.1099 - acc: 0.9583 - val_loss: 0.1445 - val_acc: 0.9443\n",
      "Epoch 10/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0924 - acc: 0.9672 - val_loss: 0.1344 - val_acc: 0.9522\n",
      "Epoch 11/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0797 - acc: 0.9748 - val_loss: 0.1157 - val_acc: 0.9607\n",
      "Epoch 12/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0641 - acc: 0.9814 - val_loss: 0.1058 - val_acc: 0.9627\n",
      "Epoch 13/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0538 - acc: 0.9835 - val_loss: 0.0933 - val_acc: 0.9725\n",
      "Epoch 14/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0435 - acc: 0.9882 - val_loss: 0.0836 - val_acc: 0.9790\n",
      "Epoch 15/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0365 - acc: 0.9921 - val_loss: 0.0900 - val_acc: 0.9758\n",
      "Epoch 16/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0340 - acc: 0.9906 - val_loss: 0.0687 - val_acc: 0.9830\n",
      "Epoch 17/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0224 - acc: 0.9945 - val_loss: 0.0677 - val_acc: 0.9856\n",
      "Epoch 18/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0177 - acc: 0.9953 - val_loss: 0.0687 - val_acc: 0.9823\n",
      "Epoch 19/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0137 - acc: 0.9971 - val_loss: 0.0654 - val_acc: 0.9830\n",
      "Epoch 20/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0126 - acc: 0.9971 - val_loss: 0.0672 - val_acc: 0.9830\n",
      "Epoch 21/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0102 - acc: 0.9979 - val_loss: 0.0693 - val_acc: 0.9862\n",
      "Epoch 22/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0092 - acc: 0.9982 - val_loss: 0.0707 - val_acc: 0.9823\n",
      "Epoch 23/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.0687 - val_acc: 0.9830\n",
      "Epoch 24/170\n",
      "3812/3812 [==============================] - 7s 2ms/step - loss: 0.0061 - acc: 0.9992 - val_loss: 0.0754 - val_acc: 0.9836\n",
      "952/952 [==============================] - 0s 418us/step\n",
      "3812/3812 [==============================] - 2s 420us/step\n",
      "Train on 4764 samples, validate on 1527 samples\n",
      "Epoch 1/170\n",
      "4764/4764 [==============================] - 19s 4ms/step - loss: 0.3061 - acc: 0.8841 - val_loss: 0.1897 - val_acc: 0.9221\n",
      "Epoch 2/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.1810 - acc: 0.9293 - val_loss: 0.1863 - val_acc: 0.9221\n",
      "Epoch 3/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.1655 - acc: 0.9366 - val_loss: 0.1807 - val_acc: 0.9293\n",
      "Epoch 4/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.1459 - acc: 0.9437 - val_loss: 0.1634 - val_acc: 0.9384\n",
      "Epoch 5/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.1238 - acc: 0.9595 - val_loss: 0.1382 - val_acc: 0.9509\n",
      "Epoch 6/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.1045 - acc: 0.9675 - val_loss: 0.1210 - val_acc: 0.9601\n",
      "Epoch 7/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0880 - acc: 0.9725 - val_loss: 0.1246 - val_acc: 0.9568\n",
      "Epoch 8/170\n",
      "4764/4764 [==============================] - 14s 3ms/step - loss: 0.0680 - acc: 0.9790 - val_loss: 0.1086 - val_acc: 0.9659\n",
      "Epoch 9/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0539 - acc: 0.9822 - val_loss: 0.0749 - val_acc: 0.9797\n",
      "Epoch 10/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0347 - acc: 0.9899 - val_loss: 0.0634 - val_acc: 0.9790\n",
      "Epoch 11/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0307 - acc: 0.9897 - val_loss: 0.0518 - val_acc: 0.9843\n",
      "Epoch 12/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0203 - acc: 0.9948 - val_loss: 0.0679 - val_acc: 0.9790\n",
      "Epoch 13/170\n",
      "4764/4764 [==============================] - 14s 3ms/step - loss: 0.0161 - acc: 0.9941 - val_loss: 0.0663 - val_acc: 0.9790\n",
      "Epoch 14/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0126 - acc: 0.9960 - val_loss: 0.0531 - val_acc: 0.9823\n",
      "Epoch 15/170\n",
      "4764/4764 [==============================] - 13s 3ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0574 - val_acc: 0.9843\n",
      "Epoch 16/170\n",
      "4764/4764 [==============================] - 14s 3ms/step - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0631 - val_acc: 0.9784\n",
      "Best: 0.982158 using {'batch_size': 16}\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 38s 10ms/step - loss: 0.0200 - acc: 0.9970 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0096 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 8.4087e-04 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 8.5647e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 33s 9ms/step - loss: 4.6544e-05 - acc: 1.0000 - val_loss: 0.0060 - val_acc: 0.9988\n",
      "930/930 [==============================] - 1s 1ms/step\n",
      "3718/3718 [==============================] - 5s 1ms/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 38s 10ms/step - loss: 0.0171 - acc: 0.9970 - val_loss: 0.0101 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0038 - acc: 0.9984 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 5.9808e-04 - acc: 0.9997 - val_loss: 0.0093 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 1.3094e-04 - acc: 1.0000 - val_loss: 0.0095 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 4.7098e-05 - acc: 1.0000 - val_loss: 0.0100 - val_acc: 0.9981\n",
      "Epoch 6/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718/3718 [==============================] - 32s 9ms/step - loss: 2.2358e-05 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9988\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 1.3219e-05 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9988\n",
      "930/930 [==============================] - 1s 1ms/step\n",
      "3718/3718 [==============================] - 5s 1ms/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 38s 10ms/step - loss: 0.0186 - acc: 0.9962 - val_loss: 0.0104 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0075 - val_acc: 0.9975\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0069 - val_acc: 0.9988\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 2.0992e-04 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9988\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 4.8524e-05 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9988\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 1.8398e-05 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9988\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 33s 9ms/step - loss: 1.2803e-05 - acc: 1.0000 - val_loss: 0.0073 - val_acc: 0.9988\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 5.3037e-06 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9988\n",
      "Epoch 10/170\n",
      "3718/3718 [==============================] - 32s 9ms/step - loss: 3.0082e-06 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9988\n",
      "930/930 [==============================] - 1s 1ms/step\n",
      "3718/3718 [==============================] - 5s 1ms/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 39s 10ms/step - loss: 0.0170 - acc: 0.9965 - val_loss: 0.0110 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0139 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0127 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0107 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 5.4241e-04 - acc: 0.9997 - val_loss: 0.0113 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 1.0147e-04 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 2.0800e-05 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 9.6422e-06 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 6.9225e-06 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9981\n",
      "929/929 [==============================] - 1s 1ms/step\n",
      "3719/3719 [==============================] - 5s 1ms/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 39s 11ms/step - loss: 0.0179 - acc: 0.9935 - val_loss: 0.0052 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0077 - val_acc: 0.9975\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0068 - val_acc: 0.9969\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0095 - val_acc: 0.9975\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 3.1930e-04 - acc: 0.9997 - val_loss: 0.0094 - val_acc: 0.9975\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 32s 9ms/step - loss: 1.0944e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "929/929 [==============================] - 1s 1ms/step\n",
      "3719/3719 [==============================] - 5s 1ms/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 24s 6ms/step - loss: 0.0285 - acc: 0.9935 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0034 - val_acc: 0.9988\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 5.0939e-04 - acc: 0.9997 - val_loss: 0.0035 - val_acc: 0.9988\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 1.4741e-04 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9988\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 1.0648e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9994\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 4.6016e-05 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9988\n",
      "Epoch 10/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 2.8819e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9988\n",
      "Epoch 11/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 1.7104e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9988\n",
      "Epoch 12/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 1.4882e-05 - acc: 1.0000 - val_loss: 0.0038 - val_acc: 0.9994\n",
      "Epoch 13/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 1.0001e-05 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9994\n",
      "930/930 [==============================] - 1s 728us/step\n",
      "3718/3718 [==============================] - 3s 736us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 24s 6ms/step - loss: 0.0269 - acc: 0.9960 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0051 - acc: 0.9978 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0013 - acc: 0.9992 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 4.0640e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 1.8886e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 8.9452e-05 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 5.9168e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 3.2780e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "930/930 [==============================] - 1s 725us/step\n",
      "3718/3718 [==============================] - 3s 709us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 24s 6ms/step - loss: 0.0260 - acc: 0.9952 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 18s 5ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0072 - val_acc: 0.9981\n",
      "Epoch 5/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718/3718 [==============================] - 17s 5ms/step - loss: 9.3375e-04 - acc: 0.9997 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 4.2315e-04 - acc: 0.9997 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 1.2917e-04 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 5.9609e-05 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9975\n",
      "930/930 [==============================] - 1s 686us/step\n",
      "3718/3718 [==============================] - 3s 681us/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 25s 7ms/step - loss: 0.0225 - acc: 0.9965 - val_loss: 0.0081 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0109 - val_acc: 0.9975\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0167 - val_acc: 0.9969\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 6.8667e-04 - acc: 0.9997 - val_loss: 0.0089 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 4.3264e-04 - acc: 0.9997 - val_loss: 0.0084 - val_acc: 0.9988\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 1.1557e-04 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 5.2899e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 3.0137e-05 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9988\n",
      "929/929 [==============================] - 1s 708us/step\n",
      "3719/3719 [==============================] - 3s 711us/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 24s 6ms/step - loss: 0.0234 - acc: 0.9941 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0072 - val_acc: 0.9975\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0021 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9969\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9969\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0052 - val_acc: 0.9975\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0070 - acc: 0.9984 - val_loss: 0.0163 - val_acc: 0.9969\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0087 - val_acc: 0.9975\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 3.9244e-04 - acc: 0.9997 - val_loss: 0.0082 - val_acc: 0.9975\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 1.2676e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9975\n",
      "Epoch 10/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 7.5614e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9975\n",
      "929/929 [==============================] - 1s 719us/step\n",
      "3719/3719 [==============================] - 3s 713us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 0.0412 - acc: 0.9968 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.0058 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0037 - acc: 0.9992 - val_loss: 0.0066 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0038 - acc: 0.9987 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9988\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 8.7494e-04 - acc: 0.9997 - val_loss: 0.0042 - val_acc: 0.9988\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 4.9139e-04 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9988\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 2.1875e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9988\n",
      "Epoch 10/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 1.3193e-04 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9988\n",
      "Epoch 11/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 7.7342e-05 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9981\n",
      "Epoch 12/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 5.7045e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9981\n",
      "Epoch 13/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 4.2463e-05 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9981\n",
      "Epoch 14/170\n",
      "3718/3718 [==============================] - 12s 3ms/step - loss: 3.0665e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9981\n",
      "Epoch 15/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 2.4157e-05 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9981\n",
      "930/930 [==============================] - 1s 547us/step\n",
      "3718/3718 [==============================] - 2s 551us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 0.0421 - acc: 0.9911 - val_loss: 0.0093 - val_acc: 0.9969\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0041 - acc: 0.9984 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0020 - acc: 0.9992 - val_loss: 0.0074 - val_acc: 0.9975\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0011 - acc: 0.9995 - val_loss: 0.0081 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 7.6868e-04 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9988\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 2.2114e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9988\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 1.1241e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9988\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 6.9674e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9988\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 5.1672e-05 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9988\n",
      "Epoch 10/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 3.2344e-05 - acc: 1.0000 - val_loss: 0.0092 - val_acc: 0.9988\n",
      "930/930 [==============================] - 0s 536us/step\n",
      "3718/3718 [==============================] - 2s 529us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 17s 5ms/step - loss: 0.0484 - acc: 0.9946 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 10s 3ms/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 10s 3ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 10s 3ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9981\n",
      "Epoch 6/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718/3718 [==============================] - 11s 3ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 10s 3ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 10s 3ms/step - loss: 8.3253e-04 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 10s 3ms/step - loss: 5.1952e-04 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9981\n",
      "Epoch 10/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 2.8742e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
      "Epoch 11/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 1.5097e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9975\n",
      "Epoch 12/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 8.1328e-05 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9975\n",
      "Epoch 13/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 4.0958e-05 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9975\n",
      "Epoch 14/170\n",
      "3718/3718 [==============================] - 11s 3ms/step - loss: 2.8791e-05 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 0.9969\n",
      "930/930 [==============================] - 1s 538us/step\n",
      "3718/3718 [==============================] - 2s 525us/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 18s 5ms/step - loss: 0.0441 - acc: 0.9871 - val_loss: 0.0078 - val_acc: 0.9969\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0082 - val_acc: 0.9975\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 10s 3ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0072 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0079 - val_acc: 0.9975\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0085 - val_acc: 0.9975\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 8.5039e-04 - acc: 0.9997 - val_loss: 0.0087 - val_acc: 0.9975\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 5.5711e-04 - acc: 0.9997 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 3.2072e-04 - acc: 0.9997 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "929/929 [==============================] - 0s 528us/step\n",
      "3719/3719 [==============================] - 2s 548us/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 17s 5ms/step - loss: 0.0453 - acc: 0.9901 - val_loss: 0.0074 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0061 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0031 - acc: 0.9995 - val_loss: 0.0084 - val_acc: 0.9975\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9975\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9975\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0053 - val_acc: 0.9975\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 9.3790e-04 - acc: 0.9997 - val_loss: 0.0049 - val_acc: 0.9975\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 6.2184e-04 - acc: 0.9997 - val_loss: 0.0050 - val_acc: 0.9975\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 3.3505e-04 - acc: 0.9997 - val_loss: 0.0046 - val_acc: 0.9975\n",
      "Epoch 10/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 1.5527e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9975\n",
      "Epoch 11/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 9.3378e-05 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9975\n",
      "Epoch 12/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 5.3186e-05 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9975\n",
      "Epoch 13/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 4.0329e-05 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9975\n",
      "Epoch 14/170\n",
      "3719/3719 [==============================] - 11s 3ms/step - loss: 2.4250e-05 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 0.9975\n",
      "929/929 [==============================] - 1s 540us/step\n",
      "3719/3719 [==============================] - 2s 524us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 14s 4ms/step - loss: 0.0681 - acc: 0.9882 - val_loss: 0.0078 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0047 - acc: 0.9984 - val_loss: 0.0063 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 8s 2ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 8s 2ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0052 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0049 - val_acc: 0.9981\n",
      "Epoch 10/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 8.6235e-04 - acc: 0.9997 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "Epoch 11/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 6.2813e-04 - acc: 0.9997 - val_loss: 0.0049 - val_acc: 0.9981\n",
      "Epoch 12/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 4.1989e-04 - acc: 0.9997 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "Epoch 13/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 2.9859e-04 - acc: 0.9997 - val_loss: 0.0047 - val_acc: 0.9981\n",
      "Epoch 14/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 1.8692e-04 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9981\n",
      "Epoch 15/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 1.3254e-04 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "Epoch 16/170\n",
      "3718/3718 [==============================] - 8s 2ms/step - loss: 1.0244e-04 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9981\n",
      "Epoch 17/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 7.5405e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9981\n",
      "Epoch 18/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 5.7676e-05 - acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9981\n",
      "930/930 [==============================] - 0s 438us/step\n",
      "3718/3718 [==============================] - 2s 440us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 14s 4ms/step - loss: 0.0757 - acc: 0.9890 - val_loss: 0.0080 - val_acc: 0.9981\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 8s 2ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0035 - acc: 0.9987 - val_loss: 0.0075 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0025 - acc: 0.9989 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 8s 2ms/step - loss: 0.0015 - acc: 0.9992 - val_loss: 0.0075 - val_acc: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 8.6756e-04 - acc: 1.0000 - val_loss: 0.0077 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 5.1867e-04 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 3.1669e-04 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9981\n",
      "930/930 [==============================] - 0s 443us/step\n",
      "3718/3718 [==============================] - 2s 445us/step\n",
      "Train on 3718 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3718/3718 [==============================] - 14s 4ms/step - loss: 0.0683 - acc: 0.9941 - val_loss: 0.0089 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0076 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0067 - val_acc: 0.9975\n",
      "Epoch 4/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0073 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0068 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3718/3718 [==============================] - 7s 2ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0078 - val_acc: 0.9975\n",
      "930/930 [==============================] - 0s 440us/step\n",
      "3718/3718 [==============================] - 2s 430us/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 14s 4ms/step - loss: 0.0744 - acc: 0.9693 - val_loss: 0.0090 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0071 - val_acc: 0.9975\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 0.0068 - val_acc: 0.9975\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0072 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0070 - val_acc: 0.9988\n",
      "Epoch 10/170\n",
      "3719/3719 [==============================] - 8s 2ms/step - loss: 9.6831e-04 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9988\n",
      "929/929 [==============================] - 0s 458us/step\n",
      "3719/3719 [==============================] - 2s 454us/step\n",
      "Train on 3719 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "3719/3719 [==============================] - 15s 4ms/step - loss: 0.0710 - acc: 0.9876 - val_loss: 0.0090 - val_acc: 0.9975\n",
      "Epoch 2/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0067 - acc: 0.9976 - val_loss: 0.0067 - val_acc: 0.9981\n",
      "Epoch 3/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0041 - acc: 0.9992 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 4/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0059 - val_acc: 0.9981\n",
      "Epoch 5/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9981\n",
      "Epoch 6/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0053 - val_acc: 0.9981\n",
      "Epoch 7/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0050 - val_acc: 0.9981\n",
      "Epoch 8/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0046 - val_acc: 0.9981\n",
      "Epoch 9/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9975\n",
      "Epoch 10/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9975\n",
      "Epoch 11/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 8.8479e-04 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9975\n",
      "Epoch 12/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 7.5908e-04 - acc: 0.9997 - val_loss: 0.0039 - val_acc: 0.9975\n",
      "Epoch 13/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 6.0523e-04 - acc: 0.9997 - val_loss: 0.0037 - val_acc: 0.9975\n",
      "Epoch 14/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 4.5617e-04 - acc: 0.9997 - val_loss: 0.0036 - val_acc: 0.9975\n",
      "Epoch 15/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 3.3928e-04 - acc: 0.9997 - val_loss: 0.0038 - val_acc: 0.9975\n",
      "Epoch 16/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 2.5874e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9975\n",
      "Epoch 17/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 1.7715e-04 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9975\n",
      "Epoch 18/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 1.5661e-04 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9975\n",
      "Epoch 19/170\n",
      "3719/3719 [==============================] - 7s 2ms/step - loss: 9.0673e-05 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9975\n",
      "929/929 [==============================] - 0s 452us/step\n",
      "3719/3719 [==============================] - 2s 439us/step\n",
      "Train on 4648 samples, validate on 1609 samples\n",
      "Epoch 1/170\n",
      "4648/4648 [==============================] - 49s 11ms/step - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0071 - val_acc: 0.9981 ETA: 1s - los\n",
      "Epoch 2/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0042 - val_acc: 0.9988\n",
      "Epoch 3/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0068 - val_acc: 0.9975\n",
      "Epoch 4/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0050 - val_acc: 0.9988\n",
      "Epoch 5/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 3.3266e-04 - acc: 0.9998 - val_loss: 0.0044 - val_acc: 0.9988\n",
      "Epoch 6/170\n",
      "4648/4648 [==============================] - 40s 9ms/step - loss: 9.7984e-05 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.999456e-05 - a\n",
      "Epoch 7/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 2.5206e-05 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9994\n",
      "Epoch 8/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 1.0196e-05 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9994\n",
      "Epoch 9/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 5.3987e-06 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9994\n",
      "Epoch 10/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 3.2646e-06 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 0.9994\n",
      "Epoch 11/170\n",
      "4648/4648 [==============================] - 41s 9ms/step - loss: 1.3065e-06 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9994\n",
      "Best: 0.998279 using {'batch_size': 4}\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 41s 11ms/step - loss: 0.6128 - acc: 0.6511 - val_loss: 0.6424 - val_acc: 0.5613\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 33s 9ms/step - loss: 0.3345 - acc: 0.8567 - val_loss: 0.2454 - val_acc: 0.9100\n",
      "Epoch 3/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3755/3755 [==============================] - 33s 9ms/step - loss: 0.1949 - acc: 0.9310 - val_loss: 0.1511 - val_acc: 0.9470\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 33s 9ms/step - loss: 0.1410 - acc: 0.9545 - val_loss: 0.2045 - val_acc: 0.9202\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 33s 9ms/step - loss: 0.1122 - acc: 0.9609 - val_loss: 0.1101 - val_acc: 0.9706\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 33s 9ms/step - loss: 0.1000 - acc: 0.9632 - val_loss: 0.1016 - val_acc: 0.9725\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.0747 - acc: 0.9758 - val_loss: 0.1244 - val_acc: 0.9604\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0750 - acc: 0.9739 - val_loss: 0.1124 - val_acc: 0.9623\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0536 - acc: 0.9803 - val_loss: 0.1191 - val_acc: 0.9662\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.0546 - acc: 0.9822 - val_loss: 0.1039 - val_acc: 0.9713\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0400 - acc: 0.9862 - val_loss: 0.0949 - val_acc: 0.9751\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 40s 11ms/step - loss: 0.0396 - acc: 0.9891 - val_loss: 0.1213 - val_acc: 0.9681\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0303 - acc: 0.9901 - val_loss: 0.0970 - val_acc: 0.9789\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0236 - acc: 0.9941 - val_loss: 0.1684 - val_acc: 0.9496\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0277 - acc: 0.9917 - val_loss: 0.1040 - val_acc: 0.9738\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0178 - acc: 0.9952 - val_loss: 0.0949 - val_acc: 0.9770\n",
      "939/939 [==============================] - 1s 1ms/step\n",
      "3755/3755 [==============================] - 5s 1ms/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 43s 12ms/step - loss: 0.6191 - acc: 0.6503 - val_loss: 0.5733 - val_acc: 0.6845\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.3299 - acc: 0.8706 - val_loss: 0.2301 - val_acc: 0.9074\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 40s 11ms/step - loss: 0.1833 - acc: 0.9316 - val_loss: 0.1706 - val_acc: 0.9298\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.1377 - acc: 0.9494 - val_loss: 0.1750 - val_acc: 0.9349\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.1162 - acc: 0.9563 - val_loss: 0.1331 - val_acc: 0.9559\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0919 - acc: 0.9678 - val_loss: 0.1656 - val_acc: 0.9413\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.0842 - acc: 0.9686 - val_loss: 0.1063 - val_acc: 0.9636\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0699 - acc: 0.9774 - val_loss: 0.1098 - val_acc: 0.9662\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.0655 - acc: 0.9728 - val_loss: 0.2245 - val_acc: 0.9195\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0503 - acc: 0.9819 - val_loss: 0.1083 - val_acc: 0.9662\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0443 - acc: 0.9824 - val_loss: 0.1163 - val_acc: 0.9706\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0427 - acc: 0.9859 - val_loss: 0.1215 - val_acc: 0.9693\n",
      "939/939 [==============================] - 2s 2ms/step\n",
      "3755/3755 [==============================] - 6s 2ms/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 45s 12ms/step - loss: 0.6193 - acc: 0.6352 - val_loss: 0.4365 - val_acc: 0.7854\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.2888 - acc: 0.8823 - val_loss: 0.2001 - val_acc: 0.9272\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.1739 - acc: 0.9411 - val_loss: 0.1483 - val_acc: 0.9540\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.1314 - acc: 0.9582 - val_loss: 0.1193 - val_acc: 0.9623\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0963 - acc: 0.9779 - val_loss: 0.1117 - val_acc: 0.96550.0963 - acc: 0.977\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0775 - acc: 0.9760 - val_loss: 0.1108 - val_acc: 0.9700\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0607 - acc: 0.9838 - val_loss: 0.1006 - val_acc: 0.9713\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0611 - acc: 0.9763 - val_loss: 0.1037 - val_acc: 0.9693- acc: 0.97 - ETA: 1s \n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0424 - acc: 0.9872 - val_loss: 0.0970 - val_acc: 0.9687\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0346 - acc: 0.9901 - val_loss: 0.1260 - val_acc: 0.9700\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 35s 9ms/step - loss: 0.0337 - acc: 0.9907 - val_loss: 0.0952 - val_acc: 0.9738\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0273 - acc: 0.9907 - val_loss: 0.1154 - val_acc: 0.9732\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0222 - acc: 0.9936 - val_loss: 0.1064 - val_acc: 0.9757\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 35s 9ms/step - loss: 0.0212 - acc: 0.9925 - val_loss: 0.1267 - val_acc: 0.9674\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.1409 - val_acc: 0.9655\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0179 - acc: 0.9931 - val_loss: 0.2442 - val_acc: 0.9400\n",
      "939/939 [==============================] - 1s 2ms/step\n",
      "3755/3755 [==============================] - 6s 2ms/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 45s 12ms/step - loss: 0.6228 - acc: 0.6519 - val_loss: 0.4244 - val_acc: 0.8186\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.2968 - acc: 0.8796 - val_loss: 0.2174 - val_acc: 0.9221\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 36s 9ms/step - loss: 0.1819 - acc: 0.9364 - val_loss: 0.2006 - val_acc: 0.9272\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 35s 9ms/step - loss: 0.1370 - acc: 0.9521 - val_loss: 0.1360 - val_acc: 0.9540\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.1032 - acc: 0.9654 - val_loss: 0.1684 - val_acc: 0.9476\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0839 - acc: 0.9712 - val_loss: 0.1264 - val_acc: 0.9553\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 35s 9ms/step - loss: 0.0717 - acc: 0.9787 - val_loss: 0.1196 - val_acc: 0.9566\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0584 - acc: 0.9806 - val_loss: 0.1402 - val_acc: 0.9585\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0475 - acc: 0.9877 - val_loss: 0.1021 - val_acc: 0.9725\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0387 - acc: 0.9872 - val_loss: 0.1432 - val_acc: 0.9655\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 36s 9ms/step - loss: 0.0386 - acc: 0.9880 - val_loss: 0.0978 - val_acc: 0.9770A: 1s - loss: 0.\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 34s 9ms/step - loss: 0.0291 - acc: 0.9904 - val_loss: 0.0878 - val_acc: 0.9770\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0253 - acc: 0.9920 - val_loss: 0.1572 - val_acc: 0.9572\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0232 - acc: 0.9928 - val_loss: 0.0939 - val_acc: 0.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 38s 10ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1006 - val_acc: 0.9713\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 37s 10ms/step - loss: 0.0187 - acc: 0.9949 - val_loss: 0.0910 - val_acc: 0.9796\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 36s 10ms/step - loss: 0.0187 - acc: 0.9931 - val_loss: 0.1048 - val_acc: 0.9751\n",
      "939/939 [==============================] - 1s 1ms/step\n",
      "3755/3755 [==============================] - 6s 2ms/step\n",
      "Train on 3756 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3756/3756 [==============================] - 45s 12ms/step - loss: 0.6215 - acc: 0.6603 - val_loss: 0.4293 - val_acc: 0.8276\n",
      "Epoch 2/170\n",
      "3756/3756 [==============================] - 37s 10ms/step - loss: 0.3065 - acc: 0.8727 - val_loss: 0.2109 - val_acc: 0.9285\n",
      "Epoch 3/170\n",
      "3756/3756 [==============================] - 37s 10ms/step - loss: 0.1863 - acc: 0.9305 - val_loss: 0.1486 - val_acc: 0.9489\n",
      "Epoch 4/170\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.1392 - acc: 0.9526 - val_loss: 0.1506 - val_acc: 0.9534\n",
      "Epoch 5/170\n",
      "3756/3756 [==============================] - 39s 10ms/step - loss: 0.1059 - acc: 0.9659 - val_loss: 0.1227 - val_acc: 0.9604\n",
      "Epoch 6/170\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.0916 - acc: 0.9707 - val_loss: 0.1214 - val_acc: 0.9610\n",
      "Epoch 7/170\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.0855 - acc: 0.9694 - val_loss: 0.1064 - val_acc: 0.9636\n",
      "Epoch 8/170\n",
      "3756/3756 [==============================] - 34s 9ms/step - loss: 0.0666 - acc: 0.9742 - val_loss: 0.1317 - val_acc: 0.9566 9s - l\n",
      "Epoch 9/170\n",
      "3756/3756 [==============================] - 36s 10ms/step - loss: 0.0586 - acc: 0.9806 - val_loss: 0.1308 - val_acc: 0.9642\n",
      "Epoch 10/170\n",
      "3756/3756 [==============================] - 34s 9ms/step - loss: 0.0434 - acc: 0.9856 - val_loss: 0.1336 - val_acc: 0.9642\n",
      "Epoch 11/170\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.0411 - acc: 0.9830 - val_loss: 0.0964 - val_acc: 0.9757\n",
      "Epoch 12/170\n",
      "3756/3756 [==============================] - 36s 10ms/step - loss: 0.0309 - acc: 0.9899 - val_loss: 0.1027 - val_acc: 0.9732\n",
      "Epoch 13/170\n",
      "3756/3756 [==============================] - 35s 9ms/step - loss: 0.0370 - acc: 0.9870 - val_loss: 0.1208 - val_acc: 0.9725\n",
      "Epoch 14/170\n",
      "3756/3756 [==============================] - 34s 9ms/step - loss: 0.0267 - acc: 0.9909 - val_loss: 0.1030 - val_acc: 0.9764\n",
      "Epoch 15/170\n",
      "3756/3756 [==============================] - 34s 9ms/step - loss: 0.0289 - acc: 0.9907 - val_loss: 0.1000 - val_acc: 0.9770\n",
      "Epoch 16/170\n",
      "3756/3756 [==============================] - 34s 9ms/step - loss: 0.0225 - acc: 0.9917 - val_loss: 0.1026 - val_acc: 0.9777\n",
      "938/938 [==============================] - 1s 1ms/step\n",
      "3756/3756 [==============================] - 6s 1ms/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 26s 7ms/step - loss: 0.6422 - acc: 0.6397 - val_loss: 0.6738 - val_acc: 0.5147\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.4992 - acc: 0.7569 - val_loss: 0.3461 - val_acc: 0.8723\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.2745 - acc: 0.8951 - val_loss: 0.2312 - val_acc: 0.9080\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.1886 - acc: 0.9281 - val_loss: 0.3068 - val_acc: 0.8691\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1474 - acc: 0.9462 - val_loss: 0.1685 - val_acc: 0.9355\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1282 - acc: 0.9513 - val_loss: 0.1822 - val_acc: 0.9278\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1154 - acc: 0.9611 - val_loss: 0.1339 - val_acc: 0.9579\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.1083 - acc: 0.9611 - val_loss: 0.1467 - val_acc: 0.9508\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0904 - acc: 0.9702 - val_loss: 0.1369 - val_acc: 0.9553\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0771 - acc: 0.9723 - val_loss: 0.1085 - val_acc: 0.9655\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0744 - acc: 0.9750 - val_loss: 0.1365 - val_acc: 0.9527\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0694 - acc: 0.9747 - val_loss: 0.1070 - val_acc: 0.9687\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0612 - acc: 0.9795 - val_loss: 0.1460 - val_acc: 0.9470\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0629 - acc: 0.9768 - val_loss: 0.0998 - val_acc: 0.9745\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 20s 5ms/step - loss: 0.0489 - acc: 0.9840 - val_loss: 0.1107 - val_acc: 0.9668\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0441 - acc: 0.9851 - val_loss: 0.1153 - val_acc: 0.9713\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0431 - acc: 0.9846 - val_loss: 0.0958 - val_acc: 0.9719\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0339 - acc: 0.9893 - val_loss: 0.1126 - val_acc: 0.9636\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0419 - acc: 0.9856 - val_loss: 0.1022 - val_acc: 0.9783\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0310 - acc: 0.9883 - val_loss: 0.0934 - val_acc: 0.9764\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0277 - acc: 0.9907 - val_loss: 0.0959 - val_acc: 0.9789\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0348 - acc: 0.9872 - val_loss: 0.1625 - val_acc: 0.9444\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0246 - acc: 0.9893 - val_loss: 0.1010 - val_acc: 0.9732\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0274 - acc: 0.9904 - val_loss: 0.1406 - val_acc: 0.9610\n",
      "Epoch 25/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.0218 - acc: 0.9939 - val_loss: 0.1041 - val_acc: 0.9777\n",
      "939/939 [==============================] - 1s 780us/step\n",
      "3755/3755 [==============================] - 3s 783us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 27s 7ms/step - loss: 0.6280 - acc: 0.6429 - val_loss: 0.5637 - val_acc: 0.7714\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.3823 - acc: 0.8344 - val_loss: 0.2754 - val_acc: 0.8927\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.2142 - acc: 0.9169 - val_loss: 0.1859 - val_acc: 0.9330\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1574 - acc: 0.9489 - val_loss: 0.1465 - val_acc: 0.9547\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 20s 5ms/step - loss: 0.1205 - acc: 0.9609 - val_loss: 0.1292 - val_acc: 0.9566\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0942 - acc: 0.9712 - val_loss: 0.1463 - val_acc: 0.9476\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0885 - acc: 0.9696 - val_loss: 0.1212 - val_acc: 0.9630\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0675 - acc: 0.9784 - val_loss: 0.1318 - val_acc: 0.9521\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0602 - acc: 0.9811 - val_loss: 0.1301 - val_acc: 0.9553\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0521 - acc: 0.9848 - val_loss: 0.1229 - val_acc: 0.9623\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0501 - acc: 0.9814 - val_loss: 0.1390 - val_acc: 0.9566\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0442 - acc: 0.9867 - val_loss: 0.1678 - val_acc: 0.9413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "939/939 [==============================] - 1s 838us/step\n",
      "3755/3755 [==============================] - 3s 828us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 27s 7ms/step - loss: 0.6559 - acc: 0.5989 - val_loss: 0.5203 - val_acc: 0.7791\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.3467 - acc: 0.8575 - val_loss: 0.2521 - val_acc: 0.8978\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1969 - acc: 0.9286 - val_loss: 0.1707 - val_acc: 0.9330\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 18s 5ms/step - loss: 0.1483 - acc: 0.9462 - val_loss: 0.1510 - val_acc: 0.9432\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1193 - acc: 0.9601 - val_loss: 0.1428 - val_acc: 0.9540\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1103 - acc: 0.9566 - val_loss: 0.1215 - val_acc: 0.9636\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0952 - acc: 0.9670 - val_loss: 0.1150 - val_acc: 0.9642\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0758 - acc: 0.9739 - val_loss: 0.1097 - val_acc: 0.9706\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0685 - acc: 0.9784 - val_loss: 0.1135 - val_acc: 0.9662\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0607 - acc: 0.9790 - val_loss: 0.1169 - val_acc: 0.9579\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0612 - acc: 0.9771 - val_loss: 0.1017 - val_acc: 0.9713\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0581 - acc: 0.9795 - val_loss: 0.1210 - val_acc: 0.9662\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0406 - acc: 0.9872 - val_loss: 0.1386 - val_acc: 0.9553\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0387 - acc: 0.9867 - val_loss: 0.1112 - val_acc: 0.9713\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0366 - acc: 0.9880 - val_loss: 0.1047 - val_acc: 0.9668\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0336 - acc: 0.9885 - val_loss: 0.1084 - val_acc: 0.9693\n",
      "939/939 [==============================] - 1s 854us/step\n",
      "3755/3755 [==============================] - 3s 846us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 27s 7ms/step - loss: 0.6475 - acc: 0.6447 - val_loss: 0.5580 - val_acc: 0.7471\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.3780 - acc: 0.8352 - val_loss: 0.2790 - val_acc: 0.8857\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.2151 - acc: 0.9220 - val_loss: 0.1890 - val_acc: 0.9361\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1713 - acc: 0.9395 - val_loss: 0.1653 - val_acc: 0.9419\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1352 - acc: 0.9537 - val_loss: 0.1663 - val_acc: 0.9425\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1178 - acc: 0.9598 - val_loss: 0.1472 - val_acc: 0.9534\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.1093 - acc: 0.9614 - val_loss: 0.1192 - val_acc: 0.9598\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0804 - acc: 0.9739 - val_loss: 0.1140 - val_acc: 0.9681\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 20s 5ms/step - loss: 0.0747 - acc: 0.9768 - val_loss: 0.1354 - val_acc: 0.9598\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0696 - acc: 0.9752 - val_loss: 0.1789 - val_acc: 0.9425\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0565 - acc: 0.9808 - val_loss: 0.1037 - val_acc: 0.9706\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0489 - acc: 0.9856 - val_loss: 0.0933 - val_acc: 0.9745\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0529 - acc: 0.9806 - val_loss: 0.1149 - val_acc: 0.9649\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0365 - acc: 0.9885 - val_loss: 0.1080 - val_acc: 0.9668\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0370 - acc: 0.9880 - val_loss: 0.1013 - val_acc: 0.9719\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.1168 - val_acc: 0.9687\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.0329 - acc: 0.9877 - val_loss: 0.1300 - val_acc: 0.9649\n",
      "939/939 [==============================] - 1s 797us/step\n",
      "3755/3755 [==============================] - 3s 797us/step\n",
      "Train on 3756 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3756/3756 [==============================] - 27s 7ms/step - loss: 0.6452 - acc: 0.6408 - val_loss: 0.5618 - val_acc: 0.7427\n",
      "Epoch 2/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.3978 - acc: 0.8280 - val_loss: 0.2982 - val_acc: 0.8774\n",
      "Epoch 3/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.2171 - acc: 0.9143 - val_loss: 0.1820 - val_acc: 0.9355\n",
      "Epoch 4/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.1673 - acc: 0.9364 - val_loss: 0.1805 - val_acc: 0.9323\n",
      "Epoch 5/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.1344 - acc: 0.9531 - val_loss: 0.1330 - val_acc: 0.9547\n",
      "Epoch 6/170\n",
      "3756/3756 [==============================] - 20s 5ms/step - loss: 0.1089 - acc: 0.9643 - val_loss: 0.1964 - val_acc: 0.9240\n",
      "Epoch 7/170\n",
      "3756/3756 [==============================] - 20s 5ms/step - loss: 0.1046 - acc: 0.9633 - val_loss: 0.1181 - val_acc: 0.9579\n",
      "Epoch 8/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0838 - acc: 0.9712 - val_loss: 0.1459 - val_acc: 0.9540\n",
      "Epoch 9/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0821 - acc: 0.9686 - val_loss: 0.1511 - val_acc: 0.9534\n",
      "Epoch 10/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0729 - acc: 0.9739 - val_loss: 0.1047 - val_acc: 0.9668\n",
      "Epoch 11/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0626 - acc: 0.9798 - val_loss: 0.1124 - val_acc: 0.9700\n",
      "Epoch 12/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0536 - acc: 0.9816 - val_loss: 0.1023 - val_acc: 0.9725\n",
      "Epoch 13/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0505 - acc: 0.9838 - val_loss: 0.1536 - val_acc: 0.9508\n",
      "Epoch 14/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0354 - acc: 0.9878 - val_loss: 0.1103 - val_acc: 0.9732\n",
      "Epoch 15/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0339 - acc: 0.9878 - val_loss: 0.1140 - val_acc: 0.9738\n",
      "Epoch 16/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0331 - acc: 0.9883 - val_loss: 0.1348 - val_acc: 0.9521\n",
      "Epoch 17/170\n",
      "3756/3756 [==============================] - 19s 5ms/step - loss: 0.0311 - acc: 0.9891 - val_loss: 0.1273 - val_acc: 0.9700\n",
      "938/938 [==============================] - 1s 849us/step\n",
      "3756/3756 [==============================] - 3s 853us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 19s 5ms/step - loss: 0.6469 - acc: 0.6354 - val_loss: 0.6742 - val_acc: 0.4987\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.5486 - acc: 0.7116 - val_loss: 0.4374 - val_acc: 0.8378\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.3252 - acc: 0.8775 - val_loss: 0.2640 - val_acc: 0.9106\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.2178 - acc: 0.9206 - val_loss: 0.1973 - val_acc: 0.9304\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1720 - acc: 0.9417 - val_loss: 0.2919 - val_acc: 0.8742\n",
      "Epoch 6/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1529 - acc: 0.9467 - val_loss: 0.1778 - val_acc: 0.9413\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1244 - acc: 0.9585 - val_loss: 0.1639 - val_acc: 0.9425\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1120 - acc: 0.9627 - val_loss: 0.1359 - val_acc: 0.9585\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1093 - acc: 0.9640 - val_loss: 0.1359 - val_acc: 0.9540\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0953 - acc: 0.9710 - val_loss: 0.2298 - val_acc: 0.9061\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0871 - acc: 0.9699 - val_loss: 0.1179 - val_acc: 0.9636\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0822 - acc: 0.9734 - val_loss: 0.1132 - val_acc: 0.9719\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0657 - acc: 0.9816 - val_loss: 0.1257 - val_acc: 0.9585\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0621 - acc: 0.9811 - val_loss: 0.1109 - val_acc: 0.9668\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0597 - acc: 0.9790 - val_loss: 0.1109 - val_acc: 0.9681\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0506 - acc: 0.9830 - val_loss: 0.1656 - val_acc: 0.9361\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0511 - acc: 0.9827 - val_loss: 0.1222 - val_acc: 0.9604\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0487 - acc: 0.9835 - val_loss: 0.1116 - val_acc: 0.9668\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0407 - acc: 0.9877 - val_loss: 0.1175 - val_acc: 0.9598\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0413 - acc: 0.9891 - val_loss: 0.1092 - val_acc: 0.9693\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0393 - acc: 0.9880 - val_loss: 0.1125 - val_acc: 0.9706\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0328 - acc: 0.9893 - val_loss: 0.1192 - val_acc: 0.9610\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0289 - acc: 0.9917 - val_loss: 0.1006 - val_acc: 0.9732\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0333 - acc: 0.9883 - val_loss: 0.1206 - val_acc: 0.9674\n",
      "Epoch 25/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0290 - acc: 0.9923 - val_loss: 0.1308 - val_acc: 0.9610\n",
      "Epoch 26/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0233 - acc: 0.9939 - val_loss: 0.1075 - val_acc: 0.9706\n",
      "Epoch 27/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0253 - acc: 0.9917 - val_loss: 0.1091 - val_acc: 0.9738\n",
      "Epoch 28/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0280 - acc: 0.9925 - val_loss: 0.1001 - val_acc: 0.9770\n",
      "Epoch 29/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0293 - acc: 0.9899 - val_loss: 0.1378 - val_acc: 0.9585\n",
      "Epoch 30/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.1081 - val_acc: 0.9751\n",
      "Epoch 31/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0170 - acc: 0.9965 - val_loss: 0.1288 - val_acc: 0.9617\n",
      "Epoch 32/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.1323 - val_acc: 0.9662\n",
      "Epoch 33/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0182 - acc: 0.9949 - val_loss: 0.1056 - val_acc: 0.9770\n",
      "939/939 [==============================] - 1s 601us/step\n",
      "3755/3755 [==============================] - 2s 578us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 20s 5ms/step - loss: 0.6417 - acc: 0.6373 - val_loss: 0.7106 - val_acc: 0.4962\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.5478 - acc: 0.7177 - val_loss: 0.5625 - val_acc: 0.6558\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.3164 - acc: 0.8748 - val_loss: 0.2584 - val_acc: 0.8991\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.2014 - acc: 0.9270 - val_loss: 0.2161 - val_acc: 0.9189\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1681 - acc: 0.9366 - val_loss: 0.1828 - val_acc: 0.9330\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1376 - acc: 0.9534 - val_loss: 0.1877 - val_acc: 0.9355\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1284 - acc: 0.9510 - val_loss: 0.1426 - val_acc: 0.9540\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1143 - acc: 0.9593 - val_loss: 0.1366 - val_acc: 0.9464\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1003 - acc: 0.9670 - val_loss: 0.1608 - val_acc: 0.9393\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0878 - acc: 0.9731 - val_loss: 0.1245 - val_acc: 0.9591\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0732 - acc: 0.9758 - val_loss: 0.1716 - val_acc: 0.9336\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0737 - acc: 0.9755 - val_loss: 0.1627 - val_acc: 0.9342\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0637 - acc: 0.9803 - val_loss: 0.2138 - val_acc: 0.9234\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0538 - acc: 0.9832 - val_loss: 0.1636 - val_acc: 0.9400\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0559 - acc: 0.9814 - val_loss: 0.1259 - val_acc: 0.9572\n",
      "939/939 [==============================] - 1s 580us/step\n",
      "3755/3755 [==============================] - 2s 571us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 20s 5ms/step - loss: 0.6828 - acc: 0.5478 - val_loss: 0.6379 - val_acc: 0.6775\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.5073 - acc: 0.7792 - val_loss: 0.3409 - val_acc: 0.8755\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.2639 - acc: 0.9009 - val_loss: 0.2107 - val_acc: 0.9227\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1976 - acc: 0.9241 - val_loss: 0.1679 - val_acc: 0.9317\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1484 - acc: 0.9483 - val_loss: 0.1540 - val_acc: 0.9489\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1202 - acc: 0.9603 - val_loss: 0.1335 - val_acc: 0.9636\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1025 - acc: 0.9686 - val_loss: 0.1510 - val_acc: 0.9464\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0940 - acc: 0.9707 - val_loss: 0.1274 - val_acc: 0.9572\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0816 - acc: 0.9699 - val_loss: 0.1176 - val_acc: 0.9585\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0726 - acc: 0.9800 - val_loss: 0.1121 - val_acc: 0.9706\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0830 - acc: 0.9718 - val_loss: 0.1354 - val_acc: 0.9521\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0602 - acc: 0.9830 - val_loss: 0.1170 - val_acc: 0.9598\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0592 - acc: 0.9803 - val_loss: 0.1416 - val_acc: 0.9559\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0424 - acc: 0.9883 - val_loss: 0.1249 - val_acc: 0.9662\n",
      "Epoch 15/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0455 - acc: 0.9872 - val_loss: 0.1034 - val_acc: 0.9706\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0377 - acc: 0.9901 - val_loss: 0.1011 - val_acc: 0.9738\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0361 - acc: 0.9877 - val_loss: 0.1037 - val_acc: 0.9706\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.1427 - val_acc: 0.9534\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0404 - acc: 0.9870 - val_loss: 0.0954 - val_acc: 0.9764\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0275 - acc: 0.9925 - val_loss: 0.1043 - val_acc: 0.9757\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0206 - acc: 0.9949 - val_loss: 0.0985 - val_acc: 0.9764\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0213 - acc: 0.9947 - val_loss: 0.1000 - val_acc: 0.9751\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0190 - acc: 0.9957 - val_loss: 0.0975 - val_acc: 0.9764\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0174 - acc: 0.9963 - val_loss: 0.0989 - val_acc: 0.9745\n",
      "939/939 [==============================] - 1s 585us/step\n",
      "3755/3755 [==============================] - 2s 587us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 20s 5ms/step - loss: 0.6662 - acc: 0.6115 - val_loss: 0.6711 - val_acc: 0.5453\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.5358 - acc: 0.7310 - val_loss: 0.4603 - val_acc: 0.7599\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.3159 - acc: 0.8706 - val_loss: 0.2812 - val_acc: 0.8851\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.2092 - acc: 0.9236 - val_loss: 0.1863 - val_acc: 0.9285\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1615 - acc: 0.9443 - val_loss: 0.1712 - val_acc: 0.9387\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1389 - acc: 0.9510 - val_loss: 0.2127 - val_acc: 0.9151\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1181 - acc: 0.9598 - val_loss: 0.1428 - val_acc: 0.9540\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.1057 - acc: 0.9654 - val_loss: 0.1449 - val_acc: 0.9515\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0932 - acc: 0.9686 - val_loss: 0.1231 - val_acc: 0.9642\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0826 - acc: 0.9736 - val_loss: 0.1334 - val_acc: 0.9623\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0797 - acc: 0.9712 - val_loss: 0.1735 - val_acc: 0.9444\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0686 - acc: 0.9771 - val_loss: 0.1125 - val_acc: 0.9649\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0629 - acc: 0.9811 - val_loss: 0.1220 - val_acc: 0.9610\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0552 - acc: 0.9824 - val_loss: 0.1181 - val_acc: 0.9610\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0489 - acc: 0.9840 - val_loss: 0.1212 - val_acc: 0.9693\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0401 - acc: 0.9883 - val_loss: 0.1348 - val_acc: 0.9623\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0523 - acc: 0.9830 - val_loss: 0.1031 - val_acc: 0.9745\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 12s 3ms/step - loss: 0.0368 - acc: 0.9875 - val_loss: 0.1269 - val_acc: 0.9617\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0360 - acc: 0.9883 - val_loss: 0.0933 - val_acc: 0.9751\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0363 - acc: 0.9877 - val_loss: 0.1025 - val_acc: 0.9764\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0308 - acc: 0.9901 - val_loss: 0.1191 - val_acc: 0.9700\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0219 - acc: 0.9949 - val_loss: 0.1085 - val_acc: 0.9738\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0243 - acc: 0.9917 - val_loss: 0.0942 - val_acc: 0.9764\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 11s 3ms/step - loss: 0.0222 - acc: 0.9939 - val_loss: 0.1015 - val_acc: 0.9770\n",
      "939/939 [==============================] - 1s 580us/step\n",
      "3755/3755 [==============================] - 2s 583us/step\n",
      "Train on 3756 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3756/3756 [==============================] - 20s 5ms/step - loss: 0.6601 - acc: 0.6246 - val_loss: 0.6421 - val_acc: 0.6264\n",
      "Epoch 2/170\n",
      "3756/3756 [==============================] - 12s 3ms/step - loss: 0.5041 - acc: 0.7551 - val_loss: 0.4178 - val_acc: 0.7720\n",
      "Epoch 3/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.3005 - acc: 0.8810 - val_loss: 0.2377 - val_acc: 0.9151\n",
      "Epoch 4/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.2079 - acc: 0.9223 - val_loss: 0.1895 - val_acc: 0.9298\n",
      "Epoch 5/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.1632 - acc: 0.9388 - val_loss: 0.1582 - val_acc: 0.9381\n",
      "Epoch 6/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.1364 - acc: 0.9515 - val_loss: 0.1386 - val_acc: 0.9502\n",
      "Epoch 7/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.1238 - acc: 0.9566 - val_loss: 0.1376 - val_acc: 0.9534\n",
      "Epoch 8/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.1088 - acc: 0.9662 - val_loss: 0.1797 - val_acc: 0.9368\n",
      "Epoch 9/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.1028 - acc: 0.9662 - val_loss: 0.1210 - val_acc: 0.9591\n",
      "Epoch 10/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0906 - acc: 0.9694 - val_loss: 0.1195 - val_acc: 0.9636\n",
      "Epoch 11/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0724 - acc: 0.9787 - val_loss: 0.1181 - val_acc: 0.9655\n",
      "Epoch 12/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0736 - acc: 0.9755 - val_loss: 0.1121 - val_acc: 0.9700\n",
      "Epoch 13/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0648 - acc: 0.9790 - val_loss: 0.1160 - val_acc: 0.9719\n",
      "Epoch 14/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0692 - acc: 0.9768 - val_loss: 0.1452 - val_acc: 0.9566\n",
      "Epoch 15/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0625 - acc: 0.9798 - val_loss: 0.1173 - val_acc: 0.9655\n",
      "Epoch 16/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0553 - acc: 0.9827 - val_loss: 0.1038 - val_acc: 0.9745\n",
      "Epoch 17/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0414 - acc: 0.9870 - val_loss: 0.1014 - val_acc: 0.9738\n",
      "Epoch 18/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0486 - acc: 0.9832 - val_loss: 0.1146 - val_acc: 0.9719\n",
      "Epoch 19/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0434 - acc: 0.9872 - val_loss: 0.1088 - val_acc: 0.9706\n",
      "Epoch 20/170\n",
      "3756/3756 [==============================] - 12s 3ms/step - loss: 0.0319 - acc: 0.9909 - val_loss: 0.1003 - val_acc: 0.9783\n",
      "Epoch 21/170\n",
      "3756/3756 [==============================] - 12s 3ms/step - loss: 0.0444 - acc: 0.9846 - val_loss: 0.1299 - val_acc: 0.9674\n",
      "Epoch 22/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0330 - acc: 0.9909 - val_loss: 0.0955 - val_acc: 0.9796\n",
      "Epoch 23/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0270 - acc: 0.9928 - val_loss: 0.1217 - val_acc: 0.9732\n",
      "Epoch 24/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0247 - acc: 0.9931 - val_loss: 0.1084 - val_acc: 0.9796\n",
      "Epoch 25/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0272 - acc: 0.9912 - val_loss: 0.1066 - val_acc: 0.9738\n",
      "Epoch 26/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0223 - acc: 0.9936 - val_loss: 0.1137 - val_acc: 0.9713\n",
      "Epoch 27/170\n",
      "3756/3756 [==============================] - 11s 3ms/step - loss: 0.0202 - acc: 0.9947 - val_loss: 0.1023 - val_acc: 0.9777\n",
      "938/938 [==============================] - 1s 568us/step\n",
      "3756/3756 [==============================] - 2s 573us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 16s 4ms/step - loss: 0.6461 - acc: 0.6394 - val_loss: 0.7097 - val_acc: 0.4968\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.6127 - acc: 0.6519 - val_loss: 0.6242 - val_acc: 0.5664\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.4921 - acc: 0.7731 - val_loss: 0.4698 - val_acc: 0.7778\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.3304 - acc: 0.8788 - val_loss: 0.3204 - val_acc: 0.8768\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.2415 - acc: 0.9137 - val_loss: 0.2404 - val_acc: 0.9189\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1981 - acc: 0.9297 - val_loss: 0.2131 - val_acc: 0.9342\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1663 - acc: 0.9382 - val_loss: 0.1713 - val_acc: 0.9438\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1475 - acc: 0.9510 - val_loss: 0.2449 - val_acc: 0.8883\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1290 - acc: 0.9585 - val_loss: 0.1658 - val_acc: 0.9406\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1256 - acc: 0.9561 - val_loss: 0.1389 - val_acc: 0.9598\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1101 - acc: 0.9640 - val_loss: 0.1589 - val_acc: 0.9432\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1063 - acc: 0.9659 - val_loss: 0.2468 - val_acc: 0.8914\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0929 - acc: 0.9672 - val_loss: 0.1252 - val_acc: 0.9623\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0837 - acc: 0.9726 - val_loss: 0.1172 - val_acc: 0.9649\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0791 - acc: 0.9771 - val_loss: 0.1338 - val_acc: 0.9515\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0841 - acc: 0.9718 - val_loss: 0.1534 - val_acc: 0.9451\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0738 - acc: 0.9766 - val_loss: 0.1194 - val_acc: 0.9668\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0753 - acc: 0.9734 - val_loss: 0.1078 - val_acc: 0.9725\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0636 - acc: 0.9768 - val_loss: 0.1097 - val_acc: 0.9668\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0548 - acc: 0.9816 - val_loss: 0.1053 - val_acc: 0.9732\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0558 - acc: 0.9806 - val_loss: 0.1041 - val_acc: 0.9745\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0484 - acc: 0.9864 - val_loss: 0.1078 - val_acc: 0.9668\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0407 - acc: 0.9877 - val_loss: 0.1048 - val_acc: 0.9681\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0449 - acc: 0.9848 - val_loss: 0.1027 - val_acc: 0.9732\n",
      "Epoch 25/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0382 - acc: 0.9899 - val_loss: 0.1138 - val_acc: 0.9662\n",
      "Epoch 26/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0335 - acc: 0.9917 - val_loss: 0.1202 - val_acc: 0.9610\n",
      "Epoch 27/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0435 - acc: 0.9859 - val_loss: 0.1309 - val_acc: 0.9579\n",
      "Epoch 28/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.1117 - val_acc: 0.9751\n",
      "Epoch 29/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0355 - acc: 0.9896 - val_loss: 0.1128 - val_acc: 0.9668\n",
      "939/939 [==============================] - 0s 472us/step\n",
      "3755/3755 [==============================] - 2s 467us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 17s 4ms/step - loss: 0.6488 - acc: 0.6362 - val_loss: 0.7058 - val_acc: 0.4962\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.6328 - acc: 0.6394 - val_loss: 0.6739 - val_acc: 0.4968\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.5614 - acc: 0.7017 - val_loss: 0.4887 - val_acc: 0.8506\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.3718 - acc: 0.8610 - val_loss: 0.3970 - val_acc: 0.8199\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.2372 - acc: 0.9169 - val_loss: 0.2661 - val_acc: 0.8876\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1791 - acc: 0.9379 - val_loss: 0.2411 - val_acc: 0.9017\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1532 - acc: 0.9430 - val_loss: 0.1532 - val_acc: 0.9521\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1282 - acc: 0.9537 - val_loss: 0.1467 - val_acc: 0.9419\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1220 - acc: 0.9582 - val_loss: 0.1310 - val_acc: 0.9553\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1274 - acc: 0.9502 - val_loss: 0.1253 - val_acc: 0.9591\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1039 - acc: 0.9675 - val_loss: 0.1696 - val_acc: 0.9259\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0974 - acc: 0.9696 - val_loss: 0.1370 - val_acc: 0.9515\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0867 - acc: 0.9715 - val_loss: 0.1157 - val_acc: 0.9623\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0790 - acc: 0.9728 - val_loss: 0.1399 - val_acc: 0.9483\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0743 - acc: 0.9755 - val_loss: 0.1160 - val_acc: 0.9610\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0710 - acc: 0.9787 - val_loss: 0.1105 - val_acc: 0.9655\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0684 - acc: 0.9763 - val_loss: 0.1248 - val_acc: 0.9489\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0570 - acc: 0.9830 - val_loss: 0.1138 - val_acc: 0.9649\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0519 - acc: 0.9848 - val_loss: 0.1035 - val_acc: 0.9687\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0535 - acc: 0.9848 - val_loss: 0.1057 - val_acc: 0.9649\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0496 - acc: 0.9838 - val_loss: 0.1134 - val_acc: 0.9649\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0449 - acc: 0.9859 - val_loss: 0.1062 - val_acc: 0.9674\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0422 - acc: 0.9885 - val_loss: 0.1156 - val_acc: 0.9617\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0383 - acc: 0.9880 - val_loss: 0.1085 - val_acc: 0.9687\n",
      "939/939 [==============================] - 0s 466us/step\n",
      "3755/3755 [==============================] - 2s 462us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3755/3755 [==============================] - 17s 4ms/step - loss: 0.6868 - acc: 0.5510 - val_loss: 0.6786 - val_acc: 0.5006\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.6504 - acc: 0.6383 - val_loss: 0.6023 - val_acc: 0.6814\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.4962 - acc: 0.8037 - val_loss: 0.3923 - val_acc: 0.8602\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.3134 - acc: 0.8855 - val_loss: 0.2706 - val_acc: 0.9049\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.2319 - acc: 0.9177 - val_loss: 0.2149 - val_acc: 0.9176\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1902 - acc: 0.9249 - val_loss: 0.1871 - val_acc: 0.9285\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1746 - acc: 0.9329 - val_loss: 0.2168 - val_acc: 0.9093\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1475 - acc: 0.9459 - val_loss: 0.1622 - val_acc: 0.9374\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1631 - acc: 0.9425 - val_loss: 0.1685 - val_acc: 0.9368\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1191 - acc: 0.9609 - val_loss: 0.1408 - val_acc: 0.9464\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1102 - acc: 0.9617 - val_loss: 0.1649 - val_acc: 0.9451\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1123 - acc: 0.9630 - val_loss: 0.1425 - val_acc: 0.9476\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1077 - acc: 0.9646 - val_loss: 0.1363 - val_acc: 0.9496\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0902 - acc: 0.9696 - val_loss: 0.1307 - val_acc: 0.9547\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0804 - acc: 0.9755 - val_loss: 0.1551 - val_acc: 0.9400\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0817 - acc: 0.9731 - val_loss: 0.1263 - val_acc: 0.9572\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0681 - acc: 0.9798 - val_loss: 0.1324 - val_acc: 0.9559\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0780 - acc: 0.9742 - val_loss: 0.1212 - val_acc: 0.9534\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0695 - acc: 0.9747 - val_loss: 0.1151 - val_acc: 0.9636\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0630 - acc: 0.9798 - val_loss: 0.1300 - val_acc: 0.9534\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0579 - acc: 0.9811 - val_loss: 0.1282 - val_acc: 0.9508\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0536 - acc: 0.9848 - val_loss: 0.1159 - val_acc: 0.9617\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0576 - acc: 0.9806 - val_loss: 0.1212 - val_acc: 0.9623\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0396 - acc: 0.9909 - val_loss: 0.1088 - val_acc: 0.9713\n",
      "Epoch 25/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0440 - acc: 0.9859 - val_loss: 0.1279 - val_acc: 0.9547\n",
      "Epoch 26/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0429 - acc: 0.9875 - val_loss: 0.1103 - val_acc: 0.9681\n",
      "Epoch 27/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0476 - acc: 0.9856 - val_loss: 0.1097 - val_acc: 0.9668\n",
      "Epoch 28/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0311 - acc: 0.9909 - val_loss: 0.1106 - val_acc: 0.9738\n",
      "Epoch 29/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0415 - acc: 0.9875 - val_loss: 0.1119 - val_acc: 0.9700\n",
      "939/939 [==============================] - 0s 483us/step\n",
      "3755/3755 [==============================] - 2s 476us/step\n",
      "Train on 3755 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3755/3755 [==============================] - 17s 5ms/step - loss: 0.6682 - acc: 0.6178 - val_loss: 0.7132 - val_acc: 0.5083\n",
      "Epoch 2/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.6348 - acc: 0.6522 - val_loss: 0.6042 - val_acc: 0.7522\n",
      "Epoch 3/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.4957 - acc: 0.7768 - val_loss: 0.4023 - val_acc: 0.8359\n",
      "Epoch 4/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.2912 - acc: 0.8929 - val_loss: 0.2433 - val_acc: 0.9144\n",
      "Epoch 5/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.2019 - acc: 0.9310 - val_loss: 0.1836 - val_acc: 0.9310\n",
      "Epoch 6/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1640 - acc: 0.9435 - val_loss: 0.1536 - val_acc: 0.9425\n",
      "Epoch 7/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1473 - acc: 0.9491 - val_loss: 0.1547 - val_acc: 0.9451\n",
      "Epoch 8/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1163 - acc: 0.9648 - val_loss: 0.1426 - val_acc: 0.9515\n",
      "Epoch 9/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.1097 - acc: 0.9662 - val_loss: 0.1234 - val_acc: 0.9585\n",
      "Epoch 10/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0947 - acc: 0.9718 - val_loss: 0.1401 - val_acc: 0.9610\n",
      "Epoch 11/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0937 - acc: 0.9688 - val_loss: 0.1194 - val_acc: 0.9566\n",
      "Epoch 12/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0817 - acc: 0.9752 - val_loss: 0.1185 - val_acc: 0.9604\n",
      "Epoch 13/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0741 - acc: 0.9798 - val_loss: 0.1693 - val_acc: 0.9330\n",
      "Epoch 14/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0667 - acc: 0.9819 - val_loss: 0.1044 - val_acc: 0.9681\n",
      "Epoch 15/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0674 - acc: 0.9795 - val_loss: 0.1040 - val_acc: 0.9732\n",
      "Epoch 16/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0651 - acc: 0.9779 - val_loss: 0.1165 - val_acc: 0.9636\n",
      "Epoch 17/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0507 - acc: 0.9867 - val_loss: 0.1020 - val_acc: 0.9700\n",
      "Epoch 18/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0536 - acc: 0.9832 - val_loss: 0.0999 - val_acc: 0.9700\n",
      "Epoch 19/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0439 - acc: 0.9877 - val_loss: 0.1035 - val_acc: 0.9757\n",
      "Epoch 20/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0392 - acc: 0.9901 - val_loss: 0.1001 - val_acc: 0.9681\n",
      "Epoch 21/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0398 - acc: 0.9870 - val_loss: 0.0945 - val_acc: 0.9706\n",
      "Epoch 22/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0351 - acc: 0.9912 - val_loss: 0.0888 - val_acc: 0.9770\n",
      "Epoch 23/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0358 - acc: 0.9880 - val_loss: 0.1295 - val_acc: 0.9649\n",
      "Epoch 24/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0290 - acc: 0.9928 - val_loss: 0.0929 - val_acc: 0.9732\n",
      "Epoch 25/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0319 - acc: 0.9909 - val_loss: 0.1010 - val_acc: 0.9636\n",
      "Epoch 26/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0329 - acc: 0.9901 - val_loss: 0.0915 - val_acc: 0.9745\n",
      "Epoch 27/170\n",
      "3755/3755 [==============================] - 8s 2ms/step - loss: 0.0328 - acc: 0.9907 - val_loss: 0.0956 - val_acc: 0.9777\n",
      "939/939 [==============================] - 0s 479us/step\n",
      "3755/3755 [==============================] - 2s 475us/step\n",
      "Train on 3756 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "3756/3756 [==============================] - 17s 5ms/step - loss: 0.6683 - acc: 0.6145 - val_loss: 0.7090 - val_acc: 0.5083\n",
      "Epoch 2/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.6292 - acc: 0.6616 - val_loss: 0.5884 - val_acc: 0.6845\n",
      "Epoch 3/170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.4701 - acc: 0.7875 - val_loss: 0.3871 - val_acc: 0.8301\n",
      "Epoch 4/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.3013 - acc: 0.8871 - val_loss: 0.2960 - val_acc: 0.8921\n",
      "Epoch 5/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.2241 - acc: 0.9199 - val_loss: 0.2253 - val_acc: 0.9227\n",
      "Epoch 6/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.1779 - acc: 0.9348 - val_loss: 0.1730 - val_acc: 0.9349\n",
      "Epoch 7/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.1549 - acc: 0.9483 - val_loss: 0.1850 - val_acc: 0.9381\n",
      "Epoch 8/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.1600 - acc: 0.9438 - val_loss: 0.1451 - val_acc: 0.9476\n",
      "Epoch 9/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.1355 - acc: 0.9491 - val_loss: 0.1387 - val_acc: 0.9534\n",
      "Epoch 10/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.1089 - acc: 0.9646 - val_loss: 0.1380 - val_acc: 0.9515\n",
      "Epoch 11/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.1038 - acc: 0.9654 - val_loss: 0.1371 - val_acc: 0.9534\n",
      "Epoch 12/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0960 - acc: 0.9683 - val_loss: 0.1312 - val_acc: 0.9547\n",
      "Epoch 13/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0864 - acc: 0.9723 - val_loss: 0.1248 - val_acc: 0.9610\n",
      "Epoch 14/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0836 - acc: 0.9742 - val_loss: 0.1245 - val_acc: 0.9540\n",
      "Epoch 15/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0738 - acc: 0.9771 - val_loss: 0.1115 - val_acc: 0.9693\n",
      "Epoch 16/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0813 - acc: 0.9710 - val_loss: 0.1176 - val_acc: 0.9630\n",
      "Epoch 17/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0639 - acc: 0.9792 - val_loss: 0.1206 - val_acc: 0.9572\n",
      "Epoch 18/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0616 - acc: 0.9806 - val_loss: 0.1301 - val_acc: 0.9617\n",
      "Epoch 19/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0645 - acc: 0.9774 - val_loss: 0.1395 - val_acc: 0.9579\n",
      "Epoch 20/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0975 - val_acc: 0.9770\n",
      "Epoch 21/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0610 - acc: 0.9803 - val_loss: 0.1691 - val_acc: 0.9483\n",
      "Epoch 22/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0473 - acc: 0.9878 - val_loss: 0.1197 - val_acc: 0.9649\n",
      "Epoch 23/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0458 - acc: 0.9854 - val_loss: 0.1177 - val_acc: 0.9553\n",
      "Epoch 24/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0420 - acc: 0.9875 - val_loss: 0.1016 - val_acc: 0.9623\n",
      "Epoch 25/170\n",
      "3756/3756 [==============================] - 8s 2ms/step - loss: 0.0389 - acc: 0.9886 - val_loss: 0.1075 - val_acc: 0.9706\n",
      "938/938 [==============================] - 0s 481us/step\n",
      "3756/3756 [==============================] - 2s 481us/step\n",
      "Train on 4694 samples, validate on 1566 samples\n",
      "Epoch 1/170\n",
      "4694/4694 [==============================] - 24s 5ms/step - loss: 0.6724 - acc: 0.5933 - val_loss: 0.6010 - val_acc: 0.7548\n",
      "Epoch 2/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.4515 - acc: 0.8055 - val_loss: 0.3440 - val_acc: 0.8461\n",
      "Epoch 3/170\n",
      "4694/4694 [==============================] - 15s 3ms/step - loss: 0.2476 - acc: 0.9043 - val_loss: 0.2074 - val_acc: 0.9291\n",
      "Epoch 4/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.1843 - acc: 0.9301 - val_loss: 0.1982 - val_acc: 0.9278\n",
      "Epoch 5/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.1511 - acc: 0.9480 - val_loss: 0.1511 - val_acc: 0.9470\n",
      "Epoch 6/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.1305 - acc: 0.9531 - val_loss: 0.1308 - val_acc: 0.9534\n",
      "Epoch 7/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.1148 - acc: 0.9606 - val_loss: 0.1366 - val_acc: 0.9521\n",
      "Epoch 8/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.1053 - acc: 0.9631 - val_loss: 0.1386 - val_acc: 0.9444\n",
      "Epoch 9/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0977 - acc: 0.9642 - val_loss: 0.1088 - val_acc: 0.9617\n",
      "Epoch 10/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0814 - acc: 0.9719 - val_loss: 0.1077 - val_acc: 0.9662\n",
      "Epoch 11/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0819 - acc: 0.9710 - val_loss: 0.1108 - val_acc: 0.9662\n",
      "Epoch 12/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0794 - acc: 0.9719 - val_loss: 0.1128 - val_acc: 0.9674\n",
      "Epoch 13/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0657 - acc: 0.9770 - val_loss: 0.1056 - val_acc: 0.9719\n",
      "Epoch 14/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0576 - acc: 0.9810 - val_loss: 0.1057 - val_acc: 0.9681\n",
      "Epoch 15/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0543 - acc: 0.9830 - val_loss: 0.1066 - val_acc: 0.9674\n",
      "Epoch 16/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0544 - acc: 0.9817 - val_loss: 0.1232 - val_acc: 0.9649\n",
      "Epoch 17/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0555 - acc: 0.9795 - val_loss: 0.1091 - val_acc: 0.9738\n",
      "Epoch 18/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0483 - acc: 0.9810 - val_loss: 0.0974 - val_acc: 0.9738\n",
      "Epoch 19/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0416 - acc: 0.9847 - val_loss: 0.0964 - val_acc: 0.9738\n",
      "Epoch 20/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0400 - acc: 0.9868 - val_loss: 0.0901 - val_acc: 0.9757\n",
      "Epoch 21/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0339 - acc: 0.9896 - val_loss: 0.0952 - val_acc: 0.9745\n",
      "Epoch 22/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0275 - acc: 0.9919 - val_loss: 0.0986 - val_acc: 0.9706\n",
      "Epoch 23/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0338 - acc: 0.9883 - val_loss: 0.0978 - val_acc: 0.9777\n",
      "Epoch 24/170\n",
      "4694/4694 [==============================] - 14s 3ms/step - loss: 0.0326 - acc: 0.9896 - val_loss: 0.1033 - val_acc: 0.9732\n",
      "Epoch 25/170\n",
      "4694/4694 [==============================] - 15s 3ms/step - loss: 0.0262 - acc: 0.9919 - val_loss: 0.0975 - val_acc: 0.9751\n",
      "Best: 0.959949 using {'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [4, 8, 16, 32]\n",
    "#batch_size = [128]\n",
    "param_grid = dict(batch_size = batch_size)\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, mode = 'auto')\n",
    "cnn_models = [None] * n_combination\n",
    "for i in chosen:    \n",
    "    model = KerasClassifier(build_fn = cnn_model)\n",
    "    grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 5)\n",
    "    grid.fit(X_c_train[i], y_c_train[i], epochs = N_EPOCHS, callbacks = [earlyStopping], validation_data = (X_c_validation[i], y_c_validation[i]))\n",
    "    print(\"Best: %f using %s\" %(grid.best_score_, grid.best_params_))\n",
    "    cnn_models[i] = grid.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.01\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.02\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.03\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.04\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.05\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.060000000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.07\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.08\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.09\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.09999999999999999\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.10999999999999999\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.11999999999999998\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.12999999999999998\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.13999999999999999\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.15\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.16\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.17\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.18000000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.19000000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.20000000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.21000000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.22000000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.23000000000000007\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.24000000000000007\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.25000000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.26000000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.2700000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.2800000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.2900000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.3000000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.3100000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.3200000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.3300000000000001\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.34000000000000014\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.35000000000000014\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.36000000000000015\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.37000000000000016\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.38000000000000017\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.3900000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.4000000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.4100000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.4200000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.4300000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.4400000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.45000000000000023\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.46000000000000024\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.47000000000000025\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.48000000000000026\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.49000000000000027\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5000000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5100000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5200000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5300000000000002\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5400000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5500000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5600000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5700000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5800000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.5900000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6000000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6100000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6200000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6300000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6400000000000003\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6500000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6600000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6700000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6800000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.6900000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7000000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7100000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7200000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7300000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7400000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7500000000000004\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7600000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7700000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7800000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.7900000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8000000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8100000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8200000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8300000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8400000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8500000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8600000000000005\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8700000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8800000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.8900000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9000000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9100000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9200000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9300000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9400000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9500000000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9600000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9700000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9800000000000006\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 0.9900000000000007\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 1.0000000000000007\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788199109938377 threshold: 1.0100000000000007\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788242687377416 threshold: 1.0200000000000007\n",
      "accuracy: 0.9787697332607512 f1_score: 0.9788242687377416 threshold: 1.0300000000000007\n",
      "accuracy: 0.9791326438033024 f1_score: 0.9791794425355531 threshold: 1.0400000000000007\n",
      "accuracy: 0.9791326438033024 f1_score: 0.9791794425355531 threshold: 1.0500000000000007\n",
      "accuracy: 0.9791326438033024 f1_score: 0.9791794425355531 threshold: 1.0600000000000007\n",
      "accuracy: 0.9791326438033024 f1_score: 0.9791794425355531 threshold: 1.0700000000000007\n",
      "accuracy: 0.9793140990745781 f1_score: 0.9793570031809234 threshold: 1.0800000000000007\n",
      "accuracy: 0.9793140990745781 f1_score: 0.9793570031809234 threshold: 1.0900000000000007\n",
      "accuracy: 0.9796770096171293 f1_score: 0.9797154717580137 threshold: 1.1000000000000008\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800781738899643 threshold: 1.1100000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1200000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1300000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1400000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1500000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1600000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1700000000000008\n",
      "accuracy: 0.979858464888405 f1_score: 0.9798917764104133 threshold: 1.1800000000000008\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.1900000000000008\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.2000000000000008\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.2100000000000009\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.2200000000000009\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.2300000000000009\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.2400000000000009\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.2500000000000009\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.260000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.270000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.280000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.290000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.300000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.310000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.320000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.330000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.340000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.350000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800735528057539 threshold: 1.360000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.370000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.380000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.390000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.400000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.410000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.420000000000001\n",
      "accuracy: 0.9800399201596807 f1_score: 0.9800693915469842 threshold: 1.430000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.9802557921493881 threshold: 1.440000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.9802557921493881 threshold: 1.450000000000001\n",
      "accuracy: 0.9804028307022319 f1_score: 0.9804367941607351 threshold: 1.460000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.470000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.480000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.490000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.500000000000001\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5100000000000011\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5200000000000011\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5300000000000011\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5400000000000011\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5500000000000012\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5600000000000012\n",
      "accuracy: 0.9802213754309562 f1_score: 0.980257421409966 threshold: 1.5700000000000012\n",
      "accuracy: 0.9804028307022319 f1_score: 0.9804351268177753 threshold: 1.5800000000000012\n",
      "accuracy: 0.9804028307022319 f1_score: 0.9804351268177753 threshold: 1.5900000000000012\n",
      "accuracy: 0.9805842859735076 f1_score: 0.9806213913921739 threshold: 1.6000000000000012\n",
      "accuracy: 0.9805842859735076 f1_score: 0.9806213913921739 threshold: 1.6100000000000012\n",
      "accuracy: 0.9805842859735076 f1_score: 0.9806213913921739 threshold: 1.6200000000000012\n",
      "accuracy: 0.9805842859735076 f1_score: 0.9806213913921739 threshold: 1.6300000000000012\n",
      "accuracy: 0.9805842859735076 f1_score: 0.9806213913921739 threshold: 1.6400000000000012\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.6500000000000012\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.6600000000000013\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.6700000000000013\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.6800000000000013\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.6900000000000013\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.7000000000000013\n",
      "accuracy: 0.9807657412447831 f1_score: 0.980802325543927 threshold: 1.7100000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7200000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7300000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7400000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7500000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7600000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7700000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7800000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.7900000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.8000000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.8100000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.8200000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809837710139752 threshold: 1.8300000000000014\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811631500248561 threshold: 1.8400000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.8500000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.8600000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.8700000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.8800000000000014\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.8900000000000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9000000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9100000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9200000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9300000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9400000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9500000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9600000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9700000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9800000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 1.9900000000000015\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 2.0000000000000013\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 2.010000000000001\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809815918531971 threshold: 2.020000000000001\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811679714523585 threshold: 2.0300000000000007\n",
      "accuracy: 0.9813101070586101 f1_score: 0.9813495381414448 threshold: 2.0400000000000005\n",
      "accuracy: 0.9813101070586101 f1_score: 0.9813495381414448 threshold: 2.0500000000000003\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.06\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.07\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.0799999999999996\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.0899999999999994\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.099999999999999\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.109999999999999\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.1199999999999988\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.1299999999999986\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.1399999999999983\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.149999999999998\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.159999999999998\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.1699999999999977\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.1799999999999975\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.1899999999999973\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.199999999999997\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.209999999999997\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.2199999999999966\n",
      "accuracy: 0.9811286517873344 f1_score: 0.9811686671865623 threshold: 2.2299999999999964\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809871062770459 threshold: 2.239999999999996\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809871062770459 threshold: 2.249999999999996\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809871062770459 threshold: 2.259999999999996\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809871062770459 threshold: 2.2699999999999956\n",
      "accuracy: 0.9809471965160588 f1_score: 0.9809871062770459 threshold: 2.2799999999999954\n",
      "accuracy: 0.9813101070586101 f1_score: 0.9813502186717284 threshold: 2.289999999999995\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.299999999999995\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.3099999999999947\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.3199999999999945\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.3299999999999943\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.339999999999994\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.349999999999994\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.3599999999999937\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.3699999999999934\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.3799999999999932\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.389999999999993\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.399999999999993\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.4099999999999926\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.4199999999999924\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.429999999999992\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.439999999999992\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.4499999999999917\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.4599999999999915\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.4699999999999913\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.479999999999991\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.489999999999991\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.4999999999999907\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.5099999999999905\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.5199999999999902\n",
      "accuracy: 0.9814915623298857 f1_score: 0.9815310953411228 threshold: 2.52999999999999\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.53999999999999\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.5499999999999896\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.5599999999999894\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.569999999999989\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.579999999999989\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.5899999999999888\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.5999999999999885\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.6099999999999883\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.619999999999988\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.629999999999988\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.6399999999999877\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.6499999999999875\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.6599999999999873\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.669999999999987\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.679999999999987\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.6899999999999866\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.6999999999999864\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.709999999999986\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.719999999999986\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.7299999999999858\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.7399999999999856\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.7499999999999853\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.759999999999985\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.769999999999985\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.7799999999999847\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.7899999999999845\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.7999999999999843\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.809999999999984\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.819999999999984\n",
      "accuracy: 0.9816730176011613 f1_score: 0.9817119552188734 threshold: 2.8299999999999836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.981854472872437 f1_score: 0.9818914591231415 threshold: 2.8399999999999834\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818914591231415 threshold: 2.849999999999983\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818914591231415 threshold: 2.859999999999983\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818914591231415 threshold: 2.869999999999983\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818914591231415 threshold: 2.8799999999999826\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818914591231415 threshold: 2.8899999999999824\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.899999999999982\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.909999999999982\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.9199999999999817\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.9299999999999815\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.9399999999999813\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.949999999999981\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.959999999999981\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.9699999999999807\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.9799999999999804\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.9899999999999802\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 2.99999999999998\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.00999999999998\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.0199999999999796\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.0299999999999794\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.039999999999979\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.049999999999979\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.0599999999999787\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.0699999999999785\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.0799999999999783\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.089999999999978\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.099999999999978\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.1099999999999777\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.1199999999999775\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.1299999999999772\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.139999999999977\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.149999999999977\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.1599999999999766\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.1699999999999764\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.179999999999976\n",
      "accuracy: 0.9820359281437125 f1_score: 0.9820723127407799 threshold: 3.189999999999976\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818927987509494 threshold: 3.1999999999999758\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.2099999999999755\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.2199999999999753\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.229999999999975\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.239999999999975\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.2499999999999747\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.2599999999999745\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.2699999999999743\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.279999999999974\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.289999999999974\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.2999999999999736\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.3099999999999734\n",
      "accuracy: 0.9820359281437125 f1_score: 0.982070478816232 threshold: 3.319999999999973\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818895273138056 threshold: 3.329999999999973\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818895273138056 threshold: 3.3399999999999728\n",
      "accuracy: 0.981854472872437 f1_score: 0.9818895273138056 threshold: 3.3499999999999726\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.3599999999999723\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.369999999999972\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.379999999999972\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.3899999999999717\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.3999999999999715\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.4099999999999713\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.419999999999971\n",
      "accuracy: 0.9822173834149882 f1_score: 0.9822519161564415 threshold: 3.429999999999971\n",
      "accuracy: 0.9823988386862639 f1_score: 0.9824328573559402 threshold: 3.4399999999999706\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.4499999999999704\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.45999999999997\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.46999999999997\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.47999999999997\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.4899999999999696\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.4999999999999694\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.509999999999969\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.519999999999969\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.5299999999999687\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.5399999999999685\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.5499999999999683\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.559999999999968\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.569999999999968\n",
      "accuracy: 0.9825802939575394 f1_score: 0.9826137832237903 threshold: 3.5799999999999677\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.5899999999999674\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.5999999999999672\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.609999999999967\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.619999999999967\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.6299999999999666\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.6399999999999664\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827946942065788 threshold: 3.649999999999966\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829755907508222 threshold: 3.659999999999966\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829755907508222 threshold: 3.6699999999999657\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.6799999999999655\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.6899999999999653\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.699999999999965\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.709999999999965\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.7199999999999647\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.7299999999999645\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.7399999999999642\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.749999999999964\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.759999999999964\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.7699999999999636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.7799999999999634\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.789999999999963\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.799999999999963\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.8099999999999627\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.8199999999999625\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.8299999999999623\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827941323701428 threshold: 3.839999999999962\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.849999999999962\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.8599999999999617\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.8699999999999615\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.8799999999999613\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.889999999999961\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.899999999999961\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.9099999999999606\n",
      "accuracy: 0.9825802939575394 f1_score: 0.982616018339088 threshold: 3.9199999999999604\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.92999999999996\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.93999999999996\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.9499999999999598\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.9599999999999596\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.9699999999999593\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.979999999999959\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.989999999999959\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 3.9999999999999587\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.009999999999959\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.019999999999959\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.0299999999999585\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.039999999999958\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.049999999999958\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.059999999999958\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.069999999999958\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.079999999999957\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.089999999999957\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.099999999999957\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.109999999999957\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.119999999999957\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.129999999999956\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.139999999999956\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.149999999999956\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.159999999999956\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.1699999999999555\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.179999999999955\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.189999999999955\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.199999999999955\n",
      "accuracy: 0.9827617492288151 f1_score: 0.9827967868295808 threshold: 4.209999999999955\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.2199999999999545\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.229999999999954\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.239999999999954\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.249999999999954\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.259999999999954\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.269999999999953\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.279999999999953\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.289999999999953\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829783721212846 threshold: 4.299999999999953\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.3099999999999525\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.319999999999952\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.329999999999952\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.339999999999952\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.349999999999952\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.3599999999999515\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.369999999999951\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.379999999999951\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.389999999999951\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.399999999999951\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.40999999999995\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.41999999999995\n",
      "accuracy: 0.9831246597713663 f1_score: 0.983159131901915 threshold: 4.42999999999995\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.43999999999995\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.4499999999999496\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.459999999999949\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.469999999999949\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.479999999999949\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.489999999999949\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.4999999999999485\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.509999999999948\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.519999999999948\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.529999999999948\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.539999999999948\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.549999999999947\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.559999999999947\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.569999999999947\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.579999999999947\n",
      "accuracy: 0.9829432045000908 f1_score: 0.9829794428456019 threshold: 4.589999999999947\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.599999999999946\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.609999999999946\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.619999999999946\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.629999999999946\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.6399999999999455\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.649999999999945\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.659999999999945\n",
      "accuracy: 0.9829432045000908 f1_score: 0.982974891711557 threshold: 4.669999999999945\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.679999999999945\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.689999999999944\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.699999999999944\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.709999999999944\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.719999999999944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.729999999999944\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.739999999999943\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.749999999999943\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.759999999999943\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.769999999999943\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.7799999999999425\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.789999999999942\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.799999999999942\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.809999999999942\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.819999999999942\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.8299999999999415\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.839999999999941\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.849999999999941\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.859999999999941\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.869999999999941\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.87999999999994\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.88999999999994\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.89999999999994\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.90999999999994\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.9199999999999395\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.929999999999939\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.939999999999939\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.949999999999939\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.959999999999939\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.9699999999999385\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.979999999999938\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.989999999999938\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 4.999999999999938\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 5.009999999999938\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 5.019999999999937\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 5.029999999999937\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 5.039999999999937\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 5.049999999999937\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831557385637625 threshold: 5.0599999999999365\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.069999999999936\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.079999999999936\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.089999999999936\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.099999999999936\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.1099999999999355\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.119999999999935\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.129999999999935\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.139999999999935\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.149999999999935\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.159999999999934\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.169999999999934\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.179999999999934\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.189999999999934\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833365729124262 threshold: 5.199999999999934\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.209999999999933\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.219999999999933\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.229999999999933\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.239999999999933\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.2499999999999325\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.259999999999932\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.269999999999932\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.279999999999932\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.289999999999932\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.299999999999931\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.309999999999931\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.319999999999931\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.329999999999931\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.339999999999931\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.34999999999993\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.35999999999993\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.36999999999993\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.37999999999993\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.3899999999999295\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.399999999999929\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.409999999999929\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.419999999999929\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.429999999999929\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.4399999999999284\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.449999999999928\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.459999999999928\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.469999999999928\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.479999999999928\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.489999999999927\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.499999999999927\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.509999999999927\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.519999999999927\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.5299999999999265\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.539999999999926\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.549999999999926\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.559999999999926\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.569999999999926\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.5799999999999255\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.589999999999925\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.599999999999925\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.609999999999925\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.619999999999925\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.629999999999924\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.639999999999924\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.649999999999924\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.659999999999924\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.6699999999999235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.679999999999923\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.689999999999923\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.699999999999923\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.709999999999923\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.7199999999999225\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.729999999999922\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.739999999999922\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.749999999999922\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.759999999999922\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.769999999999921\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.779999999999921\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.789999999999921\n",
      "accuracy: 0.9831246597713663 f1_score: 0.9831580282385367 threshold: 5.799999999999921\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.809999999999921\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.81999999999992\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.82999999999992\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.83999999999992\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.84999999999992\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.8599999999999195\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.869999999999919\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.879999999999919\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.889999999999919\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.899999999999919\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.909999999999918\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.919999999999918\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.929999999999918\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.939999999999918\n",
      "accuracy: 0.983306115042642 f1_score: 0.9833430699501137 threshold: 5.949999999999918\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 5.959999999999917\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 5.969999999999917\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 5.979999999999917\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 5.989999999999917\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 5.9999999999999165\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.009999999999916\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.019999999999916\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.029999999999916\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.039999999999916\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.0499999999999154\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.059999999999915\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.069999999999915\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.079999999999915\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.089999999999915\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.099999999999914\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.109999999999914\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.119999999999914\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.129999999999914\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.1399999999999135\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.149999999999913\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983528106861788 threshold: 6.159999999999913\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.169999999999913\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.179999999999913\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.1899999999999125\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.199999999999912\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.209999999999912\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.219999999999912\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837097186175422 threshold: 6.229999999999912\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.239999999999911\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.249999999999911\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.259999999999911\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.269999999999911\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.2799999999999105\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.28999999999991\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.29999999999991\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.30999999999991\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.31999999999991\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.3299999999999095\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.339999999999909\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.349999999999909\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.359999999999909\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.369999999999909\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.379999999999908\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.389999999999908\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.399999999999908\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.409999999999908\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.419999999999908\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.429999999999907\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.439999999999907\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.449999999999907\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.459999999999907\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.4699999999999065\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.479999999999906\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.489999999999906\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.499999999999906\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.509999999999906\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.519999999999905\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.529999999999905\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.539999999999905\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.549999999999905\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.559999999999905\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.569999999999904\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.579999999999904\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.589999999999904\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.599999999999904\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.6099999999999035\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.619999999999903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.629999999999903\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.639999999999903\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.649999999999903\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.659999999999902\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.669999999999902\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.679999999999902\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.689999999999902\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.699999999999902\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.709999999999901\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.719999999999901\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.729999999999901\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.739999999999901\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.7499999999999005\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.7599999999999\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.7699999999999\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.7799999999999\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.7899999999999\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.7999999999998995\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.809999999999899\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.819999999999899\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.829999999999899\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.839999999999899\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.849999999999898\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.859999999999898\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835269301296552 threshold: 6.869999999999898\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835315002264602 threshold: 6.879999999999898\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835315002264602 threshold: 6.8899999999998975\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835315002264602 threshold: 6.899999999999897\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835315002264602 threshold: 6.909999999999897\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.919999999999897\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.929999999999897\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.9399999999998965\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.949999999999896\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.959999999999896\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.969999999999896\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.979999999999896\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.989999999999895\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 6.999999999999895\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.009999999999895\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.019999999999895\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.0299999999998946\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.039999999999894\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.049999999999894\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.059999999999894\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.069999999999894\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.0799999999998935\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.089999999999893\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.099999999999893\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.109999999999893\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.119999999999893\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.129999999999892\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.139999999999892\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.149999999999892\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.159999999999892\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.169999999999892\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.179999999999891\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.189999999999891\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.199999999999891\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.209999999999891\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.2199999999998905\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.22999999999989\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.23999999999989\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.24999999999989\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.25999999999989\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.269999999999889\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.279999999999889\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.289999999999889\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.299999999999889\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.309999999999889\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.319999999999888\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.329999999999888\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.339999999999888\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.349999999999888\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.3599999999998875\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.369999999999887\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.379999999999887\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837119605206566 threshold: 7.389999999999887\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.399999999999887\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.4099999999998865\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.419999999999886\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.429999999999886\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.439999999999886\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.449999999999886\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.459999999999885\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.469999999999885\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.479999999999885\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.489999999999885\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.4999999999998845\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.509999999999884\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.519999999999884\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.529999999999884\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.539999999999884\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.5499999999998835\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.559999999999883\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.569999999999883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.579999999999883\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.589999999999883\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.599999999999882\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.609999999999882\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.619999999999882\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.629999999999882\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.6399999999998816\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.649999999999881\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.659999999999881\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.669999999999881\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.679999999999881\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.6899999999998805\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.69999999999988\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.70999999999988\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.71999999999988\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.72999999999988\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.739999999999879\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.749999999999879\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.759999999999879\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.769999999999879\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.779999999999879\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.789999999999878\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.799999999999878\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.809999999999878\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.819999999999878\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.8299999999998775\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.839999999999877\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.849999999999877\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.859999999999877\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.869999999999877\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.879999999999876\n",
      "accuracy: 0.9838504808564689 f1_score: 0.983892409603532 threshold: 7.889999999999876\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.899999999999876\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.909999999999876\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.919999999999876\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.929999999999875\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.939999999999875\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.949999999999875\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.959999999999875\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.9699999999998745\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.979999999999874\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.989999999999874\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 7.999999999999874\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.009999999999874\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.019999999999873\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.029999999999873\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.039999999999873\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.049999999999873\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.059999999999873\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.069999999999872\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.079999999999872\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.089999999999872\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.099999999999872\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.109999999999872\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.119999999999871\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.129999999999871\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.139999999999871\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.14999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.15999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.16999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.17999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.18999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.19999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.20999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.21999999999987\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.229999999999869\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.239999999999869\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.249999999999869\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.259999999999868\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.269999999999868\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.279999999999868\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.289999999999868\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.299999999999867\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.309999999999867\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.319999999999867\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.329999999999867\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.339999999999867\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.349999999999866\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.359999999999866\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.369999999999866\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.379999999999866\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.389999999999866\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.399999999999865\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.409999999999865\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.419999999999865\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.429999999999865\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.439999999999864\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.449999999999864\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.459999999999864\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.469999999999864\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.479999999999864\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.489999999999863\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.499999999999863\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.509999999999863\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.519999999999863\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.529999999999863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.539999999999862\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.549999999999862\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.559999999999862\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.569999999999862\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.579999999999862\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.589999999999861\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.599999999999861\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.60999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.61999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.62999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.63999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.64999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.65999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.66999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.67999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.68999999999986\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.699999999999859\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.709999999999859\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.719999999999859\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.729999999999858\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.739999999999858\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.749999999999858\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.759999999999858\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.769999999999857\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.779999999999857\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.789999999999857\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.799999999999857\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.809999999999857\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.819999999999856\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.829999999999856\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.839999999999856\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.849999999999856\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.859999999999856\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.869999999999855\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.879999999999855\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.889999999999855\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.899999999999855\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.909999999999854\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.919999999999854\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.929999999999854\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.939999999999854\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.949999999999854\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.959999999999853\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.969999999999853\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.979999999999853\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.989999999999853\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 8.999999999999853\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.009999999999852\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.019999999999852\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.029999999999852\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.039999999999852\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.049999999999851\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.059999999999851\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.069999999999851\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.07999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.08999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.09999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.10999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.11999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.12999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.13999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.14999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.15999999999985\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.169999999999849\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.179999999999849\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.189999999999849\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.199999999999848\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.209999999999848\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.219999999999848\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.229999999999848\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.239999999999847\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.249999999999847\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.259999999999847\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.269999999999847\n",
      "accuracy: 0.9836690255851932 f1_score: 0.983713751637023 threshold: 9.279999999999847\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.289999999999846\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.299999999999846\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.309999999999846\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.319999999999846\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.329999999999846\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.339999999999845\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.349999999999845\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.359999999999845\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.369999999999845\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.379999999999844\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.389999999999844\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.399999999999844\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.409999999999844\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.419999999999844\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.429999999999843\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.439999999999843\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.449999999999843\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.459999999999843\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.469999999999843\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.479999999999842\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.489999999999842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.499999999999842\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.509999999999842\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.519999999999841\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.529999999999841\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.539999999999841\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.54999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.55999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.56999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.57999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.9835340095728721 threshold: 9.58999999999984\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837143289656295 threshold: 9.59999999999984\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837143289656295 threshold: 9.60999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.61999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.62999999999984\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.639999999999839\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.649999999999839\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.659999999999838\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.669999999999838\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.679999999999838\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.689999999999838\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.699999999999838\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.709999999999837\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.719999999999837\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.729999999999837\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.739999999999837\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.749999999999837\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.759999999999836\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.769999999999836\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.779999999999836\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.789999999999836\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.799999999999836\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.809999999999835\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.819999999999835\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.829999999999835\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.839999999999835\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.849999999999834\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.859999999999834\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.869999999999834\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.879999999999834\n",
      "accuracy: 0.9834875703139176 f1_score: 0.983532914762334 threshold: 9.889999999999834\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.899999999999833\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.909999999999833\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.919999999999833\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.929999999999833\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.939999999999833\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.949999999999832\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.959999999999832\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.969999999999832\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.979999999999832\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.989999999999831\n",
      "accuracy: 0.9836690255851932 f1_score: 0.9837176858710509 threshold: 9.999999999999831\n"
     ]
    }
   ],
   "source": [
    "validation_history = dict(accuracy=[], f1score=[], threshold=[])\n",
    "threshold = 0\n",
    "while (threshold < 10):    \n",
    "    c_predictions = final_prediction(X_validation, validation_predictions, threshold)\n",
    "    accuracy = accuracy_score(np.argmax(y_validation, 1), np.argmax(c_predictions, 1)) \n",
    "    f1score = f1_score(np.argmax(y_validation, 1), np.argmax(c_predictions, 1), average='weighted')\n",
    "    print(\"accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)\n",
    "    threshold += 0.01\n",
    "    validation_history['accuracy'].append(accuracy)\n",
    "    validation_history['f1score'].append(f1score)\n",
    "    validation_history['threshold'].append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2500f7253c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_vs_accuraccy(validation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.4099999999998865\n"
     ]
    }
   ],
   "source": [
    "threshold = validation_history['threshold'][validation_history['accuracy'].index(max(validation_history['accuracy']))]\n",
    "cnn_predictions = final_prediction(X_test, predictions, threshold)\n",
    "accuracy = accuracy_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1))\n",
    "f1score = f1_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1), average='weighted')\n",
    "print(\"final accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2500f660ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_report(cnn_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      1396\n",
      "          1       0.95      0.99      0.97      1378\n",
      "          2       1.00      1.00      1.00      1348\n",
      "          3       1.00      0.99      1.00      1317\n",
      "          4       1.00      0.99      0.99      1292\n",
      "          5       0.98      0.95      0.97      1395\n",
      "          6       0.99      0.97      0.98      1321\n",
      "\n",
      "avg / total       0.99      0.98      0.98      9447\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.01\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.02\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.03\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.04\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.05\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.060000000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.07\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.08\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.09\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.09999999999999999\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.10999999999999999\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.11999999999999998\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.12999999999999998\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.13999999999999999\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.15\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.16\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.17\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.18000000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.19000000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.20000000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.21000000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.22000000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.23000000000000007\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.24000000000000007\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.25000000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.26000000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.2700000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.2800000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.2900000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.3000000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.3100000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.3200000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.3300000000000001\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.34000000000000014\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.35000000000000014\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.36000000000000015\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.37000000000000016\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.38000000000000017\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.3900000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.4000000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.4100000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.4200000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.4300000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.4400000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.45000000000000023\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.46000000000000024\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.47000000000000025\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.48000000000000026\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.49000000000000027\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5000000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5100000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5200000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5300000000000002\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5400000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5500000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5600000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5700000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5800000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.5900000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6000000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6100000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6200000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6300000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6400000000000003\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6500000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6600000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6700000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6800000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.6900000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7000000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7100000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7200000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7300000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7400000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7500000000000004\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7600000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7700000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7800000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.7900000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8000000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8100000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8200000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8300000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8400000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8500000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8600000000000005\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8700000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8800000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.8900000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9000000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9100000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9200000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9300000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9400000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9500000000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9600000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9700000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9800000000000006\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 0.9900000000000007\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 1.0000000000000007\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 1.0100000000000007\n",
      "accuracy: 0.9869949189450762 f1_score: 0.987030901307773 threshold: 1.0200000000000007\n",
      "accuracy: 0.9870554076941689 f1_score: 0.9870905301382707 threshold: 1.0300000000000007\n",
      "accuracy: 0.9871158964432616 f1_score: 0.987150636164011 threshold: 1.0400000000000007\n",
      "accuracy: 0.9872368739414469 f1_score: 0.9872703903400731 threshold: 1.0500000000000007\n",
      "accuracy: 0.9873578514396323 f1_score: 0.9873906139276859 threshold: 1.0600000000000007\n",
      "accuracy: 0.9873578514396323 f1_score: 0.9873890813084045 threshold: 1.0700000000000007\n",
      "accuracy: 0.9874183401887249 f1_score: 0.9874487649932775 threshold: 1.0800000000000007\n",
      "accuracy: 0.9875393176869103 f1_score: 0.9875698702017686 threshold: 1.0900000000000007\n",
      "accuracy: 0.9875998064360029 f1_score: 0.987629550866759 threshold: 1.1000000000000008\n",
      "accuracy: 0.9875998064360029 f1_score: 0.987629550866759 threshold: 1.1100000000000008\n",
      "accuracy: 0.9877207839341883 f1_score: 0.9877498315877627 threshold: 1.1200000000000008\n",
      "accuracy: 0.9879022501814663 f1_score: 0.9879310652786614 threshold: 1.1300000000000008\n",
      "accuracy: 0.987962738930559 f1_score: 0.987990778122712 threshold: 1.1400000000000008\n",
      "accuracy: 0.9880232276796516 f1_score: 0.9880517268709135 threshold: 1.1500000000000008\n",
      "accuracy: 0.9880837164287443 f1_score: 0.9881118719415498 threshold: 1.1600000000000008\n",
      "accuracy: 0.9882046939269296 f1_score: 0.9882335609016932 threshold: 1.1700000000000008\n",
      "accuracy: 0.9882046939269296 f1_score: 0.9882335609016932 threshold: 1.1800000000000008\n",
      "accuracy: 0.9882046939269296 f1_score: 0.9882335609016932 threshold: 1.1900000000000008\n",
      "accuracy: 0.9882651826760223 f1_score: 0.9882936876962621 threshold: 1.2000000000000008\n",
      "accuracy: 0.9882651826760223 f1_score: 0.9882936876962621 threshold: 1.2100000000000009\n",
      "accuracy: 0.9882651826760223 f1_score: 0.9882936876962621 threshold: 1.2200000000000009\n",
      "accuracy: 0.988325671425115 f1_score: 0.9883538123405683 threshold: 1.2300000000000009\n",
      "accuracy: 0.9883861601742076 f1_score: 0.9884139348510407 threshold: 1.2400000000000009\n",
      "accuracy: 0.9883861601742076 f1_score: 0.9884139348510407 threshold: 1.2500000000000009\n",
      "accuracy: 0.988507137672393 f1_score: 0.9885341735361882 threshold: 1.260000000000001\n",
      "accuracy: 0.9886281151705782 f1_score: 0.9886554300083686 threshold: 1.270000000000001\n",
      "accuracy: 0.9887490926687637 f1_score: 0.9887778445902897 threshold: 1.280000000000001\n",
      "accuracy: 0.9887490926687637 f1_score: 0.9887778445902897 threshold: 1.290000000000001\n",
      "accuracy: 0.9889305589160416 f1_score: 0.988958984624806 threshold: 1.300000000000001\n",
      "accuracy: 0.9889305589160416 f1_score: 0.988958984624806 threshold: 1.310000000000001\n",
      "accuracy: 0.9889910476651342 f1_score: 0.9890187618353455 threshold: 1.320000000000001\n",
      "accuracy: 0.9890515364142269 f1_score: 0.9890788705712729 threshold: 1.330000000000001\n",
      "accuracy: 0.9891725139124123 f1_score: 0.9891997453154383 threshold: 1.340000000000001\n",
      "accuracy: 0.9892330026615049 f1_score: 0.9892606865814854 threshold: 1.350000000000001\n",
      "accuracy: 0.9894144689087829 f1_score: 0.9894406928312482 threshold: 1.360000000000001\n",
      "accuracy: 0.9894144689087829 f1_score: 0.9894406928312482 threshold: 1.370000000000001\n",
      "accuracy: 0.9894749576578756 f1_score: 0.9895008064681513 threshold: 1.380000000000001\n",
      "accuracy: 0.9895354464069683 f1_score: 0.989560918159638 threshold: 1.390000000000001\n",
      "accuracy: 0.9895354464069683 f1_score: 0.989560918159638 threshold: 1.400000000000001\n",
      "accuracy: 0.9897169126542463 f1_score: 0.9897417757260603 threshold: 1.410000000000001\n",
      "accuracy: 0.9897169126542463 f1_score: 0.9897417757260603 threshold: 1.420000000000001\n",
      "accuracy: 0.989777401403339 f1_score: 0.9898015924780488 threshold: 1.430000000000001\n",
      "accuracy: 0.989777401403339 f1_score: 0.9898015924780488 threshold: 1.440000000000001\n",
      "accuracy: 0.9898378901524316 f1_score: 0.9898617243966713 threshold: 1.450000000000001\n",
      "accuracy: 0.9898983789015243 f1_score: 0.9899218544306915 threshold: 1.460000000000001\n",
      "accuracy: 0.989958867650617 f1_score: 0.9899819825965485 threshold: 1.470000000000001\n",
      "accuracy: 0.989958867650617 f1_score: 0.9899819825965485 threshold: 1.480000000000001\n",
      "accuracy: 0.9900798451488023 f1_score: 0.9901030138856111 threshold: 1.490000000000001\n",
      "accuracy: 0.9902008226469876 f1_score: 0.9902244108315195 threshold: 1.500000000000001\n",
      "accuracy: 0.990321800145173 f1_score: 0.990345426204995 threshold: 1.5100000000000011\n",
      "accuracy: 0.990321800145173 f1_score: 0.990345426204995 threshold: 1.5200000000000011\n",
      "accuracy: 0.990321800145173 f1_score: 0.990345426204995 threshold: 1.5300000000000011\n",
      "accuracy: 0.990321800145173 f1_score: 0.990345426204995 threshold: 1.5400000000000011\n",
      "accuracy: 0.990321800145173 f1_score: 0.990345426204995 threshold: 1.5500000000000012\n",
      "accuracy: 0.990321800145173 f1_score: 0.990345426204995 threshold: 1.5600000000000012\n",
      "accuracy: 0.9903822888942657 f1_score: 0.9904055339260875 threshold: 1.5700000000000012\n",
      "accuracy: 0.9903822888942657 f1_score: 0.9904055339260875 threshold: 1.5800000000000012\n",
      "accuracy: 0.9903822888942657 f1_score: 0.9904055339260875 threshold: 1.5900000000000012\n",
      "accuracy: 0.9904427776433583 f1_score: 0.9904656398639413 threshold: 1.6000000000000012\n",
      "accuracy: 0.9904427776433583 f1_score: 0.9904656398639413 threshold: 1.6100000000000012\n",
      "accuracy: 0.990503266392451 f1_score: 0.9905257440349843 threshold: 1.6200000000000012\n",
      "accuracy: 0.990503266392451 f1_score: 0.9905257440349843 threshold: 1.6300000000000012\n",
      "accuracy: 0.9905637551415437 f1_score: 0.9905856409186187 threshold: 1.6400000000000012\n",
      "accuracy: 0.9905637551415437 f1_score: 0.9905856409186187 threshold: 1.6500000000000012\n",
      "accuracy: 0.9905637551415437 f1_score: 0.9905856409186187 threshold: 1.6600000000000013\n",
      "accuracy: 0.9906242438906363 f1_score: 0.9906447818698877 threshold: 1.6700000000000013\n",
      "accuracy: 0.9906242438906363 f1_score: 0.9906447818698877 threshold: 1.6800000000000013\n",
      "accuracy: 0.990684732639729 f1_score: 0.9907047015832618 threshold: 1.6900000000000013\n",
      "accuracy: 0.990684732639729 f1_score: 0.9907047015832618 threshold: 1.7000000000000013\n",
      "accuracy: 0.9908057101379143 f1_score: 0.9908245378186482 threshold: 1.7100000000000013\n",
      "accuracy: 0.9907452213888217 f1_score: 0.9907643758358993 threshold: 1.7200000000000013\n",
      "accuracy: 0.9907452213888217 f1_score: 0.9907643758358993 threshold: 1.7300000000000013\n",
      "accuracy: 0.9908057101379143 f1_score: 0.99082428039862 threshold: 1.7400000000000013\n",
      "accuracy: 0.990866198887007 f1_score: 0.9908844543720049 threshold: 1.7500000000000013\n",
      "accuracy: 0.9909266876360997 f1_score: 0.9909443699033658 threshold: 1.7600000000000013\n",
      "accuracy: 0.9909266876360997 f1_score: 0.9909443699033658 threshold: 1.7700000000000014\n",
      "accuracy: 0.9909266876360997 f1_score: 0.9909443699033658 threshold: 1.7800000000000014\n",
      "accuracy: 0.9909266876360997 f1_score: 0.9909443699033658 threshold: 1.7900000000000014\n",
      "accuracy: 0.9909266876360997 f1_score: 0.9909443699033658 threshold: 1.8000000000000014\n",
      "accuracy: 0.9909266876360997 f1_score: 0.9909443699033658 threshold: 1.8100000000000014\n",
      "accuracy: 0.991047665134285 f1_score: 0.9910648180699456 threshold: 1.8200000000000014\n",
      "accuracy: 0.9911686426324704 f1_score: 0.9911846707099391 threshold: 1.8300000000000014\n",
      "accuracy: 0.991229131381563 f1_score: 0.9912445955672565 threshold: 1.8400000000000014\n",
      "accuracy: 0.9912896201306557 f1_score: 0.9913049661080567 threshold: 1.8500000000000014\n",
      "accuracy: 0.9912896201306557 f1_score: 0.9913049661080567 threshold: 1.8600000000000014\n",
      "accuracy: 0.9912896201306557 f1_score: 0.9913049661080567 threshold: 1.8700000000000014\n",
      "accuracy: 0.9913501088797484 f1_score: 0.9913657567310858 threshold: 1.8800000000000014\n",
      "accuracy: 0.9914710863779337 f1_score: 0.9914867675707201 threshold: 1.8900000000000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9914710863779337 f1_score: 0.9914867675707201 threshold: 1.9000000000000015\n",
      "accuracy: 0.9915315751270264 f1_score: 0.9915475587919218 threshold: 1.9100000000000015\n",
      "accuracy: 0.9915315751270264 f1_score: 0.9915475587919218 threshold: 1.9200000000000015\n",
      "accuracy: 0.9915315751270264 f1_score: 0.9915475587919218 threshold: 1.9300000000000015\n",
      "accuracy: 0.9915315751270264 f1_score: 0.9915475587919218 threshold: 1.9400000000000015\n",
      "accuracy: 0.9915315751270264 f1_score: 0.9915475587919218 threshold: 1.9500000000000015\n",
      "accuracy: 0.9915920638761191 f1_score: 0.9916083502021587 threshold: 1.9600000000000015\n",
      "accuracy: 0.9916525526252117 f1_score: 0.9916685691442411 threshold: 1.9700000000000015\n",
      "accuracy: 0.9916525526252117 f1_score: 0.9916685691442411 threshold: 1.9800000000000015\n",
      "accuracy: 0.9916525526252117 f1_score: 0.9916685691442411 threshold: 1.9900000000000015\n",
      "accuracy: 0.9916525526252117 f1_score: 0.9916685691442411 threshold: 2.0000000000000013\n",
      "accuracy: 0.9917130413743044 f1_score: 0.9917297472544804 threshold: 2.010000000000001\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.020000000000001\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.0300000000000007\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.0400000000000005\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.0500000000000003\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.06\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.07\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.0799999999999996\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.0899999999999994\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.099999999999999\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.109999999999999\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.1199999999999988\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.1299999999999986\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.1399999999999983\n",
      "accuracy: 0.9917735301233971 f1_score: 0.9917899509053176 threshold: 2.149999999999998\n",
      "accuracy: 0.9918340188724897 f1_score: 0.9918501529543092 threshold: 2.159999999999998\n",
      "accuracy: 0.9918340188724897 f1_score: 0.9918501529543092 threshold: 2.1699999999999977\n",
      "accuracy: 0.9918340188724897 f1_score: 0.9918501529543092 threshold: 2.1799999999999975\n",
      "accuracy: 0.9918340188724897 f1_score: 0.9918501529543092 threshold: 2.1899999999999973\n",
      "accuracy: 0.9918945076215824 f1_score: 0.9919105379195914 threshold: 2.199999999999997\n",
      "accuracy: 0.9918945076215824 f1_score: 0.9919105379195914 threshold: 2.209999999999997\n",
      "accuracy: 0.9919549963706751 f1_score: 0.9919707386358616 threshold: 2.2199999999999966\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.2299999999999964\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.239999999999996\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.249999999999996\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.259999999999996\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.2699999999999956\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.2799999999999954\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.289999999999995\n",
      "accuracy: 0.9920154851197677 f1_score: 0.9920310341738623 threshold: 2.299999999999995\n",
      "accuracy: 0.9920759738688604 f1_score: 0.99209140691302 threshold: 2.3099999999999947\n",
      "accuracy: 0.9920759738688604 f1_score: 0.99209140691302 threshold: 2.3199999999999945\n",
      "accuracy: 0.9920759738688604 f1_score: 0.99209140691302 threshold: 2.3299999999999943\n",
      "accuracy: 0.9920759738688604 f1_score: 0.99209140691302 threshold: 2.339999999999994\n",
      "accuracy: 0.9921364626179531 f1_score: 0.9921522134144257 threshold: 2.349999999999994\n",
      "accuracy: 0.9921364626179531 f1_score: 0.9921522134144257 threshold: 2.3599999999999937\n",
      "accuracy: 0.9921364626179531 f1_score: 0.9921522134144257 threshold: 2.3699999999999934\n",
      "accuracy: 0.9921969513670458 f1_score: 0.9922124135307954 threshold: 2.3799999999999932\n",
      "accuracy: 0.9922574401161384 f1_score: 0.9922723465908808 threshold: 2.389999999999993\n",
      "accuracy: 0.9922574401161384 f1_score: 0.9922723465908808 threshold: 2.399999999999993\n",
      "accuracy: 0.9923179288652311 f1_score: 0.9923334951840279 threshold: 2.4099999999999926\n",
      "accuracy: 0.9923179288652311 f1_score: 0.9923334951840279 threshold: 2.4199999999999924\n",
      "accuracy: 0.9923179288652311 f1_score: 0.9923334951840279 threshold: 2.429999999999992\n",
      "accuracy: 0.9923784176143238 f1_score: 0.9923934275186731 threshold: 2.439999999999992\n",
      "accuracy: 0.9923784176143238 f1_score: 0.9923934275186731 threshold: 2.4499999999999917\n",
      "accuracy: 0.9923784176143238 f1_score: 0.9923934275186731 threshold: 2.4599999999999915\n",
      "accuracy: 0.9923784176143238 f1_score: 0.9923934275186731 threshold: 2.4699999999999913\n",
      "accuracy: 0.9924389063634164 f1_score: 0.9924533589927615 threshold: 2.479999999999991\n",
      "accuracy: 0.9924389063634164 f1_score: 0.9924533589927615 threshold: 2.489999999999991\n",
      "accuracy: 0.9924993951125091 f1_score: 0.9925145069046497 threshold: 2.4999999999999907\n",
      "accuracy: 0.9924993951125091 f1_score: 0.9925145069046497 threshold: 2.5099999999999905\n",
      "accuracy: 0.9924993951125091 f1_score: 0.9925145069046497 threshold: 2.5199999999999902\n",
      "accuracy: 0.9925598838616018 f1_score: 0.9925744376737058 threshold: 2.52999999999999\n",
      "accuracy: 0.9925598838616018 f1_score: 0.9925744376737058 threshold: 2.53999999999999\n",
      "accuracy: 0.9925598838616018 f1_score: 0.9925744376737058 threshold: 2.5499999999999896\n",
      "accuracy: 0.9925598838616018 f1_score: 0.9925744376737058 threshold: 2.5599999999999894\n",
      "accuracy: 0.9925598838616018 f1_score: 0.9925744376737058 threshold: 2.569999999999989\n",
      "accuracy: 0.9926203726106944 f1_score: 0.9926346573314412 threshold: 2.579999999999989\n",
      "accuracy: 0.9926203726106944 f1_score: 0.9926346573314412 threshold: 2.5899999999999888\n",
      "accuracy: 0.9926808613597871 f1_score: 0.9926950576344984 threshold: 2.5999999999999885\n",
      "accuracy: 0.9926808613597871 f1_score: 0.9926950576344984 threshold: 2.6099999999999883\n",
      "accuracy: 0.9926808613597871 f1_score: 0.9926950576344984 threshold: 2.619999999999988\n",
      "accuracy: 0.9926808613597871 f1_score: 0.9926950576344984 threshold: 2.629999999999988\n",
      "accuracy: 0.9927413501088798 f1_score: 0.9927552760185915 threshold: 2.6399999999999877\n",
      "accuracy: 0.9927413501088798 f1_score: 0.9927552760185915 threshold: 2.6499999999999875\n",
      "accuracy: 0.9927413501088798 f1_score: 0.9927552760185915 threshold: 2.6599999999999873\n",
      "accuracy: 0.9927413501088798 f1_score: 0.9927552760185915 threshold: 2.669999999999987\n",
      "accuracy: 0.9927413501088798 f1_score: 0.9927552760185915 threshold: 2.679999999999987\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.6899999999999866\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.6999999999999864\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.709999999999986\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.719999999999986\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.7299999999999858\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.7399999999999856\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.7499999999999853\n",
      "accuracy: 0.9928018388579725 f1_score: 0.9928164085686146 threshold: 2.759999999999985\n",
      "accuracy: 0.992862327607065 f1_score: 0.9928763632167522 threshold: 2.769999999999985\n",
      "accuracy: 0.992862327607065 f1_score: 0.9928763632167522 threshold: 2.7799999999999847\n",
      "accuracy: 0.992862327607065 f1_score: 0.9928763632167522 threshold: 2.7899999999999845\n",
      "accuracy: 0.992862327607065 f1_score: 0.9928763632167522 threshold: 2.7999999999999843\n",
      "accuracy: 0.9929228163561578 f1_score: 0.9929374949786912 threshold: 2.809999999999984\n",
      "accuracy: 0.9929228163561578 f1_score: 0.9929374949786912 threshold: 2.819999999999984\n",
      "accuracy: 0.9929833051052505 f1_score: 0.9929976968242434 threshold: 2.8299999999999836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9929833051052505 f1_score: 0.9929976968242434 threshold: 2.8399999999999834\n",
      "accuracy: 0.9929833051052505 f1_score: 0.9929976968242434 threshold: 2.849999999999983\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.859999999999983\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.869999999999983\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.8799999999999826\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.8899999999999824\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.899999999999982\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.909999999999982\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.9199999999999817\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.9299999999999815\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.9399999999999813\n",
      "accuracy: 0.993043793854343 f1_score: 0.9930578972244001 threshold: 2.949999999999981\n",
      "accuracy: 0.9931042826034358 f1_score: 0.9931180961956273 threshold: 2.959999999999981\n",
      "accuracy: 0.9931042826034358 f1_score: 0.9931180961956273 threshold: 2.9699999999999807\n",
      "accuracy: 0.9931042826034358 f1_score: 0.9931180961956273 threshold: 2.9799999999999804\n",
      "accuracy: 0.9931042826034358 f1_score: 0.9931180961956273 threshold: 2.9899999999999802\n",
      "accuracy: 0.9931647713525285 f1_score: 0.9931788411140285 threshold: 2.99999999999998\n"
     ]
    }
   ],
   "source": [
    "train_history = dict(accuracy=[], f1score=[], threshold=[])\n",
    "threshold = 0\n",
    "while (threshold < 3):    \n",
    "    cnn_predictions = final_prediction(X_train, train_predictions, threshold)\n",
    "    accuracy = accuracy_score(np.argmax(y_train, 1), np.argmax(cnn_predictions, 1)) \n",
    "    f1score = f1_score(np.argmax(y_train, 1), np.argmax(cnn_predictions, 1), average='weighted')\n",
    "    print(\"accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)\n",
    "    threshold += 0.01\n",
    "    train_history['accuracy'].append(accuracy)\n",
    "    train_history['f1score'].append(f1score)\n",
    "    train_history['threshold'].append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2518e3b2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_vs_accuraccy(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.01\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.02\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.03\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.04\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.05\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.060000000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.07\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.08\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.09\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.09999999999999999\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.10999999999999999\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.11999999999999998\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.12999999999999998\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.13999999999999999\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.15\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.16\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.17\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.18000000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.19000000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.20000000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.21000000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.22000000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.23000000000000007\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.24000000000000007\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.25000000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.26000000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.2700000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.2800000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.2900000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.3000000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.3100000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.3200000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.3300000000000001\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.34000000000000014\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.35000000000000014\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.36000000000000015\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.37000000000000016\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.38000000000000017\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.3900000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.4000000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.4100000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.4200000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.4300000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.4400000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.45000000000000023\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.46000000000000024\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.47000000000000025\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.48000000000000026\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.49000000000000027\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5000000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5100000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5200000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5300000000000002\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5400000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5500000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5600000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5700000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5800000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.5900000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6000000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6100000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6200000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6300000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6400000000000003\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6500000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6600000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6700000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6800000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.6900000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7000000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7100000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7200000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7300000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7400000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7500000000000004\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7600000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7700000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7800000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.7900000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8000000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8100000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8200000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8300000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8400000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8500000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8600000000000005\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8700000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8800000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.8900000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9000000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9100000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9200000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9300000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9400000000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9500000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9600000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9700000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9800000000000006\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 0.9900000000000007\n",
      "accuracy: 0.9805229173282524 f1_score: 0.9805523596551696 threshold: 1.0000000000000007\n",
      "accuracy: 0.9806287710384249 f1_score: 0.9806577880414526 threshold: 1.0100000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807633501197365 threshold: 1.0200000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807633501197365 threshold: 1.0300000000000007\n",
      "accuracy: 0.9806287710384249 f1_score: 0.9806577880414526 threshold: 1.0400000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807665994547748 threshold: 1.0500000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807665994547748 threshold: 1.0600000000000007\n",
      "accuracy: 0.9806287710384249 f1_score: 0.9806600789444997 threshold: 1.0700000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807649597907925 threshold: 1.0800000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807649597907925 threshold: 1.0900000000000007\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807649597907925 threshold: 1.1000000000000008\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807649597907925 threshold: 1.1100000000000008\n",
      "accuracy: 0.98084047845877 f1_score: 0.9808687825809519 threshold: 1.1200000000000008\n",
      "accuracy: 0.98084047845877 f1_score: 0.9808687825809519 threshold: 1.1300000000000008\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807632189481753 threshold: 1.1400000000000008\n",
      "accuracy: 0.9807346247485974 f1_score: 0.9807632189481753 threshold: 1.1500000000000008\n",
      "accuracy: 0.98084047845877 f1_score: 0.9808669996797903 threshold: 1.1600000000000008\n",
      "accuracy: 0.9809463321689426 f1_score: 0.9809752988552144 threshold: 1.1700000000000008\n",
      "accuracy: 0.9809463321689426 f1_score: 0.9809752988552144 threshold: 1.1800000000000008\n",
      "accuracy: 0.98084047845877 f1_score: 0.9808697333583564 threshold: 1.1900000000000008\n",
      "accuracy: 0.98084047845877 f1_score: 0.9808697333583564 threshold: 1.2000000000000008\n",
      "accuracy: 0.9809463321689426 f1_score: 0.9809752988552144 threshold: 1.2100000000000009\n",
      "accuracy: 0.9809463321689426 f1_score: 0.9809720842577214 threshold: 1.2200000000000009\n",
      "accuracy: 0.9809463321689426 f1_score: 0.9809720842577214 threshold: 1.2300000000000009\n",
      "accuracy: 0.981052185879115 f1_score: 0.981077676725371 threshold: 1.2400000000000009\n",
      "accuracy: 0.9811580395892876 f1_score: 0.9811864079880123 threshold: 1.2500000000000009\n",
      "accuracy: 0.9811580395892876 f1_score: 0.9811864079880123 threshold: 1.260000000000001\n",
      "accuracy: 0.9811580395892876 f1_score: 0.9811864079880123 threshold: 1.270000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981397488517532 threshold: 1.280000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981397488517532 threshold: 1.290000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981397488517532 threshold: 1.300000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981397488517532 threshold: 1.310000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981397488517532 threshold: 1.320000000000001\n",
      "accuracy: 0.9812638932994602 f1_score: 0.9812888401530909 threshold: 1.330000000000001\n",
      "accuracy: 0.9812638932994602 f1_score: 0.9812888401530909 threshold: 1.340000000000001\n",
      "accuracy: 0.9812638932994602 f1_score: 0.9812888401530909 threshold: 1.350000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.9813927494309472 threshold: 1.360000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.9813927494309472 threshold: 1.370000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.9813927494309472 threshold: 1.380000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.9813927494309472 threshold: 1.390000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.400000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.410000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.420000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.430000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.440000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.450000000000001\n",
      "accuracy: 0.9812638932994602 f1_score: 0.9812845692656061 threshold: 1.460000000000001\n",
      "accuracy: 0.9812638932994602 f1_score: 0.9812845692656061 threshold: 1.470000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.480000000000001\n",
      "accuracy: 0.9812638932994602 f1_score: 0.9812845692656061 threshold: 1.490000000000001\n",
      "accuracy: 0.9813697470096326 f1_score: 0.981390214430621 threshold: 1.500000000000001\n",
      "accuracy: 0.9814756007198052 f1_score: 0.9814958526516323 threshold: 1.5100000000000011\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.5200000000000011\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.5300000000000011\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.5400000000000011\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.5500000000000012\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.5600000000000012\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.5700000000000012\n",
      "accuracy: 0.9816873081401503 f1_score: 0.9817054892790771 threshold: 1.5800000000000012\n",
      "accuracy: 0.9816873081401503 f1_score: 0.9817054892790771 threshold: 1.5900000000000012\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.6000000000000012\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.6100000000000012\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.6200000000000012\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815998233817821 threshold: 1.6300000000000012\n",
      "accuracy: 0.9814756007198052 f1_score: 0.9814934225938818 threshold: 1.6400000000000012\n",
      "accuracy: 0.9814756007198052 f1_score: 0.9814934225938818 threshold: 1.6500000000000012\n",
      "accuracy: 0.9814756007198052 f1_score: 0.9814934225938818 threshold: 1.6600000000000013\n",
      "accuracy: 0.9814756007198052 f1_score: 0.9814934225938818 threshold: 1.6700000000000013\n",
      "accuracy: 0.9815814544299778 f1_score: 0.9815990866972155 threshold: 1.6800000000000013\n",
      "accuracy: 0.9816873081401503 f1_score: 0.9817047440729162 threshold: 1.6900000000000013\n",
      "accuracy: 0.9816873081401503 f1_score: 0.9817047440729162 threshold: 1.7000000000000013\n",
      "accuracy: 0.9816873081401503 f1_score: 0.9817047440729162 threshold: 1.7100000000000013\n",
      "accuracy: 0.9816873081401503 f1_score: 0.9817047440729162 threshold: 1.7200000000000013\n",
      "accuracy: 0.9817931618503228 f1_score: 0.981808818527919 threshold: 1.7300000000000013\n",
      "accuracy: 0.9817931618503228 f1_score: 0.981808818527919 threshold: 1.7400000000000013\n",
      "accuracy: 0.9817931618503228 f1_score: 0.981808818527919 threshold: 1.7500000000000013\n",
      "accuracy: 0.9817931618503228 f1_score: 0.981808818527919 threshold: 1.7600000000000013\n",
      "accuracy: 0.9818990155604954 f1_score: 0.9819145039056748 threshold: 1.7700000000000014\n",
      "accuracy: 0.9818990155604954 f1_score: 0.9819145039056748 threshold: 1.7800000000000014\n",
      "accuracy: 0.9817931618503228 f1_score: 0.981808818527919 threshold: 1.7900000000000014\n",
      "accuracy: 0.9817931618503228 f1_score: 0.981808818527919 threshold: 1.8000000000000014\n",
      "accuracy: 0.9818990155604954 f1_score: 0.9819145039056748 threshold: 1.8100000000000014\n",
      "accuracy: 0.9818990155604954 f1_score: 0.9819145039056748 threshold: 1.8200000000000014\n",
      "accuracy: 0.982004869270668 f1_score: 0.9820186057959548 threshold: 1.8300000000000014\n",
      "accuracy: 0.982004869270668 f1_score: 0.9820186057959548 threshold: 1.8400000000000014\n",
      "accuracy: 0.982004869270668 f1_score: 0.9820186057959548 threshold: 1.8500000000000014\n",
      "accuracy: 0.9821107229808405 f1_score: 0.982124319367284 threshold: 1.8600000000000014\n",
      "accuracy: 0.982216576691013 f1_score: 0.982230026529517 threshold: 1.8700000000000014\n",
      "accuracy: 0.982216576691013 f1_score: 0.982230026529517 threshold: 1.8800000000000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.982216576691013 f1_score: 0.982230026529517 threshold: 1.8900000000000015\n",
      "accuracy: 0.982216576691013 f1_score: 0.982230026529517 threshold: 1.9000000000000015\n",
      "accuracy: 0.982216576691013 f1_score: 0.982230026529517 threshold: 1.9100000000000015\n",
      "accuracy: 0.9821107229808405 f1_score: 0.9821246077323472 threshold: 1.9200000000000015\n",
      "accuracy: 0.9821107229808405 f1_score: 0.9821246077323472 threshold: 1.9300000000000015\n",
      "accuracy: 0.9821107229808405 f1_score: 0.9821246077323472 threshold: 1.9400000000000015\n",
      "accuracy: 0.982216576691013 f1_score: 0.9822295282738431 threshold: 1.9500000000000015\n",
      "accuracy: 0.982216576691013 f1_score: 0.9822295282738431 threshold: 1.9600000000000015\n",
      "accuracy: 0.982216576691013 f1_score: 0.9822295282738431 threshold: 1.9700000000000015\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 1.9800000000000015\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 1.9900000000000015\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 2.0000000000000013\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 2.010000000000001\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 2.020000000000001\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 2.0300000000000007\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 2.0400000000000005\n",
      "accuracy: 0.9823224304011856 f1_score: 0.9823352308210087 threshold: 2.0500000000000003\n",
      "accuracy: 0.9824282841113581 f1_score: 0.9824394289538491 threshold: 2.06\n",
      "accuracy: 0.9824282841113581 f1_score: 0.9824394289538491 threshold: 2.07\n",
      "accuracy: 0.9825341378215307 f1_score: 0.9825451601074419 threshold: 2.0799999999999996\n",
      "accuracy: 0.9825341378215307 f1_score: 0.9825451601074419 threshold: 2.0899999999999994\n",
      "accuracy: 0.9825341378215307 f1_score: 0.9825451601074419 threshold: 2.099999999999999\n",
      "accuracy: 0.9825341378215307 f1_score: 0.9825451601074419 threshold: 2.109999999999999\n",
      "accuracy: 0.9825341378215307 f1_score: 0.9825451601074419 threshold: 2.1199999999999988\n",
      "accuracy: 0.9826399915317032 f1_score: 0.9826508851180242 threshold: 2.1299999999999986\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.1399999999999983\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.149999999999998\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.159999999999998\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.1699999999999977\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.1799999999999975\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.1899999999999973\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.199999999999997\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.209999999999997\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.2199999999999966\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.2299999999999964\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.239999999999996\n",
      "accuracy: 0.9827458452418757 f1_score: 0.982756604067459 threshold: 2.249999999999996\n",
      "accuracy: 0.9828516989520483 f1_score: 0.9828623170375962 threshold: 2.259999999999996\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.2699999999999956\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.2799999999999954\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.289999999999995\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.299999999999995\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.3099999999999947\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.3199999999999945\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.3299999999999943\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.339999999999994\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.349999999999994\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.3599999999999937\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.3699999999999934\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.3799999999999932\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.389999999999993\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.399999999999993\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.4099999999999926\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830737253673115 threshold: 2.4199999999999924\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.429999999999992\n",
      "accuracy: 0.9829575526622208 f1_score: 0.9829680241102724 threshold: 2.439999999999992\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.4499999999999917\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.4599999999999915\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.4699999999999913\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.479999999999991\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.489999999999991\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.4999999999999907\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.5099999999999905\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.5199999999999902\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.52999999999999\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.53999999999999\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.5499999999999896\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.5599999999999894\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.569999999999989\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.579999999999989\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.5899999999999888\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.5999999999999885\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.6099999999999883\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.619999999999988\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.629999999999988\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.6399999999999877\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.6499999999999875\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.6599999999999873\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.669999999999987\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.679999999999987\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.6899999999999866\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.6999999999999864\n",
      "accuracy: 0.9830634063723933 f1_score: 0.9830761415745146 threshold: 2.709999999999986\n",
      "accuracy: 0.9831692600825659 f1_score: 0.9831842580209127 threshold: 2.719999999999986\n",
      "accuracy: 0.9831692600825659 f1_score: 0.9831842580209127 threshold: 2.7299999999999858\n",
      "accuracy: 0.9831692600825659 f1_score: 0.9831842580209127 threshold: 2.7399999999999856\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.7499999999999853\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.759999999999985\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.769999999999985\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.7799999999999847\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.7899999999999845\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.7999999999999843\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.809999999999984\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.819999999999984\n",
      "accuracy: 0.9832751137927385 f1_score: 0.9832905939034743 threshold: 2.8299999999999836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9834868212130835 f1_score: 0.9835042924335897 threshold: 2.8399999999999834\n",
      "accuracy: 0.9834868212130835 f1_score: 0.9835042924335897 threshold: 2.849999999999983\n",
      "accuracy: 0.9834868212130835 f1_score: 0.9835042924335897 threshold: 2.859999999999983\n",
      "accuracy: 0.9834868212130835 f1_score: 0.9835042924335897 threshold: 2.869999999999983\n",
      "accuracy: 0.9834868212130835 f1_score: 0.9835042924335897 threshold: 2.8799999999999826\n",
      "accuracy: 0.9835926749232561 f1_score: 0.9836123689162285 threshold: 2.8899999999999824\n",
      "accuracy: 0.9835926749232561 f1_score: 0.9836123689162285 threshold: 2.899999999999982\n",
      "accuracy: 0.9835926749232561 f1_score: 0.9836123689162285 threshold: 2.909999999999982\n",
      "accuracy: 0.9839102360537737 f1_score: 0.9839289551126817 threshold: 2.9199999999999817\n",
      "accuracy: 0.9839102360537737 f1_score: 0.9839289551126817 threshold: 2.9299999999999815\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.9399999999999813\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.949999999999981\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.959999999999981\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.9699999999999807\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.9799999999999804\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.9899999999999802\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 2.99999999999998\n",
      "accuracy: 0.9840160897639463 f1_score: 0.9840344730820112 threshold: 3.00999999999998\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.0199999999999796\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.0299999999999794\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.039999999999979\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.049999999999979\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.0599999999999787\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.0699999999999785\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.0799999999999783\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.089999999999978\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.099999999999978\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.1099999999999777\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.1199999999999775\n",
      "accuracy: 0.9842277971842913 f1_score: 0.9842463314749953 threshold: 3.1299999999999772\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.139999999999977\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.149999999999977\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.1599999999999766\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.1699999999999764\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.179999999999976\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.189999999999976\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.1999999999999758\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.2099999999999755\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.2199999999999753\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.229999999999975\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.239999999999975\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.2499999999999747\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.2599999999999745\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.2699999999999743\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.279999999999974\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.289999999999974\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.2999999999999736\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843531836750309 threshold: 3.3099999999999734\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.319999999999973\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.329999999999973\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.3399999999999728\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.3499999999999726\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.3599999999999723\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.369999999999972\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.379999999999972\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.3899999999999717\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.3999999999999715\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.4099999999999713\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984245306799647 threshold: 3.419999999999971\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.429999999999971\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.4399999999999706\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.4499999999999704\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.45999999999997\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.46999999999997\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.47999999999997\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.4899999999999696\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.4999999999999694\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.509999999999969\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.519999999999969\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.5299999999999687\n",
      "accuracy: 0.9841219434741187 f1_score: 0.9841393405606863 threshold: 3.5399999999999685\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.5499999999999683\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.559999999999968\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.569999999999968\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.5799999999999677\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.5899999999999674\n",
      "accuracy: 0.9842277971842913 f1_score: 0.984244864117136 threshold: 3.5999999999999672\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844582606504092 threshold: 3.609999999999967\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844582606504092 threshold: 3.619999999999967\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845646797585375 threshold: 3.6299999999999666\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844591184032627 threshold: 3.6399999999999664\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844591184032627 threshold: 3.649999999999966\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843527002001494 threshold: 3.659999999999966\n",
      "accuracy: 0.9843336508944639 f1_score: 0.9843527002001494 threshold: 3.6699999999999657\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.6799999999999655\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.6899999999999653\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.699999999999965\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.709999999999965\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.7199999999999647\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.7299999999999645\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.7399999999999642\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.749999999999964\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.759999999999964\n",
      "accuracy: 0.9844395046046364 f1_score: 0.9844581715717282 threshold: 3.7699999999999636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.7799999999999634\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.789999999999963\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.799999999999963\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.8099999999999627\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.8199999999999625\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.8299999999999623\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.839999999999962\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.849999999999962\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.8599999999999617\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.8699999999999615\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.8799999999999613\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.889999999999961\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.899999999999961\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.9099999999999606\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 3.9199999999999604\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.92999999999996\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.93999999999996\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.9499999999999598\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.9599999999999596\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.9699999999999593\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.979999999999959\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.989999999999959\n",
      "accuracy: 0.9844395046046364 f1_score: 0.984457308625762 threshold: 3.9999999999999587\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.009999999999959\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.019999999999959\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.0299999999999585\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.039999999999958\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.049999999999958\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.059999999999958\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.069999999999958\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.079999999999957\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.089999999999957\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845637332357562 threshold: 4.099999999999957\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.109999999999957\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.119999999999957\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.129999999999956\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.139999999999956\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.149999999999956\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.159999999999956\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.1699999999999555\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.179999999999955\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.189999999999955\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.199999999999955\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.209999999999955\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.2199999999999545\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.229999999999954\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.239999999999954\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.249999999999954\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.259999999999954\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.269999999999953\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.279999999999953\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.289999999999953\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.299999999999953\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.3099999999999525\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.319999999999952\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.329999999999952\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.339999999999952\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.349999999999952\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.3599999999999515\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.369999999999951\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.379999999999951\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.389999999999951\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.399999999999951\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.40999999999995\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.41999999999995\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.42999999999995\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.43999999999995\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.4499999999999496\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.459999999999949\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.469999999999949\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846692007239436 threshold: 4.479999999999949\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.489999999999949\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.4999999999999485\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.509999999999948\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.519999999999948\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.529999999999948\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.539999999999948\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.549999999999947\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.559999999999947\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.569999999999947\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.579999999999947\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.589999999999947\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.599999999999946\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.609999999999946\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.619999999999946\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.629999999999946\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.6399999999999455\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.649999999999945\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.659999999999945\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.669999999999945\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.679999999999945\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.689999999999944\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845614032862487 threshold: 4.699999999999944\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.709999999999944\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.719999999999944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.729999999999944\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.739999999999943\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.749999999999943\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.759999999999943\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.769999999999943\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.7799999999999425\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.789999999999942\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.799999999999942\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.809999999999942\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.819999999999942\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.8299999999999415\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.839999999999941\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.849999999999941\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.859999999999941\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.869999999999941\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.87999999999994\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.88999999999994\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.89999999999994\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.90999999999994\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.9199999999999395\n",
      "accuracy: 0.9845453583148089 f1_score: 0.9845618853709707 threshold: 4.929999999999939\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.939999999999939\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.949999999999939\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.959999999999939\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.9699999999999385\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.979999999999938\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.989999999999938\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 4.999999999999938\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.009999999999938\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.019999999999937\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.029999999999937\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.039999999999937\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.049999999999937\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.0599999999999365\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.069999999999936\n",
      "accuracy: 0.9846512120249815 f1_score: 0.9846682682087844 threshold: 5.079999999999936\n",
      "accuracy: 0.984757065735154 f1_score: 0.9847737710370408 threshold: 5.089999999999936\n",
      "accuracy: 0.984757065735154 f1_score: 0.9847737710370408 threshold: 5.099999999999936\n",
      "accuracy: 0.984757065735154 f1_score: 0.9847737710370408 threshold: 5.1099999999999355\n",
      "accuracy: 0.984757065735154 f1_score: 0.9847737710370408 threshold: 5.119999999999935\n",
      "accuracy: 0.984757065735154 f1_score: 0.9847737710370408 threshold: 5.129999999999935\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.139999999999935\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.149999999999935\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.159999999999934\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.169999999999934\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.179999999999934\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.189999999999934\n",
      "accuracy: 0.9848629194453266 f1_score: 0.9848792688871938 threshold: 5.199999999999934\n",
      "accuracy: 0.9849687731554991 f1_score: 0.9849847618407997 threshold: 5.209999999999933\n",
      "accuracy: 0.9849687731554991 f1_score: 0.9849847618407997 threshold: 5.219999999999933\n",
      "accuracy: 0.9849687731554991 f1_score: 0.9849847618407997 threshold: 5.229999999999933\n",
      "accuracy: 0.9849687731554991 f1_score: 0.9849847618407997 threshold: 5.239999999999933\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.2499999999999325\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.259999999999932\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.269999999999932\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.279999999999932\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.289999999999932\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.299999999999931\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.309999999999931\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.319999999999931\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.329999999999931\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.339999999999931\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.34999999999993\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.35999999999993\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.36999999999993\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.37999999999993\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.3899999999999295\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.399999999999929\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.409999999999929\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.419999999999929\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.429999999999929\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.4399999999999284\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.449999999999928\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.459999999999928\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.469999999999928\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.479999999999928\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.489999999999927\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.499999999999927\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.509999999999927\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.519999999999927\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.5299999999999265\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.539999999999926\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.549999999999926\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.559999999999926\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.569999999999926\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.5799999999999255\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 5.589999999999925\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.599999999999925\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.609999999999925\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.619999999999925\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.629999999999924\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.639999999999924\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.649999999999924\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.659999999999924\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.6699999999999235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.679999999999923\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.689999999999923\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.699999999999923\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.709999999999923\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 5.7199999999999225\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.729999999999922\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.739999999999922\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.749999999999922\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.759999999999922\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.769999999999921\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.779999999999921\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.789999999999921\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.799999999999921\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.809999999999921\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.81999999999992\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.82999999999992\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.83999999999992\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.84999999999992\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.8599999999999195\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.869999999999919\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.879999999999919\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.889999999999919\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.899999999999919\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.909999999999918\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.919999999999918\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.929999999999918\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.939999999999918\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.949999999999918\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.959999999999917\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851947595906335 threshold: 5.969999999999917\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.979999999999917\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.989999999999917\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 5.9999999999999165\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 6.009999999999916\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 6.019999999999916\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 6.029999999999916\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 6.039999999999916\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 6.0499999999999154\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850884614267351 threshold: 6.059999999999915\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.069999999999915\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.079999999999915\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.089999999999915\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.099999999999914\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.109999999999914\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.119999999999914\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.129999999999914\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.1399999999999135\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.149999999999913\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.159999999999913\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.169999999999913\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.179999999999913\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.1899999999999125\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.199999999999912\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.209999999999912\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.219999999999912\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.229999999999912\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.239999999999911\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.249999999999911\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.259999999999911\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.269999999999911\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.2799999999999105\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.28999999999991\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.29999999999991\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.30999999999991\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.31999999999991\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.3299999999999095\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.339999999999909\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.349999999999909\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.359999999999909\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.369999999999909\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.379999999999908\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.389999999999908\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.399999999999908\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.409999999999908\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.419999999999908\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.429999999999907\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.439999999999907\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.449999999999907\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.459999999999907\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.4699999999999065\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.479999999999906\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.489999999999906\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.499999999999906\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.509999999999906\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.519999999999905\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.529999999999905\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.539999999999905\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.549999999999905\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.559999999999905\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.569999999999904\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.579999999999904\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.589999999999904\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.599999999999904\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.6099999999999035\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.619999999999903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.629999999999903\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.639999999999903\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.649999999999903\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.659999999999902\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.669999999999902\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.679999999999902\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.689999999999902\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.699999999999902\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.709999999999901\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.719999999999901\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.729999999999901\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.739999999999901\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.7499999999999005\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.7599999999999\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.7699999999999\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.7799999999999\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.7899999999999\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.7999999999998995\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.809999999999899\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.819999999999899\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984983868268796 threshold: 6.829999999999899\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 6.839999999999899\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850893966752579 threshold: 6.849999999999898\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851957377984686 threshold: 6.859999999999898\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851957377984686 threshold: 6.869999999999898\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851957377984686 threshold: 6.879999999999898\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851957377984686 threshold: 6.8899999999998975\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851957377984686 threshold: 6.899999999999897\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.909999999999897\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.919999999999897\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.929999999999897\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.9399999999998965\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.949999999999896\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.959999999999896\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.969999999999896\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.979999999999896\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.989999999999895\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 6.999999999999895\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.009999999999895\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.019999999999895\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.0299999999998946\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.039999999999894\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.049999999999894\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.059999999999894\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.069999999999894\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.0799999999998935\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.089999999999893\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.099999999999893\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.109999999999893\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.119999999999893\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.129999999999892\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.139999999999892\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.149999999999892\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.159999999999892\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.169999999999892\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.179999999999891\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.189999999999891\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.199999999999891\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.209999999999891\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.2199999999998905\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.22999999999989\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.23999999999989\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.24999999999989\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.25999999999989\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.269999999999889\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.279999999999889\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.289999999999889\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.299999999999889\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.309999999999889\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.319999999999888\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.329999999999888\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.339999999999888\n",
      "accuracy: 0.9850746268656716 f1_score: 0.985088017032513 threshold: 7.349999999999888\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.3599999999998875\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.369999999999887\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.379999999999887\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.389999999999887\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.399999999999887\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.4099999999998865\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.419999999999886\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.429999999999886\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.439999999999886\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.449999999999886\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.459999999999885\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.469999999999885\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.479999999999885\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.489999999999885\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.4999999999998845\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.509999999999884\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.519999999999884\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.529999999999884\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.539999999999884\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.5499999999998835\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.559999999999883\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.569999999999883\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.579999999999883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.589999999999883\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.599999999999882\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.609999999999882\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.619999999999882\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.629999999999882\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.6399999999998816\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.649999999999881\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.659999999999881\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.669999999999881\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.679999999999881\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.6899999999998805\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.69999999999988\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.70999999999988\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.71999999999988\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.72999999999988\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.739999999999879\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.749999999999879\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.759999999999879\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.769999999999879\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.779999999999879\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.789999999999878\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.799999999999878\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.809999999999878\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.819999999999878\n",
      "accuracy: 0.9849687731554991 f1_score: 0.984982446968162 threshold: 7.8299999999998775\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.839999999999877\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.849999999999877\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.859999999999877\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.869999999999877\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.879999999999876\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.889999999999876\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.899999999999876\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.909999999999876\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.919999999999876\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.929999999999875\n",
      "accuracy: 0.9850746268656716 f1_score: 0.9850887806068269 threshold: 7.939999999999875\n",
      "accuracy: 0.9851804805758442 f1_score: 0.9851943520045964 threshold: 7.949999999999875\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 7.959999999999875\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 7.9699999999998745\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 7.979999999999874\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 7.989999999999874\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 7.999999999999874\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.009999999999874\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.019999999999873\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.029999999999873\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.039999999999873\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.049999999999873\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.059999999999873\n",
      "accuracy: 0.9852863342860168 f1_score: 0.9853020749436064 threshold: 8.069999999999872\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.079999999999872\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.089999999999872\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.099999999999872\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.109999999999872\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.119999999999871\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.129999999999871\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.139999999999871\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.14999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.15999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.16999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.17999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.18999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.19999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.20999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.21999999999987\n",
      "accuracy: 0.9853921879961892 f1_score: 0.9854076011899018 threshold: 8.229999999999869\n",
      "accuracy: 0.9854980417063618 f1_score: 0.985512182156767 threshold: 8.239999999999869\n",
      "accuracy: 0.9854980417063618 f1_score: 0.985512182156767 threshold: 8.249999999999869\n",
      "accuracy: 0.9854980417063618 f1_score: 0.985512182156767 threshold: 8.259999999999868\n",
      "accuracy: 0.9854980417063618 f1_score: 0.985512182156767 threshold: 8.269999999999868\n",
      "accuracy: 0.9854980417063618 f1_score: 0.985512182156767 threshold: 8.279999999999868\n",
      "accuracy: 0.9854980417063618 f1_score: 0.985512182156767 threshold: 8.289999999999868\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.299999999999867\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.309999999999867\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.319999999999867\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.329999999999867\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.339999999999867\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.349999999999866\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.359999999999866\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.369999999999866\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.379999999999866\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.389999999999866\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.399999999999865\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.409999999999865\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.419999999999865\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.429999999999865\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.439999999999864\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.449999999999864\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.459999999999864\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.469999999999864\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.479999999999864\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.489999999999863\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.499999999999863\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.509999999999863\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.519999999999863\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.529999999999863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.539999999999862\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.549999999999862\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.559999999999862\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.569999999999862\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.579999999999862\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.589999999999861\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.599999999999861\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.60999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.61999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.62999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.63999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.64999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.65999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.66999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.67999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.68999999999986\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.699999999999859\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.709999999999859\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.719999999999859\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.729999999999858\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.739999999999858\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.749999999999858\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.759999999999858\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.769999999999857\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.779999999999857\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.789999999999857\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.799999999999857\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.809999999999857\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.819999999999856\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.829999999999856\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.839999999999856\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.849999999999856\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.859999999999856\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.869999999999855\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.879999999999855\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.889999999999855\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.899999999999855\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.909999999999854\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855100960187776 threshold: 8.919999999999854\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.929999999999854\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.939999999999854\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.949999999999854\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.959999999999853\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.969999999999853\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.979999999999853\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.989999999999853\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 8.999999999999853\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.009999999999852\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.019999999999852\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.029999999999852\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.039999999999852\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.049999999999851\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.059999999999851\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.069999999999851\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.07999999999985\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.08999999999985\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856152653874832 threshold: 9.09999999999985\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855097677345491 threshold: 9.10999999999985\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855097677345491 threshold: 9.11999999999985\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855097677345491 threshold: 9.12999999999985\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855097677345491 threshold: 9.13999999999985\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.14999999999985\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.15999999999985\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.169999999999849\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.179999999999849\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.189999999999849\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.199999999999848\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.209999999999848\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.219999999999848\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.229999999999848\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.239999999999847\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.249999999999847\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.259999999999847\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.269999999999847\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.279999999999847\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.289999999999846\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.299999999999846\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.309999999999846\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.319999999999846\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.329999999999846\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.339999999999845\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.349999999999845\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.359999999999845\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.369999999999845\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.379999999999844\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.389999999999844\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.399999999999844\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.409999999999844\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.419999999999844\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.429999999999843\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.439999999999843\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.449999999999843\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.459999999999843\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.469999999999843\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.479999999999842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.489999999999842\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.499999999999842\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.509999999999842\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.519999999999841\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.529999999999841\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.539999999999841\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.54999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.55999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.56999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.57999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.58999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.59999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.60999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.61999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.62999999999984\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.639999999999839\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.649999999999839\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.659999999999838\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.669999999999838\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.679999999999838\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.689999999999838\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.699999999999838\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.709999999999837\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.719999999999837\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.729999999999837\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.739999999999837\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.749999999999837\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.759999999999836\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.769999999999836\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.779999999999836\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.789999999999836\n",
      "accuracy: 0.9856038954165344 f1_score: 0.9856153616980299 threshold: 9.799999999999836\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.809999999999835\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.819999999999835\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.829999999999835\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.839999999999835\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.849999999999834\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.859999999999834\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.869999999999834\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.879999999999834\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.889999999999834\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.899999999999833\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.909999999999833\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.919999999999833\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.929999999999833\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.939999999999833\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.949999999999832\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.959999999999832\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.969999999999832\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.979999999999832\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.989999999999831\n",
      "accuracy: 0.9854980417063618 f1_score: 0.9855107112531057 threshold: 9.999999999999831\n"
     ]
    }
   ],
   "source": [
    "test_history = dict(accuracy=[], f1score=[], threshold=[])\n",
    "threshold = 0\n",
    "while (threshold < 10):    \n",
    "    cnn_predictions = final_prediction(X_test, predictions, threshold)\n",
    "    accuracy = accuracy_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1)) \n",
    "    f1score = f1_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1), average='weighted')\n",
    "    print(\"accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)\n",
    "    threshold += 0.01\n",
    "    test_history['accuracy'].append(accuracy)\n",
    "    test_history['f1score'].append(f1score)\n",
    "    test_history['threshold'].append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGgCAYAAACnqB1FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl8VNX9//HXZLJMQkhmIBCSQCABbTAgKFjE3bYGoSKgVrAVLdp+oWoV6Y9FDRbT8k2pSuWLRcXaloK0tEXRtlSLaCuIUlnEBRGUJRCWQDKTlUlm+/0xYXBMgCyT3Mzk/Xw85sHMuefe+cwoyZtzz73H5PP5fIiIiIhEkCijCxAREREJNQUcERERiTgKOCIiIhJxFHBEREQk4ijgiIiISMRRwBEREZGIo4AjIiIiEUcBR0RERCKOAo6IiIhEHAUcERERiTgKOCIiIhJxoo0uoL14vV4OHz5M165dMZlMRpcjIiIiTeDz+aisrCQ9PZ2oqKaPy3SagHP48GH69OljdBkiIiLSAgcPHqR3795N7t9pAk7Xrl0B/xeUlJRkcDUiIiLSFBUVFfTp0yfwe7ypOk3AOXVaKikpSQFHREQkzDR3eokmGYuIiEjEUcARERGRiKOAIyIiIhFHAUdEREQijgKOiIiIRBwFHBEREYk4CjgiIiIScRRwREREJOIo4IiIiEjEUcARERGRiKOAIyIiIhFHAUdEREQiTqdZbFNERKSjqnXX8qv3fsWxqmNn7NOjSw/uvuhunt3yLHanvR2r8xtz3hjy+ue1+/u2lAKOiIiIwV59fzkPrX/onP3+sfVPbCr/qB0qamjF5uc58dNqQ967JRRwREREDHb4v28CcEEJ3PhZw+3/OB8+SoVtpR9DNFxSDNd90T611UbDk5dBKTW4PC5izDHt88atpIAjIiJiMEdNKQBXutMpnPnbBturXv4fPqIIZ7QPgFHRX+Nnsxa1S22emiqe/PAWAOz2w/RM6dsu79taCjgiIiIGszsdEAU2ay8YNarBdtu/04Ci069T+zbary2YvV6S/gsVFnAcPxg2AUdXUYmIiBjMXlcOgC3O2uh2myW43ZrQvc1rCoiKwlbnjwv2E4fa731bSQFHRETEYA63f/KuNaFbo9ttXVKCXyemNNqvrdjc/hM+dvvhdn3f1tApKhEREWCffR8PvPYADqcDgN5JvbFEW9rlvd+PPQ6cObhYE1PgSxcw2ZJ7tUdZp9/fGwvUUbD7eX73181n7BcTFcOKm1a0X2FnoYAjIiICvPjmU/xt99+MefNY/x99rI3Pb+lj6wdfukVO7+5ZbV/Tl2S5u/Jvqni3ehfvfrLrjP3iPCYFHBERkY6k9OP/AjDhU7hlJxxKAl87vn9mOYz487hGt1087AaW/++D7LPCQLuZAVOvbcfKYIHlBkb87XnqzGfvZzaboaB9ajoXBRwRERHAXlsOcTAiZSjf/dUT7V9Anz5w/vmNbjINGMDtq/fAgQPQvz/0at9TVD1++WumvjcZ6urO3jGq40ztVcAREREB7O4qiANrehZ885tGl9PQgAH+hxFiYuDKK4157xbqOFFLRETEQA5vDdDwiiUJTwo4IiIigN3kBMCWlGpwJRIKOkUlIiKdxppda3jkzUeo8zScS7I/wX8dts3avvNbpG0o4IiISKex9J8/Z2fFzsY3RkFCHWSn5rRvUdImFHBERKTTKDv8OSTCgnVwRVHD7dknLXT7yUXtX5iEnAKOiIh0Gg5qARhx/Q+47MrbG3YYMAC6Nb5cgoQXBRwREek07NEuAGwXjYSrrza4GmlLuopKREQ6BZ/PhyPGA4C1W7rB1UhbU8AREZFO4aSrJrDUgK1nprHFSJvTKSoREYk4Xp+X7/zlO7x36L3TbV7/6I3ZC4kpGUaVJu1EAUdERCJOkeMAL336UqPbLj4CpqSkdq5I2psCjoiIRBz7Pv+9bnpUw+vLg7cNTL8QTCYDqpL2pIAjIiIRx1FaDEAPp5mL/vqf4I1DhhhQkbQ3BRwREYk4dscRAKy+WLj8coOrESPoKioREYk4jvISAGw+i8GViFEUcEREJOLYq04AYDXFG1yJGEWnqERE2sjaPWuZ9+95ja5c3c/ajz/e/EfiYzreL+A/f/JnHl7/MC6vi4EpA3n1tleJNccaXVazOGrKALBGJxpciRhFAUdEpI08/Wo+71dtb3TbjmM7eGfPer51wQ3tXNW5/eaf8/mi+gsAisqL2HFoK5f0HWlwVc3jqHVAFNhidDl4Z6VTVCIibaTsyF4AHnsL/vWH048Lj9Zv/+BdA6s7M/vR/cGvP9liTCGtYK+rAMBqsRpciRhFIzgiIm3EYfKvXH316Glcfc33A+39fjeKDynHUVliUGVn54jy1x3lBW8UOBxHDa6o+RyeKgBsXbQyeGelgCMi0kYc5vqVqwd/HUaMCLTbXkwCynFUlRpU2dmdqjvLAV90o8MGsbOxe08CYO2SYnAlYhSdohIRaQM+nw97bP3K1d2D1z2yxvgnvtpPlrV7Xefir9sLQFatfwJ0Rw1iZ+MwOQGwJacaXIkYRQFHRKQNOF0nT69c3aNP0DZbTDIAjtry9i7rnKrrqvDU/2bIMvlP73TEIHYu9vpRKKu1l8GViFF0ikpEOhWH08H4P43nUMWhFh9jePpwVt68kijT6X8jvrXvLR558xFqPf75K263/9LwKC8k9ugdtL813j/xdVXUp/x36TAAMrpmsOKmFSTFGXvVz0sfrAQgxgNpXVKBYn7v3sLbvw3N3YCT45JZPHox/bv1D8nxAD469hE/+sePqKitCLQdi3MDYO2mVcM7KwUcEelU3vroVf5z4D/n7ngWX9i/4OfXFDAg5fxA25JX8nm3vOFVUQNPgCkx+F4sAxOzoArsUbXYj2wDYNuRbaz7YDU3j5jSqtpa6423lwHgMkNO1yxgG0dN1Rw9uClk77Fy3ULmTvx16I73ryd55+A7wY1RYD0Jab0GhOx9JLwo4IhIp1K24z0ALi+Cx//V/P0nTIJjiWD/4mP4UsApPbQbusLsjXD1/tP9L+k5tMHK1dddMoktk56hpIv/dcHV8F6f+toMDjiO4wehC/zqNZj40GQy7l9NWYjuRbjiQlh9AZR9ujU0B6xX9tkHEAPf3w63f3i6/QJSsDzWL6TvJeGjRQFnyZIlPP744xw5coTc3Fyeeuoprrzyykb7ulwuCgsLWbZsGcXFxXzta19jwYIFXH/99YE+brebefPm8eKLL3L06FHS0tL4/ve/T35+PlFR/iHg73//+yxbtizo2CNGjOC9995ryUcQkU7q1C38s2J6MvKVfzZ7/x6/H8GxRDeO0sPBx8U/qfXqa77P6NE/Pr3hggsaHMN01VUMe+8AnPDX8sfnx/AexwK1GcnhrQEg45YpRN04jqsG7wW7PSTH/mz5VFazJXCPmlCxuyogBi4ecAXffHTR6Q39+0NcXEjfS8JHswPOqlWrmD59OkuWLOHyyy/nueeeY/To0ezcuZPMzMwG/fPz81mxYgXPP/88OTk5vP7660yYMIFNmzZx0UUXAbBgwQKeffZZli1bRm5uLlu2bGHKlCkkJyfzwAMPBI51/fXX87vf/S7wOjY2vG4dLiLGs9f4rwiyxtvg4oubvb/tt7GAG3t58L1hHFH+OTe2rw1p2nEzM/0PwBbfDTiG42RogkRr2OuvPgrMXcnK8j9CwPpaJri24HBXheR4pzi81f7jp2W16L+pRKZmX0W1cOFC7r77bn7wgx8wcOBAnnrqKfr06cMzzzzTaP/ly5fz8MMPM2bMGLKzs/nRj37EqFGjePLJJwN93n33XcaNG8e3v/1t+vXrxy233EJeXh5btgTfPTMuLo5evXoFHt266QZOItI8dqcDAFtsyybz2qi/dLoi+N4w9uj6e97Y0pt/zPpaTtVmpEBQa4Orj2yJ/nvS2OsDSajYff573ti69gzpcSW8NSvg1NXVsXXrVvLy8oLa8/Ly2LSp8QlotbW1WCzBy9XHx8ezcePGwOsrrriC9evXs3v3bgB27NjBxo0bGTNmTNB+//73v+nZsyfnn38+P/zhDykpOfPNp2pra6moqAh6iIg4XJUA2Fp4C39bVAIA9urTp5M8Xg/lcT7/9q9cEt6kY8bb/Md0Gf9zyh7jv3ePrQ2uPrIm+QOIg9qQHtdhqgs6vgg08xTViRMn8Hg8pKYG3zgpNTWVo0cbv5X3qFGjWLhwIVdddRX9+/dn/fr1vPLKK3g8nkCf2bNnU15eTk5ODmazGY/Hw/z587ntttsCfUaPHs13vvMd+vbty759+5g7dy7f+MY32Lp1K3GNnGMtLCzksccea87HE5EI5vF6yFuRx5uWPQDYErq36DinVqf+eeU/WPSkf7TGh+/09hYEHGtCN6iBNXH7SH+y+SNAoVQd4/8s1q9c2h4KtmT/qNCuhBoufi50p5L2J/gDk62bsd+ddCwtmmRs+soVAT6fr0HbKYsWLeKHP/whOTk5mEwm+vfvz5QpU4Lm0qxatYoVK1awcuVKcnNz+eCDD5g+fTrp6enceeedAEycODHQf9CgQQwfPpy+ffvyj3/8g5tuuqnB+z700EPMmDEj8LqiooI+fZr/g0dEIsMB+z7e3PcmALFuGG5tOPm3KYZHZwKfUkUdVVVHgrYNPgax3Zs/inCRbSBRVVAb5eXIV45phOwysPXsG/LjZvXKIW4b1Eb72H608VXWWyQKutRBn9Tzz91XOo1mBZyUlBTMZnOD0ZqSkpIGozqn9OjRgzVr1uB0OiktLSU9PZ05c+aQ9aVJazNnzmTOnDlMmjQJgMGDB3PgwAEKCwsDAeer0tLS6Nu3L3v27Gl0e1xcXKMjOyLSOTn2fRp4XvKkieRNY1t0nNsvvJ3L7n+dykaucfhar1xowcUPF44Yx6GfPEpJvO/cndvBgOR+RP2qZSNcZ5NywXB2TurKnpjKkB87x2Ml6eHckB9XwlezAk5sbCzDhg1j3bp1TJgwIdC+bt06xo0bd9Z9LRYLGRkZuFwuVq9eza233hrYVlNTE7gc/BSz2YzX6z3j8UpLSzl48CBpaWnN+Qgi0knZy4oByC2B5L2HoVcLJ9HefjvZl18OlY38kj6/hSMIgweT9tlh0s4yr7BdDRgAUW2wkk9yMtk7isguKgr9sfv2hS5dQn9cCVvNPkU1Y8YMJk+ezPDhwxk5ciRLly6lqKiIadOmAXDHHXeQkZFBYWEhAJs3b6a4uJihQ4dSXFzMvHnz8Hq9zJo1K3DMsWPHMn/+fDIzM8nNzWX79u0sXLiQu+66C4CqqirmzZvHzTffTFpaGvv37+fhhx8mJSUlKGiJiJyJw+EfebaZ4lsebk4J0WXTQXr1an1d4cBq9T9E2lizA87EiRMpLS2loKCAI0eOMGjQINauXUvfvv7ztUVFRUGjMU6nk/z8fPbu3UtiYiJjxoxh+fLlWL/0P/jixYuZO3cu99xzDyUlJaSnpzN16lQeffRRwD+a89FHH/GHP/wBh8NBWloa1157LatWraJr166t/Q5EpBOw11/WbcVyjp4iEglMPp+vY5z0bWMVFRUkJydTXl5OUpKxi9mJSPt74qlbmVn+FyafyOAPi1u+0KaItK+W/v7WWlQiErFKa0oZ/vxw9jv2B9pOXeYtIpGtDWaRiYh0DJv3vBUUbsxeuDqqDebPiEiHoxEcEYlY9g//C8BV++EvfwGLG5KW3nb2nUQkIijgiEjEclQdB6BnXDd6/ncDJCYGFrgUkcimgCMiEcte5V8vyhqbBBe07M7FIhKeNAdHRCKW3WkHwBaj20mIdDYKOCISkVweF6W1DgCscckGVyMi7U2nqEQk4rz2+WtMWDUBZ4wTAFu8zeCKRKS9aQRHRCLOGxv/gNPtDzdJTrgiaZDBFYlIe1PAEZGIY//8YwAe/TeceDKKwZeefTFgEYk8CjgiEnHs7goAUr9+LTGHj8GIEQZXJCLtTQFHRCKOw1MDgC21L6SkGFyNiBhBAUdEIo6dkwDYEnsYXImIGEVXUYnIOfl8Pg5WHMTlcbXqOL2TehMXHReiqqDWXUtVXVWD9rKoOgBs1l4hey8RCS8KOCJyTnPfmsv8DfNbfZxsWza77t1FjDmm1cc6VHGIwc8MxuF0NNyY4P/D2i291e8jIuFJAUdEzumd//4VAIsLYrwtO0ZlHOy176Wk6hgZyb1bXdP7u95sPNzUu+gIZKdpeQaRzkoBR0TOyVFaDInw8iq4/vOWHSNlFpQmgKP4i5AEHMfHWwC4fg/8Y2XD7aZevTD96rxWv4+IhCcFHBE5J/upOS0zHoFRd7XoGLb/O4/SBK8/LIWAo34hzW5dexD1+XsNO6SlQXx8SN5LRMKPAo6InJMj2g2AdUAuZGe36BhWTzRQh91+OCQ12WtK/ceNS25xTSISuXSZuIiclcfroTzWP/HG1r3lp5asPv/VUw7H0ZDUdWr+jVUrhYtIIzSCIxJh9tn30Tupd6NXKn1R9gU1rpoG7VGmKHJScjBHmQEoO1lGcYX/VFJlbUWgn7VnZovrshEPVHKi8hi17lp8+AD/JeinfLXtbH2OuxwQCzaLFtIUkYYUcEQiyBt73+C65dcxesBo1n5vbdC2p//7ND/+54/PuO/E3In86ZY/cazqGFmLsjjpPhm0PaEOYrv3bHFtVrP/2u0HT6zgwfkrWnycgNj642qlcBFphE5RiUSQRW8VAvDPz//ZYNuW/74MQGItpFadfnSrzzFbP1kHwM6irZx0n8TsDe537zZzqybtftObRbSnxbs3qlsNXGkbEtqDikhE0AiOSCTZtQsSG99kP/g5JMCT/4L/2Xq6/ZMeMOhesNeW+/t9ug2AEYfgnd9+6QDfurZVpU0cfic3/uAtXP6zYJhOn3XCRMvaoqNjML83tlV1iUhkUsARiSRu9xk3Obz1C1COmwQvLQi0W3dshG3fwxHjwefz4ago8bfHJsGBj04foHcr711z553EjxlD/MmT5+7bVFYrJCWF7ngiEjEUcEQiiCkwxuGfmGsynX59agFKa1oWZJ6eLGxzD4Nt4ImCqtpKHJXH/e3mLkH9QqKHFr8UkfahOTgiEeqrV0s5zrAAZXxKGjH1c2PsjiPYa8oAsEaf4VyXiEgY0AiOSATZH3s61Ow+8jGu6NMjOGUx9Tfrs6UF7WPq2hXbSShJhA/2bmK/8yiYwKb7y4hIGFPAEYkQ+x37+SihMvD64t9fGtyh/rY4tpSvzKUxmbC6oijBy7h1dwVm8ibHJbdhtSIibUunqEQixJ4D2xu0mXzQz1H/sMNd26B7r4bLGty910r3GrCd9D8GlMKYxIvao2wRkTahERyRCHFy10cN2jIqYN9TX2rIzYWUlAb9ZqXexKxf/uZ0Q0wMrB/fBlWKiLQPBRyRCOGsrW7QZnWbobjodEPPnmA2N9x56VL42c/A619zisREXX4tImFNAUckQjjr/BOMu9VAmX9VBGyeWEhPP/fOJhP06nXufiIiYUJzcEQihLPOP4KTVnP6r7UNi1HliIgYSiM4IgbxeD1sOriJqrqqRrdnJGVwYeqFTT6es9Y/gpPmiuOT+pv6JUa1fO0oEZFwpoAjYpBfv/9rHnjtgbP22fLDLQxLH9ak452sv7FfKolQH3C6RCvgiEjnpIAjYpBPt70OQHoFpH1lEGdPN6iwwKe732lywHG6nQB0jUvi4bePsz4bppIT0ppFRMKFAo6IQRwH90AczNwE098L3vad78Bfc8Gxaztc07TjOV3+gGOJjWd+7eXM/9178Mc7Q1u0iEiY0CRjEYM43P5JwdZR4+DYsaCHtUcff5+q0iYf79QIjsVsgbffhrIyf1ISEemENIIjYhCHzz9nxprS239/mi+xxiUDB7E77U0+ntNTC9FgiY6DqCjdx0ZEOjWN4IgYxEEtALakng222erXgXLUljf5eE6v/3jxmlgsIqIRHJG25nQ72XZkGyZMmKPMmE1mokxRnIipA8Ca3PAGe1aLFYCD7jJ2Ht+JqX4FTJPJhAlT0J/d47tTdrKME/UjQpZo3ftGREQBR6SNTVg1gdc+f63hhjj/H9buGQ02Wbt0h2pYZykmd0lu096o/u7FcbEawRERUcARaWOf7t4EUf6FL6O94DGB1wSeKBhxCPrc/rUG+3yj+3Au/OIPHO7qf+0zge8rfwKUf2mwJrEWUqvhm+cPbvPPJCLS0SngiLQxZ201xMM/V8Dgkq9szMmBzL4N9ul15Wh2PNAVKivPeuwh0+DD+jNcxx8HS1wX2HBDiCoXEQlfCjgibcwZ5V+h27LsRfj69cEbk5MbX917wAA4fhyqG64Q/mWmn2UA9ZeH7z8E3buDRXNwREQUcETamNPsA8DSMx26dWv6jnFx/kdTpaf7VwUXERFdJi7Slrw+L7X1/4ywdGnj+9Io3IiIBCjgiLSh2vrlEwDiE20GViIi0rko4Ii0IefJisBzS5fkkB+/Z11MyI8pIhIJFHBE2pCz2n8nYrMXohMSQ378JZ/04+LDsOovIT+0iEhY0yRjkTZ0ssoBgMUNxIR+tGXAk79j6ze+AY89FvJji4iEMwUckTbkrPGfoop30zaTgIcNA7vdv7imiIgE6KeiSBs6FXAsnjb8q6ZwIyLSgH4yirQhp9N/J2KLV5dwi4i0pxYFnCVLlpCVlYXFYmHYsGFs2LDhjH1dLhcFBQX0798fi8XCkCFDeO214IUH3W43+fn5ZGVlER8fT3Z2NgUFBXi93kaPOXXqVEwmE0899VRLyhdpUz6fj21HtvHmvjd599hWACxe/VtCRKQ9NXsOzqpVq5g+fTpLlizh8ssv57nnnmP06NHs3LmTzMzMBv3z8/NZsWIFzz//PDk5Obz++utMmDCBTZs2cdFFFwGwYMECnn32WZYtW0Zubi5btmxhypQpJCcn88ADDwQdb82aNWzevJn09PQWfmSRtvWXnX9h4l8nBrUleDXdTUSkPTX7n5ULFy7k7rvv5gc/+AEDBw7kqaeeok+fPjzzzDON9l++fDkPP/wwY8aMITs7mx/96EeMGjWKJ598MtDn3XffZdy4cXz729+mX79+3HLLLeTl5bFly5agYxUXF3Pffffx4osvEtMGV6SIhMLHW9YC0K0GckvgwqNw/4FUg6sSEelcmhVw6urq2Lp1K3l5eUHteXl5bNq0qdF9amtrsXxl8b/4+Hg2btwYeH3FFVewfv16du/eDcCOHTvYuHEjY8aMCfTxer1MnjyZmTNnkpube85aa2trqaioCHqItAf7/k8BmLYFPl4CO56F7w3+nsFViYh0Ls0aNz9x4gQej4fU1OB/jaampnL06NFG9xk1ahQLFy7kqquuon///qxfv55XXnkFj8cT6DN79mzKy8vJycnBbDbj8XiYP38+t912W6DPggULiI6O5v77729SrYWFhTyme4OIARx1FRALtq9fBX/7p/8qJ63wLSLSrlo089H0lft5+Hy+Bm2nLFq0iPPOO4+cnBxiY2O57777mDJlCmazOdBn1apVrFixgpUrV7Jt2zaWLVvGE088wbJlywDYunUrixYt4ve///0Z3+erHnroIcrLywOPgwcPtuSjijSb3V0FgC0xBRISFG5ERAzQrICTkpKC2WxuMFpTUlLSYFTnlB49erBmzRqqq6s5cOAAu3btIjExkaysrECfmTNnMmfOHCZNmsTgwYOZPHkyDz74IIWFhQBs2LCBkpISMjMziY6OJjo6mgMHDvCTn/yEfv36Nfq+cXFxJCUlBT1E2oPdWwOALbGHwZWIiHRezQo4sbGxDBs2jHXr1gW1r1u3jssuu+ys+1osFjIyMnC73axevZpx48YFttXU1BD1lZuVmc3mwGXikydP5sMPP+SDDz4IPNLT05k5cyavv/56cz6CSJvy+XxsSiwDwJrU0+BqREQ6r2ZfuzpjxgwmT57M8OHDGTlyJEuXLqWoqIhp06YBcMcdd5CRkREYfdm8eTPFxcUMHTqU4uJi5s2bh9frZdasWYFjjh07lvnz55OZmUlubi7bt29n4cKF3HXXXQB0796d7t27B9URExNDr169+NrXvtbiDy8Sav858J/A827WNAMrERHp3JodcCZOnEhpaSkFBQUcOXKEQYMGsXbtWvr27QtAUVFR0GiM0+kkPz+fvXv3kpiYyJgxY1i+fDlWqzXQZ/HixcydO5d77rmHkpIS0tPTmTp1Ko8++mgIPqJI+9n3yTuB5xdmXGxgJSIinZvJ5/P5jC6iPVRUVJCcnEx5ebnm40ibeW7xnUwr+wPjP4WXX6iCLl2MLklEJKy19Pe37h8vEkIuTx0AMalpCjciIgZSwBEJoTp3LQCxUbrTtoiIkRRwRELI5XEBEGMyn6OniIi0JQUckRAKjOCYNIIjImIkBRyREAqM4ERp9XARESMp4IiEUJ3XP8lYc3BERIylgCMSQi6PG9AIjoiI0RRwRELo9AhOrMGViIh0bgo4IiHk8moER0SkI1DAEQmhOq9/knFstEZwRESMpIAjEkIu36kRHAUcEREjKeCIhFBdfcDRCI6IiLEUcERCyOXzABBjVsARETGSAo5ICJ0ewYkzuBIRkc5NAUckhAIjODpFJSJiKAUckRCq49QIjsXgSkREOjcFHJEQcuEFNIIjImI0BRyREDlefZx3kssBiI3RCI6IiJEUcERCZPrr0wPPu8R2MbASERFRwBEJkf0fvg1APztcYR1icDUiIp2bAo5IiNhrygD47SsQM2KkwdWIiHRuCjgiIeKI8q8kbl34a0hJMbgaEZHOTQFHJEQcMf574Fi7pRtciYiIKOCIhECtu5aT0T4ArCm9Da5GRESijS5AJNyV1pTy1hdvAGDyQXLPTIMrEhERBRyRVrrshcvYXbYbgGQnRNm6GVyRiIgo4Ii0gs/nY0/pbjDBoGPw/U9jIVp/rUREjKafxCKt4PLU4TP5n29YGYf1e3cbW5CIiAAKOCKt4nRWBZ5b9uyDHmkGViMiIqfoKiqRVnBWlweex3VJNrASERH5MgUckVY4We0AwOICk0ULbIqIdBQKOCKtcGoEx+IGovTXSUSko9BPZJFWcNZUAmDxmgyuREREvkwBR6QVnCfBr2JdAAAgAElEQVQrALB4FHBERDoSBRyRVnCe9F9FZfHqr5KISEein8oireB01p+i8pkNrkRERL5MAUekFU7W3wcn3quAIyLSkSjgiLSCs7YaAIvumSki0qHop7JIM9W4avii7AsAPq8uAhRwREQ6Gv1UFmkGr8/LhUsG84Vjb1C7xRRjUEUiItIYBRyRZnDUlAXCTWr9MlRxbvheRV8DqxIRka9SwBFpBnvJAQAS6uDoCzZ/Y1wcPDXDwKpEROSrFHBEmsFx4hAAtloTlJUZXI2IiJyJrqISaQZH2WEArC5dFi4i0pEp4Ig0g91xFACbJ9bgSkRE5GwUcESa4bOy3QBYiTO4EhERORsFHJEmeu/Qe+SX/AkAmynB4GpERORsFHBEmmjLO38JPJ/oOt/ASkRE5FwUcESayHHgMwB+sBW+PW6mwdWIiMjZKOCINJHjpB0A2/kXwujRBlcjIiJno4Aj0kSOugoArHHJBlciIiLnooAj0kR2VyUA1nibwZWIiMi56E7G0qm5vW48Xk+T+pb5qgGwduneliWJiEgIKOBIp+Dz+bh79R38e99bgbZ9NcWYTWY8vqYFHBL9f1i79miDCkVEJJQUcKRTOFF+hN99sqJBe5PDTb0e1TAsdWioyhIRkTbSojk4S5YsISsrC4vFwrBhw9iwYcMZ+7pcLgoKCujfvz8Wi4UhQ4bw2muvBfVxu93k5+eTlZVFfHw82dnZFBQU4PV6A33mzZtHTk4OXbp0wWaz8a1vfYvNmze3pHzphMqKPwcgsRbefbk7A0pPb/vft2Nx/C61SY/id0aQes0NBn0KERFpqmaP4KxatYrp06ezZMkSLr/8cp577jlGjx7Nzp07yczMbNA/Pz+fFStW8Pzzz5OTk8Prr7/OhAkT2LRpExdddBEACxYs4Nlnn2XZsmXk5uayZcsWpkyZQnJyMg888AAA559/Pk8//TTZ2dmcPHmSX/3qV+Tl5fH555/To4dOGcjZOUr9q4B3r43i0g9OkPbjRD7HP6cm7fpbSJ75opHliYhIiJl8Pp+vOTuMGDGCiy++mGeeeSbQNnDgQMaPH09hYWGD/unp6TzyyCPce++9gbbx48eTmJjIihX+UwY33HADqampvPDCC4E+N998MwkJCSxfvrzROioqKkhOTuaNN97gm9/85jnrPtW/vLycpKSkJn9eiQyvvfIkoz/4fwwti2P7Iic33t+Dv3U/AcDLqQ8wftpTBlcoIiKNaenv72adoqqrq2Pr1q3k5eUFtefl5bFp06ZG96mtrcVisQS1xcfHs3HjxsDrK664gvXr17N7t38hwx07drBx40bGjBlzxjqWLl1KcnIyQ4YMOeP7VlRUBD2k83LUrwJu9flXAf/yWlLWpJ6G1CQiIm2nWaeoTpw4gcfjITU1Nag9NTWVo0ePNrrPqFGjWLhwIVdddRX9+/dn/fr1vPLKK3g8pyd3zp49m/LycnJycjCbzXg8HubPn89tt90WdKy///3vTJo0iZqaGtLS0li3bh0pKSmNvm9hYSGPPfZYcz6eRDB71XEAbMT7/4zpGthms6UbUpOIiLSdFk0yNplMQa99Pl+DtlMWLVrEeeedR05ODrGxsdx3331MmTIFs9kc6LNq1SpWrFjBypUr2bZtG8uWLeOJJ55g2bJlQce69tpr+eCDD9i0aRPXX389t956KyUlJY2+70MPPUR5eXngcfDgwZZ8VAljL+1cTfbjvem9IJU5x/8IgDXKP3JjjTs9zGntnmFIfSIi0naaFXBSUlIwm80NRmtKSkoajOqc0qNHD9asWUN1dTUHDhxg165dJCYmkpWVFegzc+ZM5syZw6RJkxg8eDCTJ0/mwQcfbDCnp0uXLgwYMIBLL72UF154gejo6KB5O18WFxdHUlJS0EM6l2WrHmJfTTHFzhIqTHUADIvyh5lh8f0BSK2CXr36G1ajiIi0jWYFnNjYWIYNG8a6deuC2tetW8dll1121n0tFgsZGRm43W5Wr17NuHHjAttqamqIigouxWw2B10m3hifz0dtbW1zPoJ0IvYq/yTiX26MZ9uaVD77Rzb3jJsPwNibHmLvaznsPnILcX2yznYYEREJQ82+THzGjBlMnjyZ4cOHM3LkSJYuXUpRURHTpk0D4I477iAjIyMw+rJ582aKi4sZOnQoxcXFzJs3D6/Xy6xZswLHHDt2LPPnzyczM5Pc3Fy2b9/OwoULueuuuwCorq5m/vz53HjjjaSlpVFaWsqSJUs4dOgQ3/nOd0LxPUgEspucAFx0x2wumvzT4I0XXEDWu58aUJWIiLSHZgeciRMnUlpaSkFBAUeOHGHQoEGsXbuWvn37AlBUVBQ0GuN0OsnPz2fv3r0kJiYyZswYli9fjtVqDfRZvHgxc+fO5Z577qGkpIT09HSmTp3Ko48+CvhHc3bt2sWyZcs4ceIE3bt355JLLmHDhg3k5ua29juQCOWIcgFgtfYyuBIREWlvzb4PTrjSfXA6n8T8KKpjfHx+3d/pf9m3jS5HRERaoF3ugyMSLlzuOqpj/Nnd1qOPwdWIiEh7U8CRiORwHAk8T+7ZcAkRERGJbAo4EpHsJUUAJDnBnJRscDUiItLeFHAkIjlKiwGw1kXBGW5CKSIikUsBRyKS3X4YAJu72RcKiohIBFDAkYjkcBwDTi+uKSIinYsCjkQke6V/jbJTi2uKiEjnooAjEcle7V+mwRbVxeBKRETECJqgIGHvP/v+zff+PJFKV3Wgzek+CSawxiQaWJmIiBhFAUfC3st//RnFzpLgxvoLpy6NyW7/gkRExHAKOBL2HGWHwQKztlj4YXFqoD0xPplev37MwMpERMQoCjgS9uzuSgD6X34DA+b8xeBqRESkI9AkYwl7Du9JAKyJKQZXIiIiHYUCjoQ9u8kJgC2pp8GViIhIR6GAI2HPEVUHgNWaZnAlIiLSUSjgSNizx3gAsHVLN7gSERHpKBRwJKy5PC6qYn0A2HpkGlyNiIh0FAo4EtbKy48Fnif37GNgJSIi0pEo4EhYs5ccAKBrLUQn2wyuRkREOgoFHAlrjtJiAKx1JojS/84iIuKn3wgS1uxl/oBjc8UYXImIiHQkCjgS1hzl/jWorN5YgysREZGOREs1SFhyOB0M//UQvqgqAsCGxeCKRESkI9EIjoSl97e8Ggg3ANe6ehtYjYiIdDQawZGwZN//KQCXFptY+/EQbAWPG1yRiIh0JAo4EpYclccB6BnXHdum7QZXIyIiHY1OUUlYsledAMAalWBwJSIi0hEp4EhYcpy0A2CL6WpwJSIi0hEp4EhYstc6ALDFJhlciYiIdEQKOBJ2at21PBf7IQDWeC3PICIiDSngSNjZs39L4PkVyRcaWImIiHRUCjgSduwHPgMg0wHDbvmxwdWIiEhHpIAjYcduPwxAL48F0tMNrkZERDoiBRwJO/byYwDYfFqeQUREGqeAI2EncA8cU7zBlYiISEelOxlLWPD5fBwoP4Db62Zv9SEAbOZEg6sSEZGOSgFHwsKDf7+PRduWBLXZYnWTPxERaZwCjoSFTZtWgQXiXRDjgeRauDFxiNFliYhIB6WAI2HB4a4C4PV/9+bKujRIToanZxtclYiIdFQKOBIW7NEuAGyPFkLe7QZXIyIiHZ2uopIOz+fz4YjxAmDtpvveiIjIuSngSIdXXVuJ2+x/buvZ19hiREQkLOgUlXQ4Xp+Xj0s+xuVxkZmcSenxAwBEeyAhJc3g6kREJBwo4EiH85N/3M9TW38NQBRRePGfnrI5wZSQYGRpIiISJnSKSjqcbZtWB56fCjcAU3fpxn4iItI0CjjS4TjqKhq09SmHn41daEA1IiISjhRwpMOxm/2XhCc5T7fZPDHwwx8aVJGIiIQbBRzpcBzRbgCyK82BNqs31qhyREQkDCngSIfi9rqpjPUBkOU+vdaUDYtRJYmISBhSwJEOxVF5PPC8X0yPwHNrVBcjyhERkTClgCMdiuN4EQCJtdCza2qgvVu0Vg4XEZGmU8CRDsV+/CAA1joTNyVdysiDcEkxfC/6IoMrExGRcKIb/UmH4rAfAcDmiub87/6YTffvAZcLHnzY4MpERCScKOBIh2J3HAXqr5rKzIQ1awyuSEREwpFOUUmH4qgsAcDm01VTIiLSci0KOEuWLCErKwuLxcKwYcPYsGHDGfu6XC4KCgro378/FouFIUOG8NprrwX1cbvd5Ofnk5WVRXx8PNnZ2RQUFOD1egPHmD17NoMHD6ZLly6kp6dzxx13cPjw4ZaULx2YveoEANYorTklIiIt1+yAs2rVKqZPn84jjzzC9u3bufLKKxk9ejRFRUWN9s/Pz+e5555j8eLF7Ny5k2nTpjFhwgS2b98e6LNgwQKeffZZnn76aT799FN++ctf8vjjj7N48WIAampq2LZtG3PnzmXbtm289NJL7N69mxtvvLGFH1s6Ip/Px5vVnwBgi9G6UyIi0nImn8/na84OI0aM4OKLL+aZZ54JtA0cOJDx48dTWFjYoH96ejqPPPII9957b6Bt/PjxJCYmsmLFCgBuuOEGUlNTeeGFFwJ9br75ZhISEli+fHmjdbz//vt8/etf58CBA2RmZp6z7oqKCpKTkykvLycpKanJn1fazwvvL+UHa6cCMO/kpfz0F+8aXJGIiBitpb+/mzWCU1dXx9atW8nLywtqz8vLY9OmTY3uU1tbi8USPJ8iPj6ejRs3Bl5fccUVrF+/nt27dwOwY8cONm7cyJgxY85YS3l5OSaTCavVesb3raioCHpIx/bxm38KPL+1yyUGViIiIuGuWVdRnThxAo/HQ2pqalB7amoqR48ebXSfUaNGsXDhQq666ir69+/P+vXreeWVV/B4PIE+s2fPpry8nJycHMxmMx6Ph/nz53Pbbbc1ekyn08mcOXP47ne/e8Y0V1hYyGOPPdacjycGs5cfhTj4xToYuGKG0eWIiEgYa9EkY5PJFPTa5/M1aDtl0aJFnHfeeeTk5BAbG8t9993HlClTMJtPL6S4atUqVqxYwcqVK9m2bRvLli3jiSeeYNmyZQ2O53K5mDRpEl6vlyVLlpyxxoceeojy8vLA4+DBgy35qNKO7O5KAGxjboJ+/YwtRkREwlqzRnBSUlIwm80NRmtKSkoajOqc0qNHD9asWYPT6aS0tJT09HTmzJlDVlZWoM/MmTOZM2cOkyZNAmDw4MEcOHCAwsJC7rzzzkA/l8vFrbfeyr59+3jzzTfPei4uLi6OuLi45nw8MZjdWwOALTHF4EpERCTcNWsEJzY2lmHDhrFu3bqg9nXr1nHZZZeddV+LxUJGRgZut5vVq1czbty4wLaamhqiooJLMZvNgcvE4XS42bNnD2+88Qbdu3dvTukSBuwmJwDWrj0NrkRERMJds+9kPGPGDCZPnszw4cMZOXIkS5cupaioiGnTpgFwxx13kJGREbiiavPmzRQXFzN06FCKi4uZN28eXq+XWbNmBY45duxY5s+fT2ZmJrm5uWzfvp2FCxdy1113Af775Nxyyy1s27aNv//973g8nsAoUrdu3YiNjW31FyHGefvA21TWVvJxYv0IjrWXwRWJiEi4a3bAmThxIqWlpRQUFHDkyBEGDRrE2rVr6du3LwBFRUVBozFOp5P8/Hz27t1LYmIiY8aMYfny5UFXPy1evJi5c+dyzz33UFJSQnp6OlOnTuXRRx8F4NChQ7z66qsADB06NKiet956i2uuuabZH1w6hs/LPufq318d1Naj+7kv+xcRETmbZt8HJ1zpPjgd0782/J5Rb04JavPduU+TjEVEBGin++CIhJrj0OdBrx98F4UbERFpNQUcMZS94ljQa+vQSw2qREREIokCjhjKUV0a9NoabzOoEhERiSQKOGIoe01Z0Gtbgi7/FxGR1lPAEcN8cPQDFnj+E9Rm7aqb/ImISOsp4Igh3F431/726gbtPazpBlQjIiKRptn3wREJBXvlcRwu/wrv3/3Q39a7Ar7+rZEGViUiIpFCAUcM4TheBEDXWnjRO97feEEmXKqAIyIiraeAI4awnzgEgK3WBC+/bHA1IiISaTQHRwxhtx8GwOZSxhYRkdBTwBFDOBz+xVKtXi2UKiIioaeAI21qy+EtTH9tOtuPbA+0bT+ynamfPwWADYtRpYmISATT+QFpU5NWfYcvKvazfs/rfPTjTwGY9vJdlHtrAEinq5HliYhIhNIIjrSpLyr2A/Bx2a5A2+GD/qAzZjc8VDfCiLJERCTCaQRH2p3dXAfA/33cm94v5htcjYiIRCKN4Eib8fl8DdpcHhfVMf5224svwaBB7V2WiIh0Ago40maqXdVBr10eV9Dq4ck9+rR3SSIi0kko4EibsduPBL12VJdiLzkAQJITzN20criIiLQNzcGRkCupLqFwQyEHjn0W1D559ff4Yb+bgPo7GMfEGFGeiIh0Ago4EnK/ff85ntr8VIP214ve5GipfwTH6tb/eiIi0nb0W0ZC7ujmNwG4dh9c/zlk22HaDVCaALsq9oIZbB7dwVhERNqOAo6EnKPyOMTAKEcKs3pdDTlWyta/wNSxUGv2X0Fl1R2MRUSkDSngSMjZXZUQA7bhl0P+XwGw/coEFb8J9LFFJRhVnoiIdAK6ikpCzu71Xx5u65ISaLN27RHUxxqd2K41iYhI56KAIyHnwAmAtWvPQJvVmhrUxxaX3K41iYhI56KAIyF3aikGW/LpUGOzpQf1sVqs7VqTiIh0Lgo4EnL2aDcAtu4ZgbaeqdnEeE736dMl/au7iYiIhIwmGUtIfXmtKeuXAk5SWj/+vhL+mwGpVfDtGVcbVaKIiHQCCjgSUo6assBza8++pzd0707e/YvIe+cdSE2FcTcZUJ2IiHQWCjgSUvYTB4EzrDV1//3+h4iISBvTHBwJKceJQwBYa00QF2dwNSIi0llpBEeabOfxnRRXFJMQk8ClvS/FHGVu0MdeVgyAzdVwm4iISHtRwJEm2X5kOxcvvTjw+rxu51FSXYLH5yHblk2cOY5YcyzvHHwHAKtXa02JiIhxFHCkSfaU7g5+XbYn8PzDYx826G/TWlMiImIgzcGRJnHu3NFo+y/Wwd9Wwo27gtttJq01JSIixlHAkSZx2o832n6lbQg3DP8uQ13dgtqtMVprSkREjKOAI01ysta/gGa3muB22//cDy++iC3noqD2pNiu7VWaiIhIAwo40iRO10kAelUFt9u69/b/mRB8z5uouPh2qUtERKQxCjjSJIGAUxd8dZStRx8ArIkpwTuYdZm4iIgYRwFHmsTpdgLQy9cl0BbnhriUXgDYknoG9TeZTO1XnIiIyFco4EiTnKwPOJlmG9d9AWYvfO9DICkJgPN65mDyne4/gYEGVCkiIuKn++BIkzjdToiB+EQb/1pa39i9e+BUVFqfC/j8djieACk10H/JFcYVKyIinZ4CjjSJ01sHgCUhCX7zG3j7bbjpSyuCDxpE9sz/Jfvll+Fb34JbbzWoUhEREQUcaSKntxaA+Jh4uPtu/+PLTCZ46CH/Q0RExGCagyNNcvLUCE6MLv8WEZGOTwFHzqm6rppXuxwCwBKrJRhERKTjU8CRc5rzxpzA8y6xWoJBREQ6PgUcOac9Rz4OPL8u+aKz9BQREekYFHDknBxffALAmj9C125pBlcjIiJybgo4ck4Oj3+hTWtyKlx3ncHViIiInJsCjpyT3ey/gso642GIizO4GhERkXNTwJGz8vl8OKI9ANi6ZxhcjYiISNMo4MhZOd1O6sz+RaasCjgiIhImFHDkrBwn7QBEeSGxhwKOiIiEBwUcOSu7/TAAVidE2boZXI2IiEjTtCjgLFmyhKysLCwWC8OGDWPDhg1n7OtyuSgoKKB///5YLBaGDBnCa6+9FtTH7XaTn59PVlYW8fHxZGdnU1BQgNfrDfR56aWXGDVqFCkpKZhMJj744IOWlC7N5Djhv4OxtRZI0F2MRUQkPDQ74KxatYrp06fzyCOPsH37dq688kpGjx5NUVFRo/3z8/N57rnnWLx4MTt37mTatGlMmDCB7du3B/osWLCAZ599lqeffppPP/2UX/7ylzz++OMsXrw40Ke6uprLL7+cX/ziFy34mNJSjrL6ERxXtH9BTRERkTBg8vl8vubsMGLECC6++GKeeeaZQNvAgQMZP348hYWFDfqnp6fzyCOPcO+99wbaxo8fT2JiIitWrADghhtuIDU1lRdeeCHQ5+abbyYhIYHly5cHHW///v1kZWWxfft2hg4d2uS6KyoqSE5Opry8nKSkpCbv19mt/Mtcvrfz53zzaAJvPFNtdDkiItLJtPT3d7NGcOrq6ti6dSt5eXlB7Xl5eWzatKnRfWpra7FYLEFt8fHxbNy4MfD6iiuuYP369ezevRuAHTt2sHHjRsaMGdOc8hq8b0VFRdBDms9eUQKA1af734iISPiIbk7nEydO4PF4SE1NDWpPTU3l6NGjje4zatQoFi5cyFVXXUX//v1Zv349r7zyCh6PJ9Bn9uzZlJeXk5OTg9lsxuPxMH/+fG677bYWfCS/wsJCHnvssRbv39mt3bOWWnctvynxz5eyRmn+jYiIhI8WTTI2fWUuhs/na9B2yqJFizjvvPPIyckhNjaW++67jylTpmA2mwN9Vq1axYoVK1i5ciXbtm1j2bJlPPHEEyxbtqwl5QHw0EMPUV5eHngcPHiwxcfqbLYe3sq3V36bm/58Ex/U+edW2aK1iriIiISPZo3gpKSkYDabG4zWlJSUNBjVOaVHjx6sWbMGp9NJaWkp6enpzJkzh6ysrECfmTNnMmfOHCZNmgTA4MGDOXDgAIWFhdx5553N/UwAxMXFEadlBVpkn31vg7ZbfbkGVCIiItIyzRrBiY2NZdiwYaxbty6ofd26dVx22WVn3ddisZCRkYHb7Wb16tWMGzcusK2mpoaoqOBSzGZz0GXi0n7sO7cGvf7pv+GSlAuNKUZERKQFmjWCAzBjxgwmT57M8OHDGTlyJEuXLqWoqIhp06YBcMcdd5CRkRG4omrz5s0UFxczdOhQiouLmTdvHl6vl1mzZgWOOXbsWObPn09mZia5ubls376dhQsXctdddwX6lJWVUVRUxOHD/suWP/vsMwB69epFr169Wv4NSAOn7n1ziu0k8KMfGVOMiIhICzQ74EycOJHS0lIKCgo4cuQIgwYNYu3atfTt2xeAoqKioNEYp9NJfn4+e/fuJTExkTFjxrB8+XKsVmugz+LFi5k7dy733HMPJSUlpKenM3XqVB599NFAn1dffZUpU6YEXp86nfXTn/6UefPmNfuDy5nZq0uDXltHj4eePQ2qRkREpPmafR+ccKX74DTdPT8fyTOe9wKvX+nyA278f88bWJGIiHRWLf393ewRHIlcTreTv332N95xfRE0O8vatYdxRYmIiLSAAo4E/N/m/2P2G7MbTD3v2a2PMQWJiIi0kFYTl4A9Rz4Oej2gFH6xDr6WqkvERUQkvGgERwKqP94OX7pf4wuvwlUHgPR0w2oSERFpCY3gSIDd6Qh6bT1vMCxdCgMGGFSRiIhIy2gERwLs1AS9ts16FK67xaBqREREWk4jOBJgxxn02pqiycUiIhKeNILTib1f/D5/+vhPHKo8RGVtJbvjg0dwElM090ZERMKTAk4nVeep4+u/+fpZ+5i6dWunakREREJLAaeTKjtZ1mh7/n+gKBnG7gYeTWjfokREREJEAaeTclSUNGibvAN+9lb9i5gYMJka9BEREQkHCjidlL3kQIM2sxdYsAAqKuC669q/KBERkRBRwOmkHKWHGzb27w+zZrV/MSIiIiGmy8Q7KbvjSIM2U5T+dxARkcig32idlL3imNEliIiItBkFnE7KUVXaoO0bzjQDKhEREQk9zcHppOw1/oBjccHP34T0Spj49f4GVyUiIhIaCjid1KmFNee+DT95t77x/pHGFSQiIhJCCjidlMNVATFgjbfC4p9BVBTcdZfRZYmIiISEAk4nZfdUQQzYrhwF991ndDkiIiIhpUnGnZTDexIAa2KKwZWIiIiEnkZwWsntdVPwnwKjy2i2/THVANiSUw2uREREJPQUcFrJ6/Pys7d/ZnQZzRfj/6NXt0xj6xAREWkDCjitFOXxcq/zQqPLaL5du7jwYB39rs8xuhIREZGQU8BppWiiePoXHxpdRsulpxtdgYiISMgp4LRWVBQ8/LDRVbTMhRdCnz5GVyEiIhJyCjitFR0N8+cbXYWIiIh8iS4TFxERkYijgCMiIiIRRwFHREREIo4CjoiIiEQcBRwRERGJOAo4IiIiEnEUcERERCTiKOCIiIhIxFHAERERkYijgCMiIiIRRwFHREREIo4CjoiIiEQcBRwRERGJOJ1mNXGfzwdARUWFwZWIiIhIU536vX3q93hTdZqAU1lZCUCfPn0MrkRERESaq7KykuTk5Cb3N/maG4nClNfr5fDhw3Tt2hWTyRTSY1dUVNCnTx8OHjxIUlJSSI8tp+l7bh/6ntuHvuf2oe+5fbTl9+zz+aisrCQ9PZ2oqKbPrOk0IzhRUVH07t27Td8jKSlJf4Hagb7n9qHvuX3oe24f+p7bR1t9z80ZuTlFk4xFREQk4ijgiIiISMQxz5s3b57RRUQCs9nMNddcQ3R0pznrZwh9z+1D33P70PfcPvQ9t4+O9j13mknGIiIi0nnoFJWIiIhEHAUcERERiTgKOCIiIhJxFHBEREQk4ijgiIiISMRRwGmlJUuWkJWVhcViYdiwYWzYsMHokiJKYWEhl1xyCV27dqVnz56MHz+ezz77zOiyIl5hYSEmk4np06cbXUpEKi4u5vbbb6d79+4kJCQwdOhQtm7danRZEcXtdpOfn09WVhbx8fFkZ2dTUFCA1+s1urSw9vbbbzN27FjS09MxmUysWbMmaLvP52PevHmkp6cTHx/PNddcwyeffGJIrQo4rfD/27uDkKbfOI7jHzqUlScAAAU2SURBVBs6K8SwyJ8RE4PBUivMEehWHqpBSZegKK0ET8KsrUEoeejkykVeWii/Dl1C8lCRHYJGxUQi1OFKKpBItMsYQZgZKW3f/yH+g6EnU598+Lxgh9+zy/vk8+Xh98z+/n74/X50dHRgbGwMBw8exLFjxzA9Pa06TRvRaBRerxdv3rxBJBLB79+/4fF4MDc3pzpNWyMjIzBNE3v37lWdoqVv377B5XIhNzcXz549w4cPH3Dr1i1s2bJFdZpWurq60Nvbi3A4jI8fPyIUCuHmzZu4ffu26rR1bW5uDvv27UM4HF7y+1AohO7uboTDYYyMjMAwDBw9ejTzD6/XlNCyHThwQFpaWrLWHA6HtLe3KyrSXzKZFAASjUZVp2hpdnZW7Ha7RCIRqaurE5/PpzpJO21tbeJ2u1VnaK++vl6am5uz1k6ePCnnzp1TVKQfAPL48ePMczqdFsMw5MaNG5m1X79+SWFhofT29q55H09wlmlhYQGxWAwejydr3ePx4PXr14qq9DczMwMAKCoqUlyiJ6/Xi/r6ehw5ckR1irYGBgbgdDpx6tQpbN++HVVVVbh7967qLO243W68ePECExMTAIC3b99iaGgIx48fV1ymr8nJSSQSiax90Wq1oq6uTsm++G/8nvI69PXrV6RSKRQXF2etFxcXI5FIKKrSm4ggEAjA7XajsrJSdY52Hjx4gFgshtHRUdUpWvv8+TN6enoQCARw9epVDA8P49KlS7Barbhw4YLqPG20tbVhZmYGDocDFosFqVQKnZ2dOHv2rOo0bf2/9y21L05NTa15Dwecv5STk5P1LCKL1mhltLa24t27dxgaGlKdop0vX77A5/Ph+fPnyM/PV52jtXQ6DafTiWAwCACoqqrC+/fv0dPTwwFnBfX39+P+/fvo6+tDRUUF4vE4/H4/duzYgaamJtV5WvtX9kUOOMu0bds2WCyWRac1yWRy0fRKf+/ixYsYGBjA4OAgdu7cqTpHO7FYDMlkEtXV1Zm1VCqFwcFBhMNhzM/Pw2KxKCzUR0lJCcrLy7PWdu/ejYcPHyoq0tOVK1fQ3t6OM2fOAAD27NmDqakpXL9+nQPOKjEMA8Cfk5ySkpLMuqp9ke/gLFNeXh6qq6sRiUSy1iORCGpraxVV6UdE0NraikePHuHly5coKytTnaSlw4cPY3x8HPF4PPNxOp1obGxEPB7ncLOCXC7Xop86mJiYQGlpqaIiPf38+RMbNmRvcRaLhdfEV1FZWRkMw8jaFxcWFhCNRpXsizzB+QuBQADnz5+H0+lETU0NTNPE9PQ0WlpaVKdpw+v1oq+vD0+ePEFBQUHmxKywsBAbN25UXKePgoKCRe81bd68GVu3buX7Tivs8uXLqK2tRTAYxOnTpzE8PAzTNGGapuo0rZw4cQKdnZ2w2WyoqKjA2NgYuru70dzcrDptXfvx4wc+ffqUeZ6cnEQ8HkdRURFsNhv8fj+CwSDsdjvsdjuCwSA2bdqEhoaGtY9d83tbmrlz546UlpZKXl6e7N+/n9eXVxiAJT/37t1TnaY9XhNfPU+fPpXKykqxWq3icDjENE3VSdr5/v27+Hw+sdlskp+fL7t27ZKOjg6Zn59XnbauvXr1asm/yU1NTSLy56r4tWvXxDAMsVqtcujQIRkfH1fSmiMisvZjFREREdHq4Ts4REREpB0OOERERKQdDjhERESkHQ44REREpB0OOERERKQdDjhERESkHQ44REREpB0OOERERKQdDjhERESkHQ44REREpB0OOERERKSd/wBRT/uBQpv03AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x251c046f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_vs_accuraccy(test_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
