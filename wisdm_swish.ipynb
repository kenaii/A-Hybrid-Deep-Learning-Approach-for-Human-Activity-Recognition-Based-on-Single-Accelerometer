{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import operator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import *\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "sns.set(style='ticks', palette='muted', font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BI_CLASSES = [('Downstairs', 'Upstairs'), ('Downstairs', 'Walking'), ('Jogging', 'Upstairs'), ('Jogging', 'Walking'), ('Upstairs', 'Walking')]\n",
    "N_CLASSES = 6\n",
    "N_TIME_STEPS = 200\n",
    "N_FEATURES = 3\n",
    "\n",
    "N_EPOCHS = 170\n",
    "BATCH_SIZE = 1024\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_swish(x):\n",
    "    return x * tf.nn.sigmoid(x)\n",
    "\n",
    "def ks_swish(x):\n",
    "    return x * K.sigmoid(x)\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(128, (2, 2), input_shape=(N_TIME_STEPS, N_FEATURES, 1)))\n",
    "    model.add(Activation(ks_swish))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2), padding='valid'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(ks_swish))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation(ks_swish))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    adam = optimizers.Adam(lr = LEARNING_RATE, decay=1e-6)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis = 0)\n",
    "    sigma = np.std(dataset, axis = 0)\n",
    "    return (dataset - mu) / sigma\n",
    "\n",
    "def segment_signal(data, N_TIME_STEPS = 200, step = 20):\n",
    "    segments = [] \n",
    "    labels = []\n",
    "    for i in range(0, len(data) - N_TIME_STEPS, step):\n",
    "        xs = data['x-axis'].values[i: i + N_TIME_STEPS]\n",
    "        ys = data['y-axis'].values[i: i + N_TIME_STEPS]\n",
    "        zs = data['z-axis'].values[i: i + N_TIME_STEPS]\n",
    "        label = stats.mode(data['activity'][i: i + N_TIME_STEPS])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    return segments, labels\n",
    "\n",
    "def combinations(combination, features, labels):\n",
    "    combinations_x = [0] * len(combination)\n",
    "    combinations_y = [0] * len(combination)\n",
    "    for i in chosen:\n",
    "        temp_x = [] \n",
    "        temp_y = [] \n",
    "        for k in range(2):\n",
    "            for j in range(len(labels)):\n",
    "                if (combination[i][k] == labels[j]):\n",
    "                    temp_x.append(features[j])\n",
    "                    temp_y.append(labels[j])\n",
    "        combinations_x[i] = np.asarray(temp_x, dtype=np.float32).reshape(len(temp_x), N_TIME_STEPS, N_FEATURES, 1)\n",
    "        combinations_y[i] = np.asarray(pd.get_dummies(temp_y), dtype=np.float32)\n",
    "    return combinations_x, combinations_y\n",
    "\n",
    "def final_prediction(X_temp_test, predictions, threshold):\n",
    "    cnn_predictions = np.copy(predictions)\n",
    "    i = 0\n",
    "    while i < len(predictions):\n",
    "        sorted_index = np.argsort(cnn_predictions[i])[::-1]\n",
    "        test_cnn = X_temp_test[i].reshape(1, N_TIME_STEPS, N_FEATURES, 1)\n",
    "        k = 0\n",
    "        j = 1\n",
    "        while j < len(sorted_index):        \n",
    "            if sorted_index[k] > sorted_index[j]:\n",
    "                t = int(N_CLASSES * sorted_index[j] - sorted_index[j] * (sorted_index[j] + 1) / 2 + sorted_index[k] - sorted_index[j] - 1)     \n",
    "            else:\n",
    "                t = int(N_CLASSES * sorted_index[k] - sorted_index[k] * (sorted_index[k] + 1) / 2 + sorted_index[j] - sorted_index[k] - 1)\n",
    "            if cnn_models[t] != None:\n",
    "                if threshold > cnn_predictions[i][sorted_index[k]] / cnn_predictions[i][sorted_index[j]]:    \n",
    "                    p = cnn_models[t].predict(test_cnn)\n",
    "                    if np.argmax(p):\n",
    "                        if sorted_index[k] < sorted_index[j]:\n",
    "                            k = j\n",
    "                    else:\n",
    "                        if sorted_index[k] > sorted_index[j]:\n",
    "                            k = j\n",
    "                else:\n",
    "                    break;\n",
    "            j = j + 1     \n",
    "        cnn_predictions[i] = 0\n",
    "        cnn_predictions[i][sorted_index[k]] = 1\n",
    "        i = i + 1\n",
    "    return cnn_predictions\n",
    "\n",
    "def threshold_vs_accuraccy(history):\n",
    "    plt.rcdefaults()\n",
    "    plt.plot(history['threshold'], history['accuracy'], 'r-')\n",
    "    plt.plot(history['threshold'], history['f1score'], 'g-')\n",
    "    plt.show()\n",
    "    \n",
    "def confusion_report(predictions, y_test):\n",
    "    max_test = np.argmax(y_test, axis=1)\n",
    "    max_predictions = np.argmax(predictions, axis=1)\n",
    "    confusion_matrix = metrics.confusion_matrix(max_test, max_predictions)\n",
    "\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    sns.heatmap(confusion_matrix, xticklabels=np.unique(df.activity), yticklabels=np.unique(df.activity), annot=True, fmt=\"d\");\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
    "df = pd.read_csv('data/WISDM_ar_v1.1_raw.txt', header = None, names = columns)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user           int64\n",
       "activity      object\n",
       "timestamp      int64\n",
       "x-axis       float64\n",
       "y-axis       float64\n",
       "z-axis       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x-axis'] = feature_normalize(df['x-axis'])\n",
    "df['y-axis'] = feature_normalize(df['y-axis'])\n",
    "df['z-axis'] = feature_normalize(df['z-axis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kinai\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\stats\\stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "segments, labels = segment_signal(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combinations:  15\n",
      "[('Downstairs', 'Jogging'), ('Downstairs', 'Sitting'), ('Downstairs', 'Standing'), ('Downstairs', 'Upstairs'), ('Downstairs', 'Walking'), ('Jogging', 'Sitting'), ('Jogging', 'Standing'), ('Jogging', 'Upstairs'), ('Jogging', 'Walking'), ('Sitting', 'Standing'), ('Sitting', 'Upstairs'), ('Sitting', 'Walking'), ('Standing', 'Upstairs'), ('Standing', 'Walking'), ('Upstairs', 'Walking')]\n"
     ]
    }
   ],
   "source": [
    "combination = list(itertools.combinations(np.unique(labels, axis=0), 2))\n",
    "n_combination = len(combination)\n",
    "print(\"Combinations: \", n_combination)\n",
    "print(combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = []\n",
    "for i in range(len(BI_CLASSES)):\n",
    "    chosen.append(combination.index(BI_CLASSES[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_segments, labels, test_size=0.3, random_state=42)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c_train, y_c_train = combinations(combination, X_train, y_train)\n",
    "X_c_validation, y_c_validation = combinations(combination, X_validation, y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(pd.get_dummies(y_train), dtype = np.float32)\n",
    "y_test = np.asarray(pd.get_dummies(y_test), dtype = np.float32)\n",
    "y_validation = np.asarray(pd.get_dummies(y_validation), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDEN_UNITS = 128\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_LSTM_model(inputs):\n",
    "    W = {\n",
    "        'hidden': tf.Variable(tf.random_normal([N_FEATURES, N_HIDDEN_UNITS])),\n",
    "        'output': tf.Variable(tf.random_normal([N_HIDDEN_UNITS, N_CLASSES]))\n",
    "    }\n",
    "    biases = {\n",
    "        'hidden': tf.Variable(tf.random_normal([N_HIDDEN_UNITS], mean=1.0)),\n",
    "        'output': tf.Variable(tf.random_normal([N_CLASSES]))\n",
    "    }\n",
    "\n",
    "    X = tf.transpose(inputs, [1, 0, 2])\n",
    "    X = tf.reshape(X, [-1, N_FEATURES])\n",
    "    hidden = tf_swish(tf.matmul(X, W['hidden']) + biases['hidden'])\n",
    "    hidden = tf.split(hidden, N_TIME_STEPS, 0)\n",
    "\n",
    "    # Stack 2 LSTM layers\n",
    "    lstm_layers = [tf.contrib.rnn.BasicLSTMCell(N_HIDDEN_UNITS, forget_bias=1.0) for _ in range(2)]\n",
    "    lstm_layers = tf.contrib.rnn.MultiRNNCell(lstm_layers)\n",
    "    outputs, _ = tf.contrib.rnn.static_rnn(lstm_layers, hidden, dtype=tf.float32)\n",
    "\n",
    "    # Get output for the last time step\n",
    "    lstm_last_output = outputs[-1]\n",
    "\n",
    "    return tf.matmul(lstm_last_output, W['output']) + biases['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\kinai\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-16-821460619a78>:14: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, N_TIME_STEPS, N_FEATURES], name=\"input\")\n",
    "Y = tf.placeholder(tf.float32, [None, N_CLASSES])\n",
    "\n",
    "pred_Y = create_LSTM_model(X)\n",
    "\n",
    "pred_softmax = tf.nn.softmax(pred_Y, name=\"y_\")\n",
    "\n",
    "L2_LOSS = 0.0015\n",
    "\n",
    "l2 = L2_LOSS * \\\n",
    "        sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables())\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred_Y, labels = Y)) + l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred_softmax, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 train accuracy: 0.61976963 loss train: 2.5724485 test accuracy: 0.6225487 test loss: 2.56699\n",
      "epoch: 10 train accuracy: 0.8620151 loss train: 1.8494503 test accuracy: 0.8631534 test loss: 1.8498529\n",
      "epoch: 20 train accuracy: 0.9142322 loss train: 1.6865326 test accuracy: 0.91245216 test loss: 1.6933633\n",
      "epoch: 30 train accuracy: 0.90070087 loss train: 1.6838657 test accuracy: 0.89788115 test loss: 1.6975715\n",
      "epoch: 40 train accuracy: 0.93792933 loss train: 1.5452534 test accuracy: 0.93339807 test loss: 1.5645137\n",
      "epoch: 50 train accuracy: 0.95687324 loss train: 1.4733342 test accuracy: 0.949062 test loss: 1.4978774\n",
      "epoch: 60 train accuracy: 0.9700576 loss train: 1.4071336 test accuracy: 0.9629652 test loss: 1.4311687\n",
      "epoch: 70 train accuracy: 0.97123724 loss train: 1.3769563 test accuracy: 0.9634509 test loss: 1.4023638\n",
      "epoch: 80 train accuracy: 0.9767539 loss train: 1.3305762 test accuracy: 0.96794367 test loss: 1.3639926\n",
      "epoch: 90 train accuracy: 0.9826868 loss train: 1.2860868 test accuracy: 0.97219354 test loss: 1.3269676\n",
      "epoch: 100 train accuracy: 0.9854972 loss train: 1.253334 test accuracy: 0.97437924 test loss: 1.2932422\n",
      "epoch: 110 train accuracy: 0.98733604 loss train: 1.2237219 test accuracy: 0.97559345 test loss: 1.2665516\n",
      "epoch: 120 train accuracy: 0.9896607 loss train: 1.1909277 test accuracy: 0.9768077 test loss: 1.2394722\n",
      "epoch: 130 train accuracy: 0.98969537 loss train: 1.1690636 test accuracy: 0.9778398 test loss: 1.2144963\n",
      "epoch: 140 train accuracy: 0.9885851 loss train: 1.1486562 test accuracy: 0.9762006 test loss: 1.1950698\n",
      "epoch: 150 train accuracy: 0.98823816 loss train: 1.1280327 test accuracy: 0.9744399 test loss: 1.1884687\n",
      "epoch: 160 train accuracy: 0.9926445 loss train: 1.0932477 test accuracy: 0.97899336 test loss: 1.1408387\n",
      "epoch: 170 train accuracy: 0.9959406 loss train: 1.0620087 test accuracy: 0.9811183 test loss: 1.1166656\n",
      "\n",
      "final results: accuracy: 0.98263615 loss: 1.1004175 validation accuracy: 0.98053706 validation loss: 1.113345\n"
     ]
    }
   ],
   "source": [
    "history = dict(train_loss=[], train_acc=[], test_loss=[], test_acc=[])\n",
    "\n",
    "sess = tf.InteractiveSession()  \n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_count = len(X_train)\n",
    "\n",
    "for i in range(1, N_EPOCHS + 1):\n",
    "    for start, end in zip(range(0, train_count, BATCH_SIZE), range(BATCH_SIZE, train_count + 1, BATCH_SIZE)):\n",
    "        sess.run(optimizer, feed_dict={X: X_train[start:end], Y: y_train[start:end]})\n",
    "\n",
    "    train_predictions, acc_train, loss_train = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_train, Y: y_train})\n",
    "\n",
    "    _, acc_test, loss_test = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_test, Y: y_test})\n",
    "\n",
    "    history['train_loss'].append(loss_train)\n",
    "    history['train_acc'].append(acc_train)\n",
    "    history['test_loss'].append(loss_test)\n",
    "    history['test_acc'].append(acc_test)\n",
    "        \n",
    "    if i != 1 and i % 10 != 0:\n",
    "        continue\n",
    "\n",
    "    print('epoch:', i, 'train accuracy:', acc_train, 'loss train:', loss_train, 'test accuracy:', acc_test, 'test loss:', loss_test)\n",
    "    \n",
    "predictions, acc_final, loss_final = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_test, Y: y_test})\n",
    "validation_predictions, validation_acc, validation_loss = sess.run([pred_softmax, accuracy, loss], feed_dict={X: X_validation, Y: y_validation})\n",
    "print()\n",
    "print('final results: accuracy:', acc_final, 'loss:', loss_final, 'validation accuracy:', validation_acc, 'validation loss:', validation_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215e40f2eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 14))\n",
    "\n",
    "plt.plot(np.array(history['train_loss']), \"r--\", label=\"Train loss\")\n",
    "plt.plot(np.array(history['train_acc']), \"g--\", label=\"Train accuracy\")\n",
    "\n",
    "plt.plot(np.array(history['test_loss']), \"r-\", label=\"Test loss\")\n",
    "plt.plot(np.array(history['test_acc']), \"g-\", label=\"Test accuracy\")\n",
    "\n",
    "plt.title(\"Training session's progress over iterations\")\n",
    "plt.legend(loc='upper right', shadow=True)\n",
    "plt.ylabel('Training Progress (Loss or Accuracy values)')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.ylim(0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215e429d668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 46s 10ms/step - loss: 0.5827 - acc: 0.7189 - val_loss: 0.6456 - val_acc: 0.6346\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.5054 - acc: 0.7591 - val_loss: 0.6067 - val_acc: 0.6738\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.4212 - acc: 0.8094 - val_loss: 0.4851 - val_acc: 0.7574\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.3419 - acc: 0.8487 - val_loss: 0.4656 - val_acc: 0.7773\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.2743 - acc: 0.8849 - val_loss: 0.4580 - val_acc: 0.7875\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.2214 - acc: 0.9074 - val_loss: 0.4747 - val_acc: 0.7895\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1703 - acc: 0.9321 - val_loss: 0.4172 - val_acc: 0.8262\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1276 - acc: 0.9534 - val_loss: 0.4195 - val_acc: 0.8379\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0931 - acc: 0.9687 - val_loss: 0.3974 - val_acc: 0.8445\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0644 - acc: 0.9794 - val_loss: 0.8213 - val_acc: 0.7701\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0480 - acc: 0.9857 - val_loss: 0.4288 - val_acc: 0.8614\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0336 - acc: 0.9915 - val_loss: 0.4203 - val_acc: 0.8675\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0284 - acc: 0.9915 - val_loss: 0.6437 - val_acc: 0.8282\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0201 - acc: 0.9953 - val_loss: 0.5249 - val_acc: 0.8558\n",
      "1175/1175 [==============================] - 1s 923us/step\n",
      "4700/4700 [==============================] - 4s 924us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 41s 9ms/step - loss: 0.5857 - acc: 0.7121 - val_loss: 0.6403 - val_acc: 0.6407\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.5096 - acc: 0.7557 - val_loss: 0.6076 - val_acc: 0.6621\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.4279 - acc: 0.8100 - val_loss: 0.5306 - val_acc: 0.7299\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.3467 - acc: 0.8517 - val_loss: 0.4722 - val_acc: 0.7778\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.2864 - acc: 0.8779 - val_loss: 0.4030 - val_acc: 0.8053\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.2327 - acc: 0.9049 - val_loss: 0.4277 - val_acc: 0.8048\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1858 - acc: 0.9270 - val_loss: 0.5023 - val_acc: 0.7936\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1491 - acc: 0.9404 - val_loss: 0.4714 - val_acc: 0.8002\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1053 - acc: 0.9630 - val_loss: 0.4608 - val_acc: 0.8186\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.0775 - acc: 0.9728 - val_loss: 0.4549 - val_acc: 0.8267\n",
      "1175/1175 [==============================] - 1s 1ms/step\n",
      "4700/4700 [==============================] - 5s 1ms/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 43s 9ms/step - loss: 0.6522 - acc: 0.6023 - val_loss: 0.6019 - val_acc: 0.6835\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.5461 - acc: 0.7123 - val_loss: 0.5345 - val_acc: 0.7294\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.4357 - acc: 0.7887 - val_loss: 0.4477 - val_acc: 0.7849\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.3507 - acc: 0.8472 - val_loss: 0.3855 - val_acc: 0.8180\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.2804 - acc: 0.8849 - val_loss: 0.3853 - val_acc: 0.8272\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.2225 - acc: 0.9066 - val_loss: 0.3517 - val_acc: 0.8435\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1743 - acc: 0.9343 - val_loss: 0.4176 - val_acc: 0.8257\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.1373 - acc: 0.9526 - val_loss: 0.3881 - val_acc: 0.8558\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.1110 - acc: 0.9632 - val_loss: 0.3555 - val_acc: 0.8573\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0843 - acc: 0.9738 - val_loss: 0.4167 - val_acc: 0.8542\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.0652 - acc: 0.9800 - val_loss: 0.4374 - val_acc: 0.8563\n",
      "1175/1175 [==============================] - 1s 1ms/step\n",
      "4700/4700 [==============================] - 5s 991us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 41s 9ms/step - loss: 0.6464 - acc: 0.6185 - val_loss: 0.6601 - val_acc: 0.6121\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.5373 - acc: 0.7236 - val_loss: 0.5220 - val_acc: 0.7375\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.4313 - acc: 0.7947 - val_loss: 0.4651 - val_acc: 0.7742\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.3570 - acc: 0.8402 - val_loss: 0.4080 - val_acc: 0.8048\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.2894 - acc: 0.8813 - val_loss: 0.3806 - val_acc: 0.8206\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.2361 - acc: 0.9009 - val_loss: 0.4045 - val_acc: 0.8099\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.1866 - acc: 0.9221 - val_loss: 0.4096 - val_acc: 0.8165\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.1500 - acc: 0.9417 - val_loss: 0.5122 - val_acc: 0.7956\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.1142 - acc: 0.9579 - val_loss: 0.4075 - val_acc: 0.8394\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0862 - acc: 0.9706 - val_loss: 0.4160 - val_acc: 0.8435\n",
      "1175/1175 [==============================] - 1s 961us/step\n",
      "4700/4700 [==============================] - 4s 955us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 41s 9ms/step - loss: 0.6476 - acc: 0.6151 - val_loss: 0.6096 - val_acc: 0.6616\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.5471 - acc: 0.7194 - val_loss: 0.5435 - val_acc: 0.7146\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.4453 - acc: 0.7902 - val_loss: 0.4631 - val_acc: 0.7564\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.3594 - acc: 0.8381 - val_loss: 0.4297 - val_acc: 0.7844\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.2849 - acc: 0.8836 - val_loss: 0.5232 - val_acc: 0.7604\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.2270 - acc: 0.9077 - val_loss: 0.3963 - val_acc: 0.8201\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1729 - acc: 0.9381 - val_loss: 0.3910 - val_acc: 0.8252\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.1339 - acc: 0.9526 - val_loss: 0.3812 - val_acc: 0.8415\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0969 - acc: 0.9696 - val_loss: 0.4582 - val_acc: 0.8333\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0799 - acc: 0.9713 - val_loss: 0.3859 - val_acc: 0.8491\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0522 - acc: 0.9849 - val_loss: 0.4070 - val_acc: 0.8644\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 38s 8ms/step - loss: 0.0385 - acc: 0.9915 - val_loss: 0.5064 - val_acc: 0.8400\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 37s 8ms/step - loss: 0.0336 - acc: 0.9906 - val_loss: 0.4935 - val_acc: 0.8440\n",
      "1175/1175 [==============================] - 1s 953us/step\n",
      "4700/4700 [==============================] - 5s 969us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 24s 5ms/step - loss: 0.6031 - acc: 0.7047 - val_loss: 0.6988 - val_acc: 0.5836\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.5371 - acc: 0.7432 - val_loss: 0.6254 - val_acc: 0.6570\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.4803 - acc: 0.7774 - val_loss: 0.5941 - val_acc: 0.6769\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4124 - acc: 0.8143 - val_loss: 0.5803 - val_acc: 0.6906\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.3502 - acc: 0.8491 - val_loss: 0.4603 - val_acc: 0.7798\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2961 - acc: 0.8726 - val_loss: 0.4454 - val_acc: 0.7915\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2464 - acc: 0.8996 - val_loss: 0.5006 - val_acc: 0.7752\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2047 - acc: 0.9191 - val_loss: 0.5241 - val_acc: 0.7798ETA: 1s \n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1688 - acc: 0.9345 - val_loss: 0.4067 - val_acc: 0.8262\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1375 - acc: 0.9545 - val_loss: 0.4641 - val_acc: 0.8191\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.1067 - acc: 0.9638 - val_loss: 0.5405 - val_acc: 0.8007\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0866 - acc: 0.9687 - val_loss: 0.4426 - val_acc: 0.8389 lo\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0647 - acc: 0.9789 - val_loss: 0.4817 - val_acc: 0.8323\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0504 - acc: 0.9836 - val_loss: 0.5029 - val_acc: 0.8394\n",
      "1175/1175 [==============================] - 1s 513us/step\n",
      "4700/4700 [==============================] - 2s 518us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 24s 5ms/step - loss: 0.5953 - acc: 0.7055 - val_loss: 0.7202 - val_acc: 0.5780\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.5275 - acc: 0.7466 - val_loss: 0.5959 - val_acc: 0.6672\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4683 - acc: 0.7826 - val_loss: 0.5318 - val_acc: 0.7268\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4140 - acc: 0.8134 - val_loss: 0.5853 - val_acc: 0.6967\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3547 - acc: 0.8445 - val_loss: 0.4711 - val_acc: 0.7655\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3019 - acc: 0.8715 - val_loss: 0.4340 - val_acc: 0.7992\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2598 - acc: 0.8938 - val_loss: 0.5205 - val_acc: 0.7671\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2193 - acc: 0.9123 - val_loss: 0.4426 - val_acc: 0.7971\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.1762 - acc: 0.9317 - val_loss: 0.3983 - val_acc: 0.8206\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1474 - acc: 0.9430 - val_loss: 0.4387 - val_acc: 0.8119\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 21s 5ms/step - loss: 0.1122 - acc: 0.9598 - val_loss: 0.4765 - val_acc: 0.8160\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 22s 5ms/step - loss: 0.0948 - acc: 0.9689 - val_loss: 0.4280 - val_acc: 0.8338\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 21s 5ms/step - loss: 0.0696 - acc: 0.9796 - val_loss: 0.4718 - val_acc: 0.8242\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0521 - acc: 0.9851 - val_loss: 0.4546 - val_acc: 0.8400\n",
      "1175/1175 [==============================] - 1s 511us/step\n",
      "4700/4700 [==============================] - 2s 521us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 23s 5ms/step - loss: 0.6612 - acc: 0.5960 - val_loss: 0.6161 - val_acc: 0.6636\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.5830 - acc: 0.6874 - val_loss: 0.5605 - val_acc: 0.7054\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.5060 - acc: 0.7521 - val_loss: 0.5155 - val_acc: 0.7441\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4329 - acc: 0.7917 - val_loss: 0.4560 - val_acc: 0.7788\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3635 - acc: 0.8432 - val_loss: 0.4451 - val_acc: 0.7844\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3103 - acc: 0.8728 - val_loss: 0.4638 - val_acc: 0.7778\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.2609 - acc: 0.8938 - val_loss: 0.4129 - val_acc: 0.8201\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2202 - acc: 0.9109 - val_loss: 0.3974 - val_acc: 0.8201\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1857 - acc: 0.9304 - val_loss: 0.3880 - val_acc: 0.8318\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1520 - acc: 0.9434 - val_loss: 0.3688 - val_acc: 0.8507\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1194 - acc: 0.9585 - val_loss: 0.3782 - val_acc: 0.8532\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.0971 - acc: 0.9668 - val_loss: 0.4814 - val_acc: 0.8272\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0778 - acc: 0.9762 - val_loss: 0.3963 - val_acc: 0.8563\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0643 - acc: 0.9802 - val_loss: 0.4033 - val_acc: 0.8563\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.0574 - acc: 0.9823 - val_loss: 0.3952 - val_acc: 0.8665\n",
      "1175/1175 [==============================] - 1s 515us/step\n",
      "4700/4700 [==============================] - 2s 515us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 24s 5ms/step - loss: 0.6563 - acc: 0.6053 - val_loss: 0.6237 - val_acc: 0.6315\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.5778 - acc: 0.7019 - val_loss: 0.5581 - val_acc: 0.7192\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4997 - acc: 0.7577 - val_loss: 0.4940 - val_acc: 0.7620\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4135 - acc: 0.8111 - val_loss: 0.5418 - val_acc: 0.7431 1s - loss: 0.4164 - acc: - ETA: 1s - loss:\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3532 - acc: 0.8470 - val_loss: 0.4447 - val_acc: 0.7890\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2993 - acc: 0.8696 - val_loss: 0.4062 - val_acc: 0.8135\n",
      "Epoch 7/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2573 - acc: 0.8960 - val_loss: 0.3918 - val_acc: 0.8201\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2176 - acc: 0.9128 - val_loss: 0.4232 - val_acc: 0.8145\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1847 - acc: 0.9291 - val_loss: 0.3907 - val_acc: 0.8369\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1496 - acc: 0.9443 - val_loss: 0.3992 - val_acc: 0.8344\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1250 - acc: 0.9521 - val_loss: 0.4342 - val_acc: 0.8282\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 21s 5ms/step - loss: 0.1018 - acc: 0.9653 - val_loss: 0.4339 - val_acc: 0.8303\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.0801 - acc: 0.9777 - val_loss: 0.5546 - val_acc: 0.8170\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.0616 - acc: 0.9836 - val_loss: 0.4017 - val_acc: 0.8609\n",
      "1175/1175 [==============================] - 1s 517us/step\n",
      "4700/4700 [==============================] - 2s 520us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 24s 5ms/step - loss: 0.6573 - acc: 0.5913 - val_loss: 0.6338 - val_acc: 0.6284\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.5721 - acc: 0.6985 - val_loss: 0.5769 - val_acc: 0.6993\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.4925 - acc: 0.7664 - val_loss: 0.5049 - val_acc: 0.7497\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.4152 - acc: 0.8087 - val_loss: 0.5043 - val_acc: 0.7543\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3606 - acc: 0.8453 - val_loss: 0.4468 - val_acc: 0.7885\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.3111 - acc: 0.8696 - val_loss: 0.4543 - val_acc: 0.7951 - loss: 0.3143 - acc: 0.8 - ETA: 2s - loss: 0.3128 - acc: 0.8 - ETA: 2s - loss - ETA: 0s - loss: 0.3105 \n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2695 - acc: 0.8866 - val_loss: 0.4159 - val_acc: 0.8124\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.2296 - acc: 0.9106 - val_loss: 0.4166 - val_acc: 0.8150\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.2044 - acc: 0.9204 - val_loss: 0.4175 - val_acc: 0.8338\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 21s 4ms/step - loss: 0.1667 - acc: 0.9413 - val_loss: 0.4831 - val_acc: 0.8033\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1421 - acc: 0.9489 - val_loss: 0.4211 - val_acc: 0.8328\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 20s 4ms/step - loss: 0.1246 - acc: 0.9545 - val_loss: 0.4336 - val_acc: 0.8344\n",
      "1175/1175 [==============================] - 1s 538us/step\n",
      "4700/4700 [==============================] - 3s 546us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 17s 4ms/step - loss: 0.6056 - acc: 0.6987 - val_loss: 0.6600 - val_acc: 0.6014\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5489 - acc: 0.7309 - val_loss: 0.6260 - val_acc: 0.6509\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5026 - acc: 0.7632 - val_loss: 0.5884 - val_acc: 0.6820\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4639 - acc: 0.7857 - val_loss: 0.5617 - val_acc: 0.7171\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4170 - acc: 0.8126 - val_loss: 0.5948 - val_acc: 0.6881\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3708 - acc: 0.8381 - val_loss: 0.5023 - val_acc: 0.7411\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3282 - acc: 0.8547 - val_loss: 0.4854 - val_acc: 0.7737\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2819 - acc: 0.8851 - val_loss: 0.5112 - val_acc: 0.7615\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2392 - acc: 0.9026 - val_loss: 0.4277 - val_acc: 0.8012\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2105 - acc: 0.9179 - val_loss: 0.4209 - val_acc: 0.8150\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1791 - acc: 0.9304 - val_loss: 0.4325 - val_acc: 0.8114\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1532 - acc: 0.9379 - val_loss: 0.5011 - val_acc: 0.7946\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1318 - acc: 0.9509 - val_loss: 0.4017 - val_acc: 0.8293\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1070 - acc: 0.9636 - val_loss: 0.5024 - val_acc: 0.8058\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0884 - acc: 0.9717 - val_loss: 0.4321 - val_acc: 0.8318\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0796 - acc: 0.9723 - val_loss: 0.4957 - val_acc: 0.8170\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0630 - acc: 0.9802 - val_loss: 0.4761 - val_acc: 0.8242\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0505 - acc: 0.9879 - val_loss: 0.5850 - val_acc: 0.8135\n",
      "1175/1175 [==============================] - 1s 461us/step\n",
      "4700/4700 [==============================] - 2s 457us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 16s 3ms/step - loss: 0.6025 - acc: 0.7053 - val_loss: 0.6687 - val_acc: 0.6055\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5453 - acc: 0.7355 - val_loss: 0.6027 - val_acc: 0.6723\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5016 - acc: 0.7668 - val_loss: 0.5736 - val_acc: 0.7049\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4611 - acc: 0.7830 - val_loss: 0.6618 - val_acc: 0.6330\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4166 - acc: 0.8138 - val_loss: 0.5473 - val_acc: 0.7248\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 14s 3ms/step - loss: 0.3800 - acc: 0.8300 - val_loss: 0.5334 - val_acc: 0.7314\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3387 - acc: 0.8553 - val_loss: 0.5449 - val_acc: 0.7319\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2975 - acc: 0.8781 - val_loss: 0.4965 - val_acc: 0.7615\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2666 - acc: 0.8866 - val_loss: 0.5640 - val_acc: 0.7396\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2379 - acc: 0.9009 - val_loss: 0.4480 - val_acc: 0.7926\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2031 - acc: 0.9211 - val_loss: 0.4304 - val_acc: 0.8043\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1852 - acc: 0.9298 - val_loss: 0.4845 - val_acc: 0.7926\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1549 - acc: 0.9387 - val_loss: 0.4702 - val_acc: 0.7956\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1357 - acc: 0.9513 - val_loss: 0.4618 - val_acc: 0.8104\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1132 - acc: 0.9555 - val_loss: 0.5707 - val_acc: 0.7839\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0990 - acc: 0.9683 - val_loss: 0.5272 - val_acc: 0.7997\n",
      "1175/1175 [==============================] - 1s 481us/step\n",
      "4700/4700 [==============================] - 2s 472us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 17s 4ms/step - loss: 0.6670 - acc: 0.5766 - val_loss: 0.6276 - val_acc: 0.6157\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5891 - acc: 0.6913 - val_loss: 0.5807 - val_acc: 0.6794\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5312 - acc: 0.7317 - val_loss: 0.5793 - val_acc: 0.6947\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4756 - acc: 0.7719 - val_loss: 0.5114 - val_acc: 0.7482\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4195 - acc: 0.8126 - val_loss: 0.4784 - val_acc: 0.7691\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3720 - acc: 0.8334 - val_loss: 0.4545 - val_acc: 0.7783\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3274 - acc: 0.8636 - val_loss: 0.4594 - val_acc: 0.7798\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2974 - acc: 0.8770 - val_loss: 0.4172 - val_acc: 0.8068\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2633 - acc: 0.8913 - val_loss: 0.4033 - val_acc: 0.8252\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2292 - acc: 0.9096 - val_loss: 0.3949 - val_acc: 0.8293\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2055 - acc: 0.9234 - val_loss: 0.4675 - val_acc: 0.8017\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1733 - acc: 0.9381 - val_loss: 0.3889 - val_acc: 0.8369\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1456 - acc: 0.9528 - val_loss: 0.4221 - val_acc: 0.8374\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 14s 3ms/step - loss: 0.1282 - acc: 0.9540 - val_loss: 0.3851 - val_acc: 0.8461\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1081 - acc: 0.9689 - val_loss: 0.4155 - val_acc: 0.8435\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0939 - acc: 0.9717 - val_loss: 0.4502 - val_acc: 0.8318\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0882 - acc: 0.9711 - val_loss: 0.4096 - val_acc: 0.8537\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0661 - acc: 0.9813 - val_loss: 0.4177 - val_acc: 0.8537\n",
      "Epoch 19/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0650 - acc: 0.9828 - val_loss: 0.4186 - val_acc: 0.8573\n",
      "1175/1175 [==============================] - 1s 480us/step\n",
      "4700/4700 [==============================] - 2s 482us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 16s 4ms/step - loss: 0.6646 - acc: 0.5879 - val_loss: 0.6507 - val_acc: 0.5805\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5930 - acc: 0.6826 - val_loss: 0.5891 - val_acc: 0.6860\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.5318 - acc: 0.7387 - val_loss: 0.5371 - val_acc: 0.7187\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4654 - acc: 0.7777 - val_loss: 0.5123 - val_acc: 0.7548\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4126 - acc: 0.8166 - val_loss: 0.4783 - val_acc: 0.7625\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3659 - acc: 0.8440 - val_loss: 0.4596 - val_acc: 0.7890\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3229 - acc: 0.8623 - val_loss: 0.4546 - val_acc: 0.7870\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2932 - acc: 0.8747 - val_loss: 0.4337 - val_acc: 0.8017\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2613 - acc: 0.8921 - val_loss: 0.4767 - val_acc: 0.7824\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2321 - acc: 0.9091 - val_loss: 0.3858 - val_acc: 0.8313\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2060 - acc: 0.9213 - val_loss: 0.3916 - val_acc: 0.8293\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1858 - acc: 0.9304 - val_loss: 0.3865 - val_acc: 0.8389\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1613 - acc: 0.9413 - val_loss: 0.4127 - val_acc: 0.8231\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1426 - acc: 0.9477 - val_loss: 0.4186 - val_acc: 0.8226\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1304 - acc: 0.9536 - val_loss: 0.3881 - val_acc: 0.8517\n",
      "1175/1175 [==============================] - 1s 460us/step\n",
      "4700/4700 [==============================] - 2s 461us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 17s 4ms/step - loss: 0.6654 - acc: 0.5847 - val_loss: 0.7065 - val_acc: 0.5240\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 14s 3ms/step - loss: 0.5905 - acc: 0.6783 - val_loss: 0.5849 - val_acc: 0.6947\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 14s 3ms/step - loss: 0.5240 - acc: 0.7389 - val_loss: 0.5468 - val_acc: 0.7227\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.4662 - acc: 0.7830 - val_loss: 0.5102 - val_acc: 0.7497\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 14s 3ms/step - loss: 0.4107 - acc: 0.8140 - val_loss: 0.5037 - val_acc: 0.7523\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3706 - acc: 0.8364 - val_loss: 0.4855 - val_acc: 0.7706\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3403 - acc: 0.8579 - val_loss: 0.4664 - val_acc: 0.7819\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.3037 - acc: 0.8706 - val_loss: 0.4536 - val_acc: 0.7961\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2697 - acc: 0.8864 - val_loss: 0.5129 - val_acc: 0.7762\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2452 - acc: 0.9028 - val_loss: 0.4800 - val_acc: 0.7946\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2248 - acc: 0.9119 - val_loss: 0.4555 - val_acc: 0.8033\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.2053 - acc: 0.9200 - val_loss: 0.4523 - val_acc: 0.8063\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1850 - acc: 0.9289 - val_loss: 0.4695 - val_acc: 0.8175\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1588 - acc: 0.9421 - val_loss: 0.4207 - val_acc: 0.8303\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1424 - acc: 0.9513 - val_loss: 0.4434 - val_acc: 0.8247\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1219 - acc: 0.9568 - val_loss: 0.4349 - val_acc: 0.8277\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.1085 - acc: 0.9647 - val_loss: 0.4178 - val_acc: 0.8349\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0968 - acc: 0.9689 - val_loss: 0.4385 - val_acc: 0.8384\n",
      "Epoch 19/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0813 - acc: 0.9757 - val_loss: 0.4690 - val_acc: 0.8384\n",
      "Epoch 20/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0752 - acc: 0.9774 - val_loss: 0.4922 - val_acc: 0.8298\n",
      "Epoch 21/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0692 - acc: 0.9760 - val_loss: 0.5322 - val_acc: 0.8303\n",
      "Epoch 22/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.0546 - acc: 0.9832 - val_loss: 0.4749 - val_acc: 0.8379\n",
      "1175/1175 [==============================] - 1s 502us/step\n",
      "4700/4700 [==============================] - 2s 491us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.6248 - acc: 0.6953 - val_loss: 0.6742 - val_acc: 0.5617\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5675 - acc: 0.7200 - val_loss: 0.6308 - val_acc: 0.6448\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5331 - acc: 0.7436 - val_loss: 0.6484 - val_acc: 0.6295\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.4960 - acc: 0.7615 - val_loss: 0.6153 - val_acc: 0.6631\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4634 - acc: 0.7857 - val_loss: 0.5686 - val_acc: 0.7090\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4273 - acc: 0.8094 - val_loss: 0.5755 - val_acc: 0.6922\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3982 - acc: 0.8211 - val_loss: 0.6031 - val_acc: 0.6830\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3650 - acc: 0.8423 - val_loss: 0.4941 - val_acc: 0.7528\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3337 - acc: 0.8579 - val_loss: 0.4669 - val_acc: 0.7798\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2971 - acc: 0.8774 - val_loss: 0.5094 - val_acc: 0.7523\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2736 - acc: 0.8889 - val_loss: 0.5013 - val_acc: 0.7712\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2451 - acc: 0.9053 - val_loss: 0.4781 - val_acc: 0.7793\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2272 - acc: 0.9077 - val_loss: 0.4257 - val_acc: 0.8119\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1986 - acc: 0.9268 - val_loss: 0.4452 - val_acc: 0.8084\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1818 - acc: 0.9306 - val_loss: 0.4405 - val_acc: 0.8053\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1564 - acc: 0.9451 - val_loss: 0.4774 - val_acc: 0.8068\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1465 - acc: 0.9445 - val_loss: 0.4502 - val_acc: 0.8155\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1308 - acc: 0.9515 - val_loss: 0.4607 - val_acc: 0.8145\n",
      "1175/1175 [==============================] - 0s 409us/step\n",
      "4700/4700 [==============================] - 2s 389us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.6123 - acc: 0.6991 - val_loss: 0.6536 - val_acc: 0.6239\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5557 - acc: 0.7323 - val_loss: 0.6568 - val_acc: 0.6397\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5208 - acc: 0.7468 - val_loss: 0.7137 - val_acc: 0.5973\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4819 - acc: 0.7717 - val_loss: 0.6505 - val_acc: 0.6361\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4408 - acc: 0.7979 - val_loss: 0.5358 - val_acc: 0.7212\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4112 - acc: 0.8162 - val_loss: 0.5582 - val_acc: 0.7151\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3811 - acc: 0.8313 - val_loss: 0.5014 - val_acc: 0.7503\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3467 - acc: 0.8532 - val_loss: 0.4966 - val_acc: 0.7655\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3202 - acc: 0.8653 - val_loss: 0.4812 - val_acc: 0.7717\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2906 - acc: 0.8762 - val_loss: 0.5413 - val_acc: 0.7370\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2690 - acc: 0.8913 - val_loss: 0.5637 - val_acc: 0.7416\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2471 - acc: 0.9013 - val_loss: 0.5196 - val_acc: 0.7564\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2383 - acc: 0.9060 - val_loss: 0.4834 - val_acc: 0.7788\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2073 - acc: 0.9204 - val_loss: 0.4662 - val_acc: 0.7905\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1886 - acc: 0.9298 - val_loss: 0.4606 - val_acc: 0.8002\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1798 - acc: 0.9338 - val_loss: 0.4142 - val_acc: 0.8180\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1598 - acc: 0.9417 - val_loss: 0.4300 - val_acc: 0.8150\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.1423 - acc: 0.9504 - val_loss: 0.4459 - val_acc: 0.8160\n",
      "Epoch 19/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.1295 - acc: 0.9543 - val_loss: 0.4603 - val_acc: 0.8002\n",
      "Epoch 20/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.1209 - acc: 0.9591 - val_loss: 0.4917 - val_acc: 0.8022\n",
      "Epoch 21/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1048 - acc: 0.9655 - val_loss: 0.4681 - val_acc: 0.8150\n",
      "1175/1175 [==============================] - 0s 394us/step\n",
      "4700/4700 [==============================] - 2s 390us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.6804 - acc: 0.5557 - val_loss: 0.6701 - val_acc: 0.5571\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.6309 - acc: 0.6274 - val_loss: 0.6056 - val_acc: 0.6616\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5708 - acc: 0.7100 - val_loss: 0.5691 - val_acc: 0.7059\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5257 - acc: 0.7411 - val_loss: 0.5476 - val_acc: 0.7125\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4849 - acc: 0.7721 - val_loss: 0.5339 - val_acc: 0.7309\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4503 - acc: 0.7957 - val_loss: 0.5050 - val_acc: 0.7559\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4143 - acc: 0.8138 - val_loss: 0.4892 - val_acc: 0.7696\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3838 - acc: 0.8353 - val_loss: 0.4721 - val_acc: 0.7757\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3503 - acc: 0.8532 - val_loss: 0.4619 - val_acc: 0.7819\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3234 - acc: 0.8649 - val_loss: 0.4420 - val_acc: 0.7941\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2955 - acc: 0.8781 - val_loss: 0.4328 - val_acc: 0.7977\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2664 - acc: 0.8955 - val_loss: 0.4532 - val_acc: 0.7946\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2486 - acc: 0.9021 - val_loss: 0.4640 - val_acc: 0.8012\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2219 - acc: 0.9160 - val_loss: 0.4173 - val_acc: 0.8180\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2077 - acc: 0.9226 - val_loss: 0.4244 - val_acc: 0.8242\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1779 - acc: 0.9391 - val_loss: 0.4713 - val_acc: 0.8073\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1608 - acc: 0.9445 - val_loss: 0.4061 - val_acc: 0.8349\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1519 - acc: 0.9443 - val_loss: 0.4148 - val_acc: 0.8359\n",
      "Epoch 19/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1302 - acc: 0.9560 - val_loss: 0.4026 - val_acc: 0.8389\n",
      "Epoch 20/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1253 - acc: 0.9553 - val_loss: 0.4022 - val_acc: 0.8466\n",
      "Epoch 21/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.0984 - acc: 0.9702 - val_loss: 0.4101 - val_acc: 0.8430\n",
      "Epoch 22/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.0964 - acc: 0.9679 - val_loss: 0.4113 - val_acc: 0.8481\n",
      "Epoch 23/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.0791 - acc: 0.9791 - val_loss: 0.4323 - val_acc: 0.8384\n",
      "Epoch 24/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.0722 - acc: 0.9798 - val_loss: 0.4216 - val_acc: 0.8507\n",
      "Epoch 25/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.0658 - acc: 0.9819 - val_loss: 0.4579 - val_acc: 0.8389\n",
      "1175/1175 [==============================] - 0s 399us/step\n",
      "4700/4700 [==============================] - 2s 398us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.6671 - acc: 0.5862 - val_loss: 0.6693 - val_acc: 0.5596\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.6149 - acc: 0.6551 - val_loss: 0.6573 - val_acc: 0.6106\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5596 - acc: 0.7132 - val_loss: 0.6118 - val_acc: 0.6386\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5209 - acc: 0.7504 - val_loss: 0.5803 - val_acc: 0.7095\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.4814 - acc: 0.7749 - val_loss: 0.5304 - val_acc: 0.7457\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.4398 - acc: 0.8060 - val_loss: 0.5246 - val_acc: 0.7467\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4078 - acc: 0.8185 - val_loss: 0.4814 - val_acc: 0.7691\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3752 - acc: 0.8396 - val_loss: 0.4602 - val_acc: 0.7829\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3462 - acc: 0.8543 - val_loss: 0.4588 - val_acc: 0.7839\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3271 - acc: 0.8649 - val_loss: 0.4529 - val_acc: 0.7824\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2976 - acc: 0.8802 - val_loss: 0.4445 - val_acc: 0.7936\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2791 - acc: 0.8855 - val_loss: 0.4373 - val_acc: 0.8028\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2593 - acc: 0.8951 - val_loss: 0.4260 - val_acc: 0.7997\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2464 - acc: 0.9009 - val_loss: 0.5957 - val_acc: 0.7497\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2286 - acc: 0.9106 - val_loss: 0.4554 - val_acc: 0.7997\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2056 - acc: 0.9213 - val_loss: 0.4399 - val_acc: 0.8084\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1968 - acc: 0.9234 - val_loss: 0.4054 - val_acc: 0.8272\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1819 - acc: 0.9285 - val_loss: 0.4048 - val_acc: 0.8287\n",
      "Epoch 19/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1597 - acc: 0.9415 - val_loss: 0.4020 - val_acc: 0.8344\n",
      "Epoch 20/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1420 - acc: 0.9487 - val_loss: 0.4209 - val_acc: 0.8354\n",
      "Epoch 21/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1364 - acc: 0.9523 - val_loss: 0.4815 - val_acc: 0.8175\n",
      "Epoch 22/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1193 - acc: 0.9596 - val_loss: 0.4990 - val_acc: 0.8124\n",
      "Epoch 23/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1038 - acc: 0.9683 - val_loss: 0.4330 - val_acc: 0.8384\n",
      "Epoch 24/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.0953 - acc: 0.9694 - val_loss: 0.4245 - val_acc: 0.8430\n",
      "1175/1175 [==============================] - 0s 412us/step\n",
      "4700/4700 [==============================] - 2s 404us/step\n",
      "Train on 4700 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "4700/4700 [==============================] - 13s 3ms/step - loss: 0.6683 - acc: 0.5823 - val_loss: 0.6781 - val_acc: 0.5311\n",
      "Epoch 2/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.6132 - acc: 0.6491 - val_loss: 0.6269 - val_acc: 0.6514\n",
      "Epoch 3/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5616 - acc: 0.7117 - val_loss: 0.5804 - val_acc: 0.6860\n",
      "Epoch 4/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.5102 - acc: 0.7594 - val_loss: 0.5948 - val_acc: 0.6911\n",
      "Epoch 5/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4790 - acc: 0.7749 - val_loss: 0.5835 - val_acc: 0.7166\n",
      "Epoch 6/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4473 - acc: 0.7936 - val_loss: 0.5503 - val_acc: 0.7141\n",
      "Epoch 7/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.4116 - acc: 0.8211 - val_loss: 0.5122 - val_acc: 0.7497\n",
      "Epoch 8/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3844 - acc: 0.8294 - val_loss: 0.5086 - val_acc: 0.7559\n",
      "Epoch 9/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3534 - acc: 0.8466 - val_loss: 0.4829 - val_acc: 0.7737\n",
      "Epoch 10/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3310 - acc: 0.8589 - val_loss: 0.4741 - val_acc: 0.7783\n",
      "Epoch 11/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.3035 - acc: 0.8757 - val_loss: 0.4553 - val_acc: 0.7895\n",
      "Epoch 12/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2871 - acc: 0.8845 - val_loss: 0.4500 - val_acc: 0.7977\n",
      "Epoch 13/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2622 - acc: 0.8945 - val_loss: 0.4742 - val_acc: 0.7808\n",
      "Epoch 14/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.2526 - acc: 0.8951 - val_loss: 0.4538 - val_acc: 0.7977\n",
      "Epoch 15/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2360 - acc: 0.9096 - val_loss: 0.4472 - val_acc: 0.7997\n",
      "Epoch 16/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.2178 - acc: 0.9177 - val_loss: 0.4519 - val_acc: 0.8068\n",
      "Epoch 17/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1985 - acc: 0.9245 - val_loss: 0.5349 - val_acc: 0.7829\n",
      "Epoch 18/500\n",
      "4700/4700 [==============================] - 10s 2ms/step - loss: 0.1846 - acc: 0.9302 - val_loss: 0.4460 - val_acc: 0.8033\n",
      "Epoch 19/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1631 - acc: 0.9426 - val_loss: 0.4592 - val_acc: 0.8094\n",
      "Epoch 20/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1527 - acc: 0.9453 - val_loss: 0.4477 - val_acc: 0.8165\n",
      "Epoch 21/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1430 - acc: 0.9474 - val_loss: 0.4615 - val_acc: 0.8216\n",
      "Epoch 22/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1297 - acc: 0.9528 - val_loss: 0.5907 - val_acc: 0.7982\n",
      "Epoch 23/500\n",
      "4700/4700 [==============================] - 9s 2ms/step - loss: 0.1257 - acc: 0.9536 - val_loss: 0.5255 - val_acc: 0.8043\n",
      "1175/1175 [==============================] - 0s 401us/step\n",
      "4700/4700 [==============================] - 2s 404us/step\n",
      "Train on 5875 samples, validate on 1962 samples\n",
      "Epoch 1/500\n",
      "5875/5875 [==============================] - 31s 5ms/step - loss: 0.6571 - acc: 0.6061 - val_loss: 0.6102 - val_acc: 0.6641\n",
      "Epoch 2/500\n",
      "5875/5875 [==============================] - 27s 5ms/step - loss: 0.5717 - acc: 0.6996 - val_loss: 0.5531 - val_acc: 0.6942\n",
      "Epoch 3/500\n",
      "5875/5875 [==============================] - 27s 5ms/step - loss: 0.4831 - acc: 0.7632 - val_loss: 0.4847 - val_acc: 0.7615\n",
      "Epoch 4/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.3982 - acc: 0.8204 - val_loss: 0.4269 - val_acc: 0.7961\n",
      "Epoch 5/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.3300 - acc: 0.8538 - val_loss: 0.3883 - val_acc: 0.8216\n",
      "Epoch 6/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.2788 - acc: 0.8846 - val_loss: 0.3789 - val_acc: 0.8231\n",
      "Epoch 7/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.2353 - acc: 0.9004 - val_loss: 0.3417 - val_acc: 0.8430\n",
      "Epoch 8/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.1891 - acc: 0.9263 - val_loss: 0.3477 - val_acc: 0.8435\n",
      "Epoch 9/500\n",
      "5875/5875 [==============================] - 27s 5ms/step - loss: 0.1622 - acc: 0.9370 - val_loss: 0.3601 - val_acc: 0.8517\n",
      "Epoch 10/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.1219 - acc: 0.9590 - val_loss: 0.3304 - val_acc: 0.8609\n",
      "Epoch 11/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.0989 - acc: 0.9675 - val_loss: 0.3338 - val_acc: 0.8716\n",
      "Epoch 12/500\n",
      "5875/5875 [==============================] - 26s 4ms/step - loss: 0.0847 - acc: 0.9711 - val_loss: 0.3658 - val_acc: 0.8639\n",
      "Epoch 13/500\n",
      "5875/5875 [==============================] - 27s 5ms/step - loss: 0.0634 - acc: 0.9828 - val_loss: 0.3776 - val_acc: 0.8634\n",
      "Epoch 14/500\n",
      "5875/5875 [==============================] - 27s 5ms/step - loss: 0.0472 - acc: 0.9879 - val_loss: 0.3707 - val_acc: 0.8736\n",
      "Epoch 15/500\n",
      "5875/5875 [==============================] - 26s 5ms/step - loss: 0.0417 - acc: 0.9896 - val_loss: 0.3659 - val_acc: 0.8767\n",
      "Best: 0.787404 using {'batch_size': 8}\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 96s 9ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 2.7182 - val_acc: 0.8080\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 92s 8ms/step - loss: 1.3029e-06 - acc: 1.0000 - val_loss: 2.8905 - val_acc: 0.8080\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 91s 8ms/step - loss: 3.0538e-07 - acc: 1.0000 - val_loss: 2.9824 - val_acc: 0.8080\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 92s 8ms/step - loss: 1.4850e-07 - acc: 1.0000 - val_loss: 3.0257 - val_acc: 0.8080\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 92s 8ms/step - loss: 1.1990e-07 - acc: 1.0000 - val_loss: 3.0531 - val_acc: 0.8080\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 92s 8ms/step - loss: 1.1187e-07 - acc: 1.0000 - val_loss: 3.0686 - val_acc: 0.8080\n",
      "2745/2745 [==============================] - 3s 1ms/step\n",
      "10977/10977 [==============================] - 13s 1ms/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 97s 9ms/step - loss: 0.3919 - acc: 0.8414 - val_loss: 0.2256 - val_acc: 0.9140\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.1523 - acc: 0.9401 - val_loss: 0.1124 - val_acc: 0.9569\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.0824 - acc: 0.9685 - val_loss: 0.1082 - val_acc: 0.9616\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 94s 9ms/step - loss: 0.0533 - acc: 0.9802 - val_loss: 0.0780 - val_acc: 0.9744\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.0291 - acc: 0.9897 - val_loss: 0.0675 - val_acc: 0.9759\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.0191 - acc: 0.9950 - val_loss: 0.0832 - val_acc: 0.9735\n",
      "Epoch 7/500\n",
      "10977/10977 [==============================] - 92s 8ms/step - loss: 0.0119 - acc: 0.9966 - val_loss: 0.0892 - val_acc: 0.9744\n",
      "Epoch 8/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0884 - val_acc: 0.9754\n",
      "Epoch 9/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.0070 - acc: 0.9983 - val_loss: 0.0808 - val_acc: 0.9791\n",
      "Epoch 10/500\n",
      "10977/10977 [==============================] - 93s 8ms/step - loss: 0.0037 - acc: 0.9994 - val_loss: 0.0737 - val_acc: 0.9838\n",
      "2745/2745 [==============================] - 3s 1ms/step\n",
      "10977/10977 [==============================] - 13s 1ms/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 97s 9ms/step - loss: 0.3994 - acc: 0.8408 - val_loss: 0.2815 - val_acc: 0.9002\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.2264 - acc: 0.9146 - val_loss: 0.1745 - val_acc: 0.9261\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.1148 - acc: 0.9555 - val_loss: 0.1147 - val_acc: 0.9552\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0638 - acc: 0.9755 - val_loss: 0.0897 - val_acc: 0.9647\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0386 - acc: 0.9868 - val_loss: 0.0730 - val_acc: 0.9731\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0201 - acc: 0.9939 - val_loss: 0.0975 - val_acc: 0.9709\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0148 - acc: 0.9956 - val_loss: 0.0675 - val_acc: 0.9791\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0113 - acc: 0.9965 - val_loss: 0.0824 - val_acc: 0.9763\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0976 - val_acc: 0.9741\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0672 - val_acc: 0.9825\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0702 - val_acc: 0.9823\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0702 - val_acc: 0.9830\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0643 - val_acc: 0.9830\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.0666 - val_acc: 0.9834\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0757 - val_acc: 0.9828\n",
      "Epoch 16/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 3.1756e-04 - acc: 1.0000 - val_loss: 0.0836 - val_acc: 0.9819\n",
      "Epoch 17/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 0.0053 - acc: 0.9988 - val_loss: 0.0828 - val_acc: 0.9834\n",
      "Epoch 18/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 9.2399e-04 - acc: 0.9999 - val_loss: 0.0794 - val_acc: 0.9847\n",
      "2744/2744 [==============================] - 3s 1ms/step\n",
      "10978/10978 [==============================] - 13s 1ms/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 96s 9ms/step - loss: 0.3846 - acc: 0.8411 - val_loss: 0.2150 - val_acc: 0.9136\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.1528 - acc: 0.9399 - val_loss: 0.1457 - val_acc: 0.9442\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0819 - acc: 0.9692 - val_loss: 0.0917 - val_acc: 0.9655\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0466 - acc: 0.9843 - val_loss: 0.0843 - val_acc: 0.9675\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 0.0288 - acc: 0.9911 - val_loss: 0.0569 - val_acc: 0.9802\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 94s 9ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1032 - val_acc: 0.9675\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0641 - val_acc: 0.9810\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0700 - val_acc: 0.9802\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0862 - val_acc: 0.9774\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10978/10978 [==============================] - 90s 8ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0761 - val_acc: 0.9828\n",
      "2744/2744 [==============================] - 3s 1ms/step\n",
      "10978/10978 [==============================] - 12s 1ms/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 97s 9ms/step - loss: 0.3829 - acc: 0.8423 - val_loss: 0.1935 - val_acc: 0.9293\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.1284 - acc: 0.9508 - val_loss: 0.1041 - val_acc: 0.9606\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0712 - acc: 0.9735 - val_loss: 0.0772 - val_acc: 0.9713\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 90s 8ms/step - loss: 0.0412 - acc: 0.9862 - val_loss: 0.0724 - val_acc: 0.9757\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0258 - acc: 0.9914 - val_loss: 0.0746 - val_acc: 0.9767\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0128 - acc: 0.9970 - val_loss: 0.0735 - val_acc: 0.9765\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0110 - acc: 0.9962 - val_loss: 0.0628 - val_acc: 0.9800\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0095 - acc: 0.9973 - val_loss: 0.0740 - val_acc: 0.9808\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0768 - val_acc: 0.9804\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0686 - val_acc: 0.9806\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0571 - val_acc: 0.9821\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0573 - val_acc: 0.9847\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 93s 8ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0579 - val_acc: 0.9860\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0683 - val_acc: 0.9804\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0621 - val_acc: 0.9830\n",
      "Epoch 16/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0533 - val_acc: 0.9871\n",
      "Epoch 17/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0719 - val_acc: 0.9810\n",
      "Epoch 18/500\n",
      "10978/10978 [==============================] - 90s 8ms/step - loss: 2.9289e-04 - acc: 1.0000 - val_loss: 0.0647 - val_acc: 0.9856\n",
      "Epoch 19/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 0.0038 - acc: 0.9993 - val_loss: 0.0556 - val_acc: 0.9856\n",
      "Epoch 20/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 1.8512e-04 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9879\n",
      "Epoch 21/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 4.6929e-05 - acc: 1.0000 - val_loss: 0.0532 - val_acc: 0.9877\n",
      "Epoch 22/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 9.9572e-04 - acc: 0.9995 - val_loss: 0.0818 - val_acc: 0.9832\n",
      "Epoch 23/500\n",
      "10978/10978 [==============================] - 91s 8ms/step - loss: 2.9724e-04 - acc: 1.0000 - val_loss: 0.0831 - val_acc: 0.9843\n",
      "Epoch 24/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0656 - val_acc: 0.9862\n",
      "Epoch 25/500\n",
      "10978/10978 [==============================] - 92s 8ms/step - loss: 3.5745e-05 - acc: 1.0000 - val_loss: 0.0654 - val_acc: 0.9866\n",
      "2744/2744 [==============================] - 3s 1ms/step\n",
      "10978/10978 [==============================] - 13s 1ms/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 54s 5ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 2.5621 - val_acc: 0.8080\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 49s 4ms/step - loss: 4.3686e-06 - acc: 1.0000 - val_loss: 2.7530 - val_acc: 0.8080\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 1.3129e-06 - acc: 1.0000 - val_loss: 2.8544 - val_acc: 0.8080\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 49s 4ms/step - loss: 5.4710e-07 - acc: 1.0000 - val_loss: 2.9167 - val_acc: 0.8080\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 2.8639e-07 - acc: 1.0000 - val_loss: 2.9600 - val_acc: 0.8080\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 1.8950e-07 - acc: 1.0000 - val_loss: 2.9918 - val_acc: 0.8080\n",
      "2745/2745 [==============================] - 2s 660us/step\n",
      "10977/10977 [==============================] - 7s 658us/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 52s 5ms/step - loss: 0.4288 - acc: 0.8228 - val_loss: 0.3036 - val_acc: 0.8953\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.2639 - acc: 0.8994 - val_loss: 0.1839 - val_acc: 0.9323\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.1433 - acc: 0.9431 - val_loss: 0.1448 - val_acc: 0.9429\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 49s 4ms/step - loss: 0.0873 - acc: 0.9657 - val_loss: 0.1244 - val_acc: 0.9524\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0601 - acc: 0.9784 - val_loss: 0.1028 - val_acc: 0.9616\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0372 - acc: 0.9882 - val_loss: 0.0795 - val_acc: 0.9698\n",
      "Epoch 7/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0277 - acc: 0.9921 - val_loss: 0.0824 - val_acc: 0.9683\n",
      "Epoch 8/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0164 - acc: 0.9956 - val_loss: 0.0965 - val_acc: 0.9692\n",
      "Epoch 9/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0099 - acc: 0.9978 - val_loss: 0.1029 - val_acc: 0.9705\n",
      "Epoch 10/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.0797 - val_acc: 0.9782\n",
      "Epoch 11/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0673 - val_acc: 0.9804\n",
      "Epoch 12/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0686 - val_acc: 0.9802\n",
      "Epoch 13/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0636 - val_acc: 0.9810\n",
      "Epoch 14/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0862 - val_acc: 0.9787\n",
      "Epoch 15/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0080 - acc: 0.9971 - val_loss: 0.0642 - val_acc: 0.9828\n",
      "Epoch 16/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 7.6773e-04 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9793\n",
      "Epoch 17/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0769 - val_acc: 0.9804\n",
      "Epoch 18/500\n",
      "10977/10977 [==============================] - 48s 4ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0694 - val_acc: 0.9838\n",
      "2745/2745 [==============================] - 2s 605us/step\n",
      "10977/10977 [==============================] - 7s 600us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 55s 5ms/step - loss: 0.4198 - acc: 0.8252 - val_loss: 0.2787 - val_acc: 0.8920\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 49s 5ms/step - loss: 0.2023 - acc: 0.9197 - val_loss: 0.1525 - val_acc: 0.946316 - ETA: 5s - ETA: 3s -  - ETA: 1s - \n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 49s 5ms/step - loss: 0.1057 - acc: 0.9576 - val_loss: 0.1249 - val_acc: 0.9453\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0707 - acc: 0.9756 - val_loss: 0.1178 - val_acc: 0.9606\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0451 - acc: 0.9848 - val_loss: 0.0974 - val_acc: 0.9616 - E\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0291 - acc: 0.9914 - val_loss: 0.0957 - val_acc: 0.9660\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0204 - acc: 0.9934 - val_loss: 0.0740 - val_acc: 0.9774\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0125 - acc: 0.9974 - val_loss: 0.0838 - val_acc: 0.9761cc: -\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0917 - val_acc: 0.9754\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0093 - acc: 0.9965 - val_loss: 0.0910 - val_acc: 0.9778\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0834 - val_acc: 0.9795\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0760 - val_acc: 0.9793\n",
      "2744/2744 [==============================] - 2s 676us/step\n",
      "10978/10978 [==============================] - 7s 632us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 55s 5ms/step - loss: 0.4185 - acc: 0.8270 - val_loss: 0.2928 - val_acc: 0.8979\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 49s 5ms/step - loss: 0.2501 - acc: 0.9048 - val_loss: 0.1725 - val_acc: 0.9313\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.1298 - acc: 0.9485 - val_loss: 0.1343 - val_acc: 0.9530A: 4s \n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0810 - acc: 0.9713 - val_loss: 0.0964 - val_acc: 0.9625\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0555 - acc: 0.9805 - val_loss: 0.0848 - val_acc: 0.9713\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0354 - acc: 0.9891 - val_loss: 0.0769 - val_acc: 0.9722\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 49s 5ms/step - loss: 0.0243 - acc: 0.9932 - val_loss: 0.0858 - val_acc: 0.9733\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0166 - acc: 0.9957 - val_loss: 0.0826 - val_acc: 0.9748\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 49s 5ms/step - loss: 0.0122 - acc: 0.9966 - val_loss: 0.0781 - val_acc: 0.9782\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0134 - acc: 0.9972 - val_loss: 0.0739 - val_acc: 0.9791\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0851 - val_acc: 0.9744\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0768 - val_acc: 0.9789\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0802 - val_acc: 0.9757\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0792 - val_acc: 0.9787\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0818 - val_acc: 0.9825\n",
      "2744/2744 [==============================] - 2s 622us/step\n",
      "10978/10978 [==============================] - 7s 620us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 55s 5ms/step - loss: 0.4241 - acc: 0.8239 - val_loss: 0.2775 - val_acc: 0.9071\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.2113 - acc: 0.9165 - val_loss: 0.1368 - val_acc: 0.9410\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.1094 - acc: 0.9587 - val_loss: 0.1093 - val_acc: 0.9532\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0713 - acc: 0.9735 - val_loss: 0.1101 - val_acc: 0.9563\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 49s 5ms/step - loss: 0.0447 - acc: 0.9855 - val_loss: 0.0854 - val_acc: 0.9642\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0287 - acc: 0.9913 - val_loss: 0.0666 - val_acc: 0.9789\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0209 - acc: 0.9935 - val_loss: 0.0667 - val_acc: 0.9791\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0139 - acc: 0.9965 - val_loss: 0.0634 - val_acc: 0.9802\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0095 - acc: 0.9972 - val_loss: 0.0746 - val_acc: 0.9765\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0062 - acc: 0.9988 - val_loss: 0.0628 - val_acc: 0.9828\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0050 - acc: 0.9991 - val_loss: 0.0727 - val_acc: 0.9817\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0971 - val_acc: 0.9757\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 49s 4ms/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.0673 - val_acc: 0.9838\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0653 - val_acc: 0.9858\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 50s 5ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0662 - val_acc: 0.9856\n",
      "2744/2744 [==============================] - 2s 623us/step\n",
      "10978/10978 [==============================] - 7s 611us/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 36s 3ms/step - loss: 0.0059 - acc: 0.9994 - val_loss: 2.2844 - val_acc: 0.8080\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 2.0646e-05 - acc: 1.0000 - val_loss: 2.5378 - val_acc: 0.8080\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 6.8379e-06 - acc: 1.0000 - val_loss: 2.6653 - val_acc: 0.8080\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 3.0691e-06 - acc: 1.0000 - val_loss: 2.7478 - val_acc: 0.8080\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 1.7027e-06 - acc: 1.0000 - val_loss: 2.8069 - val_acc: 0.8080\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 1.0197e-06 - acc: 1.0000 - val_loss: 2.8512 - val_acc: 0.8080\n",
      "2745/2745 [==============================] - 1s 541us/step\n",
      "10977/10977 [==============================] - 6s 524us/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 36s 3ms/step - loss: 0.4566 - acc: 0.8043 - val_loss: 0.3248 - val_acc: 0.8841\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.2974 - acc: 0.8854 - val_loss: 0.2051 - val_acc: 0.9224\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.1716 - acc: 0.9338 - val_loss: 0.1436 - val_acc: 0.9364\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.1119 - acc: 0.9569 - val_loss: 0.1298 - val_acc: 0.9459\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0839 - acc: 0.9683 - val_loss: 0.1300 - val_acc: 0.9466\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0629 - acc: 0.9756 - val_loss: 0.0947 - val_acc: 0.9621\n",
      "Epoch 7/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0440 - acc: 0.9855 - val_loss: 0.1011 - val_acc: 0.9625\n",
      "Epoch 8/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0336 - acc: 0.9903 - val_loss: 0.0821 - val_acc: 0.9720\n",
      "Epoch 9/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0242 - acc: 0.9941 - val_loss: 0.0761 - val_acc: 0.9711\n",
      "Epoch 10/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0180 - acc: 0.9962 - val_loss: 0.0722 - val_acc: 0.9752\n",
      "Epoch 11/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0911 - val_acc: 0.9716\n",
      "Epoch 12/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0111 - acc: 0.9973 - val_loss: 0.0834 - val_acc: 0.9748\n",
      "Epoch 13/500\n",
      "10977/10977 [==============================] - 32s 3ms/step - loss: 0.0060 - acc: 0.9994 - val_loss: 0.0765 - val_acc: 0.9772\n",
      "Epoch 14/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0047 - acc: 0.9996 - val_loss: 0.0827 - val_acc: 0.9769\n",
      "Epoch 15/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0709 - val_acc: 0.9810\n",
      "Epoch 16/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.0762 - val_acc: 0.9793\n",
      "Epoch 17/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0778 - val_acc: 0.9787\n",
      "Epoch 18/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0067 - acc: 0.9982 - val_loss: 0.0655 - val_acc: 0.9813\n",
      "Epoch 19/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0679 - val_acc: 0.9819\n",
      "Epoch 20/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.0658 - val_acc: 0.9806\n",
      "Epoch 21/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0634 - val_acc: 0.9821\n",
      "Epoch 22/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 7.7319e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9841\n",
      "Epoch 23/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 5.8423e-04 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9810\n",
      "Epoch 24/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 5.7835e-04 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 0.9825\n",
      "Epoch 25/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0688 - val_acc: 0.9821\n",
      "Epoch 26/500\n",
      "10977/10977 [==============================] - 31s 3ms/step - loss: 7.6780e-04 - acc: 0.9999 - val_loss: 0.0713 - val_acc: 0.9821\n",
      "2745/2745 [==============================] - 1s 532us/step\n",
      "10977/10977 [==============================] - 6s 535us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 37s 3ms/step - loss: 0.4656 - acc: 0.8017 - val_loss: 0.3567 - val_acc: 0.8608\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.2926 - acc: 0.8889 - val_loss: 0.2049 - val_acc: 0.9196\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.1702 - acc: 0.9347 - val_loss: 0.1400 - val_acc: 0.9453\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.1117 - acc: 0.9574 - val_loss: 0.1614 - val_acc: 0.9347\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0819 - acc: 0.9698 - val_loss: 0.1003 - val_acc: 0.9567\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 32s 3ms/step - loss: 0.0608 - acc: 0.9779 - val_loss: 0.0975 - val_acc: 0.9601\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0446 - acc: 0.9871 - val_loss: 0.0797 - val_acc: 0.9705\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0335 - acc: 0.9895 - val_loss: 0.0903 - val_acc: 0.9672\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0247 - acc: 0.9940 - val_loss: 0.0795 - val_acc: 0.9737\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 32s 3ms/step - loss: 0.0195 - acc: 0.9948 - val_loss: 0.0916 - val_acc: 0.9716\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0142 - acc: 0.9965 - val_loss: 0.0837 - val_acc: 0.9729\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0115 - acc: 0.9966 - val_loss: 0.0869 - val_acc: 0.9739\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0874 - val_acc: 0.9733\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0052 - acc: 0.9997 - val_loss: 0.0884 - val_acc: 0.9737\n",
      "2744/2744 [==============================] - 1s 528us/step\n",
      "10978/10978 [==============================] - 6s 528us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 36s 3ms/step - loss: 0.4515 - acc: 0.8075 - val_loss: 0.3458 - val_acc: 0.8735\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 32s 3ms/step - loss: 0.3091 - acc: 0.8813 - val_loss: 0.2954 - val_acc: 0.8843\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.2157 - acc: 0.9199 - val_loss: 0.1927 - val_acc: 0.9291\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.1390 - acc: 0.9464 - val_loss: 0.1453 - val_acc: 0.9388\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0973 - acc: 0.9639 - val_loss: 0.1305 - val_acc: 0.9446\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0689 - acc: 0.9767 - val_loss: 0.1055 - val_acc: 0.9573\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0569 - acc: 0.9803 - val_loss: 0.0957 - val_acc: 0.9606\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0426 - acc: 0.9851 - val_loss: 0.0965 - val_acc: 0.9619\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0286 - acc: 0.9923 - val_loss: 0.0803 - val_acc: 0.9718\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0252 - acc: 0.9932 - val_loss: 0.0802 - val_acc: 0.9748\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0169 - acc: 0.9960 - val_loss: 0.0973 - val_acc: 0.9683\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 33s 3ms/step - loss: 0.0150 - acc: 0.9958 - val_loss: 0.0839 - val_acc: 0.9769\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0101 - acc: 0.9979 - val_loss: 0.0917 - val_acc: 0.9711\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0089 - acc: 0.9982 - val_loss: 0.0860 - val_acc: 0.9726\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0750 - val_acc: 0.9782\n",
      "Epoch 16/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0031 - acc: 0.9998 - val_loss: 0.0776 - val_acc: 0.9797\n",
      "Epoch 17/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0852 - val_acc: 0.9782\n",
      "Epoch 18/500\n",
      "10978/10978 [==============================] - 32s 3ms/step - loss: 0.0048 - acc: 0.9990 - val_loss: 0.1007 - val_acc: 0.9748\n",
      "Epoch 19/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0881 - val_acc: 0.9763\n",
      "Epoch 20/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0070 - acc: 0.9979 - val_loss: 0.0890 - val_acc: 0.9797\n",
      "2744/2744 [==============================] - 1s 517us/step\n",
      "10978/10978 [==============================] - 6s 522us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 37s 3ms/step - loss: 0.4493 - acc: 0.8107 - val_loss: 0.3237 - val_acc: 0.8804\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.3036 - acc: 0.8838 - val_loss: 0.2476 - val_acc: 0.9026\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.2012 - acc: 0.9208 - val_loss: 0.1650 - val_acc: 0.9392\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.1284 - acc: 0.9516 - val_loss: 0.1483 - val_acc: 0.9388\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0927 - acc: 0.9657 - val_loss: 0.1291 - val_acc: 0.9532\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0692 - acc: 0.9753 - val_loss: 0.1152 - val_acc: 0.9599\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0467 - acc: 0.9861 - val_loss: 0.0976 - val_acc: 0.9664\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0375 - acc: 0.9874 - val_loss: 0.0933 - val_acc: 0.9670\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0257 - acc: 0.9926 - val_loss: 0.1030 - val_acc: 0.9664\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0217 - acc: 0.9939 - val_loss: 0.0801 - val_acc: 0.9748\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 32s 3ms/step - loss: 0.0141 - acc: 0.9971 - val_loss: 0.0828 - val_acc: 0.9761\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0865 - val_acc: 0.9724\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.0876 - val_acc: 0.9772\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0111 - acc: 0.9964 - val_loss: 0.1600 - val_acc: 0.9507\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 31s 3ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0835 - val_acc: 0.9759\n",
      "2744/2744 [==============================] - 1s 511us/step\n",
      "10978/10978 [==============================] - 6s 521us/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 27s 2ms/step - loss: 0.0109 - acc: 0.9994 - val_loss: 2.0227 - val_acc: 0.8080\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 6.2336e-05 - acc: 1.0000 - val_loss: 2.3076 - val_acc: 0.8080\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 21s 2ms/step - loss: 2.3389e-05 - acc: 1.0000 - val_loss: 2.4519 - val_acc: 0.8080\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 21s 2ms/step - loss: 1.2036e-05 - acc: 1.0000 - val_loss: 2.5449 - val_acc: 0.8080\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 7.3689e-06 - acc: 1.0000 - val_loss: 2.6120 - val_acc: 0.8080\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 4.8595e-06 - acc: 1.0000 - val_loss: 2.6650 - val_acc: 0.8080\n",
      "2745/2745 [==============================] - 1s 445us/step\n",
      "10977/10977 [==============================] - 5s 421us/step\n",
      "Train on 10977 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10977/10977 [==============================] - 27s 2ms/step - loss: 0.4820 - acc: 0.7896 - val_loss: 0.3948 - val_acc: 0.8492\n",
      "Epoch 2/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.3536 - acc: 0.8671 - val_loss: 0.2822 - val_acc: 0.9043\n",
      "Epoch 3/500\n",
      "10977/10977 [==============================] - 21s 2ms/step - loss: 0.2737 - acc: 0.8931 - val_loss: 0.2426 - val_acc: 0.9183\n",
      "Epoch 4/500\n",
      "10977/10977 [==============================] - 21s 2ms/step - loss: 0.1967 - acc: 0.9261 - val_loss: 0.1861 - val_acc: 0.9235\n",
      "Epoch 5/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.1448 - acc: 0.9447 - val_loss: 0.1586 - val_acc: 0.9371\n",
      "Epoch 6/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.1089 - acc: 0.9602 - val_loss: 0.1275 - val_acc: 0.9507\n",
      "Epoch 7/500\n",
      "10977/10977 [==============================] - 21s 2ms/step - loss: 0.0894 - acc: 0.9658 - val_loss: 0.1182 - val_acc: 0.9509\n",
      "Epoch 8/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0681 - acc: 0.9770 - val_loss: 0.1249 - val_acc: 0.9500\n",
      "Epoch 9/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0575 - acc: 0.9817 - val_loss: 0.1019 - val_acc: 0.9616\n",
      "Epoch 10/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0442 - acc: 0.9862 - val_loss: 0.1443 - val_acc: 0.9466\n",
      "Epoch 11/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0570 - acc: 0.9808 - val_loss: 0.0916 - val_acc: 0.9677\n",
      "Epoch 12/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0328 - acc: 0.9911 - val_loss: 0.0951 - val_acc: 0.9644\n",
      "Epoch 13/500\n",
      "10977/10977 [==============================] - 21s 2ms/step - loss: 0.0260 - acc: 0.9934 - val_loss: 0.0923 - val_acc: 0.9651\n",
      "Epoch 14/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0251 - acc: 0.9929 - val_loss: 0.0911 - val_acc: 0.9705\n",
      "Epoch 15/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0185 - acc: 0.9964 - val_loss: 0.0848 - val_acc: 0.9729\n",
      "Epoch 16/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0146 - acc: 0.9975 - val_loss: 0.0861 - val_acc: 0.9716\n",
      "Epoch 17/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0125 - acc: 0.9978 - val_loss: 0.0918 - val_acc: 0.9705\n",
      "Epoch 18/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0117 - acc: 0.9978 - val_loss: 0.0795 - val_acc: 0.9729\n",
      "Epoch 19/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0085 - acc: 0.9989 - val_loss: 0.0829 - val_acc: 0.9729\n",
      "Epoch 20/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0847 - val_acc: 0.9750\n",
      "Epoch 21/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0077 - acc: 0.9987 - val_loss: 0.1121 - val_acc: 0.9694\n",
      "Epoch 22/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 0.0826 - val_acc: 0.9748\n",
      "Epoch 23/500\n",
      "10977/10977 [==============================] - 22s 2ms/step - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0866 - val_acc: 0.9763\n",
      "2745/2745 [==============================] - 1s 428us/step\n",
      "10977/10977 [==============================] - 5s 422us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 27s 2ms/step - loss: 0.4811 - acc: 0.7881 - val_loss: 0.3942 - val_acc: 0.8699\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.3588 - acc: 0.8595 - val_loss: 0.2926 - val_acc: 0.8942\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 21s 2ms/step - loss: 0.2782 - acc: 0.8937 - val_loss: 0.2395 - val_acc: 0.9145\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.2240 - acc: 0.9167 - val_loss: 0.2166 - val_acc: 0.9175\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1842 - acc: 0.9305 - val_loss: 0.1943 - val_acc: 0.9252\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1437 - acc: 0.9452 - val_loss: 0.1678 - val_acc: 0.9343\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1175 - acc: 0.9556 - val_loss: 0.1472 - val_acc: 0.9410\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 21s 2ms/step - loss: 0.0944 - acc: 0.9646 - val_loss: 0.1500 - val_acc: 0.9457\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0772 - acc: 0.9711 - val_loss: 0.1165 - val_acc: 0.9560\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0631 - acc: 0.9787 - val_loss: 0.1200 - val_acc: 0.9541\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 21s 2ms/step - loss: 0.0529 - acc: 0.9811 - val_loss: 0.1259 - val_acc: 0.9524\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0445 - acc: 0.9867 - val_loss: 0.1048 - val_acc: 0.9591\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0305 - acc: 0.9926 - val_loss: 0.0950 - val_acc: 0.9647\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 21s 2ms/step - loss: 0.0278 - acc: 0.9922 - val_loss: 0.0965 - val_acc: 0.9655\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0220 - acc: 0.9950 - val_loss: 0.0976 - val_acc: 0.9675\n",
      "Epoch 16/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0213 - acc: 0.9942 - val_loss: 0.0852 - val_acc: 0.9709\n",
      "Epoch 17/500\n",
      "10978/10978 [==============================] - 21s 2ms/step - loss: 0.0131 - acc: 0.9983 - val_loss: 0.1004 - val_acc: 0.9634\n",
      "Epoch 18/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0120 - acc: 0.9976 - val_loss: 0.1008 - val_acc: 0.9666\n",
      "Epoch 19/500\n",
      "10978/10978 [==============================] - 21s 2ms/step - loss: 0.0090 - acc: 0.9989 - val_loss: 0.0923 - val_acc: 0.9726\n",
      "Epoch 20/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0078 - acc: 0.9987 - val_loss: 0.0927 - val_acc: 0.9707\n",
      "Epoch 21/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0958 - val_acc: 0.9705\n",
      "2744/2744 [==============================] - 1s 427us/step\n",
      "10978/10978 [==============================] - 5s 414us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 27s 2ms/step - loss: 0.4790 - acc: 0.7929 - val_loss: 0.3742 - val_acc: 0.8552\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.3469 - acc: 0.8620 - val_loss: 0.2966 - val_acc: 0.8757\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.2389 - acc: 0.9107 - val_loss: 0.2040 - val_acc: 0.9218\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1721 - acc: 0.9349 - val_loss: 0.1691 - val_acc: 0.9382\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1352 - acc: 0.9491 - val_loss: 0.1507 - val_acc: 0.9373\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1079 - acc: 0.9591 - val_loss: 0.1400 - val_acc: 0.9457\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0937 - acc: 0.9680 - val_loss: 0.1146 - val_acc: 0.9560\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0752 - acc: 0.9725 - val_loss: 0.1176 - val_acc: 0.9578\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0584 - acc: 0.9807 - val_loss: 0.1072 - val_acc: 0.9616\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0487 - acc: 0.9846 - val_loss: 0.0928 - val_acc: 0.9672\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0407 - acc: 0.9872 - val_loss: 0.0900 - val_acc: 0.9672\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0321 - acc: 0.9911 - val_loss: 0.0941 - val_acc: 0.9647\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0262 - acc: 0.9934 - val_loss: 0.0843 - val_acc: 0.9692\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0207 - acc: 0.9954 - val_loss: 0.0869 - val_acc: 0.9709\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0174 - acc: 0.9958 - val_loss: 0.0807 - val_acc: 0.9744\n",
      "Epoch 16/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0149 - acc: 0.9962 - val_loss: 0.0842 - val_acc: 0.9726\n",
      "Epoch 17/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0107 - acc: 0.9976 - val_loss: 0.0784 - val_acc: 0.9741\n",
      "Epoch 18/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0129 - acc: 0.9969 - val_loss: 0.0783 - val_acc: 0.9750\n",
      "Epoch 19/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0760 - val_acc: 0.9769\n",
      "Epoch 20/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0056 - acc: 0.9995 - val_loss: 0.0782 - val_acc: 0.9772\n",
      "Epoch 21/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0844 - val_acc: 0.9724\n",
      "Epoch 22/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0058 - acc: 0.9990 - val_loss: 0.0813 - val_acc: 0.9795\n",
      "Epoch 23/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0734 - val_acc: 0.9791\n",
      "Epoch 24/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0728 - val_acc: 0.9795\n",
      "Epoch 25/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.0996 - val_acc: 0.9752\n",
      "Epoch 26/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0811 - val_acc: 0.9797\n",
      "Epoch 27/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0816 - val_acc: 0.9791\n",
      "Epoch 28/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0924 - val_acc: 0.9772\n",
      "Epoch 29/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9797\n",
      "2744/2744 [==============================] - 1s 435us/step\n",
      "10978/10978 [==============================] - 5s 434us/step\n",
      "Train on 10978 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "10978/10978 [==============================] - 28s 3ms/step - loss: 0.4845 - acc: 0.7903 - val_loss: 0.4040 - val_acc: 0.8505\n",
      "Epoch 2/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.3687 - acc: 0.8534 - val_loss: 0.2938 - val_acc: 0.9026\n",
      "Epoch 3/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.2716 - acc: 0.9002 - val_loss: 0.2693 - val_acc: 0.9015\n",
      "Epoch 4/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.2080 - acc: 0.9249 - val_loss: 0.1933 - val_acc: 0.9229\n",
      "Epoch 5/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1557 - acc: 0.9431 - val_loss: 0.1617 - val_acc: 0.9347\n",
      "Epoch 6/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.1184 - acc: 0.9564 - val_loss: 0.1456 - val_acc: 0.9416\n",
      "Epoch 7/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0918 - acc: 0.9668 - val_loss: 0.1562 - val_acc: 0.9414\n",
      "Epoch 8/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0762 - acc: 0.9744 - val_loss: 0.1074 - val_acc: 0.9595\n",
      "Epoch 9/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0582 - acc: 0.9821 - val_loss: 0.1122 - val_acc: 0.9591\n",
      "Epoch 10/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0533 - acc: 0.9820 - val_loss: 0.0890 - val_acc: 0.9675\n",
      "Epoch 11/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0379 - acc: 0.9892 - val_loss: 0.0878 - val_acc: 0.9666\n",
      "Epoch 12/500\n",
      "10978/10978 [==============================] - 23s 2ms/step - loss: 0.0335 - acc: 0.9907 - val_loss: 0.0934 - val_acc: 0.9655\n",
      "Epoch 13/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0288 - acc: 0.9922 - val_loss: 0.0822 - val_acc: 0.9733\n",
      "Epoch 14/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0210 - acc: 0.9954 - val_loss: 0.1047 - val_acc: 0.9657\n",
      "Epoch 15/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0184 - acc: 0.9954 - val_loss: 0.0944 - val_acc: 0.9670\n",
      "Epoch 16/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0154 - acc: 0.9974 - val_loss: 0.0886 - val_acc: 0.9733\n",
      "Epoch 17/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0150 - acc: 0.9968 - val_loss: 0.0973 - val_acc: 0.9703\n",
      "Epoch 18/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0111 - acc: 0.9977 - val_loss: 0.0751 - val_acc: 0.9772\n",
      "Epoch 19/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0099 - acc: 0.9982 - val_loss: 0.0860 - val_acc: 0.9735\n",
      "Epoch 20/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0089 - acc: 0.9976 - val_loss: 0.0986 - val_acc: 0.9698\n",
      "Epoch 21/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0925 - val_acc: 0.9718\n",
      "Epoch 22/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0741 - val_acc: 0.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0041 - acc: 0.9995 - val_loss: 0.0971 - val_acc: 0.9733\n",
      "Epoch 24/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0032 - acc: 0.9997 - val_loss: 0.0822 - val_acc: 0.9782\n",
      "Epoch 25/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0062 - acc: 0.9986 - val_loss: 0.0838 - val_acc: 0.9793\n",
      "Epoch 26/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0196 - acc: 0.9957 - val_loss: 0.0914 - val_acc: 0.9765\n",
      "Epoch 27/500\n",
      "10978/10978 [==============================] - 22s 2ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1018 - val_acc: 0.9737\n",
      "2744/2744 [==============================] - 1s 448us/step\n",
      "10978/10978 [==============================] - 5s 427us/step\n",
      "Train on 13722 samples, validate on 4641 samples\n",
      "Epoch 1/500\n",
      "13722/13722 [==============================] - 123s 9ms/step - loss: 0.3427 - acc: 0.8668 - val_loss: 0.2028 - val_acc: 0.9186\n",
      "Epoch 2/500\n",
      "13722/13722 [==============================] - 116s 8ms/step - loss: 0.1347 - acc: 0.9467 - val_loss: 0.1116 - val_acc: 0.9621\n",
      "Epoch 3/500\n",
      "13722/13722 [==============================] - 118s 9ms/step - loss: 0.0657 - acc: 0.9746 - val_loss: 0.0824 - val_acc: 0.9685\n",
      "Epoch 4/500\n",
      "13722/13722 [==============================] - 117s 9ms/step - loss: 0.0376 - acc: 0.9864 - val_loss: 0.0917 - val_acc: 0.9709\n",
      "Epoch 5/500\n",
      "13722/13722 [==============================] - 116s 8ms/step - loss: 0.0213 - acc: 0.9928 - val_loss: 0.0754 - val_acc: 0.9722\n",
      "Epoch 6/500\n",
      "13722/13722 [==============================] - 116s 8ms/step - loss: 0.0127 - acc: 0.9964 - val_loss: 0.0639 - val_acc: 0.9795\n",
      "Epoch 7/500\n",
      "13722/13722 [==============================] - 117s 9ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0758 - val_acc: 0.9802\n",
      "Epoch 8/500\n",
      "13722/13722 [==============================] - 118s 9ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.1085 - val_acc: 0.9670\n",
      "Epoch 9/500\n",
      "13722/13722 [==============================] - 118s 9ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0701 - val_acc: 0.9813\n",
      "Epoch 10/500\n",
      "13722/13722 [==============================] - 115s 8ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0628 - val_acc: 0.9836\n",
      "Epoch 11/500\n",
      "13722/13722 [==============================] - 113s 8ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0589 - val_acc: 0.9828\n",
      "Epoch 12/500\n",
      "13722/13722 [==============================] - 113s 8ms/step - loss: 0.0017 - acc: 0.9993 - val_loss: 0.0661 - val_acc: 0.9828\n",
      "Epoch 13/500\n",
      "13722/13722 [==============================] - 113s 8ms/step - loss: 0.0031 - acc: 0.9992 - val_loss: 0.0745 - val_acc: 0.9819\n",
      "Epoch 14/500\n",
      "13722/13722 [==============================] - 114s 8ms/step - loss: 0.0020 - acc: 0.9998 - val_loss: 0.0711 - val_acc: 0.9832\n",
      "Epoch 15/500\n",
      "13722/13722 [==============================] - 113s 8ms/step - loss: 6.6438e-04 - acc: 0.9999 - val_loss: 0.0819 - val_acc: 0.9823\n",
      "Epoch 16/500\n",
      "13722/13722 [==============================] - 114s 8ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0815 - val_acc: 0.9828\n",
      "Best: 0.801997 using {'batch_size': 4}\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 94s 10ms/step - loss: 0.1278 - acc: 0.9517 - val_loss: 0.0738 - val_acc: 0.9758\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 85s 9ms/step - loss: 0.0728 - acc: 0.9752 - val_loss: 0.0609 - val_acc: 0.9788\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 85s 9ms/step - loss: 0.0508 - acc: 0.9830 - val_loss: 0.0632 - val_acc: 0.9790\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 87s 9ms/step - loss: 0.0347 - acc: 0.9877 - val_loss: 0.0532 - val_acc: 0.9810\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0227 - acc: 0.9916 - val_loss: 0.0531 - val_acc: 0.9835\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0141 - acc: 0.9954 - val_loss: 0.0659 - val_acc: 0.9823\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 87s 9ms/step - loss: 0.0084 - acc: 0.9968 - val_loss: 0.0549 - val_acc: 0.9853\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.0577 - val_acc: 0.9855\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0631 - val_acc: 0.9833\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0043 - acc: 0.9988 - val_loss: 0.0640 - val_acc: 0.9868\n",
      "2448/2448 [==============================] - 3s 1ms/step\n",
      "9789/9789 [==============================] - 12s 1ms/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 93s 10ms/step - loss: 0.1301 - acc: 0.9516 - val_loss: 0.0825 - val_acc: 0.9710\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0708 - acc: 0.9752 - val_loss: 0.0804 - val_acc: 0.9745: 0.0696 - acc: 0\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0490 - acc: 0.9839 - val_loss: 0.0616 - val_acc: 0.9778\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 87s 9ms/step - loss: 0.0335 - acc: 0.9878 - val_loss: 0.0676 - val_acc: 0.9783\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0232 - acc: 0.9918 - val_loss: 0.0409 - val_acc: 0.9868\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 87s 9ms/step - loss: 0.0140 - acc: 0.9952 - val_loss: 0.0512 - val_acc: 0.9845\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 87s 9ms/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0574 - val_acc: 0.9810\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 87s 9ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0407 - val_acc: 0.9883\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 85s 9ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0431 - val_acc: 0.9878\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0688 - val_acc: 0.9845\n",
      "Epoch 11/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0522 - val_acc: 0.9880\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0029 - acc: 0.9992 - val_loss: 0.0475 - val_acc: 0.9893\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 86s 9ms/step - loss: 0.0027 - acc: 0.9990 - val_loss: 0.0555 - val_acc: 0.9885\n",
      "2448/2448 [==============================] - 3s 1ms/step\n",
      "9789/9789 [==============================] - 13s 1ms/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 93s 10ms/step - loss: 0.1229 - acc: 0.9554 - val_loss: 0.0737 - val_acc: 0.9748\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 88s 9ms/step - loss: 0.0682 - acc: 0.9774 - val_loss: 0.0624 - val_acc: 0.9763\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0487 - acc: 0.9831 - val_loss: 0.0532 - val_acc: 0.9815ETA: 1s - loss:\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 88s 9ms/step - loss: 0.0347 - acc: 0.9882 - val_loss: 0.0644 - val_acc: 0.9783\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0217 - acc: 0.9932 - val_loss: 0.0511 - val_acc: 0.9823\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0145 - acc: 0.9952 - val_loss: 0.0446 - val_acc: 0.9858\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0635 - val_acc: 0.9825\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0418 - val_acc: 0.9855\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0536 - val_acc: 0.9845\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0408 - val_acc: 0.9875\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 89s 9ms/step - loss: 4.9877e-04 - acc: 1.0000 - val_loss: 0.0621 - val_acc: 0.9833A: 3s - loss: 4.8876e-04 - acc: 1.0\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0038 - acc: 0.9990 - val_loss: 0.0719 - val_acc: 0.9838\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0503 - val_acc: 0.9858\n",
      "Epoch 14/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0516 - val_acc: 0.9870 - loss:  - ETA: 0s - loss: 0.0024 - acc: 0.999\n",
      "Epoch 15/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0496 - val_acc: 0.9865\n",
      "2447/2447 [==============================] - 3s 1ms/step\n",
      "9790/9790 [==============================] - 13s 1ms/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 93s 10ms/step - loss: 0.1176 - acc: 0.9571 - val_loss: 0.0735 - val_acc: 0.9753\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0724 - acc: 0.9744 - val_loss: 0.0634 - val_acc: 0.9760\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0510 - acc: 0.9828 - val_loss: 0.0661 - val_acc: 0.9790\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0324 - acc: 0.9891 - val_loss: 0.0533 - val_acc: 0.9798\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0227 - acc: 0.9919 - val_loss: 0.0770 - val_acc: 0.9780\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0136 - acc: 0.9955 - val_loss: 0.0569 - val_acc: 0.9838\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0540 - val_acc: 0.9845\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0490 - val_acc: 0.9855\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0526 - val_acc: 0.9858\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0817 - val_acc: 0.9785\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0496 - val_acc: 0.9870\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0611 - val_acc: 0.9863\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 86s 9ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0514 - val_acc: 0.9870\n",
      "2447/2447 [==============================] - 3s 1ms/step\n",
      "9790/9790 [==============================] - 13s 1ms/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 93s 10ms/step - loss: 0.0710 - acc: 0.9760 - val_loss: 0.1221 - val_acc: 0.9578\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 88s 9ms/step - loss: 0.0426 - acc: 0.9853 - val_loss: 0.0932 - val_acc: 0.9663\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0303 - acc: 0.9891 - val_loss: 0.1101 - val_acc: 0.9673\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0187 - acc: 0.9925 - val_loss: 0.0976 - val_acc: 0.9720\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 88s 9ms/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.1293 - val_acc: 0.9660\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0067 - acc: 0.9980 - val_loss: 0.0885 - val_acc: 0.9773\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.2402 - val_acc: 0.9628\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0853 - val_acc: 0.9795\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.1768 - val_acc: 0.9590\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 4.3158e-04 - acc: 1.0000 - val_loss: 0.1165 - val_acc: 0.9800\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1366 - val_acc: 0.9783\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 9.7899e-05 - acc: 1.0000 - val_loss: 0.1569 - val_acc: 0.9763\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 87s 9ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.1373 - val_acc: 0.9788\n",
      "2447/2447 [==============================] - 3s 1ms/step\n",
      "9790/9790 [==============================] - 13s 1ms/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 51s 5ms/step - loss: 0.1383 - acc: 0.9494 - val_loss: 0.0872 - val_acc: 0.9725\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 44s 5ms/step - loss: 0.0750 - acc: 0.9749 - val_loss: 0.0812 - val_acc: 0.9755\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 44s 5ms/step - loss: 0.0573 - acc: 0.9810 - val_loss: 0.0635 - val_acc: 0.9768\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0432 - acc: 0.9846 - val_loss: 0.0682 - val_acc: 0.9763\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0318 - acc: 0.9888 - val_loss: 0.0664 - val_acc: 0.9798\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0206 - acc: 0.9928 - val_loss: 0.0643 - val_acc: 0.9813\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0142 - acc: 0.9954 - val_loss: 0.0659 - val_acc: 0.9795\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0102 - acc: 0.9972 - val_loss: 0.0531 - val_acc: 0.9853\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0604 - val_acc: 0.9813\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0636 - val_acc: 0.9858\n",
      "Epoch 11/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0073 - acc: 0.9972 - val_loss: 0.0736 - val_acc: 0.9845\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0849 - val_acc: 0.9810\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 45s 5ms/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0619 - val_acc: 0.9848\n",
      "2448/2448 [==============================] - 2s 679us/step\n",
      "9789/9789 [==============================] - 7s 685us/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 52s 5ms/step - loss: 0.1350 - acc: 0.9489 - val_loss: 0.0896 - val_acc: 0.9733\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0748 - acc: 0.9746 - val_loss: 0.0876 - val_acc: 0.9688\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0554 - acc: 0.9808 - val_loss: 0.0634 - val_acc: 0.9778\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0435 - acc: 0.9859 - val_loss: 0.0571 - val_acc: 0.9795\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0321 - acc: 0.9888 - val_loss: 0.0535 - val_acc: 0.9810\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0221 - acc: 0.9931 - val_loss: 0.0606 - val_acc: 0.9823\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0162 - acc: 0.9947 - val_loss: 0.0494 - val_acc: 0.9865\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0117 - acc: 0.9969 - val_loss: 0.0493 - val_acc: 0.9863\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 46s 5ms/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0553 - val_acc: 0.9868\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0543 - val_acc: 0.9865\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9789/9789 [==============================] - 48s 5ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0572 - val_acc: 0.9850\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0598 - val_acc: 0.9860\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 47s 5ms/step - loss: 0.0051 - acc: 0.9989 - val_loss: 0.0611 - val_acc: 0.9835\n",
      "2448/2448 [==============================] - 2s 718us/step\n",
      "9789/9789 [==============================] - 7s 739us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 54s 6ms/step - loss: 0.1428 - acc: 0.9476 - val_loss: 0.0760 - val_acc: 0.9743\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0764 - acc: 0.9740 - val_loss: 0.0694 - val_acc: 0.9760\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0591 - acc: 0.9797 - val_loss: 0.0637 - val_acc: 0.9788\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0464 - acc: 0.9837 - val_loss: 0.0637 - val_acc: 0.9790\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0481 - val_acc: 0.9830\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0207 - acc: 0.9938 - val_loss: 0.0478 - val_acc: 0.9838\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0516 - val_acc: 0.9855\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0438 - val_acc: 0.9858\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0510 - val_acc: 0.9845\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0457 - val_acc: 0.9865\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0049 - acc: 0.9983 - val_loss: 0.0449 - val_acc: 0.9870\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0027 - acc: 0.9994 - val_loss: 0.0476 - val_acc: 0.9878\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0483 - val_acc: 0.9868\n",
      "2447/2447 [==============================] - 2s 743us/step\n",
      "9790/9790 [==============================] - 7s 732us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 54s 5ms/step - loss: 0.1328 - acc: 0.9496 - val_loss: 0.0851 - val_acc: 0.9715\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0724 - acc: 0.9743 - val_loss: 0.0689 - val_acc: 0.9753\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0560 - acc: 0.9798 - val_loss: 0.0616 - val_acc: 0.9780\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0438 - acc: 0.9850 - val_loss: 0.0543 - val_acc: 0.9800\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0288 - acc: 0.9898 - val_loss: 0.0539 - val_acc: 0.9803\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0557 - val_acc: 0.9808\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0427 - val_acc: 0.9858\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0109 - acc: 0.9964 - val_loss: 0.0388 - val_acc: 0.9870\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0508 - val_acc: 0.9860\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0484 - val_acc: 0.9868\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0496 - val_acc: 0.9865\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0653 - val_acc: 0.9835\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0566 - val_acc: 0.9868\n",
      "2447/2447 [==============================] - 2s 734us/step\n",
      "9790/9790 [==============================] - 7s 733us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 54s 6ms/step - loss: 0.0800 - acc: 0.9709 - val_loss: 0.1270 - val_acc: 0.9578\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0455 - acc: 0.9850 - val_loss: 0.1033 - val_acc: 0.9638\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0348 - acc: 0.9880 - val_loss: 0.0904 - val_acc: 0.9675\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 49s 5ms/step - loss: 0.0256 - acc: 0.9896 - val_loss: 0.0945 - val_acc: 0.9733\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0165 - acc: 0.9939 - val_loss: 0.0836 - val_acc: 0.9763\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0107 - acc: 0.9963 - val_loss: 0.1939 - val_acc: 0.9575\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0077 - acc: 0.9973 - val_loss: 0.1244 - val_acc: 0.9683\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.1360 - val_acc: 0.9750\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 46s 5ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0761 - val_acc: 0.9783\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1344 - val_acc: 0.9740\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 49s 5ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.1663 - val_acc: 0.9705\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 48s 5ms/step - loss: 3.5005e-04 - acc: 1.0000 - val_loss: 0.1209 - val_acc: 0.9790\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 1.7702e-04 - acc: 1.0000 - val_loss: 0.1305 - val_acc: 0.9793\n",
      "Epoch 14/500\n",
      "9790/9790 [==============================] - 47s 5ms/step - loss: 7.7639e-05 - acc: 1.0000 - val_loss: 0.1323 - val_acc: 0.9788\n",
      "2447/2447 [==============================] - 2s 758us/step\n",
      "9790/9790 [==============================] - 7s 758us/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 35s 4ms/step - loss: 0.1568 - acc: 0.9390 - val_loss: 0.0842 - val_acc: 0.9738\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0813 - acc: 0.9727 - val_loss: 0.0756 - val_acc: 0.9725\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 29s 3ms/step - loss: 0.0651 - acc: 0.9786 - val_loss: 0.0738 - val_acc: 0.9748\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 29s 3ms/step - loss: 0.0531 - acc: 0.9837 - val_loss: 0.0633 - val_acc: 0.9795\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0424 - acc: 0.9868 - val_loss: 0.0664 - val_acc: 0.9783\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0340 - acc: 0.9889 - val_loss: 0.0596 - val_acc: 0.9798\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0252 - acc: 0.9921 - val_loss: 0.0561 - val_acc: 0.9830\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0192 - acc: 0.9937 - val_loss: 0.0524 - val_acc: 0.9840\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.0608 - val_acc: 0.9803\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0501 - val_acc: 0.9858\n",
      "Epoch 11/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0576 - val_acc: 0.9835\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0631 - val_acc: 0.9833\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0621 - val_acc: 0.9845\n",
      "Epoch 14/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0604 - val_acc: 0.9850\n",
      "Epoch 15/500\n",
      "9789/9789 [==============================] - 29s 3ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0597 - val_acc: 0.9855\n",
      "2448/2448 [==============================] - 1s 559us/step\n",
      "9789/9789 [==============================] - 5s 561us/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 35s 4ms/step - loss: 0.1633 - acc: 0.9371 - val_loss: 0.0821 - val_acc: 0.9715\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0794 - acc: 0.9723 - val_loss: 0.0812 - val_acc: 0.9740\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0659 - acc: 0.9781 - val_loss: 0.0632 - val_acc: 0.9770\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0524 - acc: 0.9811 - val_loss: 0.0647 - val_acc: 0.9788\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0422 - acc: 0.9859 - val_loss: 0.0578 - val_acc: 0.9800\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 29s 3ms/step - loss: 0.0312 - acc: 0.9901 - val_loss: 0.0515 - val_acc: 0.9840\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0603 - val_acc: 0.9820\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0186 - acc: 0.9944 - val_loss: 0.0497 - val_acc: 0.9858\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0144 - acc: 0.9953 - val_loss: 0.0482 - val_acc: 0.9845\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0601 - val_acc: 0.9853\n",
      "Epoch 11/500\n",
      "9789/9789 [==============================] - 30s 3ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0566 - val_acc: 0.9845\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0565 - val_acc: 0.9855\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0583 - val_acc: 0.9848\n",
      "Epoch 14/500\n",
      "9789/9789 [==============================] - 28s 3ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.0597 - val_acc: 0.9850\n",
      "2448/2448 [==============================] - 1s 554us/step\n",
      "9789/9789 [==============================] - 5s 560us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 35s 4ms/step - loss: 0.1667 - acc: 0.9312 - val_loss: 0.0939 - val_acc: 0.9703\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0802 - acc: 0.9723 - val_loss: 0.1240 - val_acc: 0.9615\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0667 - acc: 0.9767 - val_loss: 0.0670 - val_acc: 0.9743\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0528 - acc: 0.9813 - val_loss: 0.0658 - val_acc: 0.9785\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0410 - acc: 0.9865 - val_loss: 0.0664 - val_acc: 0.9763\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0311 - acc: 0.9906 - val_loss: 0.0534 - val_acc: 0.9800\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0234 - acc: 0.9921 - val_loss: 0.0450 - val_acc: 0.9845\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.0564 - val_acc: 0.9813\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0150 - acc: 0.9957 - val_loss: 0.0452 - val_acc: 0.9853\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0093 - acc: 0.9975 - val_loss: 0.0519 - val_acc: 0.9838\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0503 - val_acc: 0.9853\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0068 - acc: 0.9980 - val_loss: 0.0438 - val_acc: 0.9853\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0558 - val_acc: 0.9845\n",
      "Epoch 14/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0020 - acc: 0.9997 - val_loss: 0.0498 - val_acc: 0.9845\n",
      "Epoch 15/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0529 - val_acc: 0.9863\n",
      "Epoch 16/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0046 - acc: 0.9988 - val_loss: 0.0585 - val_acc: 0.9840\n",
      "Epoch 17/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0042 - acc: 0.9986 - val_loss: 0.0491 - val_acc: 0.9860\n",
      "2447/2447 [==============================] - 1s 583us/step\n",
      "9790/9790 [==============================] - 6s 568us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 36s 4ms/step - loss: 0.1501 - acc: 0.9408 - val_loss: 0.0872 - val_acc: 0.9695\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0790 - acc: 0.9723 - val_loss: 0.0795 - val_acc: 0.9710\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0637 - acc: 0.9794 - val_loss: 0.0763 - val_acc: 0.9730\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0525 - acc: 0.9828 - val_loss: 0.0629 - val_acc: 0.9775\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0413 - acc: 0.9852 - val_loss: 0.0772 - val_acc: 0.9748\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0294 - acc: 0.9892 - val_loss: 0.0572 - val_acc: 0.9800\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0235 - acc: 0.9921 - val_loss: 0.0510 - val_acc: 0.9825\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0179 - acc: 0.9948 - val_loss: 0.0513 - val_acc: 0.9830\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0155 - acc: 0.9955 - val_loss: 0.0500 - val_acc: 0.9830\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0530 - val_acc: 0.9835\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0067 - acc: 0.9984 - val_loss: 0.0509 - val_acc: 0.9850\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0540 - val_acc: 0.9850\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0040 - acc: 0.9993 - val_loss: 0.0627 - val_acc: 0.9833\n",
      "Epoch 14/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0575 - val_acc: 0.9850\n",
      "2447/2447 [==============================] - 1s 575us/step\n",
      "9790/9790 [==============================] - 6s 574us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 35s 4ms/step - loss: 0.0892 - acc: 0.9651 - val_loss: 0.1136 - val_acc: 0.9610\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0474 - acc: 0.9853 - val_loss: 0.0973 - val_acc: 0.9650\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0392 - acc: 0.9865 - val_loss: 0.0824 - val_acc: 0.9685\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0305 - acc: 0.9889 - val_loss: 0.0789 - val_acc: 0.9730\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0241 - acc: 0.9913 - val_loss: 0.1254 - val_acc: 0.9615\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0178 - acc: 0.9940 - val_loss: 0.1923 - val_acc: 0.9540\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0117 - acc: 0.9958 - val_loss: 0.1070 - val_acc: 0.9735\n",
      "Epoch 8/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9790/9790 [==============================] - 29s 3ms/step - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0914 - val_acc: 0.9765\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 28s 3ms/step - loss: 0.0058 - acc: 0.9988 - val_loss: 0.1425 - val_acc: 0.9695\n",
      "2447/2447 [==============================] - 1s 575us/step\n",
      "9790/9790 [==============================] - 6s 569us/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 27s 3ms/step - loss: 0.1971 - acc: 0.9217 - val_loss: 0.0851 - val_acc: 0.9713\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0911 - acc: 0.9707 - val_loss: 0.0729 - val_acc: 0.9755\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0716 - acc: 0.9776 - val_loss: 0.0672 - val_acc: 0.9770\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0593 - acc: 0.9800 - val_loss: 0.0642 - val_acc: 0.9788\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0516 - acc: 0.9842 - val_loss: 0.0692 - val_acc: 0.9780\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0448 - acc: 0.9863 - val_loss: 0.0798 - val_acc: 0.9728\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0384 - acc: 0.9877 - val_loss: 0.0612 - val_acc: 0.9800\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0286 - acc: 0.9919 - val_loss: 0.0672 - val_acc: 0.9768\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0224 - acc: 0.9932 - val_loss: 0.0658 - val_acc: 0.9803\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0197 - acc: 0.9938 - val_loss: 0.0622 - val_acc: 0.9808\n",
      "Epoch 11/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0155 - acc: 0.9953 - val_loss: 0.0614 - val_acc: 0.9808\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0100 - acc: 0.9979 - val_loss: 0.0606 - val_acc: 0.9803\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 21s 2ms/step - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0616 - val_acc: 0.9828\n",
      "Epoch 14/500\n",
      "9789/9789 [==============================] - 19s 2ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.0609 - val_acc: 0.9843\n",
      "Epoch 15/500\n",
      "9789/9789 [==============================] - 19s 2ms/step - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0609 - val_acc: 0.9858\n",
      "Epoch 16/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0628 - val_acc: 0.9848\n",
      "Epoch 17/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.0615 - val_acc: 0.9853\n",
      "2448/2448 [==============================] - 1s 438us/step\n",
      "9789/9789 [==============================] - 4s 437us/step\n",
      "Train on 9789 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9789/9789 [==============================] - 26s 3ms/step - loss: 0.1812 - acc: 0.9277 - val_loss: 0.0801 - val_acc: 0.9755\n",
      "Epoch 2/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0848 - acc: 0.9725 - val_loss: 0.1024 - val_acc: 0.9680\n",
      "Epoch 3/500\n",
      "9789/9789 [==============================] - 19s 2ms/step - loss: 0.0678 - acc: 0.9765 - val_loss: 0.0677 - val_acc: 0.9758\n",
      "Epoch 4/500\n",
      "9789/9789 [==============================] - 19s 2ms/step - loss: 0.0573 - acc: 0.9807 - val_loss: 0.0656 - val_acc: 0.9768\n",
      "Epoch 5/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0509 - acc: 0.9832 - val_loss: 0.0712 - val_acc: 0.9765\n",
      "Epoch 6/500\n",
      "9789/9789 [==============================] - 19s 2ms/step - loss: 0.0437 - acc: 0.9856 - val_loss: 0.0702 - val_acc: 0.9758\n",
      "Epoch 7/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0360 - acc: 0.9879 - val_loss: 0.0568 - val_acc: 0.9818\n",
      "Epoch 8/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0298 - acc: 0.9912 - val_loss: 0.0625 - val_acc: 0.9808\n",
      "Epoch 9/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0231 - acc: 0.9922 - val_loss: 0.0558 - val_acc: 0.9815\n",
      "Epoch 10/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0187 - acc: 0.9951 - val_loss: 0.0732 - val_acc: 0.9750\n",
      "Epoch 11/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0157 - acc: 0.9959 - val_loss: 0.0579 - val_acc: 0.9835\n",
      "Epoch 12/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0114 - acc: 0.9977 - val_loss: 0.0522 - val_acc: 0.9845\n",
      "Epoch 13/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0096 - acc: 0.9978 - val_loss: 0.0521 - val_acc: 0.9850\n",
      "Epoch 14/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0087 - acc: 0.9977 - val_loss: 0.0541 - val_acc: 0.9858\n",
      "Epoch 15/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0046 - acc: 0.9995 - val_loss: 0.0499 - val_acc: 0.9858\n",
      "Epoch 16/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0035 - acc: 0.9998 - val_loss: 0.0515 - val_acc: 0.9868\n",
      "Epoch 17/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 0.0530 - val_acc: 0.9858\n",
      "Epoch 18/500\n",
      "9789/9789 [==============================] - 19s 2ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0808 - val_acc: 0.9805\n",
      "Epoch 19/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0616 - val_acc: 0.9853\n",
      "Epoch 20/500\n",
      "9789/9789 [==============================] - 20s 2ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0610 - val_acc: 0.9855\n",
      "2448/2448 [==============================] - 1s 441us/step\n",
      "9789/9789 [==============================] - 4s 441us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 27s 3ms/step - loss: 0.1933 - acc: 0.9189 - val_loss: 0.0861 - val_acc: 0.9745\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0868 - acc: 0.9712 - val_loss: 0.0743 - val_acc: 0.9750\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0705 - acc: 0.9771 - val_loss: 0.0708 - val_acc: 0.9773\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0596 - acc: 0.9805 - val_loss: 0.0625 - val_acc: 0.9770\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0504 - acc: 0.9832 - val_loss: 0.0632 - val_acc: 0.9768\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 21s 2ms/step - loss: 0.0423 - acc: 0.9867 - val_loss: 0.0587 - val_acc: 0.9798\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0355 - acc: 0.9880 - val_loss: 0.0600 - val_acc: 0.9810\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0621 - val_acc: 0.9790\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0228 - acc: 0.9937 - val_loss: 0.0522 - val_acc: 0.9833\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0194 - acc: 0.9948 - val_loss: 0.0723 - val_acc: 0.9773\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0145 - acc: 0.9966 - val_loss: 0.0506 - val_acc: 0.9848\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0114 - acc: 0.9972 - val_loss: 0.0495 - val_acc: 0.9845\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.0485 - val_acc: 0.9860\n",
      "Epoch 14/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0074 - acc: 0.9981 - val_loss: 0.0549 - val_acc: 0.9828\n",
      "Epoch 15/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0745 - val_acc: 0.9778\n",
      "Epoch 16/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0526 - val_acc: 0.9845\n",
      "Epoch 17/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0507 - val_acc: 0.9858\n",
      "Epoch 18/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0539 - val_acc: 0.9853\n",
      "2447/2447 [==============================] - 1s 449us/step\n",
      "9790/9790 [==============================] - 4s 452us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 27s 3ms/step - loss: 0.1868 - acc: 0.9187 - val_loss: 0.0875 - val_acc: 0.9718\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0847 - acc: 0.9718 - val_loss: 0.0766 - val_acc: 0.9725\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0692 - acc: 0.9762 - val_loss: 0.0860 - val_acc: 0.9688\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0606 - acc: 0.9801 - val_loss: 0.0644 - val_acc: 0.9778\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0492 - acc: 0.9824 - val_loss: 0.0669 - val_acc: 0.9750\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 21s 2ms/step - loss: 0.0407 - acc: 0.9860 - val_loss: 0.0690 - val_acc: 0.9778\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0361 - acc: 0.9871 - val_loss: 0.0634 - val_acc: 0.9773\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0275 - acc: 0.9908 - val_loss: 0.0635 - val_acc: 0.9775\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0635 - val_acc: 0.9783\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0184 - acc: 0.9937 - val_loss: 0.0525 - val_acc: 0.9820\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0118 - acc: 0.9975 - val_loss: 0.0545 - val_acc: 0.9818\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0092 - acc: 0.9983 - val_loss: 0.0563 - val_acc: 0.9813\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0506 - val_acc: 0.9833\n",
      "Epoch 14/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0091 - acc: 0.9965 - val_loss: 0.0516 - val_acc: 0.9838\n",
      "Epoch 15/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.0509 - val_acc: 0.9850\n",
      "Epoch 16/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0028 - acc: 0.9998 - val_loss: 0.0510 - val_acc: 0.9843\n",
      "Epoch 17/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0026 - acc: 0.9998 - val_loss: 0.0554 - val_acc: 0.9848\n",
      "Epoch 18/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0017 - acc: 0.9999 - val_loss: 0.0537 - val_acc: 0.9855\n",
      "2447/2447 [==============================] - 1s 457us/step\n",
      "9790/9790 [==============================] - 5s 465us/step\n",
      "Train on 9790 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "9790/9790 [==============================] - 27s 3ms/step - loss: 0.1106 - acc: 0.9517 - val_loss: 0.1501 - val_acc: 0.9518\n",
      "Epoch 2/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0516 - acc: 0.9839 - val_loss: 0.1573 - val_acc: 0.9513\n",
      "Epoch 3/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0423 - acc: 0.9855 - val_loss: 0.1084 - val_acc: 0.9620\n",
      "Epoch 4/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0357 - acc: 0.9870 - val_loss: 0.1078 - val_acc: 0.9628\n",
      "Epoch 5/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0295 - acc: 0.9893 - val_loss: 0.0787 - val_acc: 0.9723\n",
      "Epoch 6/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0237 - acc: 0.9911 - val_loss: 0.1618 - val_acc: 0.9510\n",
      "Epoch 7/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0215 - acc: 0.9919 - val_loss: 0.1237 - val_acc: 0.9665\n",
      "Epoch 8/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0152 - acc: 0.9949 - val_loss: 0.0715 - val_acc: 0.9768\n",
      "Epoch 9/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0121 - acc: 0.9956 - val_loss: 0.1271 - val_acc: 0.9695\n",
      "Epoch 10/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.1149 - val_acc: 0.9718\n",
      "Epoch 11/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.1272 - val_acc: 0.9705\n",
      "Epoch 12/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0036 - acc: 0.9996 - val_loss: 0.1026 - val_acc: 0.9750\n",
      "Epoch 13/500\n",
      "9790/9790 [==============================] - 20s 2ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1340 - val_acc: 0.9725\n",
      "2447/2447 [==============================] - 1s 463us/step\n",
      "9790/9790 [==============================] - 5s 464us/step\n",
      "Train on 12237 samples, validate on 4003 samples\n",
      "Epoch 1/500\n",
      "12237/12237 [==============================] - 68s 6ms/step - loss: 0.1200 - acc: 0.9547 - val_loss: 0.0788 - val_acc: 0.9735\n",
      "Epoch 2/500\n",
      "12237/12237 [==============================] - 60s 5ms/step - loss: 0.0704 - acc: 0.9760 - val_loss: 0.0840 - val_acc: 0.9753\n",
      "Epoch 3/500\n",
      "12237/12237 [==============================] - 61s 5ms/step - loss: 0.0524 - acc: 0.9812 - val_loss: 0.0539 - val_acc: 0.9810\n",
      "Epoch 4/500\n",
      "12237/12237 [==============================] - 62s 5ms/step - loss: 0.0379 - acc: 0.9873 - val_loss: 0.0441 - val_acc: 0.9850\n",
      "Epoch 5/500\n",
      "12237/12237 [==============================] - 61s 5ms/step - loss: 0.0230 - acc: 0.9925 - val_loss: 0.0449 - val_acc: 0.9868\n",
      "Epoch 6/500\n",
      "12237/12237 [==============================] - 62s 5ms/step - loss: 0.0162 - acc: 0.9940 - val_loss: 0.0433 - val_acc: 0.9860\n",
      "Epoch 7/500\n",
      "12237/12237 [==============================] - 61s 5ms/step - loss: 0.0123 - acc: 0.9955 - val_loss: 0.0414 - val_acc: 0.9865\n",
      "Epoch 8/500\n",
      "12237/12237 [==============================] - 61s 5ms/step - loss: 0.0076 - acc: 0.9972 - val_loss: 0.0451 - val_acc: 0.9865\n",
      "Epoch 9/500\n",
      "12237/12237 [==============================] - 61s 5ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.0452 - val_acc: 0.9853\n",
      "Epoch 10/500\n",
      "12237/12237 [==============================] - 60s 5ms/step - loss: 0.0028 - acc: 0.9996 - val_loss: 0.0494 - val_acc: 0.9875\n",
      "Epoch 11/500\n",
      "12237/12237 [==============================] - 61s 5ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0693 - val_acc: 0.9858\n",
      "Epoch 12/500\n",
      "12237/12237 [==============================] - 60s 5ms/step - loss: 0.0019 - acc: 0.9998 - val_loss: 0.0628 - val_acc: 0.9873\n",
      "Best: 0.974504 using {'batch_size': 8}\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 154s 10ms/step - loss: 0.0556 - acc: 0.9851 - val_loss: 0.0368 - val_acc: 0.9907\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 145s 9ms/step - loss: 0.0207 - acc: 0.9947 - val_loss: 0.0307 - val_acc: 0.9912\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 145s 9ms/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0240 - val_acc: 0.9936\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0075 - acc: 0.9972 - val_loss: 0.0292 - val_acc: 0.9924\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0435 - val_acc: 0.9906\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0021 - acc: 0.9991 - val_loss: 0.0225 - val_acc: 0.9937\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0865 - val_acc: 0.9847\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0358 - val_acc: 0.9936\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0334 - val_acc: 0.9934\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 1.3417e-04 - acc: 1.0000 - val_loss: 0.0425 - val_acc: 0.9936\n",
      "Epoch 11/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16067/16067 [==============================] - 146s 9ms/step - loss: 9.4950e-04 - acc: 0.9998 - val_loss: 0.0517 - val_acc: 0.9924 ETA: 1s - loss: \n",
      "4017/4017 [==============================] - 6s 1ms/step\n",
      "16067/16067 [==============================] - 24s 1ms/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 156s 10ms/step - loss: 0.0577 - acc: 0.9846 - val_loss: 0.0302 - val_acc: 0.9912\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0246 - acc: 0.9931 - val_loss: 0.0264 - val_acc: 0.99343s - loss: 0.0251 - acc\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0326 - val_acc: 0.9919\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0084 - acc: 0.9974 - val_loss: 0.0228 - val_acc: 0.9939\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0051 - acc: 0.9981 - val_loss: 0.0245 - val_acc: 0.9942\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0273 - val_acc: 0.9934\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 5.4497e-04 - acc: 0.9999 - val_loss: 0.0459 - val_acc: 0.9907\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0287 - val_acc: 0.9942\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 146s 9ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0280 - val_acc: 0.9942\n",
      "4017/4017 [==============================] - 6s 1ms/step\n",
      "16067/16067 [==============================] - 24s 1ms/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 156s 10ms/step - loss: 0.0614 - acc: 0.9828 - val_loss: 0.0276 - val_acc: 0.9918\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0269 - acc: 0.9920 - val_loss: 0.0266 - val_acc: 0.9925\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 160s 10ms/step - loss: 0.0160 - acc: 0.9940 - val_loss: 0.0216 - val_acc: 0.9934\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 156s 10ms/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0250 - val_acc: 0.9931\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0523 - val_acc: 0.9832\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 147s 9ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0231 - val_acc: 0.9942\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 153s 10ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0210 - val_acc: 0.9949\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 151s 9ms/step - loss: 9.1437e-04 - acc: 0.9998 - val_loss: 0.0218 - val_acc: 0.9955\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 149s 9ms/step - loss: 9.9257e-04 - acc: 0.9996 - val_loss: 0.0275 - val_acc: 0.9946\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 163s 10ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0212 - val_acc: 0.9948.99 - ETA: 1s - l\n",
      "Epoch 11/500\n",
      "16067/16067 [==============================] - 163s 10ms/step - loss: 4.0096e-05 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9948\n",
      "Epoch 12/500\n",
      "16067/16067 [==============================] - 156s 10ms/step - loss: 1.8927e-04 - acc: 0.9999 - val_loss: 0.0294 - val_acc: 0.9942\n",
      "Epoch 13/500\n",
      "16067/16067 [==============================] - 158s 10ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0255 - val_acc: 0.9948\n",
      "Epoch 14/500\n",
      "16067/16067 [==============================] - 142s 9ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0240 - val_acc: 0.9952\n",
      "Epoch 15/500\n",
      "16067/16067 [==============================] - 145s 9ms/step - loss: 8.3653e-06 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9948\n",
      "Epoch 16/500\n",
      "16067/16067 [==============================] - 149s 9ms/step - loss: 2.3326e-06 - acc: 1.0000 - val_loss: 0.0254 - val_acc: 0.9946: 2.2639e-06 - acc: 1.000 - ETA - ETA: 5s - loss - ETA: 3s - loss: 2.2246e- - ETA: 2s - \n",
      "4017/4017 [==============================] - 6s 1ms/step\n",
      "16067/16067 [==============================] - 24s 1ms/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 156s 10ms/step - loss: 0.0624 - acc: 0.9797 - val_loss: 0.0270 - val_acc: 0.9928\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 143s 9ms/step - loss: 0.0249 - acc: 0.9921 - val_loss: 0.0316 - val_acc: 0.9903\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 150s 9ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.0194 - val_acc: 0.9936\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 153s 9ms/step - loss: 0.0080 - acc: 0.9970 - val_loss: 0.0235 - val_acc: 0.9936\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 149s 9ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0231 - val_acc: 0.9940\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 149s 9ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0270 - val_acc: 0.9945\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 154s 10ms/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0226 - val_acc: 0.9946\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 151s 9ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0254 - val_acc: 0.9954\n",
      "4017/4017 [==============================] - 6s 2ms/step\n",
      "16067/16067 [==============================] - 25s 2ms/step\n",
      "Train on 16068 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16068/16068 [==============================] - 158s 10ms/step - loss: 0.0635 - acc: 0.9801 - val_loss: 0.0325 - val_acc: 0.9912\n",
      "Epoch 2/500\n",
      "16068/16068 [==============================] - 148s 9ms/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.0388 - val_acc: 0.9895\n",
      "Epoch 3/500\n",
      "16068/16068 [==============================] - 149s 9ms/step - loss: 0.0151 - acc: 0.9944 - val_loss: 0.0234 - val_acc: 0.9939\n",
      "Epoch 4/500\n",
      "16068/16068 [==============================] - 149s 9ms/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0204 - val_acc: 0.9942\n",
      "Epoch 5/500\n",
      "16068/16068 [==============================] - 147s 9ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0228 - val_acc: 0.9939\n",
      "Epoch 6/500\n",
      "16068/16068 [==============================] - 146s 9ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0284 - val_acc: 0.9934\n",
      "Epoch 7/500\n",
      "16068/16068 [==============================] - 146s 9ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0230 - val_acc: 0.9948\n",
      "Epoch 8/500\n",
      "16068/16068 [==============================] - 142s 9ms/step - loss: 5.0769e-04 - acc: 0.9998 - val_loss: 0.0247 - val_acc: 0.9948- loss: 5.0895e-04 - acc: 0\n",
      "Epoch 9/500\n",
      "16068/16068 [==============================] - 142s 9ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0248 - val_acc: 0.9955\n",
      "4016/4016 [==============================] - 6s 1ms/step\n",
      "16068/16068 [==============================] - 24s 1ms/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 92s 6ms/step - loss: 0.0622 - acc: 0.9826 - val_loss: 0.0392 - val_acc: 0.9903\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 81s 5ms/step - loss: 0.0225 - acc: 0.9943 - val_loss: 0.0264 - val_acc: 0.9930\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 83s 5ms/step - loss: 0.0158 - acc: 0.9949 - val_loss: 0.0263 - val_acc: 0.9933\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 82s 5ms/step - loss: 0.0088 - acc: 0.9973 - val_loss: 0.0262 - val_acc: 0.9927\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 82s 5ms/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.0297 - val_acc: 0.9934\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 85s 5ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0292 - val_acc: 0.9936\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 85s 5ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0399 - val_acc: 0.9934\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 82s 5ms/step - loss: 3.4880e-04 - acc: 1.0000 - val_loss: 0.0422 - val_acc: 0.9936\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 8.1281e-04 - acc: 0.9998 - val_loss: 0.0551 - val_acc: 0.9904\n",
      "4017/4017 [==============================] - 3s 783us/step\n",
      "16067/16067 [==============================] - 13s 788us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 87s 5ms/step - loss: 0.0670 - acc: 0.9827 - val_loss: 0.0279 - val_acc: 0.9919\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0233 - acc: 0.9942 - val_loss: 0.0262 - val_acc: 0.9934\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0164 - acc: 0.9956 - val_loss: 0.0225 - val_acc: 0.9937\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0226 - val_acc: 0.9928\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0264 - val_acc: 0.9933\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0267 - val_acc: 0.9936\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0247 - val_acc: 0.9936\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 4.2761e-04 - acc: 1.0000 - val_loss: 0.0235 - val_acc: 0.9943\n",
      "4017/4017 [==============================] - 3s 821us/step\n",
      "16067/16067 [==============================] - 13s 827us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 88s 5ms/step - loss: 0.0729 - acc: 0.9777 - val_loss: 0.0348 - val_acc: 0.9916\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0286 - acc: 0.9920 - val_loss: 0.0258 - val_acc: 0.9933\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0187 - acc: 0.9940 - val_loss: 0.0254 - val_acc: 0.9919\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0124 - acc: 0.9957 - val_loss: 0.0342 - val_acc: 0.9903\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 81s 5ms/step - loss: 0.0061 - acc: 0.9978 - val_loss: 0.0269 - val_acc: 0.9915\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0221 - val_acc: 0.9936\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0311 - val_acc: 0.9930\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0556 - val_acc: 0.9838\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0217 - val_acc: 0.9943\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 77s 5ms/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0210 - val_acc: 0.9952\n",
      "Epoch 11/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0250 - val_acc: 0.9943\n",
      "Epoch 12/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 2.8217e-04 - acc: 0.9999 - val_loss: 0.0198 - val_acc: 0.9949\n",
      "Epoch 13/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 1.0458e-04 - acc: 1.0000 - val_loss: 0.0243 - val_acc: 0.9945\n",
      "Epoch 14/500\n",
      "16067/16067 [==============================] - 77s 5ms/step - loss: 3.0719e-05 - acc: 1.0000 - val_loss: 0.0249 - val_acc: 0.9943\n",
      "Epoch 15/500\n",
      "16067/16067 [==============================] - 77s 5ms/step - loss: 9.1807e-04 - acc: 0.9998 - val_loss: 0.0253 - val_acc: 0.9948\n",
      "Epoch 16/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 5.9165e-04 - acc: 0.9999 - val_loss: 0.0239 - val_acc: 0.9945\n",
      "Epoch 17/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 1.2899e-05 - acc: 1.0000 - val_loss: 0.0229 - val_acc: 0.9951\n",
      "4017/4017 [==============================] - 3s 813us/step\n",
      "16067/16067 [==============================] - 13s 791us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 85s 5ms/step - loss: 0.0743 - acc: 0.9753 - val_loss: 0.0289 - val_acc: 0.9925\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0292 - acc: 0.9916 - val_loss: 0.0373 - val_acc: 0.9897\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 77s 5ms/step - loss: 0.0174 - acc: 0.9944 - val_loss: 0.0236 - val_acc: 0.9927\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 77s 5ms/step - loss: 0.0109 - acc: 0.9960 - val_loss: 0.0226 - val_acc: 0.9940\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 79s 5ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0485 - val_acc: 0.9858\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0271 - val_acc: 0.9928\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 78s 5ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0228 - val_acc: 0.9948\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 76s 5ms/step - loss: 9.9406e-04 - acc: 0.9998 - val_loss: 0.0239 - val_acc: 0.9951\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 77s 5ms/step - loss: 3.5058e-04 - acc: 1.0000 - val_loss: 0.0263 - val_acc: 0.9949\n",
      "4017/4017 [==============================] - 3s 784us/step\n",
      "16067/16067 [==============================] - 12s 778us/step\n",
      "Train on 16068 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16068/16068 [==============================] - 86s 5ms/step - loss: 0.0704 - acc: 0.9779 - val_loss: 0.0469 - val_acc: 0.9874\n",
      "Epoch 2/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0281 - acc: 0.9925 - val_loss: 0.0291 - val_acc: 0.9912\n",
      "Epoch 3/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0190 - acc: 0.9942 - val_loss: 0.0294 - val_acc: 0.9916\n",
      "Epoch 4/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0118 - acc: 0.9967 - val_loss: 0.0246 - val_acc: 0.9933\n",
      "Epoch 5/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0221 - val_acc: 0.9930\n",
      "Epoch 6/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0205 - val_acc: 0.9948\n",
      "Epoch 7/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0259 - val_acc: 0.9946\n",
      "Epoch 8/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0225 - val_acc: 0.9952\n",
      "Epoch 9/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0578 - val_acc: 0.9847\n",
      "Epoch 10/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0208 - val_acc: 0.9954\n",
      "Epoch 11/500\n",
      "16068/16068 [==============================] - 77s 5ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0192 - val_acc: 0.9954\n",
      "Epoch 12/500\n",
      "16068/16068 [==============================] - 77s 5ms/step - loss: 9.9360e-05 - acc: 1.0000 - val_loss: 0.0225 - val_acc: 0.9954\n",
      "Epoch 13/500\n",
      "16068/16068 [==============================] - 77s 5ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0186 - val_acc: 0.9955\n",
      "Epoch 14/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 8.2586e-05 - acc: 1.0000 - val_loss: 0.0207 - val_acc: 0.9955\n",
      "Epoch 15/500\n",
      "16068/16068 [==============================] - 78s 5ms/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0222 - val_acc: 0.9955\n",
      "Epoch 16/500\n",
      "16068/16068 [==============================] - 77s 5ms/step - loss: 3.1811e-05 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9952\n",
      "Epoch 17/500\n",
      "16068/16068 [==============================] - 77s 5ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0226 - val_acc: 0.9946\n",
      "Epoch 18/500\n",
      "16068/16068 [==============================] - 80s 5ms/step - loss: 6.1616e-05 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9948\n",
      "4016/4016 [==============================] - 4s 874us/step\n",
      "16068/16068 [==============================] - 13s 806us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16067/16067 [==============================] - 54s 3ms/step - loss: 0.0780 - acc: 0.9788 - val_loss: 0.0320 - val_acc: 0.9921\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0244 - acc: 0.9940 - val_loss: 0.0287 - val_acc: 0.9922\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0179 - acc: 0.9947 - val_loss: 0.0261 - val_acc: 0.9927\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.0259 - val_acc: 0.9919\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0288 - val_acc: 0.9922\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0055 - acc: 0.9981 - val_loss: 0.0296 - val_acc: 0.9931\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0412 - val_acc: 0.9928\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0387 - val_acc: 0.9928\n",
      "4017/4017 [==============================] - 2s 560us/step\n",
      "16067/16067 [==============================] - 9s 556us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 54s 3ms/step - loss: 0.0774 - acc: 0.9796 - val_loss: 0.0363 - val_acc: 0.9913\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0263 - acc: 0.9940 - val_loss: 0.0286 - val_acc: 0.9928\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0187 - acc: 0.9955 - val_loss: 0.0309 - val_acc: 0.9910\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0149 - acc: 0.9961 - val_loss: 0.0325 - val_acc: 0.9892\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0093 - acc: 0.9973 - val_loss: 0.0314 - val_acc: 0.9907\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0250 - val_acc: 0.9931\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0052 - acc: 0.9981 - val_loss: 0.0275 - val_acc: 0.9930\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0228 - val_acc: 0.9940\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0311 - val_acc: 0.9930\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 47s 3ms/step - loss: 7.0788e-04 - acc: 0.9999 - val_loss: 0.0309 - val_acc: 0.9930\n",
      "Epoch 11/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0026 - acc: 0.9990 - val_loss: 0.0269 - val_acc: 0.9942\n",
      "Epoch 12/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 2.7442e-04 - acc: 1.0000 - val_loss: 0.0360 - val_acc: 0.9928\n",
      "Epoch 13/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 5.3971e-04 - acc: 0.9998 - val_loss: 0.0301 - val_acc: 0.9934\n",
      "4017/4017 [==============================] - 2s 555us/step\n",
      "16067/16067 [==============================] - 9s 557us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 54s 3ms/step - loss: 0.0837 - acc: 0.9733 - val_loss: 0.0429 - val_acc: 0.9870\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0334 - acc: 0.9917 - val_loss: 0.0275 - val_acc: 0.9922\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0237 - acc: 0.9930 - val_loss: 0.0252 - val_acc: 0.9939\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.0232 - val_acc: 0.9934\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0231 - val_acc: 0.9934\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0295 - val_acc: 0.9918\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0047 - acc: 0.9988 - val_loss: 0.0226 - val_acc: 0.9940\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0272 - val_acc: 0.9933\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0264 - val_acc: 0.9930\n",
      "Epoch 11/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0024 - acc: 0.9989 - val_loss: 0.0254 - val_acc: 0.9936\n",
      "Epoch 12/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 4.7093e-04 - acc: 0.9999 - val_loss: 0.0258 - val_acc: 0.9939\n",
      "Epoch 13/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 5.3091e-04 - acc: 0.9999 - val_loss: 0.0475 - val_acc: 0.9877\n",
      "4017/4017 [==============================] - 2s 565us/step\n",
      "16067/16067 [==============================] - 9s 566us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 54s 3ms/step - loss: 0.0817 - acc: 0.9741 - val_loss: 0.0309 - val_acc: 0.9910\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0308 - acc: 0.9916 - val_loss: 0.0321 - val_acc: 0.9909\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0213 - acc: 0.9941 - val_loss: 0.0297 - val_acc: 0.9921\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0165 - acc: 0.9953 - val_loss: 0.0247 - val_acc: 0.9930\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0104 - acc: 0.9968 - val_loss: 0.0290 - val_acc: 0.9924\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0064 - acc: 0.9983 - val_loss: 0.0275 - val_acc: 0.9930\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.0043 - acc: 0.9989 - val_loss: 0.0260 - val_acc: 0.9942\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0036 - acc: 0.9986 - val_loss: 0.0254 - val_acc: 0.9934\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 45s 3ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0253 - val_acc: 0.9943\n",
      "4017/4017 [==============================] - 2s 561us/step\n",
      "16067/16067 [==============================] - 9s 563us/step\n",
      "Train on 16068 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16068/16068 [==============================] - 55s 3ms/step - loss: 0.0867 - acc: 0.9717 - val_loss: 0.0308 - val_acc: 0.9912\n",
      "Epoch 2/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0313 - acc: 0.9920 - val_loss: 0.0263 - val_acc: 0.9927\n",
      "Epoch 3/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0225 - acc: 0.9932 - val_loss: 0.0258 - val_acc: 0.9919\n",
      "Epoch 4/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0256 - val_acc: 0.9933\n",
      "Epoch 5/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0097 - acc: 0.9966 - val_loss: 0.0240 - val_acc: 0.9934\n",
      "Epoch 6/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0297 - val_acc: 0.9942\n",
      "Epoch 7/500\n",
      "16068/16068 [==============================] - 46s 3ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0215 - val_acc: 0.9940\n",
      "Epoch 8/500\n",
      "16068/16068 [==============================] - 46s 3ms/step - loss: 0.0030 - acc: 0.9994 - val_loss: 0.0214 - val_acc: 0.9942\n",
      "Epoch 9/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0234 - val_acc: 0.9949\n",
      "Epoch 10/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 3.4693e-04 - acc: 1.0000 - val_loss: 0.0240 - val_acc: 0.9942\n",
      "Epoch 11/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 0.0220 - val_acc: 0.9951\n",
      "Epoch 12/500\n",
      "16068/16068 [==============================] - 46s 3ms/step - loss: 2.9652e-04 - acc: 1.0000 - val_loss: 0.0238 - val_acc: 0.9951\n",
      "Epoch 13/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 1.3549e-04 - acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9948\n",
      "4016/4016 [==============================] - 2s 568us/step\n",
      "16068/16068 [==============================] - 9s 562us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 41s 3ms/step - loss: 0.0960 - acc: 0.9743 - val_loss: 0.0415 - val_acc: 0.9889\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0261 - acc: 0.9941 - val_loss: 0.0287 - val_acc: 0.9922\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0197 - acc: 0.9953 - val_loss: 0.0280 - val_acc: 0.9928\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0143 - acc: 0.9966 - val_loss: 0.0301 - val_acc: 0.9924\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0122 - acc: 0.9965 - val_loss: 0.0357 - val_acc: 0.9904\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0085 - acc: 0.9976 - val_loss: 0.0256 - val_acc: 0.9933\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0412 - val_acc: 0.9913\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0332 - val_acc: 0.9918\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0322 - val_acc: 0.9930\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 9.4548e-04 - acc: 0.9999 - val_loss: 0.0387 - val_acc: 0.9912\n",
      "Epoch 11/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0325 - val_acc: 0.9934\n",
      "4017/4017 [==============================] - 2s 496us/step\n",
      "16067/16067 [==============================] - 8s 506us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 46s 3ms/step - loss: 0.1049 - acc: 0.9691 - val_loss: 0.0360 - val_acc: 0.9909\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0287 - acc: 0.9935 - val_loss: 0.0437 - val_acc: 0.9870\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 0.0229 - acc: 0.9948 - val_loss: 0.0328 - val_acc: 0.9897\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 34s 2ms/step - loss: 0.0170 - acc: 0.9961 - val_loss: 0.0244 - val_acc: 0.9936\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0133 - acc: 0.9965 - val_loss: 0.0258 - val_acc: 0.9928\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0102 - acc: 0.9973 - val_loss: 0.0280 - val_acc: 0.9928\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 34s 2ms/step - loss: 0.0062 - acc: 0.9986 - val_loss: 0.0294 - val_acc: 0.9925\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0047 - acc: 0.9991 - val_loss: 0.0385 - val_acc: 0.9904\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 34s 2ms/step - loss: 0.0049 - acc: 0.9984 - val_loss: 0.0292 - val_acc: 0.9913\n",
      "4017/4017 [==============================] - 2s 464us/step\n",
      "16067/16067 [==============================] - 8s 470us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 41s 3ms/step - loss: 0.1050 - acc: 0.9676 - val_loss: 0.0356 - val_acc: 0.9918\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0349 - acc: 0.9912 - val_loss: 0.0316 - val_acc: 0.9921\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0273 - acc: 0.9927 - val_loss: 0.0326 - val_acc: 0.9910\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0209 - acc: 0.9944 - val_loss: 0.0263 - val_acc: 0.9921\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0161 - acc: 0.9956 - val_loss: 0.0256 - val_acc: 0.9924\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0341 - val_acc: 0.9895\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.0269 - val_acc: 0.9928\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0303 - val_acc: 0.9922\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0252 - val_acc: 0.9934\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 39s 2ms/step - loss: 0.0038 - acc: 0.9985 - val_loss: 0.0284 - val_acc: 0.9934\n",
      "Epoch 11/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0293 - val_acc: 0.9922\n",
      "Epoch 12/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0258 - val_acc: 0.9936\n",
      "Epoch 13/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 6.7598e-04 - acc: 1.0000 - val_loss: 0.0251 - val_acc: 0.9936\n",
      "Epoch 14/500\n",
      "16067/16067 [==============================] - 33s 2ms/step - loss: 7.4031e-04 - acc: 0.9999 - val_loss: 0.0287 - val_acc: 0.9927\n",
      "Epoch 15/500\n",
      "16067/16067 [==============================] - 37s 2ms/step - loss: 3.2208e-04 - acc: 1.0000 - val_loss: 0.0290 - val_acc: 0.9933\n",
      "Epoch 16/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 5.6289e-04 - acc: 0.9999 - val_loss: 0.0341 - val_acc: 0.9928\n",
      "Epoch 17/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0443 - val_acc: 0.9891\n",
      "Epoch 18/500\n",
      "16067/16067 [==============================] - 32s 2ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0361 - val_acc: 0.9915\n",
      "4017/4017 [==============================] - 2s 471us/step\n",
      "16067/16067 [==============================] - 8s 473us/step\n",
      "Train on 16067 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16067/16067 [==============================] - 42s 3ms/step - loss: 0.1070 - acc: 0.9649 - val_loss: 0.0339 - val_acc: 0.9921\n",
      "Epoch 2/500\n",
      "16067/16067 [==============================] - 36s 2ms/step - loss: 0.0349 - acc: 0.9912 - val_loss: 0.0273 - val_acc: 0.9925\n",
      "Epoch 3/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0266 - acc: 0.9932 - val_loss: 0.0259 - val_acc: 0.9925\n",
      "Epoch 4/500\n",
      "16067/16067 [==============================] - 35s 2ms/step - loss: 0.0214 - acc: 0.9940 - val_loss: 0.0247 - val_acc: 0.9930\n",
      "Epoch 5/500\n",
      "16067/16067 [==============================] - 38s 2ms/step - loss: 0.0157 - acc: 0.9951 - val_loss: 0.0240 - val_acc: 0.9933\n",
      "Epoch 6/500\n",
      "16067/16067 [==============================] - 36s 2ms/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.0258 - val_acc: 0.9934\n",
      "Epoch 7/500\n",
      "16067/16067 [==============================] - 37s 2ms/step - loss: 0.0081 - acc: 0.9977 - val_loss: 0.0266 - val_acc: 0.9934\n",
      "Epoch 8/500\n",
      "16067/16067 [==============================] - 36s 2ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0262 - val_acc: 0.9930\n",
      "Epoch 9/500\n",
      "16067/16067 [==============================] - 36s 2ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0245 - val_acc: 0.9940\n",
      "Epoch 10/500\n",
      "16067/16067 [==============================] - 36s 2ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0248 - val_acc: 0.9940\n",
      "4017/4017 [==============================] - 2s 489us/step\n",
      "16067/16067 [==============================] - 8s 514us/step\n",
      "Train on 16068 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "16068/16068 [==============================] - 45s 3ms/step - loss: 0.1042 - acc: 0.9650 - val_loss: 0.0434 - val_acc: 0.9900\n",
      "Epoch 2/500\n",
      "16068/16068 [==============================] - 34s 2ms/step - loss: 0.0332 - acc: 0.9913 - val_loss: 0.0392 - val_acc: 0.9891\n",
      "Epoch 3/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16068/16068 [==============================] - 35s 2ms/step - loss: 0.0247 - acc: 0.9927 - val_loss: 0.0253 - val_acc: 0.9931\n",
      "Epoch 4/500\n",
      "16068/16068 [==============================] - 36s 2ms/step - loss: 0.0187 - acc: 0.9948 - val_loss: 0.0252 - val_acc: 0.9933\n",
      "Epoch 5/500\n",
      "16068/16068 [==============================] - 37s 2ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0240 - val_acc: 0.9931\n",
      "Epoch 6/500\n",
      "16068/16068 [==============================] - 35s 2ms/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.0285 - val_acc: 0.9912\n",
      "Epoch 7/500\n",
      "16068/16068 [==============================] - 35s 2ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0268 - val_acc: 0.9922\n",
      "Epoch 8/500\n",
      "16068/16068 [==============================] - 36s 2ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0279 - val_acc: 0.9933\n",
      "Epoch 9/500\n",
      "16068/16068 [==============================] - 37s 2ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0245 - val_acc: 0.9939\n",
      "Epoch 10/500\n",
      "16068/16068 [==============================] - 36s 2ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0254 - val_acc: 0.9939\n",
      "4016/4016 [==============================] - 2s 500us/step\n",
      "16068/16068 [==============================] - 8s 494us/step\n",
      "Train on 20084 samples, validate on 6682 samples\n",
      "Epoch 1/500\n",
      "20084/20084 [==============================] - 52s 3ms/step - loss: 0.0884 - acc: 0.9740 - val_loss: 0.0306 - val_acc: 0.9921\n",
      "Epoch 2/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0307 - acc: 0.9923 - val_loss: 0.0302 - val_acc: 0.9906\n",
      "Epoch 3/500\n",
      "20084/20084 [==============================] - 42s 2ms/step - loss: 0.0226 - acc: 0.9937 - val_loss: 0.0236 - val_acc: 0.9934\n",
      "Epoch 4/500\n",
      "20084/20084 [==============================] - 42s 2ms/step - loss: 0.0166 - acc: 0.9954 - val_loss: 0.0337 - val_acc: 0.9897\n",
      "Epoch 5/500\n",
      "20084/20084 [==============================] - 42s 2ms/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0221 - val_acc: 0.9937\n",
      "Epoch 6/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0283 - val_acc: 0.9918\n",
      "Epoch 7/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0220 - val_acc: 0.9937\n",
      "Epoch 8/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 0.0265 - val_acc: 0.9933\n",
      "Epoch 9/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0234 - val_acc: 0.9942\n",
      "Epoch 10/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0312 - val_acc: 0.9912\n",
      "Epoch 11/500\n",
      "20084/20084 [==============================] - 42s 2ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0226 - val_acc: 0.9945\n",
      "Epoch 12/500\n",
      "20084/20084 [==============================] - 41s 2ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0244 - val_acc: 0.9939\n",
      "Best: 0.993477 using {'batch_size': 32}\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 120s 10ms/step - loss: 0.1242 - acc: 0.9663 - val_loss: 0.5334 - val_acc: 0.8032\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0902 - acc: 0.9735 - val_loss: 0.4470 - val_acc: 0.8395\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 110s 10ms/step - loss: 0.0668 - acc: 0.9795 - val_loss: 0.3663 - val_acc: 0.8683\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 109s 9ms/step - loss: 0.0470 - acc: 0.9846 - val_loss: 0.4579 - val_acc: 0.8695\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 111s 10ms/step - loss: 0.0300 - acc: 0.9900 - val_loss: 0.3679 - val_acc: 0.8915\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 109s 9ms/step - loss: 0.0175 - acc: 0.9941 - val_loss: 0.3009 - val_acc: 0.9139\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0137 - acc: 0.9957 - val_loss: 0.4653 - val_acc: 0.8911\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 110s 10ms/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.4200 - val_acc: 0.90960082 - acc: 0.\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 109s 9ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.5371 - val_acc: 0.9019\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0039 - acc: 0.9990 - val_loss: 0.4805 - val_acc: 0.9110\n",
      "Epoch 11/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.6024 - val_acc: 0.8977\n",
      "2876/2876 [==============================] - 5s 2ms/step\n",
      "11501/11501 [==============================] - 18s 2ms/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 121s 10ms/step - loss: 0.3632 - acc: 0.8326 - val_loss: 0.2701 - val_acc: 0.8830\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 110s 10ms/step - loss: 0.2240 - acc: 0.9120 - val_loss: 0.1872 - val_acc: 0.9297\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 109s 9ms/step - loss: 0.1390 - acc: 0.9478 - val_loss: 0.1541 - val_acc: 0.9444\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0953 - acc: 0.9630 - val_loss: 0.1281 - val_acc: 0.9531\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0615 - acc: 0.9783 - val_loss: 0.1105 - val_acc: 0.9591\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 107s 9ms/step - loss: 0.0407 - acc: 0.9860 - val_loss: 0.1260 - val_acc: 0.9571\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 106s 9ms/step - loss: 0.0252 - acc: 0.9926 - val_loss: 0.0841 - val_acc: 0.9737\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 106s 9ms/step - loss: 0.0186 - acc: 0.9945 - val_loss: 0.0986 - val_acc: 0.9710\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0128 - acc: 0.9964 - val_loss: 0.1100 - val_acc: 0.9710c\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 107s 9ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0964 - val_acc: 0.9780\n",
      "Epoch 11/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0100 - acc: 0.9970 - val_loss: 0.0935 - val_acc: 0.9778\n",
      "Epoch 12/500\n",
      "11501/11501 [==============================] - 108s 9ms/step - loss: 0.0046 - acc: 0.9989 - val_loss: 0.0960 - val_acc: 0.9790\n",
      "2876/2876 [==============================] - 5s 2ms/step\n",
      "11501/11501 [==============================] - 18s 2ms/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 120s 10ms/step - loss: 0.3763 - acc: 0.8254 - val_loss: 0.2610 - val_acc: 0.8946\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 109s 9ms/step - loss: 0.2234 - acc: 0.9156 - val_loss: 0.1781 - val_acc: 0.9307\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.1442 - acc: 0.9436 - val_loss: 0.1257 - val_acc: 0.9527\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0926 - acc: 0.9666 - val_loss: 0.1807 - val_acc: 0.9388\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 114s 10ms/step - loss: 0.0612 - acc: 0.9788 - val_loss: 0.1176 - val_acc: 0.9587\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 103s 9ms/step - loss: 0.0427 - acc: 0.9860 - val_loss: 0.1026 - val_acc: 0.9652\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 114s 10ms/step - loss: 0.0282 - acc: 0.9907 - val_loss: 0.1078 - val_acc: 0.9660\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 113s 10ms/step - loss: 0.0181 - acc: 0.9945 - val_loss: 0.0854 - val_acc: 0.9718\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 112s 10ms/step - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0931 - val_acc: 0.9749\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 114s 10ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.1156 - val_acc: 0.9708\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.0850 - val_acc: 0.9797\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 109s 10ms/step - loss: 0.0064 - acc: 0.9984 - val_loss: 0.1533 - val_acc: 0.9639\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 111s 10ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0922 - val_acc: 0.9782\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 111s 10ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.1083 - val_acc: 0.9768\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 119s 10ms/step - loss: 0.0047 - acc: 0.9993 - val_loss: 0.0838 - val_acc: 0.9790\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 117s 10ms/step - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0981 - val_acc: 0.9788\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 111s 10ms/step - loss: 0.0057 - acc: 0.9989 - val_loss: 0.1177 - val_acc: 0.9749\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 0.0953 - val_acc: 0.9805\n",
      "Epoch 19/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.1034 - val_acc: 0.9778\n",
      "Epoch 20/500\n",
      "11502/11502 [==============================] - 113s 10ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1045 - val_acc: 0.9807\n",
      "2875/2875 [==============================] - 5s 2ms/step\n",
      "11502/11502 [==============================] - 19s 2ms/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 126s 11ms/step - loss: 0.3717 - acc: 0.8328 - val_loss: 0.2522 - val_acc: 0.9009\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 117s 10ms/step - loss: 0.2169 - acc: 0.9136 - val_loss: 0.1707 - val_acc: 0.9365\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 120s 10ms/step - loss: 0.1391 - acc: 0.9476 - val_loss: 0.1306 - val_acc: 0.9510\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 111s 10ms/step - loss: 0.0876 - acc: 0.9683 - val_loss: 0.1248 - val_acc: 0.9523\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 110s 10ms/step - loss: 0.0610 - acc: 0.9790 - val_loss: 0.0972 - val_acc: 0.9672\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 116s 10ms/step - loss: 0.0371 - acc: 0.9895 - val_loss: 0.0974 - val_acc: 0.9678\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 115s 10ms/step - loss: 0.0270 - acc: 0.9910 - val_loss: 0.0934 - val_acc: 0.9676\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 114s 10ms/step - loss: 0.0170 - acc: 0.9951 - val_loss: 0.1001 - val_acc: 0.9712\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 117s 10ms/step - loss: 0.0125 - acc: 0.9963 - val_loss: 0.1052 - val_acc: 0.9708\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 107s 9ms/step - loss: 0.0118 - acc: 0.9962 - val_loss: 0.0886 - val_acc: 0.9743\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 104s 9ms/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0927 - val_acc: 0.9778\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.0917 - val_acc: 0.9786\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 111s 10ms/step - loss: 0.0072 - acc: 0.9977 - val_loss: 0.1267 - val_acc: 0.9699\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 109s 9ms/step - loss: 0.0029 - acc: 0.9995 - val_loss: 0.0930 - val_acc: 0.9795\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.1056 - val_acc: 0.9761\n",
      "2875/2875 [==============================] - 5s 2ms/step\n",
      "11502/11502 [==============================] - 18s 2ms/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 120s 10ms/step - loss: 0.3952 - acc: 0.8160 - val_loss: 0.2640 - val_acc: 0.8936\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 110s 10ms/step - loss: 0.2346 - acc: 0.9078 - val_loss: 0.1794 - val_acc: 0.9280\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 112s 10ms/step - loss: 0.1468 - acc: 0.9434 - val_loss: 0.2259 - val_acc: 0.9094\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 108s 9ms/step - loss: 0.0924 - acc: 0.9664 - val_loss: 0.1136 - val_acc: 0.9589\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 113s 10ms/step - loss: 0.0623 - acc: 0.9771 - val_loss: 0.1028 - val_acc: 0.9668\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 117s 10ms/step - loss: 0.0388 - acc: 0.9870 - val_loss: 0.0978 - val_acc: 0.9685\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 115s 10ms/step - loss: 0.0256 - acc: 0.9917 - val_loss: 0.0984 - val_acc: 0.9703\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 116s 10ms/step - loss: 0.0193 - acc: 0.9945 - val_loss: 0.1118 - val_acc: 0.9672\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 115s 10ms/step - loss: 0.0126 - acc: 0.9966 - val_loss: 0.0802 - val_acc: 0.9778\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 116s 10ms/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0880 - val_acc: 0.9759\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 117s 10ms/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0946 - val_acc: 0.9776\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 115s 10ms/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.0906 - val_acc: 0.9782\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 117s 10ms/step - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0886 - val_acc: 0.9805\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 109s 9ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.2132 - val_acc: 0.9558\n",
      "2875/2875 [==============================] - 5s 2ms/step\n",
      "11502/11502 [==============================] - 19s 2ms/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 69s 6ms/step - loss: 0.1291 - acc: 0.9657 - val_loss: 0.6428 - val_acc: 0.7797\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 58s 5ms/step - loss: 0.1012 - acc: 0.9701 - val_loss: 0.4729 - val_acc: 0.8148\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 58s 5ms/step - loss: 0.0759 - acc: 0.9763 - val_loss: 0.4902 - val_acc: 0.8490\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 58s 5ms/step - loss: 0.0577 - acc: 0.9814 - val_loss: 0.4715 - val_acc: 0.8633\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 58s 5ms/step - loss: 0.0453 - acc: 0.9846 - val_loss: 0.5918 - val_acc: 0.8484\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 58s 5ms/step - loss: 0.0325 - acc: 0.9883 - val_loss: 0.4663 - val_acc: 0.8718\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 57s 5ms/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.7057 - val_acc: 0.8575\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0169 - acc: 0.9943 - val_loss: 0.5156 - val_acc: 0.8826\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0127 - acc: 0.9963 - val_loss: 0.5818 - val_acc: 0.8818\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 57s 5ms/step - loss: 0.0086 - acc: 0.9977 - val_loss: 0.6322 - val_acc: 0.8816\n",
      "Epoch 11/500\n",
      "11501/11501 [==============================] - 59s 5ms/step - loss: 0.0073 - acc: 0.9973 - val_loss: 0.6173 - val_acc: 0.8888\n",
      "2876/2876 [==============================] - 3s 870us/step\n",
      "11501/11501 [==============================] - 10s 890us/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 71s 6ms/step - loss: 0.3930 - acc: 0.8167 - val_loss: 0.2751 - val_acc: 0.8901\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 63s 5ms/step - loss: 0.2458 - acc: 0.9031 - val_loss: 0.2192 - val_acc: 0.9160\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 64s 6ms/step - loss: 0.1670 - acc: 0.9369 - val_loss: 0.1718 - val_acc: 0.9326\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 64s 6ms/step - loss: 0.1194 - acc: 0.9544 - val_loss: 0.1391 - val_acc: 0.9481\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 62s 5ms/step - loss: 0.0840 - acc: 0.9705 - val_loss: 0.1126 - val_acc: 0.9585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 62s 5ms/step - loss: 0.0609 - acc: 0.9781 - val_loss: 0.1148 - val_acc: 0.9618\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 61s 5ms/step - loss: 0.0396 - acc: 0.9871 - val_loss: 0.1004 - val_acc: 0.9683\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0297 - acc: 0.9906 - val_loss: 0.0897 - val_acc: 0.9708\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 59s 5ms/step - loss: 0.0229 - acc: 0.9940 - val_loss: 0.1163 - val_acc: 0.9627\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 59s 5ms/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0941 - val_acc: 0.9712\n",
      "Epoch 11/500\n",
      "11501/11501 [==============================] - 59s 5ms/step - loss: 0.0112 - acc: 0.9971 - val_loss: 0.0895 - val_acc: 0.9755\n",
      "Epoch 12/500\n",
      "11501/11501 [==============================] - 61s 5ms/step - loss: 0.0117 - acc: 0.9968 - val_loss: 0.0958 - val_acc: 0.9734\n",
      "Epoch 13/500\n",
      "11501/11501 [==============================] - 59s 5ms/step - loss: 0.0067 - acc: 0.9987 - val_loss: 0.0942 - val_acc: 0.9753\n",
      "Epoch 14/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0090 - acc: 0.9970 - val_loss: 0.0894 - val_acc: 0.9757\n",
      "Epoch 15/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0039 - acc: 0.9992 - val_loss: 0.0829 - val_acc: 0.9793\n",
      "Epoch 16/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0847 - val_acc: 0.9774\n",
      "Epoch 17/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0062 - acc: 0.9976 - val_loss: 0.1193 - val_acc: 0.9737\n",
      "Epoch 18/500\n",
      "11501/11501 [==============================] - 60s 5ms/step - loss: 0.0042 - acc: 0.9987 - val_loss: 0.0889 - val_acc: 0.9803\n",
      "Epoch 19/500\n",
      "11501/11501 [==============================] - 59s 5ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0926 - val_acc: 0.9793\n",
      "Epoch 20/500\n",
      "11501/11501 [==============================] - 61s 5ms/step - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0987 - val_acc: 0.9778\n",
      "2876/2876 [==============================] - 3s 902us/step\n",
      "11501/11501 [==============================] - 10s 899us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 73s 6ms/step - loss: 0.4070 - acc: 0.8100 - val_loss: 0.3034 - val_acc: 0.8731\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 63s 5ms/step - loss: 0.2553 - acc: 0.9000 - val_loss: 0.2053 - val_acc: 0.9201\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.1809 - acc: 0.9287 - val_loss: 0.1607 - val_acc: 0.9423\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.1234 - acc: 0.9544 - val_loss: 0.1424 - val_acc: 0.9486\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 64s 6ms/step - loss: 0.0869 - acc: 0.9694 - val_loss: 0.1255 - val_acc: 0.9564\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0630 - acc: 0.9782 - val_loss: 0.1171 - val_acc: 0.9581\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0479 - acc: 0.9834 - val_loss: 0.1269 - val_acc: 0.9573\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0345 - acc: 0.9888 - val_loss: 0.0950 - val_acc: 0.9670\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0254 - acc: 0.9914 - val_loss: 0.0915 - val_acc: 0.9699\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0202 - acc: 0.9929 - val_loss: 0.1266 - val_acc: 0.9610\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0134 - acc: 0.9962 - val_loss: 0.0877 - val_acc: 0.9747\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0112 - acc: 0.9970 - val_loss: 0.1131 - val_acc: 0.9668\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0100 - acc: 0.9973 - val_loss: 0.0857 - val_acc: 0.9766\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 65s 6ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0923 - val_acc: 0.9734\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 63s 5ms/step - loss: 0.0059 - acc: 0.9986 - val_loss: 0.0881 - val_acc: 0.9797\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.1077 - val_acc: 0.9724\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 64s 6ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0861 - val_acc: 0.9780\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.1036 - val_acc: 0.9755\n",
      "2875/2875 [==============================] - 3s 948us/step\n",
      "11502/11502 [==============================] - 11s 958us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 70s 6ms/step - loss: 0.3970 - acc: 0.8115 - val_loss: 0.2692 - val_acc: 0.8894\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 58s 5ms/step - loss: 0.2472 - acc: 0.9018 - val_loss: 0.2189 - val_acc: 0.9145\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.1743 - acc: 0.9333 - val_loss: 0.1743 - val_acc: 0.9313\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 59s 5ms/step - loss: 0.1219 - acc: 0.9546 - val_loss: 0.1536 - val_acc: 0.9359\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0855 - acc: 0.9677 - val_loss: 0.1236 - val_acc: 0.9542\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0585 - acc: 0.9815 - val_loss: 0.0971 - val_acc: 0.9647\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0413 - acc: 0.9877 - val_loss: 0.0869 - val_acc: 0.9699\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0306 - acc: 0.9897 - val_loss: 0.0809 - val_acc: 0.9751\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.1016 - val_acc: 0.9699\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0138 - acc: 0.9962 - val_loss: 0.0797 - val_acc: 0.9761\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0157 - acc: 0.9954 - val_loss: 0.0839 - val_acc: 0.9782\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0086 - acc: 0.9979 - val_loss: 0.0870 - val_acc: 0.9768\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0901 - val_acc: 0.9778\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0957 - val_acc: 0.9761\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 61s 5ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0890 - val_acc: 0.9770\n",
      "2875/2875 [==============================] - 3s 897us/step\n",
      "11502/11502 [==============================] - 10s 907us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 76s 7ms/step - loss: 0.3986 - acc: 0.8173 - val_loss: 0.2767 - val_acc: 0.8880\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 66s 6ms/step - loss: 0.2564 - acc: 0.8941 - val_loss: 0.2056 - val_acc: 0.9172\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 64s 6ms/step - loss: 0.1767 - acc: 0.9331 - val_loss: 0.1624 - val_acc: 0.9349\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.1258 - acc: 0.9527 - val_loss: 0.1411 - val_acc: 0.9459\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 74s 6ms/step - loss: 0.0905 - acc: 0.9663 - val_loss: 0.1285 - val_acc: 0.9508\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 76s 7ms/step - loss: 0.0651 - acc: 0.9778 - val_loss: 0.1046 - val_acc: 0.9656\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 73s 6ms/step - loss: 0.0531 - acc: 0.9821 - val_loss: 0.0942 - val_acc: 0.9654\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 72s 6ms/step - loss: 0.0365 - acc: 0.9878 - val_loss: 0.1060 - val_acc: 0.9641\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 78s 7ms/step - loss: 0.0287 - acc: 0.9908 - val_loss: 0.1029 - val_acc: 0.9670\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 65s 6ms/step - loss: 0.0229 - acc: 0.9926 - val_loss: 0.1016 - val_acc: 0.9681\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 70s 6ms/step - loss: 0.0133 - acc: 0.9964 - val_loss: 0.0933 - val_acc: 0.9718\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 67s 6ms/step - loss: 0.0130 - acc: 0.9969 - val_loss: 0.1017 - val_acc: 0.9701\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 71s 6ms/step - loss: 0.0136 - acc: 0.9950 - val_loss: 0.0875 - val_acc: 0.9757\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 66s 6ms/step - loss: 0.0074 - acc: 0.9983 - val_loss: 0.1013 - val_acc: 0.9737\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 67s 6ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0956 - val_acc: 0.9755\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 73s 6ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0961 - val_acc: 0.9745\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 63s 5ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0953 - val_acc: 0.9761\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 62s 5ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.1056 - val_acc: 0.9724\n",
      "2875/2875 [==============================] - 3s 931us/step\n",
      "11502/11502 [==============================] - 11s 959us/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 48s 4ms/step - loss: 0.1306 - acc: 0.9650 - val_loss: 0.6265 - val_acc: 0.7778\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.1074 - acc: 0.9679 - val_loss: 0.6643 - val_acc: 0.7913\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.0814 - acc: 0.9734 - val_loss: 0.3897 - val_acc: 0.8546\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 44s 4ms/step - loss: 0.0652 - acc: 0.9783 - val_loss: 0.3446 - val_acc: 0.8691\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 40s 3ms/step - loss: 0.0518 - acc: 0.9828 - val_loss: 0.3583 - val_acc: 0.8720\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0399 - acc: 0.9862 - val_loss: 0.4005 - val_acc: 0.8722\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0304 - acc: 0.9893 - val_loss: 0.4295 - val_acc: 0.8782\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.0238 - acc: 0.9912 - val_loss: 0.3605 - val_acc: 0.8990\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0205 - acc: 0.9929 - val_loss: 0.3604 - val_acc: 0.9023\n",
      "2876/2876 [==============================] - 2s 658us/step\n",
      "11501/11501 [==============================] - 8s 653us/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 49s 4ms/step - loss: 0.4134 - acc: 0.8092 - val_loss: 0.3003 - val_acc: 0.8743\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.2762 - acc: 0.8846 - val_loss: 0.2353 - val_acc: 0.9073\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 40s 3ms/step - loss: 0.2115 - acc: 0.9186 - val_loss: 0.2002 - val_acc: 0.9241\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.1644 - acc: 0.9357 - val_loss: 0.1713 - val_acc: 0.9376\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 41s 4ms/step - loss: 0.1339 - acc: 0.9480 - val_loss: 0.1597 - val_acc: 0.9363\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 36s 3ms/step - loss: 0.1096 - acc: 0.9595 - val_loss: 0.1316 - val_acc: 0.9525\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 36s 3ms/step - loss: 0.0865 - acc: 0.9693 - val_loss: 0.1218 - val_acc: 0.9552\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0666 - acc: 0.9774 - val_loss: 0.1321 - val_acc: 0.9506\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.0571 - acc: 0.9803 - val_loss: 0.1166 - val_acc: 0.9598\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0455 - acc: 0.9846 - val_loss: 0.1161 - val_acc: 0.9602\n",
      "Epoch 11/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.0318 - acc: 0.9905 - val_loss: 0.1172 - val_acc: 0.9616\n",
      "Epoch 12/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0298 - acc: 0.9918 - val_loss: 0.1136 - val_acc: 0.9649\n",
      "Epoch 13/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.0229 - acc: 0.9937 - val_loss: 0.0999 - val_acc: 0.9660\n",
      "Epoch 14/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0181 - acc: 0.9950 - val_loss: 0.1425 - val_acc: 0.9517\n",
      "Epoch 15/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.0188 - acc: 0.9941 - val_loss: 0.1165 - val_acc: 0.9645\n",
      "Epoch 16/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0995 - val_acc: 0.9712\n",
      "Epoch 17/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.1155 - val_acc: 0.9685\n",
      "Epoch 18/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.0070 - acc: 0.9988 - val_loss: 0.0965 - val_acc: 0.9747\n",
      "Epoch 19/500\n",
      "11501/11501 [==============================] - 40s 3ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 0.1265 - val_acc: 0.9676\n",
      "Epoch 20/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.0049 - acc: 0.9993 - val_loss: 0.1023 - val_acc: 0.9741\n",
      "Epoch 21/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1060 - val_acc: 0.9739\n",
      "Epoch 22/500\n",
      "11501/11501 [==============================] - 38s 3ms/step - loss: 0.0093 - acc: 0.9972 - val_loss: 0.0958 - val_acc: 0.9757\n",
      "Epoch 23/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0999 - val_acc: 0.9753\n",
      "Epoch 24/500\n",
      "11501/11501 [==============================] - 37s 3ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.1107 - val_acc: 0.9743\n",
      "Epoch 25/500\n",
      "11501/11501 [==============================] - 36s 3ms/step - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1350 - val_acc: 0.9689\n",
      "Epoch 26/500\n",
      "11501/11501 [==============================] - 36s 3ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.1039 - val_acc: 0.9757\n",
      "Epoch 27/500\n",
      "11501/11501 [==============================] - 39s 3ms/step - loss: 0.0058 - acc: 0.9985 - val_loss: 0.1096 - val_acc: 0.9757\n",
      "2876/2876 [==============================] - 2s 648us/step\n",
      "11501/11501 [==============================] - 7s 644us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 51s 4ms/step - loss: 0.4289 - acc: 0.7957 - val_loss: 0.2976 - val_acc: 0.8741\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.2847 - acc: 0.8818 - val_loss: 0.2386 - val_acc: 0.9112\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.2156 - acc: 0.9185 - val_loss: 0.1895 - val_acc: 0.9305\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.1632 - acc: 0.9389 - val_loss: 0.1672 - val_acc: 0.9388\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.1268 - acc: 0.9544 - val_loss: 0.1462 - val_acc: 0.9492\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.0958 - acc: 0.9652 - val_loss: 0.1156 - val_acc: 0.9562\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.0732 - acc: 0.9742 - val_loss: 0.1245 - val_acc: 0.9560\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 40s 4ms/step - loss: 0.0567 - acc: 0.9803 - val_loss: 0.1063 - val_acc: 0.9631\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11502/11502 [==============================] - 36s 3ms/step - loss: 0.0404 - acc: 0.9880 - val_loss: 0.1024 - val_acc: 0.9652\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0350 - acc: 0.9896 - val_loss: 0.0989 - val_acc: 0.9666\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0245 - acc: 0.9930 - val_loss: 0.0901 - val_acc: 0.9689\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0187 - acc: 0.9950 - val_loss: 0.0914 - val_acc: 0.9716\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0185 - acc: 0.9941 - val_loss: 0.1027 - val_acc: 0.9681\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0121 - acc: 0.9966 - val_loss: 0.0824 - val_acc: 0.9759\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0094 - acc: 0.9976 - val_loss: 0.0872 - val_acc: 0.9747\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 39s 3ms/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0956 - val_acc: 0.9722\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 41s 4ms/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.0912 - val_acc: 0.9743\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 39s 3ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0916 - val_acc: 0.9751\n",
      "Epoch 19/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.0065 - acc: 0.9982 - val_loss: 0.0882 - val_acc: 0.9772\n",
      "2875/2875 [==============================] - 2s 654us/step\n",
      "11502/11502 [==============================] - 8s 674us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 51s 4ms/step - loss: 0.4142 - acc: 0.8003 - val_loss: 0.2950 - val_acc: 0.8664\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.2768 - acc: 0.8852 - val_loss: 0.2344 - val_acc: 0.9104\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.2182 - acc: 0.9120 - val_loss: 0.2004 - val_acc: 0.9239\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.1730 - acc: 0.9337 - val_loss: 0.1652 - val_acc: 0.9357\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 39s 3ms/step - loss: 0.1353 - acc: 0.9504 - val_loss: 0.1981 - val_acc: 0.9239\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.1067 - acc: 0.9609 - val_loss: 0.1351 - val_acc: 0.9529\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0846 - acc: 0.9691 - val_loss: 0.1264 - val_acc: 0.9556\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0657 - acc: 0.9784 - val_loss: 0.1138 - val_acc: 0.9566\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.0510 - acc: 0.9833 - val_loss: 0.1130 - val_acc: 0.9560\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 38s 3ms/step - loss: 0.0420 - acc: 0.9860 - val_loss: 0.1055 - val_acc: 0.9600\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.0317 - acc: 0.9905 - val_loss: 0.1101 - val_acc: 0.9645\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 36s 3ms/step - loss: 0.0280 - acc: 0.9904 - val_loss: 0.1038 - val_acc: 0.9666\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0187 - acc: 0.9947 - val_loss: 0.1242 - val_acc: 0.9608: 0s - loss: 0.0186 - ac - ETA: 0s - loss: 0.0188 - acc: 0.9\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0185 - acc: 0.9942 - val_loss: 0.1080 - val_acc: 0.9664\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.1112 - val_acc: 0.9652\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0135 - acc: 0.9966 - val_loss: 0.0962 - val_acc: 0.9695\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 37s 3ms/step - loss: 0.0099 - acc: 0.9973 - val_loss: 0.0932 - val_acc: 0.9741\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 33s 3ms/step - loss: 0.0063 - acc: 0.9990 - val_loss: 0.1427 - val_acc: 0.9614\n",
      "Epoch 19/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0123 - acc: 0.9959 - val_loss: 0.1032 - val_acc: 0.9747\n",
      "Epoch 20/500\n",
      "11502/11502 [==============================] - 33s 3ms/step - loss: 0.0056 - acc: 0.9992 - val_loss: 0.0923 - val_acc: 0.9755\n",
      "Epoch 21/500\n",
      "11502/11502 [==============================] - 33s 3ms/step - loss: 0.0039 - acc: 0.9995 - val_loss: 0.1123 - val_acc: 0.9718\n",
      "Epoch 22/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0994 - val_acc: 0.9737\n",
      "Epoch 23/500\n",
      "11502/11502 [==============================] - 33s 3ms/step - loss: 0.0039 - acc: 0.9991 - val_loss: 0.0995 - val_acc: 0.9739\n",
      "Epoch 24/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.1022 - val_acc: 0.9739\n",
      "Epoch 25/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0874 - val_acc: 0.9774\n",
      "Epoch 26/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.1001 - val_acc: 0.9757\n",
      "Epoch 27/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0881 - val_acc: 0.9778\n",
      "Epoch 28/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.0924 - val_acc: 0.9776\n",
      "Epoch 29/500\n",
      "11502/11502 [==============================] - 33s 3ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0954 - val_acc: 0.9790\n",
      "Epoch 30/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0945 - val_acc: 0.9776\n",
      "2875/2875 [==============================] - 2s 600us/step\n",
      "11502/11502 [==============================] - 7s 601us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 47s 4ms/step - loss: 0.4388 - acc: 0.7919 - val_loss: 0.2980 - val_acc: 0.8811\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.2797 - acc: 0.8858 - val_loss: 0.2310 - val_acc: 0.9071\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.2148 - acc: 0.9158 - val_loss: 0.1962 - val_acc: 0.9243\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.1744 - acc: 0.9344 - val_loss: 0.1729 - val_acc: 0.9349\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.1368 - acc: 0.9496 - val_loss: 0.1581 - val_acc: 0.9411\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.1152 - acc: 0.9566 - val_loss: 0.1348 - val_acc: 0.9494\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0865 - acc: 0.9687 - val_loss: 0.1321 - val_acc: 0.9508\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0693 - acc: 0.9772 - val_loss: 0.1235 - val_acc: 0.9581\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.0577 - acc: 0.9790 - val_loss: 0.1168 - val_acc: 0.9552\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0492 - acc: 0.9831 - val_loss: 0.0959 - val_acc: 0.9672\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0357 - acc: 0.9908 - val_loss: 0.1016 - val_acc: 0.9647\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0287 - acc: 0.9920 - val_loss: 0.1017 - val_acc: 0.9691\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0187 - acc: 0.9956 - val_loss: 0.1362 - val_acc: 0.9571\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0204 - acc: 0.9937 - val_loss: 0.0959 - val_acc: 0.9695\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.0149 - acc: 0.9963 - val_loss: 0.1061 - val_acc: 0.9689\n",
      "2875/2875 [==============================] - 2s 616us/step\n",
      "11502/11502 [==============================] - 7s 605us/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 35s 3ms/step - loss: 0.1364 - acc: 0.9657 - val_loss: 0.6371 - val_acc: 0.7778\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.1179 - acc: 0.9662 - val_loss: 0.5594 - val_acc: 0.7781\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0995 - acc: 0.9690 - val_loss: 0.4139 - val_acc: 0.8301\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 25s 2ms/step - loss: 0.0808 - acc: 0.9749 - val_loss: 0.4542 - val_acc: 0.8434\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0661 - acc: 0.9791 - val_loss: 0.3696 - val_acc: 0.8594\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0520 - acc: 0.9825 - val_loss: 0.4006 - val_acc: 0.8687\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0434 - acc: 0.9859 - val_loss: 0.4287 - val_acc: 0.8695\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0364 - acc: 0.9881 - val_loss: 0.4474 - val_acc: 0.8693\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.4425 - val_acc: 0.8749\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0214 - acc: 0.9936 - val_loss: 0.3825 - val_acc: 0.8915\n",
      "2876/2876 [==============================] - 1s 489us/step\n",
      "11501/11501 [==============================] - 6s 491us/step\n",
      "Train on 11501 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11501/11501 [==============================] - 34s 3ms/step - loss: 0.4410 - acc: 0.7847 - val_loss: 0.3409 - val_acc: 0.8560\n",
      "Epoch 2/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.3041 - acc: 0.8696 - val_loss: 0.2807 - val_acc: 0.8778\n",
      "Epoch 3/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.2465 - acc: 0.9004 - val_loss: 0.2280 - val_acc: 0.9125\n",
      "Epoch 4/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.1956 - acc: 0.9274 - val_loss: 0.2125 - val_acc: 0.9197\n",
      "Epoch 5/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.1648 - acc: 0.9394 - val_loss: 0.1743 - val_acc: 0.9334\n",
      "Epoch 6/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.1401 - acc: 0.9470 - val_loss: 0.1674 - val_acc: 0.9394\n",
      "Epoch 7/500\n",
      "11501/11501 [==============================] - 25s 2ms/step - loss: 0.1171 - acc: 0.9570 - val_loss: 0.1621 - val_acc: 0.9450\n",
      "Epoch 8/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0992 - acc: 0.9651 - val_loss: 0.1480 - val_acc: 0.9457\n",
      "Epoch 9/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0861 - acc: 0.9701 - val_loss: 0.1318 - val_acc: 0.9510\n",
      "Epoch 10/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.0751 - acc: 0.9739 - val_loss: 0.1308 - val_acc: 0.9548\n",
      "Epoch 11/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.0612 - acc: 0.9806 - val_loss: 0.1212 - val_acc: 0.9579\n",
      "Epoch 12/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0583 - acc: 0.9795 - val_loss: 0.1284 - val_acc: 0.9546\n",
      "Epoch 13/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0470 - acc: 0.9843 - val_loss: 0.1116 - val_acc: 0.9620\n",
      "Epoch 14/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.0430 - acc: 0.9874 - val_loss: 0.1272 - val_acc: 0.9604\n",
      "Epoch 15/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.0345 - acc: 0.9900 - val_loss: 0.1208 - val_acc: 0.9614\n",
      "Epoch 16/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.0335 - acc: 0.9893 - val_loss: 0.1097 - val_acc: 0.9660\n",
      "Epoch 17/500\n",
      "11501/11501 [==============================] - 23s 2ms/step - loss: 0.0296 - acc: 0.9910 - val_loss: 0.1102 - val_acc: 0.9658\n",
      "Epoch 18/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0260 - acc: 0.9930 - val_loss: 0.1128 - val_acc: 0.9629\n",
      "Epoch 19/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0225 - acc: 0.9931 - val_loss: 0.1469 - val_acc: 0.9535\n",
      "Epoch 20/500\n",
      "11501/11501 [==============================] - 25s 2ms/step - loss: 0.0188 - acc: 0.9955 - val_loss: 0.1298 - val_acc: 0.9593\n",
      "Epoch 21/500\n",
      "11501/11501 [==============================] - 24s 2ms/step - loss: 0.0176 - acc: 0.9951 - val_loss: 0.1149 - val_acc: 0.9664\n",
      "2876/2876 [==============================] - 1s 497us/step\n",
      "11501/11501 [==============================] - 6s 490us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.4585 - acc: 0.7766 - val_loss: 0.3213 - val_acc: 0.8587\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.2992 - acc: 0.8771 - val_loss: 0.2531 - val_acc: 0.8984\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.2376 - acc: 0.9072 - val_loss: 0.2103 - val_acc: 0.9206\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.1879 - acc: 0.9311 - val_loss: 0.1829 - val_acc: 0.9332\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.1622 - acc: 0.9405 - val_loss: 0.1747 - val_acc: 0.9359\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.1351 - acc: 0.9506 - val_loss: 0.1539 - val_acc: 0.9432\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.1168 - acc: 0.9591 - val_loss: 0.1453 - val_acc: 0.9513\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0946 - acc: 0.9654 - val_loss: 0.1416 - val_acc: 0.9461\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0810 - acc: 0.9715 - val_loss: 0.1277 - val_acc: 0.9560\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0672 - acc: 0.9776 - val_loss: 0.1225 - val_acc: 0.9569\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0619 - acc: 0.9781 - val_loss: 0.1291 - val_acc: 0.9548\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0493 - acc: 0.9846 - val_loss: 0.1338 - val_acc: 0.9523\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0402 - acc: 0.9865 - val_loss: 0.1247 - val_acc: 0.9589\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0354 - acc: 0.9898 - val_loss: 0.1071 - val_acc: 0.9647\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0313 - acc: 0.9912 - val_loss: 0.1006 - val_acc: 0.9670\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 0.1140 - val_acc: 0.9620\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0230 - acc: 0.9931 - val_loss: 0.1258 - val_acc: 0.9575\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0208 - acc: 0.9938 - val_loss: 0.1024 - val_acc: 0.9672\n",
      "Epoch 19/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0181 - acc: 0.9952 - val_loss: 0.1022 - val_acc: 0.9685\n",
      "Epoch 20/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0154 - acc: 0.9963 - val_loss: 0.0934 - val_acc: 0.9678\n",
      "Epoch 21/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.1059 - val_acc: 0.9681\n",
      "Epoch 22/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0098 - acc: 0.9983 - val_loss: 0.0968 - val_acc: 0.9712\n",
      "Epoch 23/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0084 - acc: 0.9984 - val_loss: 0.0982 - val_acc: 0.9722\n",
      "Epoch 24/500\n",
      "11502/11502 [==============================] - 25s 2ms/step - loss: 0.0087 - acc: 0.9981 - val_loss: 0.1095 - val_acc: 0.9685\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0103 - acc: 0.9973 - val_loss: 0.1327 - val_acc: 0.9622\n",
      "2875/2875 [==============================] - 1s 473us/step\n",
      "11502/11502 [==============================] - 6s 485us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 34s 3ms/step - loss: 0.4759 - acc: 0.7685 - val_loss: 0.3535 - val_acc: 0.8515\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.3242 - acc: 0.8632 - val_loss: 0.2616 - val_acc: 0.9000\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.2508 - acc: 0.9024 - val_loss: 0.2737 - val_acc: 0.8814\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.2017 - acc: 0.9213 - val_loss: 0.1881 - val_acc: 0.9313\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.1620 - acc: 0.9411 - val_loss: 0.1763 - val_acc: 0.9355\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.1333 - acc: 0.9514 - val_loss: 0.1471 - val_acc: 0.9465\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.1099 - acc: 0.9615 - val_loss: 0.1385 - val_acc: 0.9465\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0932 - acc: 0.9655 - val_loss: 0.1238 - val_acc: 0.9542\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0814 - acc: 0.9715 - val_loss: 0.1304 - val_acc: 0.9527\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0600 - acc: 0.9800 - val_loss: 0.1351 - val_acc: 0.9517\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0558 - acc: 0.9813 - val_loss: 0.1093 - val_acc: 0.9600\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0433 - acc: 0.9870 - val_loss: 0.1180 - val_acc: 0.9591\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0369 - acc: 0.9888 - val_loss: 0.1089 - val_acc: 0.9614\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0322 - acc: 0.9891 - val_loss: 0.1018 - val_acc: 0.9681\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0257 - acc: 0.9926 - val_loss: 0.1002 - val_acc: 0.9676\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0218 - acc: 0.9941 - val_loss: 0.0947 - val_acc: 0.9728\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0188 - acc: 0.9953 - val_loss: 0.1053 - val_acc: 0.9660\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0160 - acc: 0.9954 - val_loss: 0.0916 - val_acc: 0.9724\n",
      "Epoch 19/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.0894 - val_acc: 0.9730\n",
      "Epoch 20/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0122 - acc: 0.9968 - val_loss: 0.0910 - val_acc: 0.9732\n",
      "Epoch 21/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0108 - acc: 0.9976 - val_loss: 0.0921 - val_acc: 0.9734\n",
      "Epoch 22/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0093 - acc: 0.9979 - val_loss: 0.0931 - val_acc: 0.9770\n",
      "Epoch 23/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0103 - acc: 0.9970 - val_loss: 0.0986 - val_acc: 0.9730\n",
      "Epoch 24/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0056 - acc: 0.9991 - val_loss: 0.0838 - val_acc: 0.9786\n",
      "Epoch 25/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.0937 - val_acc: 0.9757\n",
      "Epoch 26/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0938 - val_acc: 0.9774\n",
      "Epoch 27/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1144 - val_acc: 0.9728\n",
      "Epoch 28/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0059 - acc: 0.9987 - val_loss: 0.0918 - val_acc: 0.9770\n",
      "Epoch 29/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0029 - acc: 0.9998 - val_loss: 0.0949 - val_acc: 0.9774\n",
      "2875/2875 [==============================] - 1s 471us/step\n",
      "11502/11502 [==============================] - 5s 477us/step\n",
      "Train on 11502 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "11502/11502 [==============================] - 35s 3ms/step - loss: 0.4620 - acc: 0.7737 - val_loss: 0.3510 - val_acc: 0.8556\n",
      "Epoch 2/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.3145 - acc: 0.8636 - val_loss: 0.2985 - val_acc: 0.8664\n",
      "Epoch 3/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.2460 - acc: 0.9029 - val_loss: 0.2285 - val_acc: 0.9056\n",
      "Epoch 4/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.1964 - acc: 0.9257 - val_loss: 0.2094 - val_acc: 0.9177\n",
      "Epoch 5/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.1629 - acc: 0.9401 - val_loss: 0.2026 - val_acc: 0.9214\n",
      "Epoch 6/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.1376 - acc: 0.9495 - val_loss: 0.1478 - val_acc: 0.9477\n",
      "Epoch 7/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.1191 - acc: 0.9558 - val_loss: 0.1508 - val_acc: 0.9471\n",
      "Epoch 8/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0987 - acc: 0.9631 - val_loss: 0.1804 - val_acc: 0.9340\n",
      "Epoch 9/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0844 - acc: 0.9697 - val_loss: 0.1304 - val_acc: 0.9506\n",
      "Epoch 10/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0727 - acc: 0.9733 - val_loss: 0.1395 - val_acc: 0.9500\n",
      "Epoch 11/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0606 - acc: 0.9800 - val_loss: 0.1063 - val_acc: 0.9606\n",
      "Epoch 12/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0513 - acc: 0.9824 - val_loss: 0.1078 - val_acc: 0.9629\n",
      "Epoch 13/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0458 - acc: 0.9859 - val_loss: 0.1125 - val_acc: 0.9614\n",
      "Epoch 14/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0407 - acc: 0.9874 - val_loss: 0.0999 - val_acc: 0.9664\n",
      "Epoch 15/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0316 - acc: 0.9913 - val_loss: 0.1004 - val_acc: 0.9670\n",
      "Epoch 16/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0306 - acc: 0.9905 - val_loss: 0.1023 - val_acc: 0.9672\n",
      "Epoch 17/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0203 - acc: 0.9950 - val_loss: 0.0890 - val_acc: 0.9697\n",
      "Epoch 18/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0191 - acc: 0.9953 - val_loss: 0.0922 - val_acc: 0.9703\n",
      "Epoch 19/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0224 - acc: 0.9933 - val_loss: 0.0876 - val_acc: 0.9734\n",
      "Epoch 20/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0136 - acc: 0.9969 - val_loss: 0.0865 - val_acc: 0.9743\n",
      "Epoch 21/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0140 - acc: 0.9963 - val_loss: 0.0957 - val_acc: 0.9712\n",
      "Epoch 22/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0094 - acc: 0.9984 - val_loss: 0.0887 - val_acc: 0.9759\n",
      "Epoch 23/500\n",
      "11502/11502 [==============================] - 23s 2ms/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.1614 - val_acc: 0.9554\n",
      "Epoch 24/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0969 - val_acc: 0.9720\n",
      "Epoch 25/500\n",
      "11502/11502 [==============================] - 24s 2ms/step - loss: 0.0082 - acc: 0.9983 - val_loss: 0.0966 - val_acc: 0.9755\n",
      "2875/2875 [==============================] - 1s 489us/step\n",
      "11502/11502 [==============================] - 6s 485us/step\n",
      "Train on 14377 samples, validate on 4821 samples\n",
      "Epoch 1/500\n",
      "14377/14377 [==============================] - 55s 4ms/step - loss: 0.3906 - acc: 0.8237 - val_loss: 0.3161 - val_acc: 0.8666\n",
      "Epoch 2/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.2496 - acc: 0.9002 - val_loss: 0.2244 - val_acc: 0.9168\n",
      "Epoch 3/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.1825 - acc: 0.9311 - val_loss: 0.1864 - val_acc: 0.9251\n",
      "Epoch 4/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.1382 - acc: 0.9464 - val_loss: 0.1530 - val_acc: 0.9421\n",
      "Epoch 5/500\n",
      "14377/14377 [==============================] - 43s 3ms/step - loss: 0.1015 - acc: 0.9631 - val_loss: 0.1456 - val_acc: 0.9469\n",
      "Epoch 6/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0766 - acc: 0.9725 - val_loss: 0.1612 - val_acc: 0.9398\n",
      "Epoch 7/500\n",
      "14377/14377 [==============================] - 43s 3ms/step - loss: 0.0588 - acc: 0.9779 - val_loss: 0.1156 - val_acc: 0.9587\n",
      "Epoch 8/500\n",
      "14377/14377 [==============================] - 43s 3ms/step - loss: 0.0457 - acc: 0.9850 - val_loss: 0.0948 - val_acc: 0.9685\n",
      "Epoch 9/500\n",
      "14377/14377 [==============================] - 43s 3ms/step - loss: 0.0341 - acc: 0.9889 - val_loss: 0.1046 - val_acc: 0.9635\n",
      "Epoch 10/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0253 - acc: 0.9921 - val_loss: 0.1525 - val_acc: 0.9506\n",
      "Epoch 11/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0209 - acc: 0.9937 - val_loss: 0.0859 - val_acc: 0.9708\n",
      "Epoch 12/500\n",
      "14377/14377 [==============================] - 43s 3ms/step - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0880 - val_acc: 0.9712\n",
      "Epoch 13/500\n",
      "14377/14377 [==============================] - 41s 3ms/step - loss: 0.0121 - acc: 0.9971 - val_loss: 0.0801 - val_acc: 0.9772\n",
      "Epoch 14/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0938 - val_acc: 0.9726\n",
      "Epoch 15/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0098 - acc: 0.9971 - val_loss: 0.0794 - val_acc: 0.9780\n",
      "Epoch 16/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0798 - val_acc: 0.9790\n",
      "Epoch 17/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0049 - acc: 0.9989 - val_loss: 0.0834 - val_acc: 0.9751\n",
      "Epoch 18/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0819 - val_acc: 0.9803\n",
      "Epoch 19/500\n",
      "14377/14377 [==============================] - 42s 3ms/step - loss: 0.0043 - acc: 0.9992 - val_loss: 0.0865 - val_acc: 0.9786\n",
      "Epoch 20/500\n",
      "14377/14377 [==============================] - 43s 3ms/step - loss: 0.0041 - acc: 0.9992 - val_loss: 0.0814 - val_acc: 0.9805\n",
      "Best: 0.905613 using {'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "batch_size = [4, 8, 16, 32]\n",
    "#batch_size = [128]\n",
    "param_grid = dict(batch_size = batch_size)\n",
    "earlyStopping = EarlyStopping(monitor = 'val_loss', min_delta = 0, patience = 5, verbose = 0, mode = 'auto')\n",
    "cnn_models = [None] * n_combination\n",
    "for i in chosen:    \n",
    "    model = KerasClassifier(build_fn = cnn_model)\n",
    "    grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = 5)\n",
    "    grid.fit(X_c_train[i], y_c_train[i], epochs = N_EPOCHS, callbacks = [earlyStopping], validation_data = (X_c_validation[i], y_c_validation[i]))\n",
    "    print(\"Best: %f using %s\" %(grid.best_score_, grid.best_params_))\n",
    "    cnn_models[i] = grid.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.01\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.02\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.03\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.04\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.05\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.060000000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.07\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.08\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.09\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.09999999999999999\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.10999999999999999\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.11999999999999998\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.12999999999999998\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.13999999999999999\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.15\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.16\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.17\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.18000000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.19000000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.20000000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.21000000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.22000000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.23000000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.24000000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.25000000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.26000000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.2700000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.2800000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.2900000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.3000000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.3100000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.3200000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.3300000000000001\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.34000000000000014\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.35000000000000014\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.36000000000000015\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.37000000000000016\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.38000000000000017\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.3900000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.4000000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.4100000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.4200000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.4300000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.4400000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.45000000000000023\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.46000000000000024\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.47000000000000025\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.48000000000000026\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.49000000000000027\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5000000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5100000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5200000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5300000000000002\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5400000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5500000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5600000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5700000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5800000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.5900000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6000000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6100000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6200000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6300000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6400000000000003\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6500000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6600000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6700000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6800000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.6900000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7000000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7100000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7200000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7300000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7400000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7500000000000004\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7600000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7700000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7800000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.7900000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8000000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8100000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8200000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8300000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8400000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8500000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8600000000000005\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8700000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8800000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.8900000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9000000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9100000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9200000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9300000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9400000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9500000000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9600000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9700000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9800000000000006\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 0.9900000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 1.0000000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805943051480839 threshold: 1.0100000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0200000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0300000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0400000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0500000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0600000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0700000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0800000000000007\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970544653712 threshold: 1.0900000000000007\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9807000729868485 threshold: 1.1000000000000008\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805970624116879 threshold: 1.1100000000000008\n",
      "accuracy: 0.9806411323896753 f1_score: 0.980698494068851 threshold: 1.1200000000000008\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807999647692607 threshold: 1.1300000000000008\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807999647692607 threshold: 1.1400000000000008\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807999647692607 threshold: 1.1500000000000008\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807999647692607 threshold: 1.1600000000000008\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806940857067168 threshold: 1.1700000000000008\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9808006617944177 threshold: 1.1800000000000008\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805898255111927 threshold: 1.1900000000000008\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805897910309224 threshold: 1.2000000000000008\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805897910309224 threshold: 1.2100000000000009\n",
      "accuracy: 0.9806411323896753 f1_score: 0.980696366849306 threshold: 1.2200000000000009\n",
      "accuracy: 0.9806411323896753 f1_score: 0.980696366849306 threshold: 1.2300000000000009\n",
      "accuracy: 0.9806411323896753 f1_score: 0.980696366849306 threshold: 1.2400000000000009\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807978944886626 threshold: 1.2500000000000009\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806940099228338 threshold: 1.260000000000001\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806940099228338 threshold: 1.270000000000001\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806940099228338 threshold: 1.280000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.290000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.300000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.310000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.320000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.330000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.340000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.350000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.360000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.370000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.380000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.390000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.400000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.410000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807981901595917 threshold: 1.420000000000001\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806967076108813 threshold: 1.430000000000001\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806967076108813 threshold: 1.440000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.980800982435198 threshold: 1.450000000000001\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807982361138105 threshold: 1.460000000000001\n",
      "accuracy: 0.980849292256453 f1_score: 0.980899704480549 threshold: 1.470000000000001\n",
      "accuracy: 0.980849292256453 f1_score: 0.980899704480549 threshold: 1.480000000000001\n",
      "accuracy: 0.980849292256453 f1_score: 0.980899704480549 threshold: 1.490000000000001\n",
      "accuracy: 0.980849292256453 f1_score: 0.980899704480549 threshold: 1.500000000000001\n",
      "accuracy: 0.980849292256453 f1_score: 0.980899704480549 threshold: 1.5100000000000011\n",
      "accuracy: 0.9807452123230641 f1_score: 0.980796580794008 threshold: 1.5200000000000011\n",
      "accuracy: 0.9807452123230641 f1_score: 0.980796580794008 threshold: 1.5300000000000011\n",
      "accuracy: 0.9807452123230641 f1_score: 0.980796580794008 threshold: 1.5400000000000011\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806934615657456 threshold: 1.5500000000000012\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806934615657456 threshold: 1.5600000000000012\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806934615657456 threshold: 1.5700000000000012\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806934615657456 threshold: 1.5800000000000012\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806934615657456 threshold: 1.5900000000000012\n",
      "accuracy: 0.980849292256453 f1_score: 0.9809032605877599 threshold: 1.6000000000000012\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6100000000000012\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6200000000000012\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6300000000000012\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6400000000000012\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6500000000000012\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6600000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6700000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6800000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.6900000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.7000000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.7100000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810048030981288 threshold: 1.7200000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7300000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7400000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7500000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7600000000000013\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7700000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7800000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.7900000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8000000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8100000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8200000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8300000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8400000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8500000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8600000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8700000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8800000000000014\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.8900000000000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9000000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9100000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9200000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9300000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9400000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9500000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9600000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9700000000000015\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810021858680802 threshold: 1.9800000000000015\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 1.9900000000000015\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.0000000000000013\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.010000000000001\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.020000000000001\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.0300000000000007\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.0400000000000005\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.0500000000000003\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.06\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811037767742589 threshold: 2.07\n",
      "accuracy: 0.9811615320566195 f1_score: 0.9812077755685918 threshold: 2.0799999999999996\n",
      "accuracy: 0.9811615320566195 f1_score: 0.9812077755685918 threshold: 2.0899999999999994\n",
      "accuracy: 0.9811615320566195 f1_score: 0.9812077755685918 threshold: 2.099999999999999\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813108635969464 threshold: 2.109999999999999\n",
      "accuracy: 0.9811615320566195 f1_score: 0.981209224796351 threshold: 2.1199999999999988\n",
      "accuracy: 0.9811615320566195 f1_score: 0.981209224796351 threshold: 2.1299999999999986\n",
      "accuracy: 0.9811615320566195 f1_score: 0.981209224796351 threshold: 2.1399999999999983\n",
      "accuracy: 0.9811615320566195 f1_score: 0.981209224796351 threshold: 2.149999999999998\n",
      "accuracy: 0.9811615320566195 f1_score: 0.981209224796351 threshold: 2.159999999999998\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.1699999999999977\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.1799999999999975\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.1899999999999973\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.199999999999997\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.209999999999997\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.2199999999999966\n",
      "accuracy: 0.9812656119900083 f1_score: 0.981315691910956 threshold: 2.2299999999999964\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981419868397706 threshold: 2.239999999999996\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.249999999999996\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.259999999999996\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.2699999999999956\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.2799999999999954\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818316703364489 threshold: 2.289999999999995\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818316703364489 threshold: 2.299999999999995\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818316703364489 threshold: 2.3099999999999947\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.3199999999999945\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.3299999999999943\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.339999999999994\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.349999999999994\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.3599999999999937\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.3699999999999934\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.3799999999999932\n",
      "accuracy: 0.9816819317235637 f1_score: 0.981727731607103 threshold: 2.389999999999993\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.399999999999993\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.4099999999999926\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.4199999999999924\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.429999999999992\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.439999999999992\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.4499999999999917\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.4599999999999915\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.4699999999999913\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.479999999999991\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.489999999999991\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.4999999999999907\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.5099999999999905\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.5199999999999902\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.52999999999999\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.53999999999999\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.5499999999999896\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.5599999999999894\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816260595920504 threshold: 2.569999999999989\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.579999999999989\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.5899999999999888\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.5999999999999885\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.6099999999999883\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.619999999999988\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.629999999999988\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.6399999999999877\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.6499999999999875\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.6599999999999873\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815221504407238 threshold: 2.669999999999987\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.679999999999987\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.6899999999999866\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.6999999999999864\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.709999999999986\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.719999999999986\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.7299999999999858\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.7399999999999856\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.7499999999999853\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.759999999999985\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.769999999999985\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814179739539738 threshold: 2.7799999999999847\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.7899999999999845\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.7999999999999843\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.809999999999984\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.819999999999984\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.8299999999999836\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.8399999999999834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.849999999999983\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.859999999999983\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.869999999999983\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.8799999999999826\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.8899999999999824\n",
      "accuracy: 0.981473771856786 f1_score: 0.981523760337818 threshold: 2.899999999999982\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816280283289035 threshold: 2.909999999999982\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816280283289035 threshold: 2.9199999999999817\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816280283289035 threshold: 2.9299999999999815\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816280283289035 threshold: 2.9399999999999813\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816280283289035 threshold: 2.949999999999981\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815265223108881 threshold: 2.959999999999981\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815265223108881 threshold: 2.9699999999999807\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815265223108881 threshold: 2.9799999999999804\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981422598062314 threshold: 2.9899999999999802\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981422598062314 threshold: 2.99999999999998\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981422598062314 threshold: 3.00999999999998\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981422598062314 threshold: 3.0199999999999796\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.0299999999999794\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.039999999999979\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.049999999999979\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.0599999999999787\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.0699999999999785\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.0799999999999783\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816330065500748 threshold: 3.089999999999978\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.099999999999978\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.1099999999999777\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.1199999999999775\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.1299999999999772\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.139999999999977\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.149999999999977\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.1599999999999766\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814261587564131 threshold: 3.1699999999999764\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.179999999999976\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.189999999999976\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.1999999999999758\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.2099999999999755\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.2199999999999753\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.229999999999975\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.239999999999975\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.2499999999999747\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.2599999999999745\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.2699999999999743\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.279999999999974\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.289999999999974\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.2999999999999736\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.3099999999999734\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.319999999999973\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814263431855677 threshold: 3.329999999999973\n",
      "accuracy: 0.981473771856786 f1_score: 0.981530533755273 threshold: 3.3399999999999728\n",
      "accuracy: 0.981473771856786 f1_score: 0.981530533755273 threshold: 3.3499999999999726\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.3599999999999723\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.369999999999972\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.379999999999972\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.3899999999999717\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.3999999999999715\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.4099999999999713\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.419999999999971\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.429999999999971\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.4399999999999706\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816348198037161 threshold: 3.4499999999999704\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.45999999999997\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.46999999999997\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.47999999999997\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.4899999999999696\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.4999999999999694\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.509999999999969\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.519999999999969\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.5299999999999687\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.5399999999999685\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.5499999999999683\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.559999999999968\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.569999999999968\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.5799999999999677\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.5899999999999674\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.5999999999999672\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.609999999999967\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.619999999999967\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817387189290683 threshold: 3.6299999999999666\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.6399999999999664\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.649999999999966\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.659999999999966\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.6699999999999657\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.6799999999999655\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.6899999999999653\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819489850827197 threshold: 3.699999999999965\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819489850827197 threshold: 3.709999999999965\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819489850827197 threshold: 3.7199999999999647\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819489850827197 threshold: 3.7299999999999645\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819489850827197 threshold: 3.7399999999999642\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818451629132212 threshold: 3.749999999999964\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817392885979445 threshold: 3.759999999999964\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817392885979445 threshold: 3.7699999999999636\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817392885979445 threshold: 3.7799999999999634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.789999999999963\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.799999999999963\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.8099999999999627\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.8199999999999625\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.8299999999999623\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.839999999999962\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818422804604746 threshold: 3.849999999999962\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817406536369794 threshold: 3.8599999999999617\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818436476161376 threshold: 3.8699999999999615\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818436476161376 threshold: 3.8799999999999613\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818436476161376 threshold: 3.889999999999961\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818436476161376 threshold: 3.899999999999961\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.9099999999999606\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.9199999999999604\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.92999999999996\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.93999999999996\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.9499999999999598\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.9599999999999596\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.9699999999999593\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.979999999999959\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.989999999999959\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 3.9999999999999587\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 4.009999999999959\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 4.019999999999959\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817398461195969 threshold: 4.0299999999999585\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.039999999999958\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.049999999999958\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.059999999999958\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.069999999999958\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.079999999999957\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.089999999999957\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.099999999999957\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816368578049647 threshold: 4.109999999999957\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.119999999999957\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.129999999999956\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.139999999999956\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.149999999999956\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.159999999999956\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.1699999999999555\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.179999999999955\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.189999999999955\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.199999999999955\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.209999999999955\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.2199999999999545\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.229999999999954\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.239999999999954\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.249999999999954\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.259999999999954\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.269999999999953\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.279999999999953\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.289999999999953\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.299999999999953\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.3099999999999525\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.319999999999952\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.329999999999952\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.339999999999952\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.349999999999952\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.3599999999999515\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.369999999999951\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.379999999999951\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.389999999999951\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.399999999999951\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.40999999999995\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817383128061603 threshold: 4.41999999999995\n",
      "accuracy: 0.9817860116569526 f1_score: 0.981841355826151 threshold: 4.42999999999995\n",
      "accuracy: 0.9817860116569526 f1_score: 0.981841355826151 threshold: 4.43999999999995\n",
      "accuracy: 0.9817860116569526 f1_score: 0.981841355826151 threshold: 4.4499999999999496\n",
      "accuracy: 0.9817860116569526 f1_score: 0.981841355826151 threshold: 4.459999999999949\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.469999999999949\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.479999999999949\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.489999999999949\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.4999999999999485\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.509999999999948\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.519999999999948\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.529999999999948\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.539999999999948\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.549999999999947\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.559999999999947\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.569999999999947\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.579999999999947\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818386873991202 threshold: 4.589999999999947\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417900973154 threshold: 4.599999999999946\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417900973154 threshold: 4.609999999999946\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417900973154 threshold: 4.619999999999946\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417900973154 threshold: 4.629999999999946\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417900973154 threshold: 4.6399999999999455\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.649999999999945\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.659999999999945\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.669999999999945\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.679999999999945\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.689999999999944\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.699999999999944\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.709999999999944\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.719999999999944\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.729999999999944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.739999999999943\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819417568477188 threshold: 4.749999999999943\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.759999999999943\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.769999999999943\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.7799999999999425\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.789999999999942\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.799999999999942\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.809999999999942\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.819999999999942\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.8299999999999415\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.839999999999941\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.849999999999941\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819391571018279 threshold: 4.859999999999941\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.869999999999941\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.87999999999994\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.88999999999994\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.89999999999994\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.90999999999994\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.9199999999999395\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.929999999999939\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.939999999999939\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.949999999999939\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.959999999999939\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.9699999999999385\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.979999999999938\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.989999999999938\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 4.999999999999938\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.009999999999938\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.019999999999937\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.029999999999937\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.039999999999937\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.049999999999937\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.0599999999999365\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.069999999999936\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.079999999999936\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.089999999999936\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.099999999999936\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.1099999999999355\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.119999999999935\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.129999999999935\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.139999999999935\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.149999999999935\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.159999999999934\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.169999999999934\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.179999999999934\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.189999999999934\n",
      "accuracy: 0.9818900915903414 f1_score: 0.9819392453330723 threshold: 5.199999999999934\n",
      "accuracy: 0.9817860116569526 f1_score: 0.9818360876532292 threshold: 5.209999999999933\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817322602617596 threshold: 5.219999999999933\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817322602617596 threshold: 5.229999999999933\n",
      "accuracy: 0.9816819317235637 f1_score: 0.9817322602617596 threshold: 5.239999999999933\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.2499999999999325\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.259999999999932\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.269999999999932\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.279999999999932\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.289999999999932\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.299999999999931\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.309999999999931\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.319999999999931\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.329999999999931\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.339999999999931\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.34999999999993\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.35999999999993\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.36999999999993\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.37999999999993\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.3899999999999295\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.399999999999929\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.409999999999929\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.419999999999929\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.429999999999929\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.4399999999999284\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.449999999999928\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.459999999999928\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.469999999999928\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815222558377688 threshold: 5.479999999999928\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814184145334934 threshold: 5.489999999999927\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815200820289378 threshold: 5.499999999999927\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815200820289378 threshold: 5.509999999999927\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815200820289378 threshold: 5.519999999999927\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815200820289378 threshold: 5.5299999999999265\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815200820289378 threshold: 5.539999999999926\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815200820289378 threshold: 5.549999999999926\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.559999999999926\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.569999999999926\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.5799999999999255\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.589999999999925\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.599999999999925\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.609999999999925\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814168355967727 threshold: 5.619999999999925\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.629999999999924\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.639999999999924\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.649999999999924\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.659999999999924\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.6699999999999235\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.679999999999923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.689999999999923\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.699999999999923\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.709999999999923\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.7199999999999225\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.729999999999922\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.739999999999922\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.749999999999922\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815182775245437 threshold: 5.759999999999922\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.769999999999921\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.779999999999921\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.789999999999921\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.799999999999921\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.809999999999921\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.81999999999992\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.82999999999992\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.83999999999992\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.84999999999992\n",
      "accuracy: 0.9815778517901749 f1_score: 0.9816197467867072 threshold: 5.8599999999999195\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815158009916205 threshold: 5.869999999999919\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815158009916205 threshold: 5.879999999999919\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815158009916205 threshold: 5.889999999999919\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815158009916205 threshold: 5.899999999999919\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.909999999999918\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.919999999999918\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.929999999999918\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.939999999999918\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.949999999999918\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.959999999999917\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.969999999999917\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.979999999999917\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.989999999999917\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 5.9999999999999165\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.009999999999916\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.019999999999916\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.029999999999916\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.039999999999916\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.0499999999999154\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.059999999999915\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.069999999999915\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.079999999999915\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118387157263 threshold: 6.089999999999915\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.099999999999914\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.109999999999914\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.119999999999914\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.129999999999914\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.1399999999999135\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.149999999999913\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.159999999999913\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.169999999999913\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.179999999999913\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.1899999999999125\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813086039364377 threshold: 6.199999999999912\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.209999999999912\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.219999999999912\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.229999999999912\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.239999999999911\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.249999999999911\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.259999999999911\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.269999999999911\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.2799999999999105\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.28999999999991\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.29999999999991\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.30999999999991\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.31999999999991\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.3299999999999095\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.339999999999909\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.349999999999909\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.359999999999909\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.369999999999909\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.379999999999908\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.389999999999908\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.399999999999908\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814101956492949 threshold: 6.409999999999908\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.419999999999908\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.429999999999907\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.439999999999907\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.449999999999907\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.459999999999907\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.4699999999999065\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.479999999999906\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.489999999999906\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.499999999999906\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.509999999999906\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.519999999999905\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.529999999999905\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.539999999999905\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.549999999999905\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.559999999999905\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.569999999999904\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.579999999999904\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815134855188713 threshold: 6.589999999999904\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.599999999999904\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.6099999999999035\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.619999999999903\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.629999999999903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.639999999999903\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.649999999999903\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.659999999999902\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.669999999999902\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.679999999999902\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.689999999999902\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.699999999999902\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.709999999999901\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.719999999999901\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.729999999999901\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.739999999999901\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.7499999999999005\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.7599999999999\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.7699999999999\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.7799999999999\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.7899999999999\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.7999999999998995\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.809999999999899\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.819999999999899\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.829999999999899\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.839999999999899\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.849999999999898\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.859999999999898\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.869999999999898\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.879999999999898\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.8899999999998975\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.899999999999897\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.909999999999897\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.919999999999897\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.929999999999897\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.9399999999998965\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.949999999999896\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.959999999999896\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.969999999999896\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.979999999999896\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.989999999999895\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 6.999999999999895\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 7.009999999999895\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 7.019999999999895\n",
      "accuracy: 0.981473771856786 f1_score: 0.9815133127710889 threshold: 7.0299999999998946\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981409288641737 threshold: 7.039999999999894\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981409288641737 threshold: 7.049999999999894\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981409288641737 threshold: 7.059999999999894\n",
      "accuracy: 0.9813696919233972 f1_score: 0.981409288641737 threshold: 7.069999999999894\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.0799999999998935\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.089999999999893\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.099999999999893\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.109999999999893\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.119999999999893\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.129999999999892\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.139999999999892\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.149999999999892\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.159999999999892\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.169999999999892\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.179999999999891\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.189999999999891\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.199999999999891\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.209999999999891\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.2199999999998905\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.22999999999989\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.23999999999989\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.24999999999989\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.25999999999989\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.269999999999889\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.279999999999889\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.289999999999889\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.299999999999889\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.309999999999889\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.319999999999888\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.329999999999888\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.339999999999888\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.349999999999888\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.3599999999998875\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.369999999999887\n",
      "accuracy: 0.9813696919233972 f1_score: 0.9814118914138267 threshold: 7.379999999999887\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813087150735795 threshold: 7.389999999999887\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813087150735795 threshold: 7.399999999999887\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813087150735795 threshold: 7.4099999999998865\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813087150735795 threshold: 7.419999999999886\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813087150735795 threshold: 7.429999999999886\n",
      "accuracy: 0.9812656119900083 f1_score: 0.9813087150735795 threshold: 7.439999999999886\n",
      "accuracy: 0.9811615320566195 f1_score: 0.9812055434993205 threshold: 7.449999999999886\n",
      "accuracy: 0.9811615320566195 f1_score: 0.9812055434993205 threshold: 7.459999999999885\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.469999999999885\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.479999999999885\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.489999999999885\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.4999999999998845\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.509999999999884\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.519999999999884\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.529999999999884\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.539999999999884\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.5499999999998835\n",
      "accuracy: 0.9810574521232306 f1_score: 0.9811023765289998 threshold: 7.559999999999883\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810010052198842 threshold: 7.569999999999883\n",
      "accuracy: 0.9809533721898418 f1_score: 0.9810010052198842 threshold: 7.579999999999883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.589999999999883\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.599999999999882\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.609999999999882\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.619999999999882\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.629999999999882\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.6399999999998816\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.649999999999881\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.659999999999881\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.669999999999881\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808949773921326 threshold: 7.679999999999881\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.6899999999998805\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.69999999999988\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.70999999999988\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.71999999999988\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.72999999999988\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.739999999999879\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.749999999999879\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.759999999999879\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.769999999999879\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.779999999999879\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.789999999999878\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.799999999999878\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.809999999999878\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.819999999999878\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.8299999999998775\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.839999999999877\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.849999999999877\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.859999999999877\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.869999999999877\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.879999999999876\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.889999999999876\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.899999999999876\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.909999999999876\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.919999999999876\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.929999999999875\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.939999999999875\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.949999999999875\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.959999999999875\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.9699999999998745\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.979999999999874\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.989999999999874\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 7.999999999999874\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.009999999999874\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.019999999999873\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.029999999999873\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.039999999999873\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.049999999999873\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.059999999999873\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.069999999999872\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.079999999999872\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.089999999999872\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.099999999999872\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.109999999999872\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.119999999999871\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.129999999999871\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.139999999999871\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.14999999999987\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.15999999999987\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.16999999999987\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.17999999999987\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.18999999999987\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808922098237042 threshold: 8.19999999999987\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.20999999999987\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.21999999999987\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.229999999999869\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.239999999999869\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.249999999999869\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.259999999999868\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.269999999999868\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.279999999999868\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.289999999999868\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.299999999999867\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.309999999999867\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.319999999999867\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.329999999999867\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.339999999999867\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.349999999999866\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.359999999999866\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.369999999999866\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.379999999999866\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.389999999999866\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.399999999999865\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807882346226938 threshold: 8.409999999999865\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.419999999999865\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.429999999999865\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.439999999999864\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.449999999999864\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.459999999999864\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.469999999999864\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.479999999999864\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.489999999999863\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.499999999999863\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.509999999999863\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.519999999999863\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.529999999999863\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.539999999999862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.549999999999862\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.559999999999862\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.569999999999862\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.579999999999862\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.589999999999861\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.599999999999861\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.60999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.61999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.62999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.63999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.64999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.65999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.66999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.67999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.68999999999986\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.699999999999859\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.709999999999859\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.719999999999859\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.729999999999858\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.739999999999858\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.749999999999858\n",
      "accuracy: 0.980849292256453 f1_score: 0.9808923754887517 threshold: 8.759999999999858\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807883834964218 threshold: 8.769999999999857\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807883834964218 threshold: 8.779999999999857\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807883834964218 threshold: 8.789999999999857\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807883834964218 threshold: 8.799999999999857\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807883834964218 threshold: 8.809999999999857\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807883834964218 threshold: 8.819999999999856\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.829999999999856\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.839999999999856\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.849999999999856\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.859999999999856\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.869999999999855\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.879999999999855\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.889999999999855\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.899999999999855\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.909999999999854\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.919999999999854\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.929999999999854\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.939999999999854\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.949999999999854\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.959999999999853\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.969999999999853\n",
      "accuracy: 0.980849292256453 f1_score: 0.980889643824727 threshold: 8.979999999999853\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807863884377777 threshold: 8.989999999999853\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807863884377777 threshold: 8.999999999999853\n",
      "accuracy: 0.9807452123230641 f1_score: 0.9807863884377777 threshold: 9.009999999999852\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806831374577463 threshold: 9.019999999999852\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806831374577463 threshold: 9.029999999999852\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806831374577463 threshold: 9.039999999999852\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806831374577463 threshold: 9.049999999999851\n",
      "accuracy: 0.9806411323896753 f1_score: 0.9806831374577463 threshold: 9.059999999999851\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805790959037782 threshold: 9.069999999999851\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805790959037782 threshold: 9.07999999999985\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805790959037782 threshold: 9.08999999999985\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805790959037782 threshold: 9.09999999999985\n",
      "accuracy: 0.9805370524562864 f1_score: 0.9805790959037782 threshold: 9.10999999999985\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.11999999999985\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.12999999999985\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.13999999999985\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.14999999999985\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.15999999999985\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.169999999999849\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.179999999999849\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.189999999999849\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.199999999999848\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.209999999999848\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.219999999999848\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.229999999999848\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.239999999999847\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.249999999999847\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.259999999999847\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.269999999999847\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.279999999999847\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.289999999999846\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.299999999999846\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.309999999999846\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.319999999999846\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.329999999999846\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.339999999999845\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.349999999999845\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.359999999999845\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.369999999999845\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.379999999999844\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.389999999999844\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.399999999999844\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.409999999999844\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.419999999999844\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.429999999999843\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.439999999999843\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804750374016438 threshold: 9.449999999999843\n",
      "accuracy: 0.9803288925895087 f1_score: 0.9803718033697788 threshold: 9.459999999999843\n",
      "accuracy: 0.9803288925895087 f1_score: 0.9803718033697788 threshold: 9.469999999999843\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.479999999999842\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.489999999999842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.499999999999842\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.509999999999842\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.519999999999841\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.529999999999841\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.539999999999841\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.54999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.55999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.56999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.57999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.58999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.59999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.60999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.61999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.62999999999984\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.639999999999839\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.649999999999839\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.659999999999838\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.669999999999838\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.679999999999838\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.689999999999838\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.699999999999838\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.709999999999837\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.719999999999837\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.729999999999837\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.739999999999837\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.749999999999837\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.759999999999836\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.769999999999836\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.779999999999836\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.789999999999836\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.799999999999836\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.809999999999835\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.819999999999835\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.829999999999835\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.839999999999835\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.849999999999834\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.859999999999834\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.869999999999834\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.879999999999834\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.889999999999834\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.899999999999833\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.909999999999833\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.919999999999833\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.929999999999833\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.939999999999833\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.949999999999832\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.959999999999832\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.969999999999832\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.979999999999832\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.989999999999831\n",
      "accuracy: 0.9804329725228976 f1_score: 0.9804759221856854 threshold: 9.999999999999831\n"
     ]
    }
   ],
   "source": [
    "validation_history = dict(accuracy=[], f1score=[], threshold=[])\n",
    "threshold = 0\n",
    "while (threshold < 10):    \n",
    "    c_predictions = final_prediction(X_validation, validation_predictions, threshold)\n",
    "    accuracy = accuracy_score(np.argmax(y_validation, 1), np.argmax(c_predictions, 1)) \n",
    "    f1score = f1_score(np.argmax(y_validation, 1), np.argmax(c_predictions, 1), average='weighted')\n",
    "    print(\"accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)\n",
    "    threshold += 0.01\n",
    "    validation_history['accuracy'].append(accuracy)\n",
    "    validation_history['f1score'].append(f1score)\n",
    "    validation_history['threshold'].append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215e43eea20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_vs_accuraccy(validation_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.709999999999965\n"
     ]
    }
   ],
   "source": [
    "threshold = validation_history['threshold'][validation_history['accuracy'].index(max(validation_history['accuracy']))]\n",
    "cnn_predictions = final_prediction(X_test, predictions, threshold)\n",
    "accuracy = accuracy_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1))\n",
    "f1score = f1_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1), average='weighted')\n",
    "print(\"final accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x215a7605128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_report(cnn_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.94      1530\n",
      "          1       0.99      0.99      0.99      5198\n",
      "          2       0.98      0.99      0.99       893\n",
      "          3       0.99      0.98      0.99       692\n",
      "          4       0.95      0.96      0.95      1797\n",
      "          5       0.99      0.99      0.99      6361\n",
      "\n",
      "avg / total       0.98      0.98      0.98     16471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.01\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.02\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.03\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.04\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.05\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.060000000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.07\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.08\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.09\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.09999999999999999\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.10999999999999999\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.11999999999999998\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.12999999999999998\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.13999999999999999\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.15\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.16\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.17\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.18000000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.19000000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.20000000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.21000000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.22000000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.23000000000000007\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.24000000000000007\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.25000000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.26000000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.2700000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.2800000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.2900000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.3000000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.3100000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.3200000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.3300000000000001\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.34000000000000014\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.35000000000000014\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.36000000000000015\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.37000000000000016\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.38000000000000017\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.3900000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.4000000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.4100000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.4200000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.4300000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.4400000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.45000000000000023\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.46000000000000024\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.47000000000000025\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.48000000000000026\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.49000000000000027\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5000000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5100000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5200000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5300000000000002\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5400000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5500000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5600000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5700000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5800000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.5900000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6000000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6100000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6200000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6300000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6400000000000003\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6500000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6600000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6700000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6800000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.6900000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7000000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7100000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7200000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7300000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7400000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7500000000000004\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7600000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7700000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7800000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.7900000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8000000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8100000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8200000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8300000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8400000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8500000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8600000000000005\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8700000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8800000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.8900000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9000000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9100000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9200000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9300000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9400000000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9500000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9600000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9700000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9800000000000006\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 0.9900000000000007\n",
      "accuracy: 0.9970161682048435 f1_score: 0.9970171543150793 threshold: 1.0000000000000007\n",
      "accuracy: 0.9970855596419402 f1_score: 0.9970866660451758 threshold: 1.0100000000000007\n",
      "accuracy: 0.9970855596419402 f1_score: 0.9970866660451758 threshold: 1.0200000000000007\n",
      "accuracy: 0.9970855596419402 f1_score: 0.997086669976841 threshold: 1.0300000000000007\n",
      "accuracy: 0.9971202553604885 f1_score: 0.99712134253641 threshold: 1.0400000000000007\n",
      "accuracy: 0.9971202553604885 f1_score: 0.99712134253641 threshold: 1.0500000000000007\n",
      "accuracy: 0.9971202553604885 f1_score: 0.99712134253641 threshold: 1.0600000000000007\n",
      "accuracy: 0.9971549510790368 f1_score: 0.9971560202452135 threshold: 1.0700000000000007\n",
      "accuracy: 0.9971549510790368 f1_score: 0.9971560202452135 threshold: 1.0800000000000007\n",
      "accuracy: 0.9971896467975851 f1_score: 0.9971906991778232 threshold: 1.0900000000000007\n",
      "accuracy: 0.9971896467975851 f1_score: 0.9971906991778232 threshold: 1.1000000000000008\n",
      "accuracy: 0.9972243425161335 f1_score: 0.9972252550947104 threshold: 1.1100000000000008\n",
      "accuracy: 0.9972243425161335 f1_score: 0.9972252550947104 threshold: 1.1200000000000008\n",
      "accuracy: 0.9973284296717785 f1_score: 0.9973292994365259 threshold: 1.1300000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.1400000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.1500000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.1600000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.1700000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.1800000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.1900000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.2000000000000008\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.2100000000000009\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.2200000000000009\n",
      "accuracy: 0.9973631253903268 f1_score: 0.9973639763363226 threshold: 1.2300000000000009\n",
      "accuracy: 0.9973978211088752 f1_score: 0.9973985615516318 threshold: 1.2400000000000009\n",
      "accuracy: 0.9974325168274235 f1_score: 0.9974332521807631 threshold: 1.2500000000000009\n",
      "accuracy: 0.9974325168274235 f1_score: 0.9974332521807631 threshold: 1.260000000000001\n",
      "accuracy: 0.9974325168274235 f1_score: 0.9974332521807631 threshold: 1.270000000000001\n",
      "accuracy: 0.9974325168274235 f1_score: 0.9974332521807631 threshold: 1.280000000000001\n",
      "accuracy: 0.9974325168274235 f1_score: 0.9974332521807631 threshold: 1.290000000000001\n",
      "accuracy: 0.9974672125459718 f1_score: 0.9974679440657958 threshold: 1.300000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.310000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.320000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.330000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.340000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.350000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.360000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.370000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.380000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.390000000000001\n",
      "accuracy: 0.9975019082645201 f1_score: 0.9975027450953416 threshold: 1.400000000000001\n",
      "accuracy: 0.9975366039830685 f1_score: 0.9975374485986509 threshold: 1.410000000000001\n",
      "accuracy: 0.9975366039830685 f1_score: 0.9975374485986509 threshold: 1.420000000000001\n",
      "accuracy: 0.9975366039830685 f1_score: 0.9975374485986509 threshold: 1.430000000000001\n",
      "accuracy: 0.9975712997016168 f1_score: 0.9975721364058432 threshold: 1.440000000000001\n",
      "accuracy: 0.9975712997016168 f1_score: 0.9975721364058432 threshold: 1.450000000000001\n",
      "accuracy: 0.9976059954201651 f1_score: 0.9976066984545382 threshold: 1.460000000000001\n",
      "accuracy: 0.9976059954201651 f1_score: 0.9976066984545382 threshold: 1.470000000000001\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.480000000000001\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.490000000000001\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.500000000000001\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.5100000000000011\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.5200000000000011\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.5300000000000011\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.5400000000000011\n",
      "accuracy: 0.9976406911387135 f1_score: 0.9976413997044932 threshold: 1.5500000000000012\n",
      "accuracy: 0.9977100825758102 f1_score: 0.9977107831012156 threshold: 1.5600000000000012\n",
      "accuracy: 0.9977447782943585 f1_score: 0.9977453525440803 threshold: 1.5700000000000012\n",
      "accuracy: 0.9977447782943585 f1_score: 0.9977453525440803 threshold: 1.5800000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.5900000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6000000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6100000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6200000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6300000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6400000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6500000000000012\n",
      "accuracy: 0.9977794740129068 f1_score: 0.9977799183562154 threshold: 1.6600000000000013\n",
      "accuracy: 0.9978141697314551 f1_score: 0.9978146085327424 threshold: 1.6700000000000013\n",
      "accuracy: 0.9978141697314551 f1_score: 0.9978146085327424 threshold: 1.6800000000000013\n",
      "accuracy: 0.9978488654500035 f1_score: 0.9978491922107869 threshold: 1.6900000000000013\n",
      "accuracy: 0.9978488654500035 f1_score: 0.9978491922107869 threshold: 1.7000000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7100000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7200000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7300000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7400000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7500000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7600000000000013\n",
      "accuracy: 0.9978835611685518 f1_score: 0.9978838862292987 threshold: 1.7700000000000014\n",
      "accuracy: 0.9979182568871001 f1_score: 0.9979186928174016 threshold: 1.7800000000000014\n",
      "accuracy: 0.9979182568871001 f1_score: 0.9979186928174016 threshold: 1.7900000000000014\n",
      "accuracy: 0.9979529526056484 f1_score: 0.9979533846692702 threshold: 1.8000000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8100000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8200000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8300000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8400000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8500000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8600000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8700000000000014\n",
      "accuracy: 0.9979876483241968 f1_score: 0.9979880741895373 threshold: 1.8800000000000014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.8900000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9000000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9100000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9200000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9300000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9400000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9500000000000015\n",
      "accuracy: 0.9980223440427451 f1_score: 0.9980227649761096 threshold: 1.9600000000000015\n",
      "accuracy: 0.9980570397612935 f1_score: 0.99805746646329 threshold: 1.9700000000000015\n",
      "accuracy: 0.9980570397612935 f1_score: 0.99805746646329 threshold: 1.9800000000000015\n",
      "accuracy: 0.9980570397612935 f1_score: 0.99805746646329 threshold: 1.9900000000000015\n",
      "accuracy: 0.9980917354798418 f1_score: 0.9980921525216679 threshold: 2.0000000000000013\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.010000000000001\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.020000000000001\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.0300000000000007\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.0400000000000005\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.0500000000000003\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.06\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.07\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.0799999999999996\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.0899999999999994\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.099999999999999\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.109999999999999\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.1199999999999988\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.1299999999999986\n",
      "accuracy: 0.9981264311983902 f1_score: 0.9981268446527869 threshold: 2.1399999999999983\n",
      "accuracy: 0.9981611269169385 f1_score: 0.998161441123408 threshold: 2.149999999999998\n",
      "accuracy: 0.9981611269169385 f1_score: 0.998161441123408 threshold: 2.159999999999998\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.1699999999999977\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.1799999999999975\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.1899999999999973\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.199999999999997\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.209999999999997\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.2199999999999966\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.2299999999999964\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.239999999999996\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.249999999999996\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.259999999999996\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.2699999999999956\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.2799999999999954\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.289999999999995\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.299999999999995\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.3099999999999947\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.3199999999999945\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.3299999999999943\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.339999999999994\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.349999999999994\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.3599999999999937\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.3699999999999934\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.3799999999999932\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.389999999999993\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.399999999999993\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.4099999999999926\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.4199999999999924\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.429999999999992\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.439999999999992\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.4499999999999917\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.4599999999999915\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.4699999999999913\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.479999999999991\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.489999999999991\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.4999999999999907\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.5099999999999905\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.5199999999999902\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.52999999999999\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.53999999999999\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.5499999999999896\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.5599999999999894\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.569999999999989\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.579999999999989\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.5899999999999888\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.5999999999999885\n",
      "accuracy: 0.9982305183540351 f1_score: 0.9982307588761926 threshold: 2.6099999999999883\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.619999999999988\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.629999999999988\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.6399999999999877\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.6499999999999875\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.6599999999999873\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.669999999999987\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.679999999999987\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.6899999999999866\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.6999999999999864\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.709999999999986\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.719999999999986\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.7299999999999858\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.7399999999999856\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.7499999999999853\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.759999999999985\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.769999999999985\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.7799999999999847\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.7899999999999845\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.7999999999999843\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.809999999999984\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.819999999999984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.8299999999999836\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.8399999999999834\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.849999999999983\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.859999999999983\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.869999999999983\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.8799999999999826\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.8899999999999824\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.899999999999982\n",
      "accuracy: 0.9982652140725834 f1_score: 0.9982655397904107 threshold: 2.909999999999982\n",
      "accuracy: 0.9983346055096801 f1_score: 0.9983349184939982 threshold: 2.9199999999999817\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.9299999999999815\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.9399999999999813\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.949999999999981\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.959999999999981\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.9699999999999807\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.9799999999999804\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.9899999999999802\n",
      "accuracy: 0.9983693012282284 f1_score: 0.9983696133426365 threshold: 2.99999999999998\n"
     ]
    }
   ],
   "source": [
    "train_history = dict(accuracy=[], f1score=[], threshold=[])\n",
    "threshold = 0\n",
    "while (threshold < 3):    \n",
    "    cnn_predictions = final_prediction(X_train, train_predictions, threshold)\n",
    "    accuracy = accuracy_score(np.argmax(y_train, 1), np.argmax(cnn_predictions, 1)) \n",
    "    f1score = f1_score(np.argmax(y_train, 1), np.argmax(cnn_predictions, 1), average='weighted')\n",
    "    print(\"accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)\n",
    "    threshold += 0.01\n",
    "    train_history['accuracy'].append(accuracy)\n",
    "    train_history['f1score'].append(f1score)\n",
    "    train_history['threshold'].append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21759776470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_vs_accuraccy(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.01\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.02\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.03\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.04\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.05\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.060000000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.07\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.08\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.09\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.09999999999999999\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.10999999999999999\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.11999999999999998\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.12999999999999998\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.13999999999999999\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.15\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.16\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.17\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.18000000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.19000000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.20000000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.21000000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.22000000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.23000000000000007\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.24000000000000007\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.25000000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.26000000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.2700000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.2800000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.2900000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.3000000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.3100000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.3200000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.3300000000000001\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.34000000000000014\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.35000000000000014\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.36000000000000015\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.37000000000000016\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.38000000000000017\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.3900000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.4000000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.4100000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.4200000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.4300000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.4400000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.45000000000000023\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.46000000000000024\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.47000000000000025\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.48000000000000026\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.49000000000000027\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5000000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5100000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5200000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5300000000000002\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5400000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5500000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5600000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5700000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5800000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.5900000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6000000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6100000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6200000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6300000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6400000000000003\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6500000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6600000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6700000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6800000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.6900000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7000000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7100000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7200000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7300000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7400000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7500000000000004\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7600000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7700000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7800000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.7900000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8000000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8100000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8200000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8300000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8400000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8500000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8600000000000005\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8700000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8800000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.8900000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9000000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9100000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9200000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9300000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9400000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9500000000000006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9600000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9700000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9800000000000006\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 0.9900000000000007\n",
      "accuracy: 0.9826361483820047 f1_score: 0.982641110877415 threshold: 1.0000000000000007\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825801085753681 threshold: 1.0100000000000007\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827029600751357 threshold: 1.0200000000000007\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827029600751357 threshold: 1.0300000000000007\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828272594804923 threshold: 1.0400000000000007\n",
      "accuracy: 0.982757573917795 f1_score: 0.9827679695923506 threshold: 1.0500000000000007\n",
      "accuracy: 0.982757573917795 f1_score: 0.9827679695923506 threshold: 1.0600000000000007\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828304161216593 threshold: 1.0700000000000007\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828304161216593 threshold: 1.0800000000000007\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828304161216593 threshold: 1.0900000000000007\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828304161216593 threshold: 1.1000000000000008\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828304161216593 threshold: 1.1100000000000008\n",
      "accuracy: 0.982757573917795 f1_score: 0.9827685710947406 threshold: 1.1200000000000008\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828289013961417 threshold: 1.1300000000000008\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828289013961417 threshold: 1.1400000000000008\n",
      "accuracy: 0.982757573917795 f1_score: 0.9827694703968352 threshold: 1.1500000000000008\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828302259691142 threshold: 1.1600000000000008\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828302259691142 threshold: 1.1700000000000008\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830122103339679 threshold: 1.1800000000000008\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830731674456644 threshold: 1.1900000000000008\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830731674456644 threshold: 1.2000000000000008\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830731674456644 threshold: 1.2100000000000009\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830731674456644 threshold: 1.2200000000000009\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830731674456644 threshold: 1.2300000000000009\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830725064335119 threshold: 1.2400000000000009\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832551270485796 threshold: 1.2500000000000009\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833160756481272 threshold: 1.260000000000001\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833160756481272 threshold: 1.270000000000001\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833160756481272 threshold: 1.280000000000001\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833770190415259 threshold: 1.290000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388251249188 threshold: 1.300000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388251249188 threshold: 1.310000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388251249188 threshold: 1.320000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388251249188 threshold: 1.330000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388251249188 threshold: 1.340000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388251249188 threshold: 1.350000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9835005965499091 threshold: 1.360000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9835005965499091 threshold: 1.370000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9835005965499091 threshold: 1.380000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388079679771 threshold: 1.390000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388079679771 threshold: 1.400000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388079679771 threshold: 1.410000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834388079679771 threshold: 1.420000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.430000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.440000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.450000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.460000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.470000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.480000000000001\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834981019506938 threshold: 1.490000000000001\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835590568921221 threshold: 1.500000000000001\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835590568921221 threshold: 1.5100000000000011\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836213874334108 threshold: 1.5200000000000011\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836213874334108 threshold: 1.5300000000000011\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836213874334108 threshold: 1.5400000000000011\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836213874334108 threshold: 1.5500000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835604535587028 threshold: 1.5600000000000012\n",
      "accuracy: 0.983486127132536 f1_score: 0.9835001650867101 threshold: 1.5700000000000012\n",
      "accuracy: 0.983486127132536 f1_score: 0.9835001650867101 threshold: 1.5800000000000012\n",
      "accuracy: 0.983486127132536 f1_score: 0.9835001650867101 threshold: 1.5900000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835604535587028 threshold: 1.6000000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835604535587028 threshold: 1.6100000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835604535587028 threshold: 1.6200000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6300000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6400000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6500000000000012\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6600000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6700000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6800000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.6900000000000013\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834991203394908 threshold: 1.7000000000000013\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834991203394908 threshold: 1.7100000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.7200000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.7300000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.7400000000000013\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835594263327719 threshold: 1.7500000000000013\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836187295767399 threshold: 1.7600000000000013\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836187295767399 threshold: 1.7700000000000014\n",
      "accuracy: 0.9836682654362212 f1_score: 0.9836790376114288 threshold: 1.7800000000000014\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836180815209641 threshold: 1.7900000000000014\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836180815209641 threshold: 1.8000000000000014\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836180815209641 threshold: 1.8100000000000014\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836180815209641 threshold: 1.8200000000000014\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836180815209641 threshold: 1.8300000000000014\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834961537942156 threshold: 1.8400000000000014\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834961537942156 threshold: 1.8500000000000014\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834961537942156 threshold: 1.8600000000000014\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834961537942156 threshold: 1.8700000000000014\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834961537942156 threshold: 1.8800000000000014\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834961537942156 threshold: 1.8900000000000015\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833755507160017 threshold: 1.9000000000000015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9833647015967458 f1_score: 0.9833755507160017 threshold: 1.9100000000000015\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833755507160017 threshold: 1.9200000000000015\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833755507160017 threshold: 1.9300000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 1.9400000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 1.9500000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 1.9600000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 1.9700000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 1.9800000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 1.9900000000000015\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833152510584525 threshold: 2.0000000000000013\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833755507160017 threshold: 2.010000000000001\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833755507160017 threshold: 2.020000000000001\n",
      "accuracy: 0.9834254143646409 f1_score: 0.983436513242778 threshold: 2.0300000000000007\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834957673556569 threshold: 2.0400000000000005\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834957673556569 threshold: 2.0500000000000003\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835581448677534 threshold: 2.06\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836189036363971 threshold: 2.07\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836189036363971 threshold: 2.0799999999999996\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836189036363971 threshold: 2.0899999999999994\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836189036363971 threshold: 2.099999999999999\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836189036363971 threshold: 2.109999999999999\n",
      "accuracy: 0.983546839900431 f1_score: 0.983559653143835 threshold: 2.1199999999999988\n",
      "accuracy: 0.983546839900431 f1_score: 0.983559653143835 threshold: 2.1299999999999986\n",
      "accuracy: 0.983546839900431 f1_score: 0.983559653143835 threshold: 2.1399999999999983\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836205894095447 threshold: 2.149999999999998\n",
      "accuracy: 0.9836682654362212 f1_score: 0.9836799612082416 threshold: 2.159999999999998\n",
      "accuracy: 0.9836682654362212 f1_score: 0.9836799612082416 threshold: 2.1699999999999977\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837402679986069 threshold: 2.1799999999999975\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837402679986069 threshold: 2.1899999999999973\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9838012170232042 threshold: 2.199999999999997\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838615269870945 threshold: 2.209999999999997\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839222314535446 threshold: 2.2199999999999966\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839222314535446 threshold: 2.2299999999999964\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840438806528703 threshold: 2.239999999999996\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840438806528703 threshold: 2.249999999999996\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840438806528703 threshold: 2.259999999999996\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840438806528703 threshold: 2.2699999999999956\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840438806528703 threshold: 2.2799999999999954\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840438806528703 threshold: 2.289999999999995\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841031673740231 threshold: 2.299999999999995\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841031673740231 threshold: 2.3099999999999947\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841031673740231 threshold: 2.3199999999999945\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984164109277014 threshold: 2.3299999999999943\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984164109277014 threshold: 2.339999999999994\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984164109277014 threshold: 2.349999999999994\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984164109277014 threshold: 2.3599999999999937\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984164109277014 threshold: 2.3699999999999934\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984164109277014 threshold: 2.3799999999999932\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.389999999999993\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.399999999999993\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.4099999999999926\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.4199999999999924\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.429999999999992\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.439999999999992\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984103776716441 threshold: 2.4499999999999917\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.4599999999999915\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.4699999999999913\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.479999999999991\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.489999999999991\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.4999999999999907\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.5099999999999905\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.5199999999999902\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.52999999999999\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841655813219838 threshold: 2.53999999999999\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840443286582387 threshold: 2.5499999999999896\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840443286582387 threshold: 2.5599999999999894\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840443286582387 threshold: 2.569999999999989\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841052675345419 threshold: 2.579999999999989\n",
      "accuracy: 0.9840325420435918 f1_score: 0.984043425588164 threshold: 2.5899999999999888\n",
      "accuracy: 0.9840325420435918 f1_score: 0.984043425588164 threshold: 2.5999999999999885\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839824874969975 threshold: 2.6099999999999883\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839824874969975 threshold: 2.619999999999988\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839824874969975 threshold: 2.629999999999988\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839824874969975 threshold: 2.6399999999999877\n",
      "accuracy: 0.9840325420435918 f1_score: 0.984043425588164 threshold: 2.6499999999999875\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841037569180677 threshold: 2.6599999999999873\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.669999999999987\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.679999999999987\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.6899999999999866\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.6999999999999864\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.709999999999986\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.719999999999986\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.7299999999999858\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.7399999999999856\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984104197936793 threshold: 2.7499999999999853\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.759999999999985\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.769999999999985\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.7799999999999847\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.7899999999999845\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.7999999999999843\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.809999999999984\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.819999999999984\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840419197217409 threshold: 2.8299999999999836\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.8399999999999834\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.849999999999983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.859999999999983\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.869999999999983\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.8799999999999826\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.8899999999999824\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841028539121441 threshold: 2.899999999999982\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841636147223044 threshold: 2.909999999999982\n",
      "accuracy: 0.9841539675793819 f1_score: 0.9841636147223044 threshold: 2.9199999999999817\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842239667195882 threshold: 2.9299999999999815\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842239667195882 threshold: 2.9399999999999813\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842239667195882 threshold: 2.949999999999981\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842239667195882 threshold: 2.959999999999981\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842239667195882 threshold: 2.9699999999999807\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842239667195882 threshold: 2.9799999999999804\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842834047155373 threshold: 2.9899999999999802\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842834047155373 threshold: 2.99999999999998\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.00999999999998\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.0199999999999796\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.0299999999999794\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.039999999999979\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.049999999999979\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.0599999999999787\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.0699999999999785\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.0799999999999783\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.089999999999978\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.099999999999978\n",
      "accuracy: 0.9843361058830672 f1_score: 0.984343758723055 threshold: 3.1099999999999777\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842819422061293 threshold: 3.1199999999999775\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842819422061293 threshold: 3.1299999999999772\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842819422061293 threshold: 3.139999999999977\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842819422061293 threshold: 3.149999999999977\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.1599999999999766\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.1699999999999764\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.179999999999976\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.189999999999976\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.1999999999999758\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.2099999999999755\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.2199999999999753\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.229999999999975\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.239999999999975\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.2499999999999747\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.2599999999999745\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.2699999999999743\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.279999999999974\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.289999999999974\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.2999999999999736\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.3099999999999734\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.319999999999973\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.329999999999973\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.3399999999999728\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.3499999999999726\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.3599999999999723\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.369999999999972\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.379999999999972\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.3899999999999717\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.3999999999999715\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842209890190152 threshold: 3.4099999999999713\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842803545991722 threshold: 3.419999999999971\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842803545991722 threshold: 3.429999999999971\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842803545991722 threshold: 3.4399999999999706\n",
      "accuracy: 0.9843361058830672 f1_score: 0.9843413237943726 threshold: 3.4499999999999704\n",
      "accuracy: 0.9843361058830672 f1_score: 0.9843413237943726 threshold: 3.45999999999997\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842818698222975 threshold: 3.46999999999997\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842818698222975 threshold: 3.47999999999997\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842818698222975 threshold: 3.4899999999999696\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842818698222975 threshold: 3.4999999999999694\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842818698222975 threshold: 3.509999999999969\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.519999999999969\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.5299999999999687\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.5399999999999685\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.5499999999999683\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.559999999999968\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.569999999999968\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.5799999999999677\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.5899999999999674\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.5999999999999672\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.609999999999967\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.619999999999967\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.6299999999999666\n",
      "accuracy: 0.9842753931151721 f1_score: 0.9842821805076584 threshold: 3.6399999999999664\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.649999999999966\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.659999999999966\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.6699999999999657\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.6799999999999655\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.6899999999999653\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.699999999999965\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.709999999999965\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.7199999999999647\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.7299999999999645\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.7399999999999642\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.749999999999964\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.759999999999964\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.7699999999999636\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.7799999999999634\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.789999999999963\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.799999999999963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.8099999999999627\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.8199999999999625\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.8299999999999623\n",
      "accuracy: 0.984214680347277 f1_score: 0.9842214982617271 threshold: 3.839999999999962\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984162133458707 threshold: 3.849999999999962\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984162133458707 threshold: 3.8599999999999617\n",
      "accuracy: 0.9841539675793819 f1_score: 0.984162133458707 threshold: 3.8699999999999615\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.8799999999999613\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.889999999999961\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.899999999999961\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.9099999999999606\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.9199999999999604\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.92999999999996\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.93999999999996\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.9499999999999598\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.9599999999999596\n",
      "accuracy: 0.9840932548114869 f1_score: 0.984102778786401 threshold: 3.9699999999999593\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841033224254074 threshold: 3.979999999999959\n",
      "accuracy: 0.9840932548114869 f1_score: 0.9841033224254074 threshold: 3.989999999999959\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840414585887264 threshold: 3.9999999999999587\n",
      "accuracy: 0.9840325420435918 f1_score: 0.9840414585887264 threshold: 4.009999999999959\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.019999999999959\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.0299999999999585\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.039999999999958\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.049999999999958\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.059999999999958\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.069999999999958\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.079999999999957\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.089999999999957\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.099999999999957\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.109999999999957\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839795773443335 threshold: 4.119999999999957\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839176841116275 threshold: 4.129999999999956\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839176841116275 threshold: 4.139999999999956\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839176841116275 threshold: 4.149999999999956\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838583268151481 threshold: 4.159999999999956\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838583268151481 threshold: 4.1699999999999555\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.179999999999955\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.189999999999955\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.199999999999955\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837365337725062 threshold: 4.209999999999955\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837365337725062 threshold: 4.2199999999999545\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837365337725062 threshold: 4.229999999999954\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837988025235316 threshold: 4.239999999999954\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837988025235316 threshold: 4.249999999999954\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837988025235316 threshold: 4.259999999999954\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837988025235316 threshold: 4.269999999999953\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837988025235316 threshold: 4.279999999999953\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.289999999999953\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.299999999999953\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.3099999999999525\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.319999999999952\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.329999999999952\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.339999999999952\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.349999999999952\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.3599999999999515\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.369999999999951\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.379999999999951\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.389999999999951\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.399999999999951\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.40999999999995\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837974327956343 threshold: 4.41999999999995\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838581828598209 threshold: 4.42999999999995\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839186035855184 threshold: 4.43999999999995\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839186035855184 threshold: 4.4499999999999496\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839186035855184 threshold: 4.459999999999949\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839186035855184 threshold: 4.469999999999949\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839794995169446 threshold: 4.479999999999949\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839781672946701 threshold: 4.489999999999949\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839781672946701 threshold: 4.4999999999999485\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839781672946701 threshold: 4.509999999999948\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839781672946701 threshold: 4.519999999999948\n",
      "accuracy: 0.9839718292756967 f1_score: 0.9839781672946701 threshold: 4.529999999999948\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839162740961915 threshold: 4.539999999999948\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839162740961915 threshold: 4.549999999999947\n",
      "accuracy: 0.9839111165078016 f1_score: 0.9839162740961915 threshold: 4.559999999999947\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838560046809325 threshold: 4.569999999999947\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838560046809325 threshold: 4.579999999999947\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838560046809325 threshold: 4.589999999999947\n",
      "accuracy: 0.9838504037399065 f1_score: 0.9838560046809325 threshold: 4.599999999999946\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.609999999999946\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.619999999999946\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.629999999999946\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.6399999999999455\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.649999999999945\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.659999999999945\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.669999999999945\n",
      "accuracy: 0.9837896909720114 f1_score: 0.9837953132342966 threshold: 4.679999999999945\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837343891132112 threshold: 4.689999999999944\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837343891132112 threshold: 4.699999999999944\n",
      "accuracy: 0.9837289782041163 f1_score: 0.9837343891132112 threshold: 4.709999999999944\n",
      "accuracy: 0.9836682654362212 f1_score: 0.983673969039193 threshold: 4.719999999999944\n",
      "accuracy: 0.9836682654362212 f1_score: 0.983673969039193 threshold: 4.729999999999944\n",
      "accuracy: 0.9836682654362212 f1_score: 0.983673969039193 threshold: 4.739999999999943\n",
      "accuracy: 0.9836682654362212 f1_score: 0.983673969039193 threshold: 4.749999999999943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9836682654362212 f1_score: 0.983673969039193 threshold: 4.759999999999943\n",
      "accuracy: 0.9836682654362212 f1_score: 0.983673969039193 threshold: 4.769999999999943\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836120287699277 threshold: 4.7799999999999425\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836120287699277 threshold: 4.789999999999942\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836120287699277 threshold: 4.799999999999942\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836120287699277 threshold: 4.809999999999942\n",
      "accuracy: 0.9836075526683261 f1_score: 0.9836120287699277 threshold: 4.819999999999942\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835500735495354 threshold: 4.8299999999999415\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835500735495354 threshold: 4.839999999999941\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835500735495354 threshold: 4.849999999999941\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835500735495354 threshold: 4.859999999999941\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835500735495354 threshold: 4.869999999999941\n",
      "accuracy: 0.983546839900431 f1_score: 0.9835500735495354 threshold: 4.87999999999994\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834908506964877 threshold: 4.88999999999994\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834908506964877 threshold: 4.89999999999994\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.90999999999994\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.9199999999999395\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.929999999999939\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.939999999999939\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.949999999999939\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.959999999999939\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.9699999999999385\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.979999999999938\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.989999999999938\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 4.999999999999938\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 5.009999999999938\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 5.019999999999937\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 5.029999999999937\n",
      "accuracy: 0.983486127132536 f1_score: 0.9834895447044476 threshold: 5.039999999999937\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.049999999999937\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.0599999999999365\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.069999999999936\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.079999999999936\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.089999999999936\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.099999999999936\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.1099999999999355\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.119999999999935\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.129999999999935\n",
      "accuracy: 0.9834254143646409 f1_score: 0.9834275740648083 threshold: 5.139999999999935\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833655915232077 threshold: 5.149999999999935\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833655915232077 threshold: 5.159999999999934\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833655915232077 threshold: 5.169999999999934\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833655915232077 threshold: 5.179999999999934\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833655915232077 threshold: 5.189999999999934\n",
      "accuracy: 0.9833647015967458 f1_score: 0.9833655915232077 threshold: 5.199999999999934\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.209999999999933\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.219999999999933\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.229999999999933\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.239999999999933\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.2499999999999325\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.259999999999932\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.269999999999932\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.279999999999932\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.289999999999932\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.299999999999931\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.309999999999931\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.319999999999931\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.329999999999931\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.339999999999931\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.34999999999993\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.35999999999993\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.36999999999993\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.37999999999993\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.3899999999999295\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.399999999999929\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.409999999999929\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.419999999999929\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.429999999999929\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.4399999999999284\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.449999999999928\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.459999999999928\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.469999999999928\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.479999999999928\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.489999999999927\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.499999999999927\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.509999999999927\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.519999999999927\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.5299999999999265\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.539999999999926\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.549999999999926\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.559999999999926\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.569999999999926\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.5799999999999255\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.589999999999925\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.599999999999925\n",
      "accuracy: 0.9833039888288507 f1_score: 0.983304652770278 threshold: 5.609999999999925\n",
      "accuracy: 0.9832432760609556 f1_score: 0.983244182875531 threshold: 5.619999999999925\n",
      "accuracy: 0.9832432760609556 f1_score: 0.983244182875531 threshold: 5.629999999999924\n",
      "accuracy: 0.9832432760609556 f1_score: 0.983244182875531 threshold: 5.639999999999924\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.649999999999924\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.659999999999924\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.6699999999999235\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.679999999999923\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.689999999999923\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.699999999999923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.709999999999923\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.7199999999999225\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.729999999999922\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.739999999999922\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.749999999999922\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.759999999999922\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.769999999999921\n",
      "accuracy: 0.9833039888288507 f1_score: 0.9833048646943573 threshold: 5.779999999999921\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.789999999999921\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.799999999999921\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.809999999999921\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.81999999999992\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.82999999999992\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.83999999999992\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832455074020359 threshold: 5.84999999999992\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831850393281752 threshold: 5.8599999999999195\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832444505949323 threshold: 5.869999999999919\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832444505949323 threshold: 5.879999999999919\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832444505949323 threshold: 5.889999999999919\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832444505949323 threshold: 5.899999999999919\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832444505949323 threshold: 5.909999999999918\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832444505949323 threshold: 5.919999999999918\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831835108664608 threshold: 5.929999999999918\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831835108664608 threshold: 5.939999999999918\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 5.949999999999918\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 5.959999999999917\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 5.969999999999917\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 5.979999999999917\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 5.989999999999917\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 5.9999999999999165\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 6.009999999999916\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 6.019999999999916\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831228296665843 threshold: 6.029999999999916\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830636651612626 threshold: 6.039999999999916\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830636651612626 threshold: 6.0499999999999154\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830636651612626 threshold: 6.059999999999915\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830636651612626 threshold: 6.069999999999915\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830636651612626 threshold: 6.079999999999915\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.089999999999915\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.099999999999914\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.109999999999914\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.119999999999914\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.129999999999914\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.1399999999999135\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.149999999999913\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.159999999999913\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.169999999999913\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.179999999999913\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.1899999999999125\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.199999999999912\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.209999999999912\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.219999999999912\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.229999999999912\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.239999999999911\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.249999999999911\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.259999999999911\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.269999999999911\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.2799999999999105\n",
      "accuracy: 0.9830611377572703 f1_score: 0.983065265483355 threshold: 6.28999999999991\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831259922849498 threshold: 6.29999999999991\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831259922849498 threshold: 6.30999999999991\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831259922849498 threshold: 6.31999999999991\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831259922849498 threshold: 6.3299999999999095\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831259922849498 threshold: 6.339999999999909\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983186438734908 threshold: 6.349999999999909\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.359999999999909\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.369999999999909\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.379999999999908\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.389999999999908\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.399999999999908\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.409999999999908\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.419999999999908\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.429999999999907\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.439999999999907\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.449999999999907\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.459999999999907\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.4699999999999065\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.479999999999906\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.489999999999906\n",
      "accuracy: 0.9832432760609556 f1_score: 0.9832471348186754 threshold: 6.499999999999906\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983185083268727 threshold: 6.509999999999906\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983185083268727 threshold: 6.519999999999905\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983185083268727 threshold: 6.529999999999905\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983185083268727 threshold: 6.539999999999905\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983185083268727 threshold: 6.549999999999905\n",
      "accuracy: 0.9831825632930605 f1_score: 0.983185083268727 threshold: 6.559999999999905\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.569999999999904\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.579999999999904\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.589999999999904\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.599999999999904\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.6099999999999035\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.619999999999903\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.629999999999903\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.639999999999903\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.649999999999903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.659999999999902\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.669999999999902\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.679999999999902\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.689999999999902\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.699999999999902\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.709999999999901\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831246190759176 threshold: 6.719999999999901\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.729999999999901\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.739999999999901\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.7499999999999005\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.7599999999999\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.7699999999999\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.7799999999999\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.7899999999999\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.7999999999998995\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.809999999999899\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.819999999999899\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.829999999999899\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.839999999999899\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.849999999999898\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.859999999999898\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.869999999999898\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831855387447701 threshold: 6.879999999999898\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 6.8899999999998975\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.899999999999897\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.909999999999897\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.919999999999897\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.929999999999897\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.9399999999998965\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.949999999999896\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.959999999999896\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.969999999999896\n",
      "accuracy: 0.9831825632930605 f1_score: 0.9831870987557679 threshold: 6.979999999999896\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 6.989999999999895\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 6.999999999999895\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.009999999999895\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.019999999999895\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.0299999999998946\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.039999999999894\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.049999999999894\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.059999999999894\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.069999999999894\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.0799999999998935\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.089999999999893\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.099999999999893\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.109999999999893\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.119999999999893\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.129999999999892\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.139999999999892\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.149999999999892\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.159999999999892\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.169999999999892\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.179999999999891\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.189999999999891\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.199999999999891\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.209999999999891\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.2199999999998905\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.22999999999989\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.23999999999989\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.24999999999989\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.25999999999989\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.269999999999889\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.279999999999889\n",
      "accuracy: 0.9831218505251654 f1_score: 0.9831262000460588 threshold: 7.289999999999889\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.299999999999889\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.309999999999889\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.319999999999888\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.329999999999888\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.339999999999888\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.349999999999888\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.3599999999998875\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.369999999999887\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.379999999999887\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.389999999999887\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.399999999999887\n",
      "accuracy: 0.9831218505251654 f1_score: 0.983126465247361 threshold: 7.4099999999998865\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.419999999999886\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.429999999999886\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.439999999999886\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.449999999999886\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.459999999999885\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.469999999999885\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.479999999999885\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.489999999999885\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.4999999999998845\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.509999999999884\n",
      "accuracy: 0.9830611377572703 f1_score: 0.9830660185441464 threshold: 7.519999999999884\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.529999999999884\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.539999999999884\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.5499999999998835\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.559999999999883\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.569999999999883\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.579999999999883\n",
      "accuracy: 0.9830004249893752 f1_score: 0.9830037485677474 threshold: 7.589999999999883\n",
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.599999999999882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.609999999999882\n",
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.619999999999882\n",
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.629999999999882\n",
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.6399999999998816\n",
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.649999999999881\n",
      "accuracy: 0.9829397122214801 f1_score: 0.9829428111326829 threshold: 7.659999999999881\n",
      "accuracy: 0.982878999453585 f1_score: 0.9828823684870089 threshold: 7.669999999999881\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.679999999999881\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.6899999999998805\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.69999999999988\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.70999999999988\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.71999999999988\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.72999999999988\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.739999999999879\n",
      "accuracy: 0.98281828668569 f1_score: 0.9828219266546229 threshold: 7.749999999999879\n",
      "accuracy: 0.982757573917795 f1_score: 0.982761485602461 threshold: 7.759999999999879\n",
      "accuracy: 0.982757573917795 f1_score: 0.982761485602461 threshold: 7.769999999999879\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.779999999999879\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.789999999999878\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.799999999999878\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.809999999999878\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.819999999999878\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.8299999999998775\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.839999999999877\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.849999999999877\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.859999999999877\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.869999999999877\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.879999999999876\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.889999999999876\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.899999999999876\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.909999999999876\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.919999999999876\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.929999999999875\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827021605722485 threshold: 7.939999999999875\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 7.949999999999875\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 7.959999999999875\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 7.9699999999998745\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 7.979999999999874\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 7.989999999999874\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 7.999999999999874\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 8.009999999999874\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 8.019999999999873\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 8.029999999999873\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 8.039999999999873\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826412404403501 threshold: 8.049999999999873\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803153428729 threshold: 8.059999999999873\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803153428729 threshold: 8.069999999999872\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803153428729 threshold: 8.079999999999872\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803153428729 threshold: 8.089999999999872\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803153428729 threshold: 8.099999999999872\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.109999999999872\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.119999999999871\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.129999999999871\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.139999999999871\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.14999999999987\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.15999999999987\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825196170053803 threshold: 8.16999999999987\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.17999999999987\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.18999999999987\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.19999999999987\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.20999999999987\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.21999999999987\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.229999999999869\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.239999999999869\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.249999999999869\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.259999999999868\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.269999999999868\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.279999999999868\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.289999999999868\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.299999999999867\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826409801791964 threshold: 8.309999999999867\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827017078264976 threshold: 8.319999999999867\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827017078264976 threshold: 8.329999999999867\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827017078264976 threshold: 8.339999999999867\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827017078264976 threshold: 8.349999999999866\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827017078264976 threshold: 8.359999999999866\n",
      "accuracy: 0.9826968611498998 f1_score: 0.9827017078264976 threshold: 8.369999999999866\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.379999999999866\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.389999999999866\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.399999999999865\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.409999999999865\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.419999999999865\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.429999999999865\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.439999999999864\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.449999999999864\n",
      "accuracy: 0.9826361483820047 f1_score: 0.9826407806274717 threshold: 8.459999999999864\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.469999999999864\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.479999999999864\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.489999999999863\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.499999999999863\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.509999999999863\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.519999999999863\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.529999999999863\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.539999999999862\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.549999999999862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.559999999999862\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.569999999999862\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.579999999999862\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.589999999999861\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.599999999999861\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.60999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.61999999999986\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.62999999999986\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.63999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.64999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.65999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.66999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.67999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.68999999999986\n",
      "accuracy: 0.9825754356141096 f1_score: 0.9825803446526815 threshold: 8.699999999999859\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.709999999999859\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.719999999999859\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.729999999999858\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.739999999999858\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.749999999999858\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.759999999999858\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.769999999999857\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.779999999999857\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.789999999999857\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.799999999999857\n",
      "accuracy: 0.9825147228462145 f1_score: 0.9825199094519677 threshold: 8.809999999999857\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.819999999999856\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.829999999999856\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.839999999999856\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.849999999999856\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.859999999999856\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.869999999999855\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.879999999999855\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.889999999999855\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.899999999999855\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.909999999999854\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.919999999999854\n",
      "accuracy: 0.9824540100783195 f1_score: 0.9824605892361843 threshold: 8.929999999999854\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.939999999999854\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.949999999999854\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.959999999999853\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.969999999999853\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.979999999999853\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.989999999999853\n",
      "accuracy: 0.9823932973104244 f1_score: 0.9823984352323349 threshold: 8.999999999999853\n",
      "accuracy: 0.9823325845425293 f1_score: 0.9823377357637608 threshold: 9.009999999999852\n",
      "accuracy: 0.9823325845425293 f1_score: 0.9823377357637608 threshold: 9.019999999999852\n",
      "accuracy: 0.9823325845425293 f1_score: 0.9823377357637608 threshold: 9.029999999999852\n",
      "accuracy: 0.9823325845425293 f1_score: 0.9823377357637608 threshold: 9.039999999999852\n",
      "accuracy: 0.9823325845425293 f1_score: 0.9823377357637608 threshold: 9.049999999999851\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822772843877385 threshold: 9.059999999999851\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822772843877385 threshold: 9.069999999999851\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822772843877385 threshold: 9.07999999999985\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822772843877385 threshold: 9.08999999999985\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822168337102832 threshold: 9.09999999999985\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822168337102832 threshold: 9.10999999999985\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822168337102832 threshold: 9.11999999999985\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822790275947086 threshold: 9.12999999999985\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822790275947086 threshold: 9.13999999999985\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822790275947086 threshold: 9.14999999999985\n",
      "accuracy: 0.9822718717746342 f1_score: 0.9822790275947086 threshold: 9.15999999999985\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.169999999999849\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.179999999999849\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.189999999999849\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.199999999999848\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.209999999999848\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.219999999999848\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.229999999999848\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.239999999999847\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.249999999999847\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.259999999999847\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.269999999999847\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.279999999999847\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.289999999999846\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.299999999999846\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.309999999999846\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.319999999999846\n",
      "accuracy: 0.9822111590067392 f1_score: 0.98221972039449 threshold: 9.329999999999846\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.339999999999845\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.349999999999845\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.359999999999845\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.369999999999845\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.379999999999844\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.389999999999844\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.399999999999844\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.409999999999844\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.419999999999844\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.429999999999843\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.439999999999843\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.449999999999843\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.459999999999843\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.469999999999843\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.479999999999842\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.489999999999842\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.499999999999842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.509999999999842\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.519999999999841\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.529999999999841\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.539999999999841\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.54999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.55999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.56999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.57999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.58999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.59999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.60999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.61999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.62999999999984\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.639999999999839\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.649999999999839\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.659999999999838\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.669999999999838\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.679999999999838\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.689999999999838\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588286923281 threshold: 9.699999999999838\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.709999999999837\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.719999999999837\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.729999999999837\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.739999999999837\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.749999999999837\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.759999999999836\n",
      "accuracy: 0.9822111590067392 f1_score: 0.9822211705646758 threshold: 9.769999999999836\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588434532333 threshold: 9.779999999999836\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821588434532333 threshold: 9.789999999999836\n",
      "accuracy: 0.982089733470949 f1_score: 0.9820984143835988 threshold: 9.799999999999836\n",
      "accuracy: 0.982089733470949 f1_score: 0.9820984143835988 threshold: 9.809999999999835\n",
      "accuracy: 0.982089733470949 f1_score: 0.9820984143835988 threshold: 9.819999999999835\n",
      "accuracy: 0.982089733470949 f1_score: 0.9820984143835988 threshold: 9.829999999999835\n",
      "accuracy: 0.982089733470949 f1_score: 0.9820984143835988 threshold: 9.839999999999835\n",
      "accuracy: 0.982089733470949 f1_score: 0.9820984143835988 threshold: 9.849999999999834\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.859999999999834\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.869999999999834\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.879999999999834\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.889999999999834\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.899999999999833\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.909999999999833\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.919999999999833\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.929999999999833\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.939999999999833\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.949999999999832\n",
      "accuracy: 0.9821504462388441 f1_score: 0.9821593039218507 threshold: 9.959999999999832\n",
      "accuracy: 0.982089733470949 f1_score: 0.982100045005722 threshold: 9.969999999999832\n",
      "accuracy: 0.982089733470949 f1_score: 0.982100045005722 threshold: 9.979999999999832\n",
      "accuracy: 0.982089733470949 f1_score: 0.982100045005722 threshold: 9.989999999999831\n",
      "accuracy: 0.982089733470949 f1_score: 0.982100045005722 threshold: 9.999999999999831\n"
     ]
    }
   ],
   "source": [
    "test_history = dict(accuracy=[], f1score=[], threshold=[])\n",
    "threshold = 0\n",
    "while (threshold < 10):    \n",
    "    cnn_predictions = final_prediction(X_test, predictions, threshold)\n",
    "    accuracy = accuracy_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1)) \n",
    "    f1score = f1_score(np.argmax(y_test, 1), np.argmax(cnn_predictions, 1), average='weighted')\n",
    "    print(\"accuracy:\", accuracy, \"f1_score:\", f1score,\"threshold:\", threshold)\n",
    "    threshold += 0.01\n",
    "    test_history['accuracy'].append(accuracy)\n",
    "    test_history['f1score'].append(f1score)\n",
    "    test_history['threshold'].append(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x217599d3b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "threshold_vs_accuraccy(test_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
